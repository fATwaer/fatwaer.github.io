<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>B-tree on Pok</title>
    <link>/tags/b-tree/</link>
    <description>Recent content in B-tree on Pok</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Mar 2020 22:29:40 +0800</lastBuildDate><atom:link href="/tags/b-tree/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>B-tree和LSM-tree</title>
      <link>/posts/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/b-tree-and-lsm-tree/</link>
      <pubDate>Wed, 18 Mar 2020 22:29:40 +0800</pubDate>
      
      <guid>/posts/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/b-tree-and-lsm-tree/</guid>
      <description>最初的数据库 LSM-tree得从最简单的数据库的shell实现说起，如：
#! /bin/bash  db_set() { echo &amp;#34;$1,$2&amp;#34; &amp;gt;&amp;gt; database } db_get() { grep &amp;#34;^$1,&amp;#34; database | sed -e &amp;#34;s/^$1,//&amp;#34; | tail -n 1 } db_set将两个参数简单追加database文件，而db_get利用匹配出来的结果去掉key和逗号得到value，再利用tail获取到最set到database中去。
读取优化 很明显，由于是追加写也是最简单的写操作，这种set方式通常足够高效，但是对于get，事件复杂度就需要上升到O(n)，所以最常见的想法是对数据追加索引，比如利用哈希表在内存中设置一个key，而key对应的value设置为该key/value在文件中的偏移。
   key byte offset     abc 0   b 64   &amp;hellip; &amp;hellip;   aacb 3613    就有类似于这样一个哈希表存储在内存中，这也就是Bitcask的核心做法，只需要一次磁盘寻址就可以加载到这个value，适合每个键的值频繁更新的场景。
存储优化 因为都会往同一个文件追加文件，所以设置键的写入，会造成磁盘空间用尽。解决办法是将日志分解成一定大小的段，文件到达一定大小就关闭，后续的写入写到新的段文件中，读请求仍旧使用旧段文件，当后台线程将后台文件合并/压缩后，读请求就能切换到新的合并段上，旧段文件安全删除。
其他  文件格式：替换类似于CSV的字符格式为二进制格式。 删除记录：追加删除标记，当合并时检测到这个标记丢弃响应的key 崩溃恢复：这个主要针对存储在内存中的哈希表，当机器宕机后，哈希表将会丢失，重启恢复需要重新读取所有的段文件才能恢复，Bitcask的做法时将相应段的哈希表快照存储磁盘中。 记录写入：写入操作的过程中如果发送了崩溃，那么最新的值将是不完整的，可以在一条记录前追加校验，如果损毁就需要丢弃。 并发控制：写入需要按先后顺序写入，所以写线程通常只有一个，而读取是可以多个同时进行的。  SSTables SSTables全名为排序字符串表(Sort String Tables)，写入的记录会被排序。对key进行排序会有如下的有点：</description>
    </item>
    
  </channel>
</rss>
