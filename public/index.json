[{"categories":null,"contents":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string`     Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float     Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0}     Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\n    Type Conversion i := 2 f := float64(i) u := uint(i)     Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;)     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"/notes/cpp/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string`     Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float     Arrays // var numbers [5]int numbers := [.","tags":null,"title":"Basic Types"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"15. 三数之和 class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res; std::sort(nums.begin(), nums.end()); for (int i = 0; i \u0026lt; nums.size(); ++i) { int first = nums[i]; if (first \u0026gt; 0) { continue; } if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i-1] == first) { continue; } int target = -1 * first; int j = i + 1; int k = nums.size() - 1; while (j \u0026lt; k) { int second = nums[j]; int third = nums[k]; if (second + third \u0026gt; target) { k--; continue; } else if (second + third \u0026lt; target) { j++; continue; } else { res.emplace_back(std::vector\u0026lt;int\u0026gt;({first, second, third})); ++j; --k; while (j \u0026lt; k \u0026amp;\u0026amp; nums[j] == nums[j-1]) ++j; while (j \u0026lt; k \u0026amp;\u0026amp; nums[k] == nums[k+1]) --k; } } } return res; } }; 题目的注意事项是：不包含重复的三元组，暴力去解决还需要set来去重，特别麻烦。\n解法应该是将三数和转化为两数和的问题，排序+双指针。\n注意：\n 因为是递增序列，如果第一个不是负数，那后面相加肯定不可能等于0 找到target后，用双指针移动不断找到两个合适的值，并且要用移动指针去重。  ","date":"November 18, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/lt_top100_array/","summary":"15. 三数之和 class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res; std::sort(nums.begin(), nums.end()); for (int i = 0; i \u0026lt; nums.size(); ++i) { int first = nums[i]; if (first \u0026gt; 0) { continue; } if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i-1] == first) { continue; } int target = -1 * first; int j = i + 1; int k = nums.size() - 1; while (j \u0026lt; k) { int second = nums[j]; int third = nums[k]; if (second + third \u0026gt; target) { k--; continue; } else if (second + third \u0026lt; target) { j++; continue; } else { res.","tags":null,"title":"Lt_top100_array"},{"categories":["notes"],"contents":"集群搜索流程 我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 1、当请求到达一个节点，那么这个节点就会变成协调节点 2、协调节点把搜索请求发送到其他节点的索引分片上搜索数据 3、然后再汇总数据返回给客户端。\n文档路由的规则比较常见，对文档ID进行hash得到具体分片，es 不能扩容，扩容就会存在节点对应不上的情况。\n分页集群搜索流程 请求如：\nGET /_search { \u0026quot;from\u0026quot;: 90, \u0026quot;size\u0026quot;: 10 } 的查询流程如下：\n 客户端发送一个 search 请求到 Node 3 ， Node 3 会创建一个大小为 from + size 的空优先队列。 Node 3 将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为 from + size 的本地有序优先队列中。 每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，也就是 Node 3 ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。  PS：搜索请求被发送到某个节点时，这个节点就变成了协调节点\n并且：注意是 from + size，而不是 size，因为每个节点的数据不一定是排好序的，当from很大的时候会有深分页存在，多个节点需要返回很多数据，协调节点进行排序，所以会占用相当多的CPU/内存/带宽。“深分页” 很少符合人的行为，人的行为一般停留在前几页，深分页一般是爬虫。\n获取集群状态：\nGET _cluster/stats?pretty 获取分片状态：\nGET /_cat/shards/\u0026lt;target\u0026gt; GET /_cat/shards ref  es官方教程：https://www.elastic.co/guide/cn/elasticsearch/guide/current/distributed-search.html  ","date":"August 26, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch6%E6%89%A7%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（6）：执行分布式搜索"},{"categories":["notes"],"contents":"单节点索引分片 在创建索引时，可以在setting字段中加入分片设置，下面的配置创建了3个主分片和一份副本，即每个主分片一个副本。\nPUT /blogs { \u0026quot;settings\u0026quot; : { \u0026quot;number_of_shards\u0026quot; : 3, \u0026quot;number_of_replicas\u0026quot; : 1 } } 当集群中只有一个节点时，状态为：\n但是可以看到，NODE1 上只有主分片，没有副本分片，因为在同一个节点上既保存原始数据又保存副本是没有意义的。\n通过 _health 接口查询，\nGET /_cluster/health 其中 status 的值和对应的解释如：\ngreen：所有的主分片和副本分片都正常运行。 yellow：所有的主分片都正常运行，但不是所有的副本分片都正常运行。 red：有主分片没能正常运行。\n可以发现此时的集群状态为 yellow ，是因为此时没有副本分片。\n多节点分片 当加入新物理节点后，es集群就会在新节点上创建副本节点，此时集群状态就会转变为green，因为所有主副分片都正常运行了。 多节点负载 当拥有三个节点后，es 会为了分散负载而对分片进行重新分配，分片数据，如： 每一个分片都是一个独立的功能完整的搜索引擎，拥有使用一个节点上的所有资源的能力。\n继续扩容 es 的主分片数量在创建索引的时候，主分片数量就确定了，之后不可以修改，能修改的只有副本节点。\n主分片的数目定义了这个索引能够 存储 的最大数据量。\n PUT /blogs/_settings { \u0026quot;number_of_replicas\u0026quot; : 2 } 原本3主3副个节点就会扩充到3主6副个节点，这样即使两个节点宕机，也不会丢失数据。其次，有多个副本节点能够获得更高的吞吐，因为在不同的节点上都能处理相同分片的请求了，当然副本节点的数量提升的吞吐取决于机器性能，分片越多，从机器获取的资源也就更少。\nref https://learnku.com/articles/40400\n","date":"August 15, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch5%E9%AB%98%E5%8F%AF%E7%94%A8%E4%BF%9D%E8%AF%81/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（5）：高可用保证"},{"categories":["notes"],"contents":"相关性计算 使用前面的例子，索引中目前一共三个文档：\n “I love to go rock climbing” “I like to build cabinets” “I like to collect rock albums”\n GET /megacorp/_search { \u0026quot;query\u0026quot; : { \u0026quot;match\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } }, \u0026quot;explain\u0026quot; : true } 在 _search 的时候加上 explain 选项就能在结果中输出相关性计算解释。\n \u0026quot;_explanation\u0026quot; : { \u0026quot;value\u0026quot; : 1.4167401, \u0026quot;description\u0026quot; : \u0026quot;sum of:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 0.4589591, \u0026quot;description\u0026quot; : \u0026quot;weight(about:rock in 0) [PerFieldSimilarity], result of:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 0.4589591, \u0026quot;description\u0026quot; : \u0026quot;score(freq=1.0), computed as boost * idf * tf from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 2.2, \u0026quot;description\u0026quot; : \u0026quot;boost\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 0.47000363, \u0026quot;description\u0026quot; : \u0026quot;idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 2, \u0026quot;description\u0026quot; : \u0026quot;n, number of documents containing term\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 3, \u0026quot;description\u0026quot; : \u0026quot;N, total number of documents with field\u0026quot;, \u0026quot;details\u0026quot; : [ ] } ] }, { \u0026quot;value\u0026quot; : 0.44386417, \u0026quot;description\u0026quot; : \u0026quot;tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 1.0, \u0026quot;description\u0026quot; : \u0026quot;freq, occurrences of term within document\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 1.2, \u0026quot;description\u0026quot; : \u0026quot;k1, term saturation parameter\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 0.75, \u0026quot;description\u0026quot; : \u0026quot;b, length normalization parameter\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 6.0, \u0026quot;description\u0026quot; : \u0026quot;dl, length of field\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 5.6666665, \u0026quot;description\u0026quot; : \u0026quot;avgdl, average length of field\u0026quot;, \u0026quot;details\u0026quot; : [ ] } ] } ] } ] }, { \u0026quot;value\u0026quot; : 0.95778096, \u0026quot;description\u0026quot; : \u0026quot;weight(about:climbing in 0) [PerFieldSimilarity], result of:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 0.95778096, \u0026quot;description\u0026quot; : \u0026quot;score(freq=1.0), computed as boost * idf * tf from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 2.2, \u0026quot;description\u0026quot; : \u0026quot;boost\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 0.98082924, \u0026quot;description\u0026quot; : \u0026quot;idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 1, \u0026quot;description\u0026quot; : \u0026quot;n, number of documents containing term\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 3, \u0026quot;description\u0026quot; : \u0026quot;N, total number of documents with field\u0026quot;, \u0026quot;details\u0026quot; : [ ] } ] }, { \u0026quot;value\u0026quot; : 0.44386417, \u0026quot;description\u0026quot; : \u0026quot;tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\u0026quot;, \u0026quot;details\u0026quot; : [ { \u0026quot;value\u0026quot; : 1.0, \u0026quot;description\u0026quot; : \u0026quot;freq, occurrences of term within document\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 1.2, \u0026quot;description\u0026quot; : \u0026quot;k1, term saturation parameter\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 0.75, \u0026quot;description\u0026quot; : \u0026quot;b, length normalization parameter\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 6.0, \u0026quot;description\u0026quot; : \u0026quot;dl, length of field\u0026quot;, \u0026quot;details\u0026quot; : [ ] }, { \u0026quot;value\u0026quot; : 5.6666665, \u0026quot;description\u0026quot; : \u0026quot;avgdl, average length of field\u0026quot;, \u0026quot;details\u0026quot; : [ ] } ] } ] } ] } ] } 从返回结果中可以看到，其实相关性计算的分数是\trock 和 climbing 两个词语的相关性分数相加而成：\nscore = score(rock) + score(climbing)  而每个词语的分数的计算公式为：\nscore(single word) = boost * idf * tf  其中 boost 在这里先可以理解为常量，重点在于词频 tf (Term Frequency) 和逆文档频率 idf (Inverse Document Frequency)。词频表示在这篇文档中出现的次数，出现次数越多也就更加相关，逆文档频率是指含有这个词的文档的数量的逆，也就是说这个词在所有文档中出现得越频繁，这个词就越不重要。\n更加具体的计算公式在 explaination 中也描述得特别清晰：\n其中 idf 的计算公式为：\n  n 为含有该词语文档的个数\n  N 为含有这个字段的文档总数（包括曾经被索引过的文档数）\n  tf 的计算公式为： 公式中有k1，b 这两个常量，在这里先不用关系它们。变量有 freq 代表词语在文档中出现的频次，avgdl 平均文档长度，以及 dl 当前文档长度。我们可以稍微化简下公式：\n那么就能分析到，freq 越大，频次越高，文档也就越相关；dl 越大，值就会更小，文档就更加不相干；avgdl 越大，平局文档长度越长（词越稀有），文档就会越相关。\n计算 rock in 0:\n score = boost * idf * tf boost = 2.2 idf = ln(1 + (N - n + 0.5) / (n + 0.5)) = ln 1.6 = 0.47000363  n = 2 ：含有该词语文档的个数 N = 3： 含有这个字段的文档总数（包括曾经被索引过的文档数）   tf = freq / (freq + k1 * (1 - b + b * dl / avgdl)) = 0.44386417  freq = 1：在文档中出现的次数 k1 * (1 - b + b * dl / avgdl) = dl / avgdl：文档长度变量，文档长度越长，更加相关。 b、k1 都是常参数，dl 是指该文档的字段长度 ，avgdl 指的是平均文档字段长度。    climbing in 0:\n  boost = 2.2\n  idf = ln(1 + (N - n + 0.5) / (n + 0.5)) = ln 2.66 = 0.98082924 n = 1 ：含有该词语文档的个数 N = 3： 含有这个字段的文档总数（包括曾经被索引过的文档数）\n  tf = 0.44386417\n  最终计算出的相关性分 = 2.2 * 0.47000363 * 0.44386417 + 2.2 * 0.98082924 * 0.44386417 = 1.4167401\n","date":"August 7, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch4%E7%9B%B8%E5%85%B3%E6%80%A7%E8%AE%A1%E7%AE%97/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（4）：相关性计算"},{"categories":["notes"],"contents":"ES 分片如何索引文档 一篇文档会被分词分解成一个个词语，生成一个倒排索引，一个倒排索引是一个 Lucene 索引的段，多个段组成一个 Lucene 索引，而一个 Lucene 索引被称之为一个 ElasticSearch 的分片，将多个分片分布式存储形成了 ElasticSearch。 。\nES 倒排索引的特性 ES 的倒排索引在写入磁盘是 保持不变的，这样优势是：\n 不需要锁 因为不变性，内核不需要再读取磁盘，直接缓存到内存中请求内存。 对于某个索引 filter 缓存将会一直有效 缺点是因为不可变，新加入一个文档都需要重建索引，索引的数据量大小和更新频率可能只能选择其一。  更新倒排索引 如何更新 为了保持不变性，可以增加新的索引反馈最近的修改，并且使得每个索引都会被查询到，在每一个分片上查询完结果后合并。\n更新流程 1、新的文档被追加到内存索引缓存中，内存索引缓存会不时地提交到磁盘，此时在内存中，还不可见。\n2、缓存被提交的时候，会提交一个新的段（一个新的倒排索引）和一个带有新段名字的提交点到磁盘。\n3、被提交到磁盘的新段被读取打开，里面包含的文档可以被搜索。\n4、内存缓存被清空，准备接受新的文档。\n实时搜索 因为按段搜索（多个倒排索引）的存在，一个新的文档从索引到可被搜索（按段写入磁盘）的延迟降低了，但是可能还需要几分钟，因为按段搜索需要调用 fsync 创建一个提交点。但是 fsync 操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。更加轻量的方式是走 refresh API。\nrefresh 是一种轻量级的刷新，通过 refresh 可以不通过 fsync 就让文档被索引到，因为 refresh 通过 write 的系统调用，将内存中的数据转换成文件系统的页缓存，数据能够被很快的写入（还是在内存中），并且能被 read 系统调用作为文件打开。\n下面的API，可以通过设置刷新时间把内存刷新的间隔拉长，默认是1s，如果设置成 -1 那么就是不刷新。\nPOST /_refresh # 所有索引都刷新 POST /blogs/_refresh # 单个索引刷新 PUT my_logs { \u0026quot;settings\u0026quot;: { \u0026quot;refresh_interval\u0026quot;: \u0026quot;60s\u0026quot; } } 在被刷入磁盘前,内存中新数据是不能被刷新的，例如：\nPOST my_logs/_doc { \u0026quot;abc\u0026quot; : 1 } GET my_logs/_search 在search API中是60s内看不到新post的数据的。\n文件系统页缓存 页缓存（Page Cache）是位于内存和文件之间的缓冲区，它实际上也是一块内存区域。页缓存对应文件中的一块区域，如果页缓存和对应的文件区域内容不一致，则该页缓存叫做脏页（Dirty Page）。\n页缓存查看：\nSZKSGD00582 : ~ -\u0026gt; free -h total used free shared buff/cache available Mem: 23G 538M 22G 401M 897M 22G Swap: 0B 0B 0B 或者：\nSZKSGD00582 : ~ -\u0026gt; cat /proc/meminfo MemTotal: 24629088 kB MemFree: 23157836 kB MemAvailable: 23353692 kB Buffers: 20724 kB -\u0026gt; Cached: 875168 kB SwapCached: 0 kB Active: 538556 kB Inactive: 807752 kB Active(anon): 464264 kB Inactive(anon): 393480 kB Active(file): 74292 kB Inactive(file): 414272 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 0 kB SwapFree: 0 kB -\u0026gt; Dirty: 0 kB Writeback: 0 kB AnonPages: 407528 kB Mapped: 185108 kB Shmem: 411116 kB Slab: 58664 kB SReclaimable: 23568 kB SUnreclaim: 35096 kB KernelStack: 7648 kB PageTables: 3396 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 12314544 kB Committed_AS: 3829504 kB VmallocTotal: 34359738367 kB VmallocUsed: 0 kB VmallocChunk: 0 kB Percpu: 1776 kB AnonHugePages: 190464 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB Hugetlb: 0 kB DirectMap4k: 15360 kB DirectMap2M: 3129344 kB DirectMap1G: 23068672 kB write 系统调用：\n 用户发起write操作 操作系统查找页缓存 若未命中，则产生缺页异常，然后创建页缓存，将用户传入的内容写入页缓存 若命中，则直接将用户传入的内容写入页缓存 用户write调用完成 页被修改后成为脏页，操作系统有两种机制将脏页写回磁盘  用户手动调用fsync() 由pdflush进程定时将脏页写回磁盘（脏页数据比例过高，脏页缓存占用的内存太多，长时间未刷新）    read 系统调用：\n 用户发起read操作 操作系统查找页缓存 若未命中，则产生缺页异常，然后创建页缓存，并从磁盘读取相应页填充页缓存 若命中，则直接从页缓存返回要读取的内容 用户read调用完成  实时删除 删除操作：每个提交点会包含一个.del文件，包含被删除的文档，被删除的任然可以被搜索到。\n更新操作: 旧文档被标记为删除，新版本文档被索引到一个新的段中\n持久化 虽然通过每秒刷新（refresh）实现了近实时搜索，但是refresh只是写入页缓存，并没有真正写入到磁盘中，我们仍然需要经常进行完整提交来确保能从失败中恢复。es提供了translog（事务日志）机制用于记录操作。类似于redis的aof。\n1、一篇文档被索引后会被写入内存缓冲区，并追加到translog。（数据内存中）\n2、内存缓冲区的数据被写入到一个新段，但是没有fsync，但是可以被用于搜索。（文件系统缓存，仍旧在内存中）\n3、数据不断积累，执行索引刷新（flush），新的 translog 创建，执行全量提交，内存中的数据写入新段，缓冲区清空，通过fsync将提交点写入硬盘，删除老的translog。\n translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。\n  translog 也被用来提供实时 CRUD 。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。\n flush API 可以用于手动刷新数据，将页缓存刷入磁盘中去。\nPOST /blogs/_flush # 刷新（flush）blogs 索引 POST /_flush?wait_for_ongoing # 刷新（flush）所有的索引并且并且等待所有刷新在返回前完成。 持久化也能通过索引的配置来刷新：\nPUT /my_index/_settings { \u0026#34;index.translog.durability\u0026#34;: \u0026#34;async\u0026#34;, # 异步刷入磁盘，同步为 \u0026#34;request\u0026#34; \u0026#34;index.translog.sync_interval\u0026#34;: \u0026#34;5s\u0026#34; # 同步磁盘的间隔 } translog 默认5s刷一次，或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)，因为数据结构简单+顺序写速度较快。整个请求被 fsync 到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。当然如果希望获得更高的吞吐，并且在同步间隔丢失的数据无所谓，那么可以设置为 async，当请求。\n段合并 每次refesh都会产生一个段，但每秒刷新很快就会导致段数量太多的问题，从而消耗很多cpu、内存、文件句柄，而搜索请求会查询每一个段，所以段数量越多，搜索数量越多。（就像一个哈希表被拆分成多个哈希表，时间复杂度从O(1)转变成O(n)）\n段合并在进行索引和搜索时会自动进行： 1、索引文档时，refresh 创建新段用于搜索 2、合并进程选择大小相似的段在后台合并成大段，不影响索引和搜索 3、新大段被写入磁盘（flush），另外新的小段也被flush到磁盘，新的提交点被创建，translog也会被清空。 4、新段可以被打开搜索 5、老段被删除\n强制合并API：\nPOST /logstash-2014-10/_optimize?max_num_segments=1 合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。\n总结 es 的索引写入分成两个部分：\n 为了内存使得文档能够被快速被搜索，首先被缓存在内存中，再通过 refresh 使得文档可以被及时搜索到，再周期性地写入磁盘提交。 为了保证文档不丢失，translog能够在内存失效的情况下，从磁盘恢复数据。  ref  如何保证 elasticsearch 数据不丢失：https://segmentfault.com/a/1190000039075240  ","date":"July 31, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch3%E6%96%87%E6%A1%A3%E5%A6%82%E4%BD%95%E8%A2%AB%E5%AE%9E%E6%97%B6%E7%B4%A2%E5%BC%95/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（3）：文档如何被实时索引"},{"categories":["notes"],"contents":"分析文档：分词 请求分析 POST _analyze { \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;lowercase\u0026#34;, \u0026#34;asciifolding\u0026#34; ], \u0026#34;text\u0026#34;: \u0026#34;Is this déja vu?\u0026#34; } 为索引设置不同的分词器 PUT my-index-000002 { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;analyzer\u0026#34;: { \u0026#34;std_english\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;stopwords\u0026#34;: \u0026#34;_english_\u0026#34; } } } }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;my_text\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;english\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;std_english\u0026#34; } } } } } } POST my-index-000002/_analyze { \u0026#34;field\u0026#34;: \u0026#34;my_text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;The old brown cow\u0026#34; } POST my-index-000002/_analyze { \u0026#34;field\u0026#34;: \u0026#34;my_text.english\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;The old brown cow\u0026#34; } 分析器也能在elastic search的启动配置中设置。\n分词过程 文档加入索引前，都会经过系列处理： 1、字符过滤 （char_filter） 2、文本切分 （tokenizer） 3、分词过滤 （filter） 4、分词索引\nPOST _analyze { \u0026#34;char_filter\u0026#34;: [\u0026#34;html_strip\u0026#34;], \u0026#34;tokenizer\u0026#34; : \u0026#34;whitespace\u0026#34;, \u0026#34;filter\u0026#34;: [\u0026#34;stop\u0026#34;], \u0026#34;text\u0026#34;: \u0026#34;\u0026lt;body\u0026gt; share your experiece with NoSql and big data technologies \u0026lt;/body\u0026gt;\u0026#34; } 给定一个语句 text ：\u0026lt;body\u0026gt; share your experiece with NoSql and big data technologies \u0026lt;/body\u0026gt;\n并且设置相应的分词配置。\nref   于是可以形成倒排索引： https://dragonsong.tech/posts/rd/es/index_structure/\n  elastsearch 自身支持的分析器： https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html\n  ","date":"July 24, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch2%E6%96%87%E6%A1%A3%E5%88%86%E8%AF%8D/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（2）：文档分词原理"},{"categories":["notes"],"contents":"文档创建和删除 创建文档 ElasticSearch 提供创建一篇文档的接口如下，如果这是索引的第一篇文档，索引也会被同时创建。\nPUT /\u0026lt;target\u0026gt;/_doc/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_doc/ PUT /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; 下面的例子利用PUT方法创建一个 id 为1的文档：\n其中，version字段为1，并且result的值为created。\n另一种创建文档的方式是通过POST，又ES自动生成一个全局唯一的 _id 给新的文档：\n更新的文档 如果重复对这个文档执行PUT操作，那么ES就会转变为更新，并且自增version字段。\n查询索引的信息 因为创建文档的同时会自动创建索引以及和请求结构相关的mappings(类似数据库的表结构schema)\n直接通过GET索引名就可以查询到索引的信息：\nGET /\u0026lt;index_name\u0026gt; 例如：\n通常会得到三个信息：\n aliases： 用于别名 mappings：索引的字段信息，如图中的索引 index-001 是根据 POST/PUT 请求的字段自动生成的，并且自动推导成对应的类型，但是对于字符串类型（text）在默认请求下，会新增一个子字段keyword，用于精准匹配查询。 settings：包含了 ElasticSearch 配置、分片等信息  查看文档 文档索引完成后，能够通过下面的查询查到新加入的文档：\nGET /\u0026lt;index_name\u0026gt;/_doc/1 # 找到 _id 为 1 的文档 GET /\u0026lt;index_name\u0026gt;/_search # 查找出该索引下的所有文档 删除文档 DELETE /\u0026lt;index\u0026gt;/_doc/\u0026lt;_id\u0026gt; 例如：\n如果找到了，会返回200OK，并且 found 判断是否存在文档，_version  字段在删除成功后会自增\n常见的查询方式 准备查询数据 PUT /megacorp/employee/1 { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } PUT /megacorp/employee/2 { \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 32, \u0026quot;about\u0026quot; : \u0026quot;I like to collect rock albums\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;music\u0026quot; ] } PUT /megacorp/employee/3 { \u0026quot;first_name\u0026quot; : \u0026quot;Douglas\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Fir\u0026quot;, \u0026quot;age\u0026quot; : 35, \u0026quot;about\u0026quot;: \u0026quot;I like to build cabinets\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;forestry\u0026quot; ] } PS: megacorp 是官方的例子，在下面的例子中，创建的方式和前面叙述的有些不同，官方的例子是在ElasticSearch 2.X出的， 在索引和文档之间，还存在类型这一概念，虽然在后续的版本中可能不再维护，但是在这里用做例子并无大碍。\n请求的方式   基于 URL 的搜索方式：\nGET /megacorp/employee/_search?q=last_name:Smith\n  基于 Request Body 的搜索方式\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;query_string\u0026quot;: { \u0026quot;fields\u0026quot;: [\u0026quot;last_name\u0026quot;], \u0026quot;query\u0026quot;: \u0026quot;Smith\u0026quot; } } }   一个完整的请求 GET /megacorp/_search { \u0026quot;query\u0026quot; : { \u0026quot;match\u0026quot; : { \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot; } }, \u0026quot;from\u0026quot;: 0, \u0026quot;size\u0026quot;: 2, \u0026quot;_source\u0026quot;: [\u0026quot;first_name\u0026quot;, \u0026quot;last_name\u0026quot;], \u0026quot;sort\u0026quot;: [{\u0026quot;age\u0026quot;: \u0026quot;desc\u0026quot;}] }  query：相当于SQL中的WHERE子句 from/size： 和SQL的 FROM/LIMIT 用法一致，用于分页 _source： 相当于 SELECT sort：对应 ORDER BY  查询返回结构 查询字符串(query_string) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;query_string\u0026quot;: { \u0026quot;fields\u0026quot;: [\u0026quot;about\u0026quot;], \u0026quot;query\u0026quot;: \u0026quot;I AND cabinets\u0026quot; } } } 简单查询字串(simpile_query_string) simpile_query_string 是 query_string 的一种优化方式，能够将 AND/OR 关键词简化：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;simple_query_string\u0026quot;: { \u0026quot;fields\u0026quot;: [\u0026quot;about\u0026quot;], \u0026quot;query\u0026quot;: \u0026quot;I + cabinets\u0026quot; } } } 全文搜索(match) GET /megacorp/employee/_search { \u0026quot;query\u0026quot; : { \u0026quot;match\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } } } 查询在 about 属性上喜欢 rock climbing 的人。rock albums和 rock climbing 都会被命中。如果字段是设置了 not_analyzed  或者是日期、数字、布尔，也会给定精确匹配的值。\n短语检索(match_phrase) GET /megacorp/employee/_search { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } } } 只有完全含有短语 rock climbing 的文档才被检索\n多字段查询(multi_match) 允许在多个字段上执行相同的查询\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;multi_match\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;like music\u0026quot;, \u0026quot;fields\u0026quot;: [\u0026quot;about\u0026quot;, \u0026quot;interests\u0026quot;] } } } 范围查询(range) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 20, \u0026quot;lt\u0026quot;: 33 } } } }  gt: 大于 gte: 大于等于 lt: 小于 lte: 小于等于  精确值查找(term/terms) term 查询被用于精确值匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;25\u0026quot;} } } } terms 查询是 term 的多值版本\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;age\u0026quot;: [\u0026quot;25\u0026quot;, \u0026quot;32\u0026quot;] } } }  存在性查找(exsists/missing) exsists 和 missing 是一个逻辑相反的关系，用于判断字段是否有值，类似于 SQL 的WHERE FieldA IS NOT null\n{ \u0026quot;exists\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;title\u0026quot; } } 前缀查询(match_prefix) 因为目前只有三条记录，分别是：\n\u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;first_name\u0026quot; : \u0026quot;Douglas\u0026quot;, 当期待用 J 去匹配John和Jane在first_name字段匹配不会成功，而需要使用字段first_name.keyword ：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;first_name.keyword\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;J\u0026quot; } } } } 或者使用小写的 j，因为 first_name 是一个被分词的字段(analyzed)，在经过一系列的分词器和转化后，存储在倒排索引是小写的单词，而 first_name.keyword 字段是 first_name 的不做分词版本，可以用大写的 J 匹配到。\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;first_name\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;j\u0026quot; } } } } 模糊查询和正则表达式(wildcard/regexp) 因为语句会被es分解成词，match查询的最小模糊匹配是词，利用模糊查询就能将模糊粒度降低到字母，如：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;wildcard\u0026quot;: { \u0026quot;about\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;c*\u0026quot; } } } } 或者:\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;regexp\u0026quot;: { \u0026quot;about\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;c.*\u0026quot; } } } } 数据在索引时的预处理有助于提高前缀匹配的效率，而通配符和正则表达式查询只能在查询时完成，尽管这些查询有其应用场景，但使用仍需谨慎。\nprefix 、 wildcard 和 regexp 查询是基于词操作的，像语句“Quick brown fox”如果设置了analyzed 就会被分解成 quick 、 brown 和 fox。\n{ \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;br.*\u0026quot; }}  语句能够检索到，但是下面这些组合了词语的查询不行\n{ \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;Qu.*\u0026quot; }} { \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;quick br*\u0026quot; }} 复合查询 复合查询使用 bool 查询来实现逻辑的组合，接受以下四种参数：\n must： 文档必须匹配这些条件才能被包含进来。 must_not：文档必须不匹配这些条件才能被包含进来。 should: 如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter: 必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。  结构为：\n\u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ SUB_QUERY ], \u0026quot;must_not\u0026quot;: [ SUB_QUERY ] } } 例如：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ {\u0026quot;range\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 } }} ], \u0026quot;must_not\u0026quot;: [ {\u0026quot;match\u0026quot;: { \u0026quot;about\u0026quot;: \u0026quot;cabinets\u0026quot; }} ] } } } 过滤查询(filter) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: {\u0026quot;match\u0026quot; : {\u0026quot;about\u0026quot; : \u0026quot;like build\u0026quot;}}, \u0026quot;filter\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot; : {\u0026quot;range\u0026quot;: {\u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 }}} } } } } } 将查询移到 bool 查询的 filter 的 bool 语句中，例如像年龄这样的字段，只需要进行过滤，不需要放在查询做，所以可以放到filter中来优化查询性能。\n过滤查询(constant_score) constant_score 是filter的另外一种形式，通常用在只进行filter，而不用查询相关性分的情况。\n如下：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;constant_score\u0026quot;: { \u0026quot;filter\u0026quot;: {\u0026quot;range\u0026quot;: {\u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 }}} } } } ref  19 个很有用的 ElasticSearch 查询语句 elastic search guide  ","date":"July 16, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch1%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（1）：基础查询"},{"categories":["notes"],"contents":"docker-compose.yml version: '2.2' services: node01: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node01 environment: - node.name=node01 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \u0026quot;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026quot; ulimits: memlock: soft: -1 hard: -1 volumes: - es-data01:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 networks: - es-network node02: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node02 environment: - node.name=node02 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \u0026quot;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026quot; ulimits: memlock: soft: -1 hard: -1 volumes: - es-data02:/usr/share/elasticsearch/data ports: - 9201:9201 - 9301:9301 networks: - es-network node03: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node03 environment: - node.name=node03 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \u0026quot;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026quot; ulimits: memlock: soft: -1 hard: -1 volumes: - es-data03:/usr/share/elasticsearch/data ports: - 9202:9202 - 9302:9302 networks: - es-network kibana: image: docker.elastic.co/kibana/kibana:7.11.1 environment: ELASTICSEARCH_HOSTS: http://node01:9200 ports: - 5601:5601 networks: - es-network depends_on: - node01 volumes: es-data01: driver: local es-data02: driver: local es-data03: driver: local networks: es-network: driver: bridge 来源于： https://quoeamaster.medium.com/deploying-elasticsearch-and-kibana-with-docker-86a4ac78d851\nhttps://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html https://doc.yonyoucloud.com/doc/mastering-elasticsearch/chapter-4/46_README.html\n启动和检查 # 启动 sudo docker-compose up # 集群监控 curl pwaer.ink:9200/_cat/health =\u0026gt; 1627449664 05:21:04 es-cluster-7 green 3 3 12 6 0 0 0 0 - 100.0% # 数据和索引文件挂载位置 /usr/share/elasticsearch/data ","date":"July 8, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch0%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/","summary":"包括 Elasticsearch 的CRUD和基础检索方式","tags":null,"title":"ElasticSearch（0）：快速搭建"},{"categories":["sys"],"contents":"前言 准确的度量系统的开销是很重要的, 系统级别比较出名的是 Latency Numbers Every Programmer Should Know, 而在各种变成语言中, 需要依赖基准测试来判断程序实际的耗时。\nLatency Comparison Numbers (~2012) ---------------------------------- L1 cache reference 0.5 ns Branch mispredict 5 ns L2 cache reference 7 ns 14x L1 cache Mutex lock/unlock 25 ns Main memory reference 100 ns 20x L2 cache, 200x L1 cache Compress 1K bytes with Zippy 3,000 ns 3 us Send 1K bytes over 1 Gbps network 10,000 ns 10 us Read 4K randomly from SSD* 150,000 ns 150 us ~1GB/sec SSD Read 1 MB sequentially from memory 250,000 ns 250 us Round trip within same datacenter 500,000 ns 500 us Read 1 MB sequentially from SSD* 1,000,000 ns 1,000 us 1 ms ~1GB/sec SSD, 4X memory Disk seek 10,000,000 ns 10,000 us 10 ms 20x datacenter roundtrip Read 1 MB sequentially from disk 20,000,000 ns 20,000 us 20 ms 80x memory, 20X SSD Send packet CA-\u0026gt;Netherlands-\u0026gt;CA 150,000,000 ns 150,000 us 150 ms Notes ----- 1 ns = 10^-9 seconds 1 us = 10^-6 seconds = 1,000 ns 1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns Credit ------ By Jeff Dean: http://research.google.com/people/jeff/ Originally by Peter Norvig: http://norvig.com/21-days.html#answers Contributions ------------- 'Humanized' comparison: https://gist.github.com/hellerbarde/2843375 Visual comparison chart: http://i.imgur.com/k0t1e.png 基准测试 在CPP中可以依赖 goolge benchmark 来完成这样的事情，安装和编译非常简单，按照文档给出的命令可以很快部署并且开始使用。\n$ git clone https://github.com/google/benchmark.git # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory. $ git clone https://github.com/google/googletest.git benchmark/googletest # Go to the library root directory $ cd benchmark # Make a build directory to place the build output. $ cmake -E make_directory \u0026quot;build\u0026quot; # Generate build system files with cmake. $ cmake -E chdir \u0026quot;build\u0026quot; cmake -DCMAKE_BUILD_TYPE=Release ../ # or, starting with CMake 3.13, use a simpler form: # cmake -DCMAKE_BUILD_TYPE=Release -S . -B \u0026quot;build\u0026quot; # Build the library. $ cmake --build \u0026quot;build\u0026quot; --config Release 然后进行安装\nsudo cmake --build \u0026quot;build\u0026quot; --config Release --target install 开始一个简单的测试 // bench.cc  #include \u0026lt;benchmark/benchmark.h\u0026gt;#include \u0026lt;vector\u0026gt; static void BM_create(benchmark::State\u0026amp; state) { // Perform setup here  for (auto _ : state) { // This code gets timed  std::vector\u0026lt;int\u0026gt; vec; (void)vec; } } static void BM_push_back(benchmark::State\u0026amp; state) { // Perform setup here  for (auto _ : state) { // This code gets timed  std::vector\u0026lt;int\u0026gt; vec; vec.push_back(1); } } static void BM_reserve(benchmark::State\u0026amp; state) { // Perform setup here  for (auto _ : state) { // This code gets timed  std::vector\u0026lt;int\u0026gt; vec; vec.reserve(1); vec.push_back(1); } } // Register the function as a benchmark BENCHMARK(BM_create); BENCHMARK(BM_push_back); BENCHMARK(BM_reserve); // Run the benchmark BENCHMARK_MAIN(); 编译、链接并且运行：\ng++ bench.cc -std=c++11 -g -lbenchmark -lpthread -o bench \u0026amp;\u0026amp; ./bench 可以看到一个清晰的耗时测试结果：\n","date":"April 30, 2021","hero":"/images/default-hero.jpg","permalink":"/posts/sys/google-benchmark/","summary":"前言 准确的度量系统的开销是很重要的, 系统级别比较出名的是 Latency Numbers Every Programmer Should Know, 而在各种变成语言中, 需要依赖基准测试来判断程序实际的耗时。\nLatency Comparison Numbers (~2012) ---------------------------------- L1 cache reference 0.5 ns Branch mispredict 5 ns L2 cache reference 7 ns 14x L1 cache Mutex lock/unlock 25 ns Main memory reference 100 ns 20x L2 cache, 200x L1 cache Compress 1K bytes with Zippy 3,000 ns 3 us Send 1K bytes over 1 Gbps network 10,000 ns 10 us Read 4K randomly from SSD* 150,000 ns 150 us ~1GB/sec SSD Read 1 MB sequentially from memory 250,000 ns 250 us Round trip within same datacenter 500,000 ns 500 us Read 1 MB sequentially from SSD* 1,000,000 ns 1,000 us 1 ms ~1GB/sec SSD, 4X memory Disk seek 10,000,000 ns 10,000 us 10 ms 20x datacenter roundtrip Read 1 MB sequentially from disk 20,000,000 ns 20,000 us 20 ms 80x memory, 20X SSD Send packet CA-\u0026gt;Netherlands-\u0026gt;CA 150,000,000 ns 150,000 us 150 ms Notes ----- 1 ns = 10^-9 seconds 1 us = 10^-6 seconds = 1,000 ns 1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns Credit ------ By Jeff Dean: http://research.","tags":null,"title":"google benchmark：利用 perf 工具查看程序热点"},{"categories":["sys"],"contents":"内存不符预期的不断上涨，可能的原因是内存泄漏，例如new出来的对象未进行delete就重新进行复制，使得之前分配的内存块被悬空，应用程序没办法访问到那部分内存，并且也没有办法释放；在C++中，STL容器都会有clear()方法并且伴随RAII原则对容器里元素进行清理，但除了STL还有可能是字符串不断地在进行累加，不断的分配出新的内存块存放增长的字符串。\n在cppzh 群 内看到讨论利用jemalloc对内存占用的调试，能够清楚的 dump 出内存的使用情况，便尝试了下。\n安装 # 用于生成 pdf yum -y install graphviz ghostscript wget https://github.com/jemalloc/jemalloc/archive/5.1.0.tar.gz tar zxvf 5.1.0.tar.gz cd jemalloc-5.1.0/ ./autogen.sh ./configure --prefix=/usr/local/jemalloc-5.1.0 --enable-prof make -j make install 程序退出时的用例和检查 # run MALLOC_CONF=prof_leak:true,lg_prof_sample:0,prof_final:true LD_PRELOAD=/usr/local/jemalloc-5.1.0/lib/libjemalloc.so.2 ./a.out # 查看内存占用情况 /usr/local/jemalloc-5.1.0/bin/jeprof a.out jeprof.34447.0.f.heap \u0026gt; top 长时间运行-测试用例 对于长时间运行的程序，例如服务端程序通常不能够退出，jemalloc提供每增长指定大小进行一次内存dump。\n下面这个例子mock长时间运行的程序，分别测试顺序容器(vector)和关联容器(map)，string 和最基本的new，并且每100ms执行1000次，代表服务端的运行情况。\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;map\u0026gt;#include \u0026lt;chrono\u0026gt;#include \u0026lt;thread\u0026gt; int main() { std::vector\u0026lt;int\u0026gt; vec; std::map\u0026lt;int, int\u0026gt; mp; std::string s; for (;;) { for (int i = 0; i \u0026lt; 1000; ++i) { vec.push_back(i); mp[rand()] = i; s += \u0026#34;xxxx\u0026#34;; new char[4]; } std::this_thread::sleep_for(std::chrono::microseconds(100)); } return 0; } 编译运行:\ng++ test.cc -o a.out 将环境变量MALLOC_CONF设置为prof:true,lg_prof_interval:26使jemalloc开启prof并且每2^26字节(64M)大小进行一次dump，并且利用LD_PRELOAD 环境变量代替。\nexport MALLOC_CONF=\u0026#34;prof:true,lg_prof_interval:26\u0026#34; LD_PRELOAD=/usr/local/jemalloc-5.1.0/lib/libjemalloc.so.2 ./a.out [root@pwh c++]# ls -l -t total 212 -rw-r--r-- 1 root root 5208 Dec 19 14:31 jeprof.17988.17.i17.heap -rw-r--r-- 1 root root 5206 Dec 19 14:31 jeprof.17988.16.i16.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.15.i15.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.14.i14.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.13.i13.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.12.i12.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.11.i11.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.10.i10.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.9.i9.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.8.i8.heap -rw-r--r-- 1 root root 5198 Dec 19 14:31 jeprof.17988.7.i7.heap -rw-r--r-- 1 root root 5198 Dec 19 14:31 jeprof.17988.6.i6.heap ... 结果分析 由于是每隔一段内存大小进行的dump，每个文件都是内存的片段信息，利用--base指定从哪一份heap文件开始分析。\n$ /usr/local/jemalloc-5.1.0/bin/jeprof a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap $ /usr/local/jemalloc-5.1.0/bin/jeprof a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap Using local file a.out. Argument \u0026#34;MSWin32\u0026#34; isn\u0026#39;t numeric in numeric eq (==) at /usr/local/jemalloc-5.1.0/bin/jeprof line 5123. Argument \u0026#34;linux\u0026#34; isn\u0026#39;t numeric in numeric eq (==) at /usr/local/jemalloc-5.1.0/bin/jeprof line 5123. Using local file jeprof.17988.17.i17.heap. Welcome to jeprof! For help, type \u0026#39;help\u0026#39;. (jeprof) top Total: 1002.5 MB 754.5 75.3% 75.3% 754.5 75.3% __gnu_cxx::new_allocator::allocate@4031fc 124.0 12.4% 87.6% 124.0 12.4% __gnu_cxx::new_allocator::allocate@402fac 124.0 12.4% 100.0% 124.0 12.4% std::__cxx11::basic_string::_M_mutate 0.0 0.0% 100.0% 1002.5 100.0% __libc_start_main 0.0 0.0% 100.0% 1002.5 100.0% _start 0.0 0.0% 100.0% 1002.5 100.0% main 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_create_node 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_emplace_hint_unique 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_get_node 0.0 0.0% 100.0% 124.0 12.4% std::_Vector_base::_M_allocate # 导出为 pdf /usr/local/jemalloc-5.1.0/bin/jeprof --pdf a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap \u0026gt; a.pdf 统计内存使用情况 取了新的一段内存区间将其导出为pdf后，总共分配使用718MB内存，其中在map的[]的操作符重载函数中占用了514.5MB，为string分配了60MB，为vector分配了60MB，而最基础的new char[4]的调用栈是停留在main()中，所以main()也占用了84MB，得到的数据和Total MB(718.5MB)吻合。\nref  https://www.yuanguohuo.com/2019/01/02/jemalloc-heap-profiling/ http://jemalloc.net/  ","date":"December 18, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/sys/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/","summary":"内存不符预期的不断上涨，可能的原因是内存泄漏，例如new出来的对象未进行delete就重新进行复制，使得之前分配的内存块被悬空，应用程序没办法访问到那部分内存，并且也没有办法释放；在C++中，STL容器都会有clear()方法并且伴随RAII原则对容器里元素进行清理，但除了STL还有可能是字符串不断地在进行累加，不断的分配出新的内存块存放增长的字符串。\n在cppzh 群 内看到讨论利用jemalloc对内存占用的调试，能够清楚的 dump 出内存的使用情况，便尝试了下。\n安装 # 用于生成 pdf yum -y install graphviz ghostscript wget https://github.com/jemalloc/jemalloc/archive/5.1.0.tar.gz tar zxvf 5.1.0.tar.gz cd jemalloc-5.1.0/ ./autogen.sh ./configure --prefix=/usr/local/jemalloc-5.1.0 --enable-prof make -j make install 程序退出时的用例和检查 # run MALLOC_CONF=prof_leak:true,lg_prof_sample:0,prof_final:true LD_PRELOAD=/usr/local/jemalloc-5.1.0/lib/libjemalloc.so.2 ./a.out # 查看内存占用情况 /usr/local/jemalloc-5.1.0/bin/jeprof a.out jeprof.34447.0.f.heap \u0026gt; top 长时间运行-测试用例 对于长时间运行的程序，例如服务端程序通常不能够退出，jemalloc提供每增长指定大小进行一次内存dump。\n下面这个例子mock长时间运行的程序，分别测试顺序容器(vector)和关联容器(map)，string 和最基本的new，并且每100ms执行1000次，代表服务端的运行情况。\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;map\u0026gt;#include \u0026lt;chrono\u0026gt;#include \u0026lt;thread\u0026gt; int main() { std::vector\u0026lt;int\u0026gt; vec; std::map\u0026lt;int, int\u0026gt; mp; std::string s; for (;;) { for (int i = 0; i \u0026lt; 1000; ++i) { vec.","tags":null,"title":"利用Jemalloc进行内存泄漏的调试"},{"categories":["sys"],"contents":"异步请求过程 在利用异步gRPC实现请求的时候，通常使用gRPC example中的greeter_async_client2.cc作为模板发起异步请求，并通过CompletionQueue中的Next()阻塞机制等待请求的完成。\n异步请求流程应该如下：\n在greeter_async_client2.cc中，每一个请求都会创建一个AsyncClientCall，并且根据这个new出来的对象地址，作为唯一标识，存储在CompletionQueue中，\n// struct for keeping state and data information  struct AsyncClientCall { // Container for the data we expect from the server.  HelloReply reply; // Context for the client. It could be used to convey extra information to  // the server and/or tweak certain RPC behaviors.  ClientContext context; // Storage for the status of the RPC upon completion.  Status status; std::unique_ptr\u0026lt;ClientAsyncResponseReader\u0026lt;HelloReply\u0026gt;\u0026gt; response_reader; }; void SayHello(const std::string\u0026amp; user) { // Data we are sending to the server.  HelloRequest request; request.set_name(user); // Call object to store rpc data  AsyncClientCall* call = new AsyncClientCall; // stub_-\u0026gt;PrepareAsyncSayHello() creates an RPC object, returning  // an instance to store in \u0026#34;call\u0026#34; but does not actually start the RPC  // Because we are using the asynchronous API, we need to hold on to  // the \u0026#34;call\u0026#34; instance in order to get updates on the ongoing RPC.  call-\u0026gt;response_reader = stub_-\u0026gt;PrepareAsyncSayHello(\u0026amp;call-\u0026gt;context, request, \u0026amp;cq_); // StartCall initiates the RPC call  call-\u0026gt;response_reader-\u0026gt;StartCall(); // Request that, upon completion of the RPC, \u0026#34;reply\u0026#34; be updated with the  // server\u0026#39;s response; \u0026#34;status\u0026#34; with the indication of whether the operation  // was successful. Tag the request with the memory address of the call object.  call-\u0026gt;response_reader-\u0026gt;Finish(\u0026amp;call-\u0026gt;reply, \u0026amp;call-\u0026gt;status, (void*)call); } 在官方的例子中，客户端启动了一个线程专门去处理数据异步的接收，但是能同步完成，即在发送完后 直接利用cq.Next()等待请求的完成。\n为什么需要复用一个CompletionQueue 假设目前有个线程正在执行一个操作，并且需要调用多个不同的gRPC服务获取数据，如果使用同步的调用， 那么就需要经过多次调用的时间才能完成数据的获取。\n ... ↓ call A --\u0026gt;t1--\u0026gt; gRPC Server A ↓ call B --\u0026gt;t2--\u0026gt; gRPC Server B ↓ call C --\u0026gt;t3--\u0026gt; gRPC Server C ↓ ... 完成三次数据取的时间就是 t1 + t2 + t3，换成官方的example中的aync_client中的异步调用，收到请求需要CompletetionQueue的Next()调用来同步，处理收到的请求。因为要发起不同的RPC请求，容易惯性地开启多个CompletetionQueue来发起请求，最终等待的时候就会需要多个Next()进行同步，从而不得不开启另一个线程检查 多个CompletetionQueue是否完成，或者单线调用多次Next()导致使用的时间和同步调用没有差别。\n如果使用同一个CompletetionQueue发送请求，那么就可以使用一个Next()等待多个请求同步，所使用的时间就是 Max(t1, t2, t3)。使用同一个CompletetionQueue会产生一个问题，Next()等待收到响应后，如何分发到不同的 响应处理中去就成了一个新的问题，最简单的方法之一就是在CompletetionQueue的tag值上想方法，类似于greeter_async_client2.cc中的AsyncClientCall，将结构体的地址写入CQ中，然后在Next()返回得到tag值时 转型成AsyncClientCall类型。在这个结构体中，加入一个类似于type的字段，用于判断请求的类型，就能区分收到的响应是哪个gRPC请求对应的响应。\n简单例子 Protobuffer 协议文件 grpc/examples/protos/helloworld.proto\nsyntax = \u0026#34;proto3\u0026#34;;option java_multiple_files = true;option java_package = \u0026#34;io.grpc.examples.helloworld\u0026#34;;option java_outer_classname = \u0026#34;HelloWorldProto\u0026#34;;option objc_class_prefix = \u0026#34;HLW\u0026#34;;package helloworld;// The greeting service definition. service Greeter { // Sends a greeting  rpc SayHello (HelloRequest) returns (HelloReply) {}}// The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1;}// The response message containing the greetings message HelloReply { string message = 1;}service PingPongService { rpc PingPong (PingRequest) returns (PongReply) {}}message PingRequest { string seq = 1;}message PongReply { string seq = 1;}server.cc #include \u0026lt;iostream\u0026gt;#include \u0026lt;memory\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;thread\u0026gt; #include \u0026lt;grpcpp/grpcpp.h\u0026gt;#include \u0026lt;grpcpp/health_check_service_interface.h\u0026gt;#include \u0026lt;grpcpp/ext/proto_server_reflection_plugin.h\u0026gt; #ifdef BAZEL_BUILD #include \u0026#34;examples/protos/helloworld.grpc.pb.h\u0026#34;#else #include \u0026#34;helloworld.grpc.pb.h\u0026#34;#endif  using grpc::Server; using grpc::ServerBuilder; using grpc::ServerContext; using grpc::Status; using helloworld::HelloRequest; using helloworld::HelloReply; using helloworld::Greeter; using helloworld::PingPongService; using helloworld::PingRequest; using helloworld::PongReply; // Logic and data behind the server\u0026#39;s behavior. class GreeterServiceImpl final : public Greeter::Service { Status SayHello(ServerContext* context, const HelloRequest* request, HelloReply* reply) override { std::cout \u0026lt;\u0026lt; request-\u0026gt;name() \u0026lt;\u0026lt; std::endl; reply-\u0026gt;set_message(\u0026#34;world\u0026#34;); return Status::OK; } }; class PingPongServiceImpl final : public PingPongService::Service { Status PingPong(ServerContext* context, const PingRequest* request, PongReply* reply) override { std::cout \u0026lt;\u0026lt; request-\u0026gt;seq() \u0026lt;\u0026lt; std::endl; reply-\u0026gt;set_seq(\u0026#34;pong\u0026#34;); return Status::OK; } }; void RunServer() { std::string server_address(\u0026#34;0.0.0.0:50051\u0026#34;); GreeterServiceImpl service; grpc::EnableDefaultHealthCheckService(true); grpc::reflection::InitProtoReflectionServerBuilderPlugin(); ServerBuilder builder; // Listen on the given address without any authentication mechanism.  builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); // Register \u0026#34;service\u0026#34; as the instance through which we\u0026#39;ll communicate with  // clients. In this case it corresponds to an *synchronous* service.  builder.RegisterService(\u0026amp;service); // Finally assemble the server.  std::unique_ptr\u0026lt;Server\u0026gt; server(builder.BuildAndStart()); std::cout \u0026lt;\u0026lt; \u0026#34;Server listening on \u0026#34; \u0026lt;\u0026lt; server_address \u0026lt;\u0026lt; std::endl; // Wait for the server to shutdown. Note that some other thread must be  // responsible for shutting down the server for this call to ever return.  server-\u0026gt;Wait(); } void RunPingPongServer() { std::string server_address(\u0026#34;0.0.0.0:50052\u0026#34;); PingPongServiceImpl service; grpc::EnableDefaultHealthCheckService(true); grpc::reflection::InitProtoReflectionServerBuilderPlugin(); ServerBuilder builder; // Listen on the given address without any authentication mechanism.  builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); // Register \u0026#34;service\u0026#34; as the instance through which we\u0026#39;ll communicate with  // clients. In this case it corresponds to an *synchronous* service.  builder.RegisterService(\u0026amp;service); // Finally assemble the server.  std::unique_ptr\u0026lt;Server\u0026gt; server(builder.BuildAndStart()); std::cout \u0026lt;\u0026lt; \u0026#34;Server listening on \u0026#34; \u0026lt;\u0026lt; server_address \u0026lt;\u0026lt; std::endl; // Wait for the server to shutdown. Note that some other thread must be  // responsible for shutting down the server for this call to ever return.  server-\u0026gt;Wait(); } int main(int argc, char** argv) { std::thread t1 = std::thread(RunServer); std::thread t2 = std::thread(RunPingPongServer); t1.join(); t2.join(); return 0; } async_client.cc #include \u0026lt;iostream\u0026gt;#include \u0026lt;memory\u0026gt;#include \u0026lt;string\u0026gt; #include \u0026lt;grpcpp/grpcpp.h\u0026gt;#include \u0026lt;grpc/support/log.h\u0026gt;#include \u0026lt;thread\u0026gt; #ifdef BAZEL_BUILD #include \u0026#34;examples/protos/helloworld.grpc.pb.h\u0026#34;#else #include \u0026#34;helloworld.grpc.pb.h\u0026#34;#endif  using grpc::Channel; using grpc::ClientAsyncResponseReader; using grpc::ClientContext; using grpc::CompletionQueue; using grpc::Status; using helloworld::PingRequest; using helloworld::PongReply; using helloworld::PingPongService; using helloworld::HelloRequest; using helloworld::HelloReply; using helloworld::Greeter; struct AsyncClientCall { int type; PongReply pong_reply; HelloReply hello_reply; ClientContext context; Status status; std::unique_ptr\u0026lt;ClientAsyncResponseReader\u0026lt;PongReply\u0026gt;\u0026gt; pingpong_reader; std::unique_ptr\u0026lt;ClientAsyncResponseReader\u0026lt;HelloReply\u0026gt;\u0026gt; greeter_reader; }; class PingPongClient { public: explicit PingPongClient(std::shared_ptr\u0026lt;Channel\u0026gt; channel, CompletionQueue *cq) : stub_(PingPongService::NewStub(channel)), cq_(cq) {} void PingPong(const std::string\u0026amp; seq) { PingRequest request; request.set_seq(seq); AsyncClientCall* call = new AsyncClientCall; call-\u0026gt;type = 1; call-\u0026gt;pingpong_reader = stub_-\u0026gt;PrepareAsyncPingPong(\u0026amp;call-\u0026gt;context, request, cq_); call-\u0026gt;pingpong_reader-\u0026gt;StartCall(); call-\u0026gt;pingpong_reader-\u0026gt;Finish(\u0026amp;call-\u0026gt;pong_reply, \u0026amp;call-\u0026gt;status, (void*)call); std::cout \u0026lt;\u0026lt; \u0026#34;pingpong call struct address:\u0026#34; \u0026lt;\u0026lt; call \u0026lt;\u0026lt; std::endl; } private: std::unique_ptr\u0026lt;PingPongService::Stub\u0026gt; stub_; CompletionQueue *cq_; }; class GreeterClient { public: explicit GreeterClient(std::shared_ptr\u0026lt;Channel\u0026gt; channel, CompletionQueue *cq) : stub_(Greeter::NewStub(channel)), cq_(cq) {} void SayHello(const std::string\u0026amp; user) { HelloRequest request; request.set_name(user); AsyncClientCall* call = new AsyncClientCall; call-\u0026gt;type = 0; call-\u0026gt;greeter_reader = stub_-\u0026gt;PrepareAsyncSayHello(\u0026amp;call-\u0026gt;context, request, cq_); call-\u0026gt;greeter_reader-\u0026gt;StartCall(); call-\u0026gt;greeter_reader-\u0026gt;Finish(\u0026amp;call-\u0026gt;hello_reply, \u0026amp;call-\u0026gt;status, (void*)call); std::cout \u0026lt;\u0026lt; \u0026#34;greeter call struct address:\u0026#34; \u0026lt;\u0026lt; call \u0026lt;\u0026lt; std::endl; } private: std::unique_ptr\u0026lt;Greeter::Stub\u0026gt; stub_; CompletionQueue *cq_; }; void AsyncCompleteRpc(CompletionQueue\u0026amp; cq_) { void* got_tag; bool ok = false; while (cq_.Next(\u0026amp;got_tag, \u0026amp;ok)) { AsyncClientCall* call = static_cast\u0026lt;AsyncClientCall*\u0026gt;(got_tag); if (call-\u0026gt;status.ok()) if (call-\u0026gt;type == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;address=\u0026#34; \u0026lt;\u0026lt; call \u0026lt;\u0026lt; \u0026#34; received: \u0026#34; \u0026lt;\u0026lt; call-\u0026gt;hello_reply.message() \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;address=\u0026#34; \u0026lt;\u0026lt; call \u0026lt;\u0026lt; \u0026#34; received: \u0026#34; \u0026lt;\u0026lt; call-\u0026gt;pong_reply.seq() \u0026lt;\u0026lt; std::endl; } else std::cout \u0026lt;\u0026lt; \u0026#34;RPC failed\u0026#34; \u0026lt;\u0026lt; std::endl; delete call; } } int main(int argc, char** argv) { CompletionQueue cq; GreeterClient greeter(grpc::CreateChannel( \u0026#34;localhost:50051\u0026#34;, grpc::InsecureChannelCredentials()), \u0026amp;cq); PingPongClient client(grpc::CreateChannel( \u0026#34;localhost:50052\u0026#34;, grpc::InsecureChannelCredentials()), \u0026amp;cq); greeter.SayHello(\u0026#34;hello\u0026#34;); client.PingPong(\u0026#34;ping\u0026#34;); AsyncCompleteRpc(cq); return 0; } 运行结果 \u0026gt;\u0026gt; ./server Server listening on 0.0.0.0:50052 Server listening on 0.0.0.0:50051 ---- \u0026gt;\u0026gt; ./async_client greeter call struct address:0x1748eb0 pingpong call struct address:0x174e410 address=0x1748eb0 received: world address=0x174e410 received: pong ","date":"October 19, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/sys/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/","summary":"异步请求过程 在利用异步gRPC实现请求的时候，通常使用gRPC example中的greeter_async_client2.cc作为模板发起异步请求，并通过CompletionQueue中的Next()阻塞机制等待请求的完成。\n异步请求流程应该如下：\n在greeter_async_client2.cc中，每一个请求都会创建一个AsyncClientCall，并且根据这个new出来的对象地址，作为唯一标识，存储在CompletionQueue中，\n// struct for keeping state and data information  struct AsyncClientCall { // Container for the data we expect from the server.  HelloReply reply; // Context for the client. It could be used to convey extra information to  // the server and/or tweak certain RPC behaviors.  ClientContext context; // Storage for the status of the RPC upon completion.  Status status; std::unique_ptr\u0026lt;ClientAsyncResponseReader\u0026lt;HelloReply\u0026gt;\u0026gt; response_reader; }; void SayHello(const std::string\u0026amp; user) { // Data we are sending to the server.","tags":null,"title":"gRPC：复用CompletionQueue"},{"categories":["notes"],"contents":"前言 如果一次性总结，文章太过于冗长，上部分更加是一种在编程中会碰到的技术细节，而这一部分是一些编程中需要记住的良好习惯。\n1. 养成估算的习惯 1000字节数据通过路由器需要多少时间？类似这样的问题需要有个大致的答案，通过学习估算，能将估算发展到对事物的数量级有直觉的程度，就可以确定方案的可能性。\n无论什么时候有人需要你进行估算，你都可以给出答案。 如果没有经验，估算通常可以去问问已经做过该事情的人。 追踪自己的估算能力，如果估算错了，找出什么事情与自己的预期不同。\n2. 调试的过程 这里不讲技术上怎么调试，而是另外一种途径进行调试：向别人一行一行解释代码的作用，并且详细描述假定的情况，可能在解释的过程中就可以知道哪里处理问题。\n花很长时间找到bug后，想想可以做点什么使找到这个bug更加容易，例如内建更加好的测试。\n3. 重构 不要害怕重构，老旧的代码如果不适用，所有代码都可以被替换。重构往往在非正交设计，违反DRY原则、过时的知识、性能缺陷存在时发生。\n那么如何合理地进行重构？\n 不要在重构同时新增功能 开始重构前要有良好的测试，确保重构后能通过 采用小改动的模式，利用局部改动慢慢扩大到更大规模的改动，避免长时间的调试  4. 测试的一些建议 根据合约(契约式编程)进行单元测试，先测试子模块，再测试模块自身子模块，再测试模块自身。 单元测试应该在模块目录，使测试代码容易找到，既可以说明怎么使用模块的功能，又可以用于构建回归测试，验证未来对代码的改动是否正确。\n另外测试都应该具有以下功能：\n setup和cleanup的标准途径 可选择地选择可用测试方法 分析输出结果的手段 标准化故障报告的形式  5. 曳光弹与原型开发 曳光弹原本是指在机枪子弹中间接出现的用于显示子弹射击目标的子弹，比起精确计算风向、射速、角度再射击，曳光弹的方式更加实际。曳光弹的原理就是指，尝试制作一个项目，慢慢地靠近客户需求的一种构建方式，可以有效的展现工作进度，并且这种构建方式的每一段代码都需要有完整的错误检查，结构，文档，以及自查。\n而原型开发这种方式通常是一种实验性的探索，为取得某种功能，不必关注太多细节情况，通常没有太多文档和注释。\n6. 做变化的催化剂 这一点对自己的要求比较高，在团队合作中，写出很好的代码，让团队的其他人大吃一惊，渐渐影响他们，从而提高项目质量。\n7. 不要过度修饰和求精程序 这和过早优化的概念同理，但概念更加偏向于用户，今日了不起的软件往往被明天更加完美的软件更加可取，让用户先使用，用他们的反馈引领软件走向最终解决方案。但是并不是说就可以用不整洁的代码，或者制作糟糕的代码。\n8. 管理知识资产 对于金融资产的管理：\n 定期投资，形成习惯 多元化是长期成功的关键 在保守的投资和高风险，高回报的投资之间平衡资产 设法低买高卖获取最大回报 周期性的评估和平衡财产  而程序员管理自己的知识资产可以类比：\n 定投，周期性的学习 多元化，广度学习，底线是需要知道目前所使用技术的各种特性，优劣 管理风险，不要把所学的技术都放在一个篮子里 低买高卖：新兴技术可能就是被低估的股票，提前学习可能可以更好的找到工作 重新评估：热门技术可能很快就冷门了，甚至过一段时间有需要重新温习忘记的数据库技术等，需要对自己的知识体系重新评估。  所以可以给自己设立一些周期性的目标，防止自己的脱节：\n 定期投资可以是每年至少学习一种新的语言，每月阅读一本技术书籍，阅读非技术书籍。 偶尔学习一些公开课 参与一些组织，打听公司以外的人都在做什么 试验不同的环境，技术或者非技术都是如此，逃离舒适区 持续投入！  9. 交流 交流很重要，即使是“自闭”人群，该说话的时候还是得好好说话。\n书中提到的最关键的几点：\n了解听众  你想让他们学到什么 他们对你讲的什么感兴趣 他们有多丰富的经验 他们要多少细节 你想要谁拥有这些信息 你如何促使他们听你说话  认真倾听和及时回复 对于前者，你不听别人讲话，别人也懒得听你的 ：）；及时回复这一点，在现代社会中其实很容易遗忘，但是即使简单回复，”我稍后回复你“，也会显得礼貌。\n参考资料  《The Programatic Programmer》 https://en.wikipedia.org/wiki/Law_of_Demeter  ","date":"April 15, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/notes/programatic2/","summary":"前言 如果一次性总结，文章太过于冗长，上部分更加是一种在编程中会碰到的技术细节，而这一部分是一些编程中需要记住的良好习惯。\n1. 养成估算的习惯 1000字节数据通过路由器需要多少时间？类似这样的问题需要有个大致的答案，通过学习估算，能将估算发展到对事物的数量级有直觉的程度，就可以确定方案的可能性。\n无论什么时候有人需要你进行估算，你都可以给出答案。 如果没有经验，估算通常可以去问问已经做过该事情的人。 追踪自己的估算能力，如果估算错了，找出什么事情与自己的预期不同。\n2. 调试的过程 这里不讲技术上怎么调试，而是另外一种途径进行调试：向别人一行一行解释代码的作用，并且详细描述假定的情况，可能在解释的过程中就可以知道哪里处理问题。\n花很长时间找到bug后，想想可以做点什么使找到这个bug更加容易，例如内建更加好的测试。\n3. 重构 不要害怕重构，老旧的代码如果不适用，所有代码都可以被替换。重构往往在非正交设计，违反DRY原则、过时的知识、性能缺陷存在时发生。\n那么如何合理地进行重构？\n 不要在重构同时新增功能 开始重构前要有良好的测试，确保重构后能通过 采用小改动的模式，利用局部改动慢慢扩大到更大规模的改动，避免长时间的调试  4. 测试的一些建议 根据合约(契约式编程)进行单元测试，先测试子模块，再测试模块自身子模块，再测试模块自身。 单元测试应该在模块目录，使测试代码容易找到，既可以说明怎么使用模块的功能，又可以用于构建回归测试，验证未来对代码的改动是否正确。\n另外测试都应该具有以下功能：\n setup和cleanup的标准途径 可选择地选择可用测试方法 分析输出结果的手段 标准化故障报告的形式  5. 曳光弹与原型开发 曳光弹原本是指在机枪子弹中间接出现的用于显示子弹射击目标的子弹，比起精确计算风向、射速、角度再射击，曳光弹的方式更加实际。曳光弹的原理就是指，尝试制作一个项目，慢慢地靠近客户需求的一种构建方式，可以有效的展现工作进度，并且这种构建方式的每一段代码都需要有完整的错误检查，结构，文档，以及自查。\n而原型开发这种方式通常是一种实验性的探索，为取得某种功能，不必关注太多细节情况，通常没有太多文档和注释。\n6. 做变化的催化剂 这一点对自己的要求比较高，在团队合作中，写出很好的代码，让团队的其他人大吃一惊，渐渐影响他们，从而提高项目质量。\n7. 不要过度修饰和求精程序 这和过早优化的概念同理，但概念更加偏向于用户，今日了不起的软件往往被明天更加完美的软件更加可取，让用户先使用，用他们的反馈引领软件走向最终解决方案。但是并不是说就可以用不整洁的代码，或者制作糟糕的代码。\n8. 管理知识资产 对于金融资产的管理：\n 定期投资，形成习惯 多元化是长期成功的关键 在保守的投资和高风险，高回报的投资之间平衡资产 设法低买高卖获取最大回报 周期性的评估和平衡财产  而程序员管理自己的知识资产可以类比：\n 定投，周期性的学习 多元化，广度学习，底线是需要知道目前所使用技术的各种特性，优劣 管理风险，不要把所学的技术都放在一个篮子里 低买高卖：新兴技术可能就是被低估的股票，提前学习可能可以更好的找到工作 重新评估：热门技术可能很快就冷门了，甚至过一段时间有需要重新温习忘记的数据库技术等，需要对自己的知识体系重新评估。  所以可以给自己设立一些周期性的目标，防止自己的脱节：\n 定期投资可以是每年至少学习一种新的语言，每月阅读一本技术书籍，阅读非技术书籍。 偶尔学习一些公开课 参与一些组织，打听公司以外的人都在做什么 试验不同的环境，技术或者非技术都是如此，逃离舒适区 持续投入！  9. 交流 交流很重要，即使是“自闭”人群，该说话的时候还是得好好说话。","tags":null,"title":"实效性软件构建的途径-下"},{"categories":["notes"],"contents":"前言 无意中看到了这本书，译名是程序员修炼之道，想尝试在这本书中找到一些跟软件构建相关问题的答案。这本书虽然是上个世纪出版的，要注意时代的局限性和过期的经验，进行自我验证，但一遍看下来，对我来说，干货还是有很多的。\n1. 需求挖掘 这一点我认为是最重要的一点，于是放在最前面。\n找出用户为何要做特定事情的原因，而不是目前要做这件事情的方式，开发最终是需要解决商业问题。 比如，“只有员工和上级和人事部门才能查看员工的档案”和“只有指定人员能查看员工档案”，后者更加容易编写出适用于元数据编程的程序，也更加的灵活。\n这个用户不仅仅指实际使用的人，也可以是交给你这个工作的人。\n2. 做好退路和保险 书中是用代码所存储的机器因为崩溃而引发的问题，虽然在git的时代，这种问题不容易发生了，但是这种想法得印在脑子里，如果真发生类似的问题，损失将是非常大的。\n这一点和可撤销性想类似，要考虑架构部署的改动和灵活性，假设某次会议决定使用MySQL进行存储数据，但是在快完成时，需要换成其他DB进行存储，如果要改动很大，那么就是错误建立在了假定的决策上面。假定项目以后只会用到MySQL，很多代码都被写死了。\n再比如开发Unix软件，是否考虑所有平台的可以执行问题，例如epoll可以在linux上使用，那么如果在只有Kqueue的FreeBSD上面会怎么样，所以需要保证代码在一些决策上可以变通。\n3. 不要破窗户 这也就是常说的破窗效应，一扇破窗户，只要一段时间不修理，就会逐渐带来废弃感，逐渐变为破败的废弃物。软件中的破窗户就是指，低劣的设计，错误的决策，糟糕的代码。应该发现一个就修一个，如果没时间就加入注释，并且可以深究窗户什么时候破的，原因是什么，如何修理。\n并且要注意变化，随着软件补丁的添加，会慢慢偏离其规范，周期性地审视环境的变化，以免量变引发的雪崩。\n4. 重复的工作(Don\u0026rsquo;t Repeat Yourself) 这种重复不单单指代码的复制粘贴，还有可能是一些不容易发现的错误。\n强加的重复  例如客户端和服务端使用不同的语言，那么两端都会有类似的数据结构，可以用schema的元数据自动生成相关的类定义。 文档：注释会随代码更新而过时，注释应该用于更加高级的说明，我的理解是注释应该写下这段代码应该干什么，而不是干了什么 语言：例如C/C++应该在头文件的函数声明前说明接口问题，实现文件中记载实现细节 文档和代码：如果边写代码边写文档，就会造成代码和文档的重复问题，比如代码改动了，文档也会随即发生变。如果最开始就根据用户的需求写成文档来生成测试，所有的代码只需要在提交时通过所有的测试即可。  无意的重复 通常是设计问题引起的，注意数据之间的关联性，书中的例子是一个数据集合中同时出现了两个点和一段距离，如果点发生了变化，那么需要同时更改距离，比较好的做法是通过点来计算距离，而不是通过赋值。\n耐性的重复 这就是在项目中放着好好的代码不用，自己重写写个轮子来浪费时间。\n开发者之间的重复 分工不明确导致工作职责重复，这个往往需要清晰的设计和强有力的技术项目领导进行责任划分。\n5. 解耦 接口设计时，应该考虑到传入的类型，比如某个函数需要B类型中的时间成员变量，下面这种耦合度更低。\nvoid foo(B \u0026amp;b) { theTime = b.t; } void foo(time \u0026amp;t) { theTime = t; } 较小响应集 根据统计结果，较大响应集更加容易出错，响应集的定义是：类的各个方法直接调用的函数的数目。\nDemeter法则 wiki：https://en.wikipedia.org/wiki/Law_of_Demeter\n 每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元； 每个单元只能和它的朋友交谈：不能和陌生单元交谈； 只和自己直接的朋友交谈。  在OOP中，这个法则的规定为某个对象的任何方法都应该只调用属于一下情形中的方法：\n 它自身的方法 传入该方法的任何参数的方法 该类所属的成员对象所含有的方法 所持有的任何对象的方法  class Demeter { private: A *a; int func(); public: // ...  void example(B\u0026amp; b); } void Demeter::example(B\u0026amp; b) { C c; int f = func(); // 1. 它自身的方法  b.invert(); // 2. 传入该方法的任何参数的方法  a = new A(); a-\u0026gt;setActive(); // 3. 该类所属的成员对象所含有的方法  c.print() // 4. 所持有的任何对象的方法 } 元数据驱动应用 用配置来定义程序行为，比如使用什么数据库，单机还是多机等，给予程序退路，可撤销性。\n时间耦合 这个名词头一次听到，概念比较简单，这种耦合发生于假定了事件发生的顺序，要考虑事件可能的发生顺序和并发性。\n发布和订阅 这里的意思是将事情/业务拆分成多个例程进行处理，如果用单个例程处理所有的情况，其实就是大量的if、else的组合。如果我们对某个publisher生成的特定事件感兴趣，要做的事情就是登记自己，然后由publisher通知subscriber。\n6. 正交性 正交换个词可以是不相依赖性，解耦性，消除无关事物之间的相互影响。在设计正交组件的时候，可以问自己“如果我显式的改变了某个特定功能背后的需求，有多少模块会受到影响”。\n不要依赖无法控制的事物属性，比如把电话号码作为顾客标识符，如果电话公司重新分配了区号会怎么样。\n在编码时：代码解耦，减少向外暴露的接口和数据，避免全局数据，避免相似的函数。\n构建单元测试的时候，也是对正交性的一种验证，如果只是为了某个测试，需要拉扯到系统中其他一大部分，那么解耦性就没有做的很好。\n修正bug的时候也是，修正一个bug如果要牵扯到系统的很多地方，那么也需要警惕解耦问题。\netc: 可以尝试月报自己的bug所影响文件数目的趋势。\n7. 契约式编程 在项目合作过程中，可能需要不断地和他人的代码进行接合，别人的代码可能不符合高标准代码，所以需要防御性编码。用断言检查坏数据，数据库的列加上约束。更进一步，连自己的代码也不信任，防御性的编程。\n 前条件：调用例程前的需求 后条件：例程保证会做的事情 不变项：在计算机科学中，不变条件是指，在程序执行过程或部分过程中，可始终被假定成立的条件。程序员往往使用断言来现式定义不变条件。  通常前条件是由调用者来保证的，也就是说，如果被调用者需要一个正整数，而调用者传递一个负数，那行为应该是未定义的。\n当调用者确保了例程的前条件后，后条件和不变项都应该为真。\n8. 断言式编程 判断绝不可能发生的事情，而不是进行代替错误处理。并且断言失败会退出进程，最好的是用断言产生异常，跳到某个退出点，执行清理。另外，进行断言的代码，不要再有其他的副作用。\n9. 尽早崩溃 一般来说，尽早的崩溃比隐藏着错误继续运行的结果可能更坏，所以当出现问题的时候及早对程序结束运行。 有时候直接退出不合适，全局资源可能没有释放，比如一些全局锁等，所以可能需要在崩溃前进行清理，打日志等。\n10. 使用异常 很有可能在 C 中看到下面这样的代码\nretcode = OK; if (socket.read(name) != OK) { retcode = BAD_READ; } if (socket.read(age) != OK) { retcode = BAD_READ; } if (socket.read(address) != OK) { retcode = BAD_READ; } return retcode; 过多的判断而导致的丑陋代码，甚至忘记代码原本要做什么就有异常进行专门处理。\nretcode = OK; try { socket.read(name); socket.read(age); socket.read(address); } catch (IOException e) { retcode = BAD_READ; LOG.ERROR(\u0026#34;Error reading from . . .\u0026#34;); } return retcode; 由于C++没有Java那样在try..catch后面有finally子句，所以常常会有重复的情况，违反了DRY((Don\u0026rsquo;t Repeat Yourself)原则，比如：\nvoid doSomething(void) { Node *n = new Node; try { /* do something */ } catch (exception e) { delete n; throw; } delete n; } 碰到这样的情况，这种情况下，通常需要把 n 转变为栈上对象，如果非得需要使用指针，可以利用智能指针进行自动销毁。\n参考资料  《The Programatic Programmer》 https://en.wikipedia.org/wiki/Law_of_Demeter  ","date":"April 12, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/notes/programatic1/","summary":"前言 无意中看到了这本书，译名是程序员修炼之道，想尝试在这本书中找到一些跟软件构建相关问题的答案。这本书虽然是上个世纪出版的，要注意时代的局限性和过期的经验，进行自我验证，但一遍看下来，对我来说，干货还是有很多的。\n1. 需求挖掘 这一点我认为是最重要的一点，于是放在最前面。\n找出用户为何要做特定事情的原因，而不是目前要做这件事情的方式，开发最终是需要解决商业问题。 比如，“只有员工和上级和人事部门才能查看员工的档案”和“只有指定人员能查看员工档案”，后者更加容易编写出适用于元数据编程的程序，也更加的灵活。\n这个用户不仅仅指实际使用的人，也可以是交给你这个工作的人。\n2. 做好退路和保险 书中是用代码所存储的机器因为崩溃而引发的问题，虽然在git的时代，这种问题不容易发生了，但是这种想法得印在脑子里，如果真发生类似的问题，损失将是非常大的。\n这一点和可撤销性想类似，要考虑架构部署的改动和灵活性，假设某次会议决定使用MySQL进行存储数据，但是在快完成时，需要换成其他DB进行存储，如果要改动很大，那么就是错误建立在了假定的决策上面。假定项目以后只会用到MySQL，很多代码都被写死了。\n再比如开发Unix软件，是否考虑所有平台的可以执行问题，例如epoll可以在linux上使用，那么如果在只有Kqueue的FreeBSD上面会怎么样，所以需要保证代码在一些决策上可以变通。\n3. 不要破窗户 这也就是常说的破窗效应，一扇破窗户，只要一段时间不修理，就会逐渐带来废弃感，逐渐变为破败的废弃物。软件中的破窗户就是指，低劣的设计，错误的决策，糟糕的代码。应该发现一个就修一个，如果没时间就加入注释，并且可以深究窗户什么时候破的，原因是什么，如何修理。\n并且要注意变化，随着软件补丁的添加，会慢慢偏离其规范，周期性地审视环境的变化，以免量变引发的雪崩。\n4. 重复的工作(Don\u0026rsquo;t Repeat Yourself) 这种重复不单单指代码的复制粘贴，还有可能是一些不容易发现的错误。\n强加的重复  例如客户端和服务端使用不同的语言，那么两端都会有类似的数据结构，可以用schema的元数据自动生成相关的类定义。 文档：注释会随代码更新而过时，注释应该用于更加高级的说明，我的理解是注释应该写下这段代码应该干什么，而不是干了什么 语言：例如C/C++应该在头文件的函数声明前说明接口问题，实现文件中记载实现细节 文档和代码：如果边写代码边写文档，就会造成代码和文档的重复问题，比如代码改动了，文档也会随即发生变。如果最开始就根据用户的需求写成文档来生成测试，所有的代码只需要在提交时通过所有的测试即可。  无意的重复 通常是设计问题引起的，注意数据之间的关联性，书中的例子是一个数据集合中同时出现了两个点和一段距离，如果点发生了变化，那么需要同时更改距离，比较好的做法是通过点来计算距离，而不是通过赋值。\n耐性的重复 这就是在项目中放着好好的代码不用，自己重写写个轮子来浪费时间。\n开发者之间的重复 分工不明确导致工作职责重复，这个往往需要清晰的设计和强有力的技术项目领导进行责任划分。\n5. 解耦 接口设计时，应该考虑到传入的类型，比如某个函数需要B类型中的时间成员变量，下面这种耦合度更低。\nvoid foo(B \u0026amp;b) { theTime = b.t; } void foo(time \u0026amp;t) { theTime = t; } 较小响应集 根据统计结果，较大响应集更加容易出错，响应集的定义是：类的各个方法直接调用的函数的数目。\nDemeter法则 wiki：https://en.wikipedia.org/wiki/Law_of_Demeter\n 每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元； 每个单元只能和它的朋友交谈：不能和陌生单元交谈； 只和自己直接的朋友交谈。  在OOP中，这个法则的规定为某个对象的任何方法都应该只调用属于一下情形中的方法：\n 它自身的方法 传入该方法的任何参数的方法 该类所属的成员对象所含有的方法 所持有的任何对象的方法  class Demeter { private: A *a; int func(); public: // .","tags":null,"title":"实效性软件构建的途径-上"},{"categories":["sys"],"contents":" “The most effective debugging tool is still careful thought, coupled with judiciously placed print statements” — Brian Kernighan, Unix for Beginners.\n 最朴素的debug方法还是使用print，并且在合适的地方插入print语句，过多的日志信息反而会引起混乱，使debug效率降低。\n日志分级 根据事情的验证程度，可以将事件的严重情况分为：\n INFO WARNING ERROR CRITICAL  每当输出日志的时候，在响应事件前面加上前缀，相关的语言应该都有现成的库，根据需求进行选取即可。\n对于一个事件运行的程序，比如daemon进程，日志输出在响应文件夹，利用grep就能很好的查询不同严重程度的事件的发生情况。\n日志的位置通常在/var/log目录下，例如nginx的日志文件就在/var/log/nginx目录下，系统服务systemd的地址文件就在/var/log/journal目录下。\n日志除了写入文件外，还能通过相关配置写入到套接字/远程服务器上，对日志进行集中处理或存储。\n其他： - 交互式日志查看工具: lnav\ndebug 工具 除了GNU项目中的gdb和python自带的pdb，还有一些能在debug过程中自动显示相关变量以及寄存器值的debug工具：\n pwndb lldb  backtrace 利用strace可以查询一些系统调用的次数，例如\nstore : ~/go \u0026gt;\u0026gt; ls bin pkg src store : ~/go \u0026gt;\u0026gt; sudo strace -e lstat ls -l \u0026gt; /dev/null lstat(\u0026#34;pkg\u0026#34;, {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 lstat(\u0026#34;src\u0026#34;, {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 lstat(\u0026#34;bin\u0026#34;, {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 +++ exited with 0 +++ 通过strace获得ls程序调用了多少次lstat。\n扩展阅读： - https://blogs.oracle.com/linux/strace-the-sysadmins-microscope-v2\n静态分析 静态分析(wiki)就像是对一个文本直接检查，推断相应的语法错误和可能的语法错误。\n例如python有pyflakes，shell脚本有shellcheck，在github上也有相关的静态分析工具集合。\n性能剖析  Premature optimization is the root of all evil\n 通常认为过早优化是不好的，有时间可以读下**Premature Optimization**。\n最简单的性能测试可以通过程序结束的时间减去程序开始运行的时间获得。比如：\n$ time ls \u0026gt; /dev/null real 0m0.002s user 0m0.001s sys 0m0.000s 可以获得三个时间:\n real: 从程序开始到程序结束的时间，包括了I/O，网络的时间 user：运行用户级别代码的时间 sys: 运行内核的时间  CPU 在python中，可以利用cProfile模组进行测试每个函数所使用的时间，line profile测试每一行执行时间。\n内存占用   c/c++: Valgrind https://valgrind.org/\n  python: mem-profiler https://pypi.org/project/memory-profiler/\n  事件采样 perf 简介 perf工具是Linux下用于性能剖析的工具，执行相应的程序，由内核或者硬件来计数程序所触发的事件。\n事件分为几类：\n software events: 完全由内核计数的事件，比如：上下文切换，fault等 PMU hardware events: 由处理器自己或者性能监控单元PMU(Performance Monitoring Unit)提供，比如这些事件：运行CPU时钟的数量，失效指令，L1级cache未命中次数等。由CPU的种类和模型决定。 tracepoint events：由内核的ftrace实现，并且只能用在2.6.3x等更新的内核。  失效指令这个术语是intel中的instructions retired，意思是所执行的指令数目，并不包括由于分支预测失败的那一部分指令。\n Instructions Retired: This event indicates the number of instructions that retired or executed completely. This does not include partially processed instructions executed due to branch mispredictions.\n 回到perf工具，机器所支持的事件列表可以通过list查询:\n$ perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] context-switches OR cs [Software event] cpu-clock [Software event] ... 开始监控一个程序运行 $ perf stat -B dd if=/dev/zero of=/dev/null count=1000000 1000000+0 records in 1000000+0 records out 512000000 bytes (512 MB) copied, 0.461866 s, 1.1 GB/s Performance counter stats for \u0026#39;dd if=/dev/zero of=/dev/null count=1000000\u0026#39;: 453.12 msec task-clock # 0.979 CPUs utilized 43 context-switches # 0.095 K/sec 0 cpu-migrations # 0.000 K/sec 216 page-faults # 0.477 K/sec \u0026lt;not supported\u0026gt; cycles \u0026lt;not supported\u0026gt; instructions \u0026lt;not supported\u0026gt; branches \u0026lt;not supported\u0026gt; branch-misses 0.462827938 seconds time elapsed 0.087344000 seconds user 0.366061000 seconds sys 火焰图 利用perf工具还有一个比较方便的功能就是生成火焰图。\n例如，以上面的例子制作一个火焰图:\n$ git clone git@github.com:brendangregg/FlameGraph.git $ perf record -F 99 -g dd if=/dev/zero of=/dev/null count=1000000 $ perf script \u0026gt; out.perf $ FlameGraph/stackcollapse-perf.pl out.perf \u0026gt; out.folded $ FlameGraph/flamegraph.pl out.folded \u0026gt; myflame.svg 就能得到一个dd命令执行的调用过程的*.svg：\n另外python有pycallgraph，golang也有go tool pprof工具进行性能剖析。\n性能监控 资源概览 除了经常使用的top，还有许多开源的可视化的工具也比较方便。\nhtop glances 磁盘与I/O # io监控 $ iotop # 全局系统磁盘空间使用 df -h # 指定目录占用情况 $ du -sh * # 交互式磁盘占用工具 $ ncdu 内存 $ free -h 打开的文件 $ lsof 网络 常用命令：\n$ ss $ ip $ netstat $ ifconfig 网络使用情况 iftop nethogs MISC 除了这些基本的命令外，还有一些杂项，比如比较两个命令哪个执行得比较快的工具hyperfine:\n还有 cgroup/taskset 等工具，其中cgroup需要单独拿出讲，cgroup在Docker中的资源隔离起着重要作用，先挖个坑。\n参考  https://missing.csail.mit.edu/2020/debugging-profiling/  perf相关:\n http://perf.wiki.kernel.org/index.php/Tutorial https://github.com/brendangregg/FlameGraph  hyperfine:\n https://github.com/sharkdp/hyperfine  ","date":"March 20, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/","summary":"“The most effective debugging tool is still careful thought, coupled with judiciously placed print statements” — Brian Kernighan, Unix for Beginners.\n 最朴素的debug方法还是使用print，并且在合适的地方插入print语句，过多的日志信息反而会引起混乱，使debug效率降低。\n日志分级 根据事情的验证程度，可以将事件的严重情况分为：\n INFO WARNING ERROR CRITICAL  每当输出日志的时候，在响应事件前面加上前缀，相关的语言应该都有现成的库，根据需求进行选取即可。\n对于一个事件运行的程序，比如daemon进程，日志输出在响应文件夹，利用grep就能很好的查询不同严重程度的事件的发生情况。\n日志的位置通常在/var/log目录下，例如nginx的日志文件就在/var/log/nginx目录下，系统服务systemd的地址文件就在/var/log/journal目录下。\n日志除了写入文件外，还能通过相关配置写入到套接字/远程服务器上，对日志进行集中处理或存储。\n其他： - 交互式日志查看工具: lnav\ndebug 工具 除了GNU项目中的gdb和python自带的pdb，还有一些能在debug过程中自动显示相关变量以及寄存器值的debug工具：\n pwndb lldb  backtrace 利用strace可以查询一些系统调用的次数，例如\nstore : ~/go \u0026gt;\u0026gt; ls bin pkg src store : ~/go \u0026gt;\u0026gt; sudo strace -e lstat ls -l \u0026gt; /dev/null lstat(\u0026#34;pkg\u0026#34;, {st_mode=S_IFDIR|0755, st_size=4096, .","tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析"},{"categories":["algorithm"],"contents":"最初的数据库 LSM-tree得从最简单的数据库的shell实现说起，如：\n#! /bin/bash  db_set() { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get() { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } db_set将两个参数简单追加database文件，而db_get利用匹配出来的结果去掉key和逗号得到value，再利用tail获取到最set到database中去。\n读取优化 很明显，由于是追加写也是最简单的写操作，这种set方式通常足够高效，但是对于get，事件复杂度就需要上升到O(n)，所以最常见的想法是对数据追加索引，比如利用哈希表在内存中设置一个key，而key对应的value设置为该key/value在文件中的偏移。\n   key byte offset     abc 0   b 64   \u0026hellip; \u0026hellip;   aacb 3613    就有类似于这样一个哈希表存储在内存中，这也就是Bitcask的核心做法，只需要一次磁盘寻址就可以加载到这个value，适合每个键的值频繁更新的场景。\n存储优化 因为都会往同一个文件追加文件，所以设置键的写入，会造成磁盘空间用尽。解决办法是将日志分解成一定大小的段，文件到达一定大小就关闭，后续的写入写到新的段文件中，读请求仍旧使用旧段文件，当后台线程将后台文件合并/压缩后，读请求就能切换到新的合并段上，旧段文件安全删除。\n其他  文件格式：替换类似于CSV的字符格式为二进制格式。 删除记录：追加删除标记，当合并时检测到这个标记丢弃响应的key 崩溃恢复：这个主要针对存储在内存中的哈希表，当机器宕机后，哈希表将会丢失，重启恢复需要重新读取所有的段文件才能恢复，Bitcask的做法时将相应段的哈希表快照存储磁盘中。 记录写入：写入操作的过程中如果发送了崩溃，那么最新的值将是不完整的，可以在一条记录前追加校验，如果损毁就需要丢弃。 并发控制：写入需要按先后顺序写入，所以写线程通常只有一个，而读取是可以多个同时进行的。  SSTables SSTables全名为排序字符串表(Sort String Tables)，写入的记录会被排序。对key进行排序会有如下的有点：\n 合并段更加高效：方法类似于归并排序，同时读取多个段文件，比较每一个文件的第一个键，将最小的键拷贝到输出文件，重复这个过程，就可以得到一个按键排序的合并段文件。另外就是文件大于可用内存也可以进行，像前面的方法，需要将所有kv都保存在内存中，合并完成才能写入磁盘，而归并的方法只需要维护输入端的数量个kv，即使出现相同的kv，也可以保证他们是相邻的，覆盖即可。 压缩内存：查找特定键时，不需要保存所有键的索引，而是建立稀疏索引，比如1个几KB大小的文件，只需要1个key即可。根据这个key的字典序找到稀疏索引中提供的偏移，读取该部分，找到相应的key即可。 范围查询：请求某个范围内的多个key/value更加方便。  构建和维护SSTables  写入Key写写入内存表(类似于红黑树的平衡树) 内存表大小大于某个阈值，根据二叉排序树的特点，顺序写入磁盘，此时在内存中新生成一个内存表 查表时，先查询内存表找到偏移，如果没找到，那么查找以前的段文件 后台周期性合并，压缩，丢弃不需要的key 写入key需要追加日志(用于恢复内存表)，但是超出阈值并写完当前内存表后，可以删除该日志。  优化SSTables  读取SSTables中不存在的key会回溯到最旧的段文件，所以开销很大，对于这种存在问题，可以使用布隆过滤器。 其他是一些压缩/合并的方式，例如LevelDB/RocksDB使用的分层压缩，HBase使用大小分级，而Cassandra两种都支持。  LSM-tree和SSTables SSTables的算法本质就是LevelDB和RocksDB所使用，并且最初这种索引结构是被称为以日志结构的合并树(Log-Structured Merge-Tree)，因此，基于合并和压缩排序文件原理的存储引擎，通常被称为LSM存储引擎。\nB-tree B树其实已经非常熟悉了，常见于各大关系型数据的索引。Btree也是按键排序的key-value对，以及高效的区间查询。但是在存储方面，是以4KB甚至更大作为存储单元，这样更加借鉴底层硬件。\n由于B树也保持平衡，具有n个key的B树深度也是O(log n)，其中一个页中包含子页的引用数量称为分页因子，当分页因子为500的4KB页的四级树可存储256TB数据。\n崩溃问题：和日志合并树一样，也要考虑写时发生崩溃的问题，因为在重写页时，如果发生崩溃直接导致的结果是索引破坏，所以需要预写日志WAL(WriteAhead Log)在写入前，追加写入日志文件，用于恢复B树到最近一致状态。\n优化B-tree  写时复制：修改的页被写入不同位置，创建完成后修改父页中的引用。这样就不用覆盖和维护WAL 保存键的缩略信息，减少key在页内占用，增加分页因子，降低层数 尝试让页的磁盘位置更加接近，减少寻道时间 另外一点就是常见的添加一个额外的指针到相邻的页，这样就不需要跳回父页，减少不必要的I/O 最后就是分型树等等  LSM-tree和B-tree的优劣 通常认为B树读取更快，而LSM树写入更快。\nLSM-tree的优点 对于B树来说，一次写操作需要写两次磁盘：\n 写入日志(WAL) 写入到实际的B树中，另外还有页分裂的可能，导致多次I/O  而对于LSM树来说：\n 追加写一次 但是又反复的后台压缩和SSTables合并  所以要注意一次写入请求会导致多次磁盘写(写放大)，SSD由于其物理性质所决定，只能承受住比机械硬盘更低覆盖重写次数，所以需要加入考量，另外，如果写入磁盘占用的带块越多，可用的磁盘带宽也就越少。而LSM时拥有较低的写放大。\n另外，回到SSTables的构建，LSM的写入时是从内存一次性写入到磁盘的，也就是其磁盘块更加连续，顺序写比随机写要快得多，相比于分散的磁盘块，拥有更低的寻道时间。相关联的还有碎片化问题，由于B树是面向页的，也可能被分裂成多个页时，页中空间无法使用，导致碎片化。而SSTables的定期合并可以消除碎片话，拥有更加紧凑的数据表达方式。\nLSM-tree的缺点  压缩过程(I/O)中会干扰当前读写操作(I/O)，造成读写等待。 另外B-tree的key在磁盘中，只有一个副本，而LSM-tree有多个。所以在关系型数据库中，B树可以直接定义锁在页中，完成键范围上的事务隔离。  参考  《数据密集型应用系统设计》  ","date":"March 18, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/b-tree-and-lsm-tree/","summary":"最初的数据库 LSM-tree得从最简单的数据库的shell实现说起，如：\n#! /bin/bash  db_set() { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get() { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } db_set将两个参数简单追加database文件，而db_get利用匹配出来的结果去掉key和逗号得到value，再利用tail获取到最set到database中去。\n读取优化 很明显，由于是追加写也是最简单的写操作，这种set方式通常足够高效，但是对于get，事件复杂度就需要上升到O(n)，所以最常见的想法是对数据追加索引，比如利用哈希表在内存中设置一个key，而key对应的value设置为该key/value在文件中的偏移。\n   key byte offset     abc 0   b 64   \u0026hellip; \u0026hellip;   aacb 3613    就有类似于这样一个哈希表存储在内存中，这也就是Bitcask的核心做法，只需要一次磁盘寻址就可以加载到这个value，适合每个键的值频繁更新的场景。\n存储优化 因为都会往同一个文件追加文件，所以设置键的写入，会造成磁盘空间用尽。解决办法是将日志分解成一定大小的段，文件到达一定大小就关闭，后续的写入写到新的段文件中，读请求仍旧使用旧段文件，当后台线程将后台文件合并/压缩后，读请求就能切换到新的合并段上，旧段文件安全删除。\n其他  文件格式：替换类似于CSV的字符格式为二进制格式。 删除记录：追加删除标记，当合并时检测到这个标记丢弃响应的key 崩溃恢复：这个主要针对存储在内存中的哈希表，当机器宕机后，哈希表将会丢失，重启恢复需要重新读取所有的段文件才能恢复，Bitcask的做法时将相应段的哈希表快照存储磁盘中。 记录写入：写入操作的过程中如果发送了崩溃，那么最新的值将是不完整的，可以在一条记录前追加校验，如果损毁就需要丢弃。 并发控制：写入需要按先后顺序写入，所以写线程通常只有一个，而读取是可以多个同时进行的。  SSTables SSTables全名为排序字符串表(Sort String Tables)，写入的记录会被排序。对key进行排序会有如下的有点：","tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree"},{"categories":["sys"],"contents":"前言 因为前段时间把6.824的lab3做完了，但是lab内部是用channel mock了一个简单的网络来测试网络丢包，网络分区等问题，也就是说跑在单机上面，其rpc也是通过channel和反射实现。目前比较有名的RPC框架就是gRPC，golang也自带了rpc库，这篇文章主要讲述这两者的简单使用，以及谈论一些关于rpc的观点。\nRPC历史 RPC也称远程过程调用，自从上世纪70年代就存在的思想，RPC模型是尝试使远程服务看起来像在统一进程空间的函数一样。但是，一种基于HTTP原则的设计理念REST可以扮演RPC的角色，利用url表示资源，利用HTTP的其他功能提供身份验证等，并且RPC虽然看上去非常简洁，实际上是存在缺陷的，比如rpc的时间根据网络情况可能大不相同，网络不可信时，超时重传会使RPC函数被调用多次，这就又需要这个函数能保证幂等性等。\n虽然有以上问题，RPC没有消失肯定有其独特存在的原因，首先是使用二进制编码的RPC协议能实现比REST上基于JSON的数据流协议获得更好的性能(但是JSON数据流可以提供良好的调试功能，这是二进制编码不可比拟的)。所以REST一般用于公共API，而RPC框架侧重于同一组织内多项服务之间的请求，也通常发生在同一个数据中心。\nRPC的目标是让客户端和服务端易于交互(编程意义上)，隐藏底层的网络协议。\n原生RPC 这里直接尝试写一个简单的KV服务，提供Put，Get的接口。\n客户端代码 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc\u0026#34; ) // // Common RPC request/reply definitions //  const ( OK = \u0026#34;OK\u0026#34; ErrNoKey = \u0026#34;ErrNoKey\u0026#34; ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Client //  func connect() *rpc.Client { client, err := rpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;fatwaer.store:1234\u0026#34;) if err != nil { log.Fatal(\u0026#34;dialing:\u0026#34;, err) } return client } func get(key string) string { client := connect() args := GetArgs{\u0026#34;subject\u0026#34;} reply := GetReply{} err := client.Call(\u0026#34;KV.Get\u0026#34;, \u0026amp;args, \u0026amp;reply) if err != nil { log.Fatal(\u0026#34;error:\u0026#34;, err) } client.Close() return reply.Value } func put(key string, val string) { client := connect() args := PutArgs{\u0026#34;subject\u0026#34;, \u0026#34;6.824\u0026#34;} reply := PutReply{} err := client.Call(\u0026#34;KV.Put\u0026#34;, \u0026amp;args, \u0026amp;reply) if err != nil { log.Fatal(\u0026#34;error:\u0026#34;, err) } client.Close() } // // main //  func main() { put(\u0026#34;subject\u0026#34;, \u0026#34;6.824\u0026#34;) fmt.Printf(\u0026#34;Put(subject, 6.824) done\\n\u0026#34;) fmt.Printf(\u0026#34;get(subject) -\u0026gt; %s\\n\u0026#34;, get(\u0026#34;subject\u0026#34;)) } 服务端代码 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;sync\u0026#34; ) // // Common RPC request/reply definitions //  const ( OK = \u0026#34;OK\u0026#34; ErrNoKey = \u0026#34;ErrNoKey\u0026#34; ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Server //  type KV struct { mu sync.Mutex data map[string]string } func server() { kv := new(KV) kv.data = map[string]string{} rpcs := rpc.NewServer() rpcs.Register(kv) l, e := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if e != nil { log.Fatal(\u0026#34;listen error:\u0026#34;, e) } fmt.Println(\u0026#34;server Listen \u0026#34;) for { conn, err := l.Accept() if err == nil { go rpcs.ServeConn(conn) } else { break } } l.Close() } func (kv *KV) Get(args *GetArgs, reply *GetReply) error { fmt.Printf(\u0026#34;server recive get %s\\n\u0026#34;, args.Key) kv.mu.Lock() defer kv.mu.Unlock() val, ok := kv.data[args.Key] if ok { reply.Err = OK reply.Value = val } else { reply.Err = ErrNoKey reply.Value = \u0026#34;\u0026#34; } return nil } func (kv *KV) Put(args *PutArgs, reply *PutReply) error { fmt.Printf(\u0026#34;server recive put %s-\u0026gt;%s\\n\u0026#34;, args.Key, args.Value) kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value reply.Err = OK return nil } // // main //  func main() { server() } 运行结果 分别在两台云服务器上运行，确保可以通过网络传递消息：\n代码结构 Software structure\rclient app handler fns\rstub fns dispatcher\rRPC lib RPC lib\rnet ------------ net\r客户端/服务端需要先建立相应的TCP连接，即服务端先在相应端口绑定监听，然后客户端与该端口三次握手后，服务端accept返回得到建立好的TCP连接，注册到RPC中，然后将数据写入到连接内，服务端收到调用，执行相应的程序返回。\n gRPC gRPC的使用分为三部:\n 将需要在网络中传递的数据/服务定义在.proto里 利用protocol buffer compiler基于上面的.proto生成代码 使用gRPC的API  安装依赖  grpc  go get google.golang.org/grpc go get -u github.com/golang/protobuf/protoc-gen-go export PATH=$PATH:$GOPATH/bin  protocol buffer compiler(protoc)  PROTOC_ZIP=protoc-3.7.1-linux-x86_64.zip curl -OL https://github.com/protocolbuffers/protobuf/releases/download/v3.7.1/$PROTOC_ZIP sudo unzip -o $PROTOC_ZIP -d /usr/local bin/protoc sudo unzip -o $PROTOC_ZIP -d /usr/local \u0026#39;include/*\u0026#39; rm -f $PROTOC_ZIP 定义自己的proto  kv.proto  syntax = \u0026quot;proto3\u0026quot;;\rpackage kv;\rservice kv {\rrpc Put (PutArgs) returns (PutReply) {}\rrpc Get (GetArgs) returns (GetReply) {}\r}\rmessage PutArgs {\rstring key = 1;\rstring value = 2;\r}\rmessage PutReply {\rstring ok = 1;\r}\rmessage GetArgs {\rstring key = 1;\r}\rmessage GetReply {\rstring ok = 1;\rstring value = 2;\r}\rsyntax为protobuf编码版本，message类似于类型定义关键字，而每一个message内都需要有一个单独的值来指定某个变量。\n生成 .pb.go 例如如下的代码结构：\nstore : ~/gokv/grpc/src \u0026gt; tree . . ├── kv │ ├── kv.proto store : ~/gokv/grpc/src \u0026gt; echo $GOPATH /root/go:/root/gokv/grpc 执行\nprotoc -I kv/ kv/kv.proto --go_out=plugins=grpc:kv 在kv目录下生成kv.pb.go，然后在外部利用import kv即可使用kv.pb.go中生成的代码。 kv.pb.go包含了如下内容：\n 生成的服务端和客户端的代码 对调用参数进行序列化、反序列化的代码  写自己的KV服务 和上面原生RPC的类似：\n 服务端代码  package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; pb \u0026#34;kv\u0026#34; ) const ( port = \u0026#34;:1234\u0026#34; ) // server is used to implement kv.Kvserver. type server struct { data map[string] string mu sync.Mutex pb.UnimplementedKvServer } // Put implements implement kv.Kvserver func (s *server) Put(ctx context.Context, in *pb.PutArgs) (*pb.PutReply, error) { log.Printf(\u0026#34;Received Put: %v\u0026#34;, in) s.mu.Lock() defer s.mu.Unlock() s.data[in.Key] = in.Value return \u0026amp;pb.PutReply{Ok: \u0026#34;Ok\u0026#34;}, nil } func (s *server) Get(ctx context.Context, in *pb.GetArgs) (*pb.GetReply, error) { log.Printf(\u0026#34;Received Get: %v\u0026#34;, in) s.mu.Lock() defer s.mu.Unlock() value := s.data[in.Key] return \u0026amp;pb.GetReply{Ok: \u0026#34;Ok\u0026#34;, Value:value}, nil } func main() { log.Printf(\u0026#34;server start\\n\u0026#34;) lis, err := net.Listen(\u0026#34;tcp\u0026#34;, port) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } rpcs := grpc.NewServer() srv := new(server) srv.data = map[string]string{} pb.RegisterKvServer(rpcs, srv) log.Printf(\u0026#34;Listen at %s\\n\u0026#34;, port) if err := rpcs.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } }  客户端代码  package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; pb \u0026#34;kv\u0026#34; ) const ( address = \u0026#34;fatwaer.store:1234\u0026#34; ) func main() { // set-up connection.  conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;didn\u0026#39;t connect: %v\u0026#34;, err) } defer conn.Close() c := pb.NewKvClient(conn) log.Printf(\u0026#34;connect ok\u0026#34;) ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.Put(ctx, \u0026amp;pb.PutArgs{Key: \u0026#34;Hello\u0026#34;, Value: \u0026#34;World\u0026#34;}) if err != nil { log.Fatalf(\u0026#34;put err %v\u0026#34;, err) } log.Printf(\u0026#34;put %s\u0026#34;, r.GetOk()) nr, err := c.Get(ctx, \u0026amp;pb.GetArgs{Key: \u0026#34;Hello\u0026#34;}) if err != nil { log.Fatalf(\u0026#34;put err %v\u0026#34;, err) } log.Printf(\u0026#34;get %s, get value %s\u0026#34;, nr.GetOk(), nr.GetValue()) } 运行结果 和原生RPC使用很类似，但是中间加了一层protobuf的使用问题，而protobuf的存在却可以解决在多语言之间进行通信的问题，而原生不行。 参考资料  《数据密集型应用系统设计》 https://pdos.csail.mit.edu/6.824/notes/kv.go https://pdos.csail.mit.edu/6.824/notes/l-rpc.txt https://developers.google.com/protocol-buffers/docs/overview https://developers.google.com/protocol-buffers/docs/proto https://grpc.io/docs/tutorials/basic/go/ http://google.github.io/proto-lens/installing-protoc.html  ","date":"February 26, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/sys/rpc-and-grpc/","summary":"前言 因为前段时间把6.824的lab3做完了，但是lab内部是用channel mock了一个简单的网络来测试网络丢包，网络分区等问题，也就是说跑在单机上面，其rpc也是通过channel和反射实现。目前比较有名的RPC框架就是gRPC，golang也自带了rpc库，这篇文章主要讲述这两者的简单使用，以及谈论一些关于rpc的观点。\nRPC历史 RPC也称远程过程调用，自从上世纪70年代就存在的思想，RPC模型是尝试使远程服务看起来像在统一进程空间的函数一样。但是，一种基于HTTP原则的设计理念REST可以扮演RPC的角色，利用url表示资源，利用HTTP的其他功能提供身份验证等，并且RPC虽然看上去非常简洁，实际上是存在缺陷的，比如rpc的时间根据网络情况可能大不相同，网络不可信时，超时重传会使RPC函数被调用多次，这就又需要这个函数能保证幂等性等。\n虽然有以上问题，RPC没有消失肯定有其独特存在的原因，首先是使用二进制编码的RPC协议能实现比REST上基于JSON的数据流协议获得更好的性能(但是JSON数据流可以提供良好的调试功能，这是二进制编码不可比拟的)。所以REST一般用于公共API，而RPC框架侧重于同一组织内多项服务之间的请求，也通常发生在同一个数据中心。\nRPC的目标是让客户端和服务端易于交互(编程意义上)，隐藏底层的网络协议。\n原生RPC 这里直接尝试写一个简单的KV服务，提供Put，Get的接口。\n客户端代码 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc\u0026#34; ) // // Common RPC request/reply definitions //  const ( OK = \u0026#34;OK\u0026#34; ErrNoKey = \u0026#34;ErrNoKey\u0026#34; ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Client //  func connect() *rpc.","tags":["distributed system"],"title":"Golang原生RPC与gPRC"},{"categories":["language"],"contents":"前言 这篇笔记主要是说明一些bash scripts中要注意的问题，比如变量的赋值，函数，Shebang，特殊变量，通配符等；以及介绍一些提高在shell环境下提高工作效率的工具，例如查看使用方法的时候，可以快速翻阅 TLDR 获取命令的用法，而不用使用 man 手册慢慢地找相关的参数等。\n基本变量 赋值变量通过 foo=bar 来完成，并且带空格的 foo = bar 不会成功，因为相当于直接连续调用 foo 、 = 、 bar 三个命令，另外双引号 \u0026quot; 会展开变量而单引号不会 ' 。\nfoo=bar echo \u0026#34;$foo\u0026#34; # prints bar echo \u0026#39;$foo\u0026#39; # prints $foo 函数 mcd.sh\nmcd () { mkdir -p \u0026#34;$1\u0026#34; cd \u0026#34;$1\u0026#34; } Here $1 is the first argument to the script/function\n $0 - Name of the script $1 to $9 - Arguments to the script. $1 is the first argument and so on. $@ - All the arguments $# - Number of arguments $? - Return code of the previous command $$ - Process Identification number for the current script !! - Entire last command, including arguments. A common pattern is to  更多参数相关\nSpecial Characters\n加载函数 source mcd.sh mcd test  利用source读取函数后可以把.sh中的函数加载到shell环境中，于是可以直接使用函数名作为命令来执行，这里产生一个test文件并且进入到test目录中。\n 条件截断 类似于其他编程语言的函数截断，一般用于测试上一条命令的执行结果。\nfalse || echo \u0026#34;Oops, fail\u0026#34; # Oops, fail true || echo \u0026#34;Will not be printed\u0026#34; # true \u0026amp;\u0026amp; echo \u0026#34;Things went well\u0026#34; # Things went well false \u0026amp;\u0026amp; echo \u0026#34;Will not be printed\u0026#34; # false ; echo \u0026#34;This will always run\u0026#34; # This will always run  命令替代 当在shell使用 $(CMD) 后，CMD命令将会被执行，并且会将这条命令的输出给替换掉。例如 for file in $(ls)先会调用ls，然后变量所有ls所输出的文件名。\n另外一个很少被人知道的特性叫做 过程替代(process substitution), \u0026lt;( CMD ) 将会执行CMD指令，并且把输出放到一个临时文件内，然后把\u0026lt;()替换为这个临时文件的名字。例如 diff \u0026lt;(ls foo) \u0026lt;(ls bar) 将会显示 foo 和 bar 两个目录内的不同\n#!/bin/bash  echo \u0026#34;Starting program at $(date)\u0026#34; # Date will be substituted echo \u0026#34;Running program $0with $#arguments with pid $$\u0026#34; for file in $@; do grep foobar $file \u0026gt; /dev/null 2\u0026gt; /dev/null # When pattern is not found, grep has exit status 1 # We redirect STDOUT and STDERR to a null register since we do not care about them if [[ $? -ne 0 ]]; then echo \u0026#34;File $filedoes not have any foobar, adding one\u0026#34; echo \u0026#34;# foobar\u0026#34; \u0026gt;\u0026gt; \u0026#34;$file\u0026#34; fi done 这个脚本所完成的事情是：在所有参数文件中，如果没有文件内没有grep到foobar这个字符串，那么就会输出 File $file does not have any foobar, adding one 输出到标准输出，然后追加 # foobar\u0026quot; \u0026gt;\u0026gt; \u0026quot;$file 到 $file 的结尾。\n其中：\n$# 代表该脚本执行使用的PID，\n$@ 所有参数，不包括$0。\n$? 代表grep指令的运行结果，如果没有匹配到会输出不等于0的值。\n\u0026gt; /dev/null 即 1 \u0026gt; /dev/null将标准输出指向null，\n2 \u0026gt; /dev/null 将标准错误输出指向null。\nif 判断中的逻辑词和其他编程语言有些区别，具体可以看 http://man7.org/linux/man-pages/man1/test.1.html\n[]和[[]] 的区别:\nhttp://mywiki.wooledge.org/BashFAQ/031\n [ (\u0026ldquo;test\u0026rdquo; command) and [[ (\u0026ldquo;new test\u0026rdquo; command) are used to evaluate expressions. [[ works only in Bash, Zsh and the Korn shell, and is more powerful; [ and test are available in POSIX shells.\n 一般来说使用 [[]] 这种形式犯错的机会更少。\nshell globbing 一共分为两类：\n  通配符(Wildcards)： ? 和 * 给定文件 foo, foo1, foo2, foo10, bar， rm foo? 会删除foo1和foo2， rm foo* 将会删除除了bar的所有文件。\n  Curly braces {}\n  convert image.{png,jpg} # Will expand to convert image.png image.jpg cp /path/to/project/{foo,bar,baz}.sh /newpath # Will expand to cp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath # Globbing techniques can also be combined mv *{.py,.sh} folder # Will move all *.py and *.sh files mkdir foo bar # This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/h touch {foo,bar}/{a..j} touch foo/x bar/y # Show differences between files in foo and bar diff \u0026lt;(ls foo) \u0026lt;(ls bar) # Outputs # \u0026lt; x # --- # \u0026gt; y  Shebang #!/usr/local/bin/python import sys for arg in reversed(sys.argv[1:]): print(arg) shell 知道使用python解释器而不是shell是因为写了一行叫做shebang的在脚本顶部。\n但是由于不同机器的安装不一样，所以可以通过env来定位 #!/usr/bin/env python\n 函数与shell脚本的区别  函数的语言需要和shell的语言相同，需要写shebang，所以前面mcd在不同的系统上不能使用，脚本倒是可以使用任意语言（废话 函数会在定义式被读取的时候加载，脚本每次都会重新加载，函数比脚本稍微快点，但是每次修改都需要重新加载。 函数是在shell环境下执行，能修改环境变量，而脚本在其进程中执行，所以执行脚本并不能改变文件路径，可以通过 export 来设置脚本的环境变量 modularity, code reuse and clarity of shell code，shell 脚本里也会有自己的函数  命令行工具 shellcheck   安装 koalaman/shellcheck\nyum -y install epel-release yum install ShellCheck   使用\niZbp1237a4x521y1gkpax4Z : /tmp/missing \u0026gt; shellcheck random.sh n=$(( RANDOM % 100 )) ^-- SC2034: n appears unused. Verify it or export it. In random.sh line 5: if [[ n -eq 42 ]]; then ^-- SC2130: -eq is for integer comparisons. Use = instead. ^-- SC2050: This expression is constant. Did you forget the $ on a variable?d 相当于shell脚本编译器，然后根据产生的错误到 shellcheck wiki找原因。\n  TLDR 出去敲 -help 或者 man cmd 的方式查询使用，当仅仅只想知道某个命令怎么使用的时候，可以使用TLDR查询用法。\n直接访问：https://tldr.ostera.io/xargs\n或者去github下载相关客户端显示在命令行上：https://tldr.sh/\n文件搜索: find使用 # Find all directories named src find . -name src -type d # Find all python files that have a folder named test in their path find . -path \u0026#39;**/test/**/*.py\u0026#39; -type f # Find all files modified in the last day find . -mtime -1 # Find all zip files with size in range 500k to 10M find . -size +500k -size -10M -name \u0026#39;*.tar.gz\u0026#39; find后批量执行 # Delete all files with .tmp extension find . -name \u0026#39;*.tmp\u0026#39; -exec rm {} \\; # Find all PNG files and convert them to JPG find . -name \u0026#39;*.png\u0026#39; -exec convert {} {.}.jpg \\; 文件搜索: fd fd 是 find 的简化版本，人性化许多。\n How to install fd on CentOS sharkdp/fd    文件搜索: locate locate也是一个用来找文件的命令，使用也比较简单。\niZbp1237a4x521y1gkpax4Z : ~ \u0026gt; locate run.sh /run.sh /root/run.sh /root/.vim/plugged/YouCompleteMe/third_party/requests_deps/urllib3/_travis/run.sh /root/.vim/plugged/YouCompleteMe/third_party/ycmd/third_party/requests_deps/urllib3/_travis/run.sh /root/mc/run.sh /root/minecraft/run.sh /root/openssl/openssl-OpenSSL_1_1_1-stable/demos/certs/ocsprun.sh /root/ssr/shadowsocksr/logrun.sh iZbp1237a4x521y1gkpax4Z : ~ \u0026gt; 但是locate有一些容易犯错的点，locate是通过unpdatedb来查询的，而updatedb通过crond进行更新，一般一天更新一次，所以有时候新下载下来的文件会出现找不到的情况，这时可以手动updatedb，即:\n$ updatedb $ locate file 像我的centos上并没有自带locate，安装为：\n$ yum -y install mlocate 找代码: grep 常用的例子还是得看 TLDR：https://tldr.ostera.io/grep，而自己最常用的还是 grep -rn 'content' * ， -r 用于递归， -n 用于打印行数。\n另外还有ack, ag, rg等就不一一列举了。\n ack: https://beyondgrep.com/ ag: https://github.com/ggreer/the_silver_searcher rg: https://github.com/BurntSushi/ripgrep  找指令 这里倒是很简单，利用 ctrl+r 可以在历史里反向搜索，以及简单的利用管道进行grep： history | grep cmd 。另外 fzf 在这里推荐使用一下，在必要的时候可能比较有用。 fzf：https://github.com/junegunn/fzf/wiki/Configuring-shell-key-bindings#ctrl-r\n一些其他的shell，和bash不同，提供了基于历史的自动建议型shell，像 zsh 和 fish 内都提供有。如果在命令中敲入了一些以明文显示的敏感性文字的话，可以在.bash_history或者.zhistory中删除。\nTips: 自己的机器可以使用一些便捷的的工具，但如果需要管理多台服务器甚至是集群，linux提供的最基础的find等命令还是记清楚的好。\n目录导航 命令行下查看目录确实没有那么直观，可以利用 ln -s 创建一个软连接快速选择，当然也有一些命令行下的工具：\nFasd ranks files and directories by frecency\n fasd :https://github.com/clvv/fasd  get an overview of a directory structure:\n tree: https://linux.die.net/man/1/tree broot: https://github.com/jarun/nnn  full fledged file managers:\n nnn: https://github.com/jarun/nnn ranger: https://github.com/ranger/ranger  练习   Read [man ls](http://man7.org/linux/man-pages/man1/ls.1.html) and write an ls command that lists files in the following manner\n Includes all files, including hidden files Sizes are listed in human readable format (e.g. 454M instead of 454279954) Files are ordered by recency Output is colorized  ls -alth --color=auto   Write bash functions marco and polo that do the following. Whenever you execute marco the current working directory should be saved in some manner, then when you execute polo, no matter what directory you are in, polo should cd you back to the directory where you executed marco. For ease of debugging you can write the code in a file marco.sh and (re)load the definitions to your shell by executing source marco.sh\n#!/bin/bash # marco.sh path=$(pwd) export MARCOPATH=$path } #!/bin/bash # polo.sh cd \u0026#34;$MARCOPATH\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;cd error\u0026#34; } Marco Polo →（马可·波罗) :)\n  Say you have a command that fails rarely. In order to debug it you need to capture its output but it can be time consuming to get a failure run. Write a bash script that runs the following script until it fails and captures its standard output and error streams to files and prints everything at the end. Bonus points if you can also report how many runs it took for the script to fail.\n#!/bin/bash  return_code=0 while [[ $return_code -eq 0 ]] do output=$(sh \u0026#34;$1\u0026#34; 2\u0026gt;\u0026amp;1) return_code=$? cnt=$((cnt+1)) done cnt=$((cnt-1)) echo \u0026#34;failed after ${cnt}th.\u0026#34; echo \u0026#34;output:\u0026#34; echo \u0026#34;$output\u0026#34;   As we covered in lecture find’s -exec can be very powerful for performing operations over the files we are searching for. However, what if we want to do something with all the files, like creating a zip file? As you have seen so far commands will take input from both arguments and STDIN. When piping commands, we are connecting STDOUT to STDIN, but some commands like tar take inputs from arguments. To bridge this disconnect there’s the [xargs](http://man7.org/linux/man-pages/man1/xargs.1.html) command which will execute a command using STDIN as arguments. For example ls | xargs rm will delete the files in the current directory.\nYour task is to write a command that recursively finds all HTML files in the folder and makes a zip with them. Note that your command should work even if the files have spaces (hint: check -d flag for xargs)\nfind . -name *.html -type f | xargs tar cf target.tar   ","date":"February 13, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/shell-tools-and-scripting/","summary":"前言 这篇笔记主要是说明一些bash scripts中要注意的问题，比如变量的赋值，函数，Shebang，特殊变量，通配符等；以及介绍一些提高在shell环境下提高工作效率的工具，例如查看使用方法的时候，可以快速翻阅 TLDR 获取命令的用法，而不用使用 man 手册慢慢地找相关的参数等。\n基本变量 赋值变量通过 foo=bar 来完成，并且带空格的 foo = bar 不会成功，因为相当于直接连续调用 foo 、 = 、 bar 三个命令，另外双引号 \u0026quot; 会展开变量而单引号不会 ' 。\nfoo=bar echo \u0026#34;$foo\u0026#34; # prints bar echo \u0026#39;$foo\u0026#39; # prints $foo 函数 mcd.sh\nmcd () { mkdir -p \u0026#34;$1\u0026#34; cd \u0026#34;$1\u0026#34; } Here $1 is the first argument to the script/function\n $0 - Name of the script $1 to $9 - Arguments to the script.","tags":["shell","globbing"],"title":"Shell Tools and Scripting"},{"categories":["sys"],"contents":"强一致性Key/Value服务 其实在写完Raft后，K/V的接口已经比较明显了，只需要将操作写入Raft entry的Command内，然后等待Raft的同步，再应用到状态机（例如map[string]string）即可，但是实际上在跑3A测试的时候还是出现了很多问题。\n并发(Concurrency) 虽然保证同一个客户端同时只会发送一个Put或者Get请求，但是在面对多个客户端时，如何处理这些请求，并且将这些请求写入到Raft的log entry中。老生常谈的问题，但是在这里处理比较简单，在Raft开始协调一个新的共识(Agreement)的时候,也就是start()，已经使用了mutex来附加新的entry到log中。\n网络不可靠(Unreliable) 这里是在3A碰到的第一个要认真考虑的点，如果一个RPC请求（比如append “1”-\u0026gt;\u0026ldquo;2\u0026rdquo;）经过了慢速网络而触发了重传，导致这个RPC被调用了两次，所以在Hint中有提醒，让client的每一个请求都有一个独一无二的ID来保证每个操作只能被执行一次。而如何使得每个操作只会被执行一次，并保证幂等性，还需要考虑到接下来的几个情况。\n服务器主机崩溃(Crash) 服务器主机崩溃的情景里要考虑的不是网络问题，而是当发生了主机崩溃，往往代表着新的一轮选举和新的leader诞生。所以当真正发生leader切换的时候，客户端需要做的事情是将当前的RPC重新发往新的leader。另外一点是持久化问题，这个会在快照机制中遇到一些需要思考的点。\n网络分区(Partition) 由于是实现一个强一致性的KV服务，在并发条件下，每一个Get/Put/Append操作都会被按顺序执行一次，而每次调用都需要监控之前的操作序列所做的操作所带来的影响，就好像在调用前，前面的所有的调用已经完成，通常称其为线性化。\n最先碰到网络分区和检查一致性是TestOnePartition3A，这个测试中做了如下几件事情：\n 创建一个5个server的kv服务器集群 客户端请求: Put:1 -\u0026gt; 13 建立网络分区，3台主机处于大多数(majority)，另外两台主机(保证有一台是leader)处于少数(minority)。 往majority中提交Put:1-\u0026gt;14 检查majority 往minority中提交操作Put:1 -\u0026gt; 15和Get:1 检测6中两个操作是否会成功 往majority提交Put:1-\u0026gt;16并检查 合并两个分区，检查最后Key 1的值。  最后的值应该为15，在这里碰到的一致性检查是关于第六步Get操作，从Raft可以知道在minority中提交的操作是不会被commit的，更不会被应用到状态机，此时minority中的key 1的值是13，相比于majority中的14，是一个过期的值，所以6步中的Get RPC在分区合并前不应该返回。\n当分区合并后，minority的leader会被majority中的新leader的心跳设置为follower，所以旧leader的kv服务应该检测到自己不再是leader而返回现存的RPC：Put:1 -\u0026gt; 15和Get:1，使客户端重定向到新的leader。\n而Get什么时候返回？这个在Hint中也提到了，最方便的做法就是将Get也塞入raft的log entry内，在这种情境下，处于minority分区的Get操作就会被读取到过期的数据。\n标识操作(UniqueID) 如何为每一个操作定独一无二ID？我的做法是每个操作维护三个变量以及新加一个RPC用于客户端注册：\n seriesN：每个客户端初始化为-1，每执行一次Get/Put/Append调用前自增1。 Client ID：初始化为-1，用于辨识客户端，由kv服务端来分配，客户端进行维护。 Server ID：代表分配Client ID的服务端，用于解决同一个操作因为leader切换而造成ID冲突。  每当启用一个新的客户端并且提交操作时，先自增seriesN，如果Client ID为-1，就会向服务端注册自己，即请求一个可用的Client ID，并设置Server ID。每当一个操作在raft中达成共识时，应用到状态机后，应该记录Cid和Sid的最大值，用于防止重复的操作被提交到状态机。\n当出现小于当前seriesN的操作出现时，需要返回一个duplicate的错误告知客户端。\n考虑下面这种情景：\ns1 | x = 0 | x += 1 同步到其他server s2 | x = 0 | x += 1 s3 | x = 0 | x += 1 s4 | x = 0 | x += 1 s5 | x = 0 | nil   leader s1 提交了一个 x += 1 的操作后，并同步到了s2, s3, s4，然后发生分区。 s2 当选新一轮的leader，并同步完成 s1 恢复到该分区中，被s2的心跳转变为follower client对s1的rpc被返回，重定向到s2，重复的op被提交。  这里也可以通过比较相同clinetID的seriesN来决定是否应用到状态机，但是如果第一步中，x += 1 并没有提交到s1以外的服务器，s2服务器当选leader后先为另一个client分配了相同的client ID，在分区合并前提交过几次操作，那么 x += 1的操作将会被驳回，所以这里需要server ID处理命名空间的冲突。\n既然服务端要分配client ID，那么如何记住这些id以应对服务器崩溃，比较简单的办法是分配一个client ID后就做一次持久化，因为真正进行提交操作的client并不是很多也并不频繁。另外一种方法是根据raft的applyMsg会带有Sid，Cid，SeriesN三者，所以当服务crash后重启时，会随着一致性检查恢复之前自己已经分配过的Cid。\nPart A内容的大致就是这些，还剩一些优化的细节，比如client在找到server后就记住server的索引，没必要每次都向集群所有服务器发送请求。关于RPC，配置到服务器上时，没必要为每次RPC都新建一次连接，应该维护住这个连接直到主动断开或者发生错误。\n快照(Snapshot) 快照机制主要作用是两点:\n 一是压缩日志，实际系统中，日志不能在内存中无限增长，如果没有相关机制清理陈旧的信息，那么会产生可用性的问题。日志压缩除了利用快照机制外，在Raft论文中还有提到了利用LSM-Tree对Raft的日志进行增量压缩的方法，由于保证日志的增长是顺序的，在这里利用日志结构树能承受住更高的I/O吞吐量。 第二点是在写Lab中发现的，拥有快照机制的Raft能够更快地使落后的(发生了崩溃或者网络分区)follower恢复到同步水平。  Snapshot要做什么 快照所做的事情也比较简单，主要针对的是那些已经提交过的条目(即在大多是中达成共识)进行压缩，让这些条目所应用后的状态有一个备份，然后再将这些进行截断即可。因为没有必要每应用一个条目就执行一次快照，所以在应用到状态机后，可以设置一个阈值与当前在内存中的raft log进行比较，当超过这个阈值后执行日志压缩，这也就是3b主要需要做的事情。\n3B部分最难处理也就是如何进行日志截断、什么时候进行日志截断、截断后需要重新设置哪些值，在想好这三个问题后动手会减少大量的debug工作。\n什么时候进行截断 截断的时间是发生在应用到状态机后检测到raft log的大小已经增长超过了阈值，于是kv服务将自己的状态map[string]string进行保存，随着logIndex一起递交给自己的raft，raft根据index获取到最后条目的term，进行持久化，然后截断自己的日志。\n如何进行日志截断 截断首先要考虑到截断后对其他操作的影响：\n raft负责发送appendEntry的操作，对于落后的机器可能会读取到陈旧的条目 raft收到appendEntry，常常发生于旧leader对最新的服务器(leader和follower)发送的心跳 raft收到InstallSnapshot后，会有log的截断操作   InstallSnapshot RPC: 6. If existing log entry has same index and term as snapshot’s last included entry, retain log entries following it and reply\n 这些操作本质上都是数组下标界限的问题，需要根据实际逻辑进行判断。\n另外一点就是关于Golang的切片内存模型，因为在这里raft log是以切片进行保存，所以类似于arr[beg:end]的操作只是移动指向底层的指针和长度，所以这里得需要新分配一个切片给rf.log。\n截断后需要重新设置哪些值 首先是在论文里的LastIncludeIndex和LastIncludeTerm，这两个变量可以维护在raft的状态里，以免每次都需要进行一次I/O读取这两个变量。因为需要维护这两个变量，所以每当要读取和写入快照时都需要更新。\n另外一对重要的值是commitIndex和applyIndex，根据raft论文:\n If commitIndex \u0026gt; lastApplied: increment lastApplied, apply log[lastApplied] to state machine\n 这种情况在InstallSnapshot内要着重考虑，因为InstallSnapshot的LastIncludeIndex会大于当前的commitIndex，当某台follower还在apply到状态机的时候，收到了快照，需要做的事情是，应用完上一个快照后，检查自己的applyIndex和commitIndex。而在InstallSnapshot内需要做的事情除了设置LastIncludeIndex和LastIncludeTerm，还同时提高applyIndex和commitIndex。\n中断的之前的apply过程并不会导致不一致，在安装完快照后，需要重置kv的状态机，所以不用担心同步问题。\n快照与K/V服务 3A部分中的kv服务是通过一致性检查后，一个一个地从0开始恢复状态，把以前的操作重新做一遍来恢复自己已分配掉的client ID，因为这个ID是会保存在raft的log中，对日志压缩也就会造成这些信息丢失，所以将当前已经分配掉的client ID写入到快照是有必要的。\n部署后的 K/V 服务  Server 1: state: http://fatwaer.store/kv/state.html log : http://fatwaer.store/kv/log.html Server 2: state: http://106.13.211.207/kv/state.html log : http://106.13.211.207/kv/log.html Server 3: state: http://18.162.39.157/kv/state.html log : http://18.162.39.157/kv/log.html  参考资料  《数据密集型应用系统设计》 《Unix网络编程：卷1》 https://blog.golang.org/go-slices-usage-and-internals https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf  ","date":"February 12, 2020","hero":"/images/default-hero.jpg","permalink":"/posts/sys/kv-server/","summary":"强一致性Key/Value服务 其实在写完Raft后，K/V的接口已经比较明显了，只需要将操作写入Raft entry的Command内，然后等待Raft的同步，再应用到状态机（例如map[string]string）即可，但是实际上在跑3A测试的时候还是出现了很多问题。\n并发(Concurrency) 虽然保证同一个客户端同时只会发送一个Put或者Get请求，但是在面对多个客户端时，如何处理这些请求，并且将这些请求写入到Raft的log entry中。老生常谈的问题，但是在这里处理比较简单，在Raft开始协调一个新的共识(Agreement)的时候,也就是start()，已经使用了mutex来附加新的entry到log中。\n网络不可靠(Unreliable) 这里是在3A碰到的第一个要认真考虑的点，如果一个RPC请求（比如append “1”-\u0026gt;\u0026ldquo;2\u0026rdquo;）经过了慢速网络而触发了重传，导致这个RPC被调用了两次，所以在Hint中有提醒，让client的每一个请求都有一个独一无二的ID来保证每个操作只能被执行一次。而如何使得每个操作只会被执行一次，并保证幂等性，还需要考虑到接下来的几个情况。\n服务器主机崩溃(Crash) 服务器主机崩溃的情景里要考虑的不是网络问题，而是当发生了主机崩溃，往往代表着新的一轮选举和新的leader诞生。所以当真正发生leader切换的时候，客户端需要做的事情是将当前的RPC重新发往新的leader。另外一点是持久化问题，这个会在快照机制中遇到一些需要思考的点。\n网络分区(Partition) 由于是实现一个强一致性的KV服务，在并发条件下，每一个Get/Put/Append操作都会被按顺序执行一次，而每次调用都需要监控之前的操作序列所做的操作所带来的影响，就好像在调用前，前面的所有的调用已经完成，通常称其为线性化。\n最先碰到网络分区和检查一致性是TestOnePartition3A，这个测试中做了如下几件事情：\n 创建一个5个server的kv服务器集群 客户端请求: Put:1 -\u0026gt; 13 建立网络分区，3台主机处于大多数(majority)，另外两台主机(保证有一台是leader)处于少数(minority)。 往majority中提交Put:1-\u0026gt;14 检查majority 往minority中提交操作Put:1 -\u0026gt; 15和Get:1 检测6中两个操作是否会成功 往majority提交Put:1-\u0026gt;16并检查 合并两个分区，检查最后Key 1的值。  最后的值应该为15，在这里碰到的一致性检查是关于第六步Get操作，从Raft可以知道在minority中提交的操作是不会被commit的，更不会被应用到状态机，此时minority中的key 1的值是13，相比于majority中的14，是一个过期的值，所以6步中的Get RPC在分区合并前不应该返回。\n当分区合并后，minority的leader会被majority中的新leader的心跳设置为follower，所以旧leader的kv服务应该检测到自己不再是leader而返回现存的RPC：Put:1 -\u0026gt; 15和Get:1，使客户端重定向到新的leader。\n而Get什么时候返回？这个在Hint中也提到了，最方便的做法就是将Get也塞入raft的log entry内，在这种情境下，处于minority分区的Get操作就会被读取到过期的数据。\n标识操作(UniqueID) 如何为每一个操作定独一无二ID？我的做法是每个操作维护三个变量以及新加一个RPC用于客户端注册：\n seriesN：每个客户端初始化为-1，每执行一次Get/Put/Append调用前自增1。 Client ID：初始化为-1，用于辨识客户端，由kv服务端来分配，客户端进行维护。 Server ID：代表分配Client ID的服务端，用于解决同一个操作因为leader切换而造成ID冲突。  每当启用一个新的客户端并且提交操作时，先自增seriesN，如果Client ID为-1，就会向服务端注册自己，即请求一个可用的Client ID，并设置Server ID。每当一个操作在raft中达成共识时，应用到状态机后，应该记录Cid和Sid的最大值，用于防止重复的操作被提交到状态机。\n当出现小于当前seriesN的操作出现时，需要返回一个duplicate的错误告知客户端。\n考虑下面这种情景：\ns1 | x = 0 | x += 1 同步到其他server s2 | x = 0 | x += 1 s3 | x = 0 | x += 1 s4 | x = 0 | x += 1 s5 | x = 0 | nil   leader s1 提交了一个 x += 1 的操作后，并同步到了s2, s3, s4，然后发生分区。 s2 当选新一轮的leader，并同步完成 s1 恢复到该分区中，被s2的心跳转变为follower client对s1的rpc被返回，重定向到s2，重复的op被提交。  这里也可以通过比较相同clinetID的seriesN来决定是否应用到状态机，但是如果第一步中，x += 1 并没有提交到s1以外的服务器，s2服务器当选leader后先为另一个client分配了相同的client ID，在分区合并前提交过几次操作，那么 x += 1的操作将会被驳回，所以这里需要server ID处理命名空间的冲突。","tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service"},{"categories":["sys"],"contents":"80386 下的保护模式划为5个部分：\n 类型检查 界限检查 可寻址域的限制 过程调用的限制 指令集的限制  事实上按照段页机制又需要分为段机制下的保护和页机制下的保护。\n段级别的保护 段描述符中存储了保护参数，当段描述符到段寄存器中和访问相应的段时，CPU 会自动启用保护机制进行检测。\n 段描述符格式\n 上图中一共有三种段，除了常被应用程序使用的数据段和可执行段外，还有一种用作门（gate）的描述符。\n当段寄存器加载一个段的时候，不仅仅只是加载了段的基地址，还会加载其他的保护机制所需要用到的信息。在段寄存器的不可见部分存储了段基地址，界限，特权等级，所以在保护机制在检查合法性时没有额外的时钟周期损耗。\n段机制的类型检查 描述符中的 TYPE 域用来区分不同描述符的格式和描述符的作用。\n  在数据段的 writable bit 代表正在执行的指令可否写入到该段。\n  代码段中的 readable bit 代表正在执行的指令能否读取该段中的数据，例如操作数为常量的情况。\n一个可读可执行的段可以被两种形式加载：\n 通过 CS 寄存器，例如 ljmp cs:addr 加载到通用段寄存器中    类型检查会在两种情况下进行：\n  当描述符被加载到到段寄存器时，相应的段寄存器只能加载对应的描述符种类，例如：\n CS 寄存器只能加载可执行的段 不可读但是可执行的段不能被加载到数据段寄存器中 只有科协的数据段能被加载到SS寄存器    当指令显式或者隐式地引用段寄存器，相应的段只能被预先定义好的方式来使用，例如：\n 不能尝试往可执行的段中写入 不能往w位未置位的数据段中写入 不能读取r位未置位的可执行段（数据段默认可读）    段机制的界限检查 故名思意，界限（limit）域在描述符中被处理器阻止程序寻址到超出段界限外的地方，与段界限相关的还有 G (granularity) bit，对于数据段，还有 E-bit (expansion-direction bit) 和 the B-bit (big bit)。\n bit 组合\n 除去 expand-down 类型的数据段，下列这些情况会产生一般保护错误（general-protection exception）：\n 尝试访问1字节的地址，地址大于界限 尝试访问1字的地址，地址大于等于界限 尝试访问2字的地址，地址大于等于界限值-2  界限的检查能捕获一些程序的运行错误例如非法的指针计算。这些错误会在刚刚发生时被检测到，所以检测这些错误更加简单，如果没有这个机制，这些错误可能会影响到其他的部件，到那时候再去追踪就难多了。\n特权等级 特权等级分为四级，但是基本只会用到两级，最高特权级别 ring 0和最低的特权级别 ring 3。\n特权等级在以下这些地方展现：\n  CPL(Current privilege level): CPL 代表当前正在运行的程序或者任务的权限等级，存储在CS或者SS段寄存器的第0和1位。通常CPL和当前运行的代码段的等级相同，当CPL发生改变时，代表程序在不同特权等级之间的控制转移。\n但是当代码段描述符的 conforming 位置位时，情况有所不同，conforming 置位的代码段能被特权等级与其相等或者更低权限的任务所访问，并且，在执行 conforming 置位的代码时，CPL不会发生改变，所以通常 conforming 代码段用于低权限任务需要执行数学函数或者异常处理函数等情况。\n  DPL(descriptor privilege level): 在段描述符或者门描述符中存在一个域用于表明这个描述符的特权等级，当正在执行的代码段尝试去访问一个段或者门时，CPL和RPL就会与DPL进行比较，DPL根据段或门的类型不同会有不同的解释方法：\n 数据段：DPL代表可以访问该段的最低权限，比如数据段的DPL位1，仅只有程序运行在CPL为0或1时才能访问该段。 非 conforming 的代码段（不使用 call gate）：DPL代表程序必须运行在的特权等级（即使特权等级大于DPL也不行） Call gate：DPL代表可以访问该段的最低权限，同数据段 使用call gate 访问代码段：DPL代表可以访问该段的最高权限，比如某个代码段的DPL为2，运行在特权等级 0 或者 1 的程序无法访问。 TSS：DPL代表可以访问该段的最低权限，同数据段    RPL(Requested privilege level): RPL 是存储在段选择子第0 和 1 位，处理器在检查特权等级时会同时检查 CPL 和 RPL。即使程序运行的特权等级 (CPL) 已经满足了相应段的特权等级 (DPL)，如果 RPL 不能满足 DPL 的话，访问段的操作仍然会被拒绝。这意味着，如果 RPL 树枝上大于 CPL，那么RPL将会作为尝试去访问相应段的特权等级，反之亦然。RPL 可以被保证 特权代码不会代表应用程序去访问一个该应用程序并没有权限的段。\n关于 RPL 的作用在 Intel® 64 Developer’s Manual : 4.10.4 Checking Caller Access Privileges (ARPL Instruction) 里面有几个例子进行说明。\n当一个应用程序过程(the calling procedure)调用操作系统 的一个过程(the called procedure)时，在执行操作系统过程中会将特权等级设置为应用程序的段选择子的 RPL。当操作系统尝试去访问相关的段时，处理器会对 RPL 而不是特权等级值更低的 CPL（此时为0）进行特权等级检查。\n在上图中，应用程序正运行在代码段A中，处理数据段D1中的数据，此时在数据段D1中指向了一个特权数据结构（在数据段D中的操作系统数据结构，数据段的 DPL 为0）。因为 CPL 的值大于特权等级值，权限不足以访问。\n为了访问到数据段 D，应用程序执行了一个调用，并且通过栈传递了段选择子 D1（存在RPL） 到操作系统。在传递段选择子前，应用程序会将段选择子设置为当前的 CPL （SS或者CS中）。当通过门 C （运行在特权等级0）利用段选择子 D1 （栈上的值）访问数据段 D时，由于D1的RPL要大于DPL，访问数据段 D 的操作被拒绝。\n该部分后面还有一种情况，通过门调用时，由于应用程序可以修改栈上的段选择器中的 RPL 值（对应图中数据段D2），这会导致保护机制被破坏，于是有了 ARPL 指令对栈上的 RPL 和调用此操作系统过程的程序的 CPL 进行比较。\n  段机制的数据的访问限制 为了访问到在内存中的操作数，程序必须将数据段加载到数据段(DS, ES, FS, GS, SS)寄存器中。处理器会在访问数据段时自动比较特权等级。\n数据段寄存器能加载一个数据段的前提是DPL大于RPL和CPL。\n段机制的控制转移限制 控制转移往往伴随着JMP, CALL, RET, INT, IRET指令以及中断和异常机制。在同一个代码段的JMP, CALL, RET仅仅只有段界限检查。远距离的调用或者跳转会引用到其他段，因此，处理器会进行特权检查。\n例如：ljmp $0x8,$0x7c32，$0x8为段寄存器值。\nJMP 或者 CALL 会通过两种方式引用另外一个段：\n 操作数中存在另一个可执行的代码段描述符 操作数中有一个调用门描述符  一般情况下，处理器正在运行的代码段的 DPL 和 CPL 相等，但是如果代码段的 conforming 位置位时，CPL 可能大于 DPL。所以只有当 DPL 和 CPL 相等时或者代码段的conforming 位置位并且 DPL 小于等于 CPL 时，JMP和CALL能够直接从原先的代码段跳转到另一个代码段。\n 代码段的检查\n 门限描述符对过程调用的保护 一共有4中描述符用于在不同特权等级间进行跳转：\n call gate Trap gates Interrupt gates Task gates  call gate 和普通描述符一样，定义在GDT或者LDT中，它定义了一个过程调用的入口和调用该过程所需要的特权等级。call gate描述符对于jmp和call指令来说和代码段的处理方式一样。\n call gate\n selector 和 offset 域能形成一个到调用过程入口的指针，call gate 保证能跳转到另一个段的合法地址，而不是跳转到一个过程调用的中间或者\u0026hellip;.一条指令的中间。一条指令的控制转移的偏移地址不会在call gate跳转中使用（前面那种跳转到中途的情况）。\n执行指令时，首先通过操作数中的段选择器得到门限描述符的偏移，在门限描述符中的 selector 字段获得目标调用过程的代码段描述符，执行过程调用，在这过程中，一共涉及到4个特权等级，CPL，RPL，门限的 DPL 和目标代码段的 DPL。\n通过 gate 可以实现不同特权等级的转移，但是只有通过 call 指令能切换到更低的特权等级上，而 jmp 指令只能在同特权等级之间跳转（不考虑comforming 代码段）。\n对于 jmp 指令，要求：\nMAX (CPL,RPL) \u0026lt;= gate DPL target segment DPL = CPL 对于 call 指令或者 jmp 目的代码段为 comforming：\nMAX (CPL,RPL) \u0026lt;= gate DPL target segment DPL \u0026lt;= CPL 栈切换 为了维护系统的整体性，任意特权等级拥有各自独立的栈，处理器通过TSS（task state segment）定位这些不同特权等级的栈。比如通过call gate切换特权等级时，新的栈指针将会从tss中读取出来。\n TSS\n 处理器会利用目标代码段的DPL找到对应特权等级（PL 0，1，2）的栈，并且 DPL 必须与 CPL 相等。TSS 中没有对应特权等级为3的栈，因为特权等级3的过程不能被其他任意低于其特权等级的过程调用。每个栈都必须有足够的空间去存储 ss:esp，返回地址，参数等。\n为了在不同特权等级之间调用过程，处理器必须将调用者的参数从旧的栈帧中拷贝到新特权等级的栈帧中去。call gate 描述符中的 count 字段代表多少双字（doublewords）需要拷贝，如果count为0，拷贝就不会发生。\n 切换特权等级的栈切换：\n  新栈检查是否有足够的空间容纳参数等，否则产生一个栈错误，错误代码设置为0. 将旧栈SS:ESP压入新栈（占用两个双字） 复制剩下的参数 调用者的call的下一条指令地址以 CS:EIP 压入新栈 将新的 SS:ESP 指向新栈栈顶  从过程调用中返回（ret） 和 call 指令类似，同一个代码段之间的 ret 只有界限检查。对于段间的 ret，首先会弹出由 call 压入的返回地址，通常情况下时合法的，但是也有可能由于调用过程替换掉了这个地址或者没有很好地维护栈，这个返回地址也是不可信的，所以权限检查还是会有的。\n段之间的 ret 只能返回到与其相等或者更高特权值的等级去，当栈上保存的 CS 中的 RPL 大于当前的 CPL 时，特权等级间的控制转移就会发生：\n 检查下表中的内容，加载栈上的 CS:EIP 和 SS:ESP 到相应寄存器。 原先的栈指针会被 ret 指令做相应的调整，此时 esp 的值不会进行界限检查，如果 esp 实在超出了界限，那么下次对栈的操作将会产生错误。 基础段寄存器的特权值将会被检查，如果这些段寄存器引用了那些 DPL 大于新 CPL（栈上保存的CS得到） 的段，那么段寄存器就会加载 null selector，即 GDT 中的一个 null 描述符（INDEX = 0, TI = 0）。并且，此时不会产生异常，直到下次操作相应段内存时产生一般保护异常。  SF = Stack Fault GP = General Protection Exception NP = Segment-Not-Present Exception Type of Check Exception Error Code ESP is within current SS segment SF 0 ESP + 7 is within current SS segment SF 0 RPL of return CS is greater than CPL GP Return CS Return CS selector is not null GP Return CS Return CS segment is within descriptor table limit GP Return CS Return CS descriptor is a code segment GP Return CS Return CS segment is present NP Return CS DPL of return nonconforming code segment = RPL of return CS, or DPL of return conforming code segment \u0026lt;= RPL of return CS GP Return CS ESP + N + 15 is within SS segment N Immediate Operand of RET N Instruction SF Return SS SS selector at ESP + N + 12 is not null GP Return SS SS selector at ESP + N + 12 is within descriptor table limit GP Return SS SS descriptor is writable data segment GP Return SS SS segment is present SF Return SS Saved SS segment DPL = RPL of saved CS GP Return SS Saved SS selector RPL = Saved SS segment DPL GP Return SS 指令集的限制 影响到保护机制的指令分为两类，特权指令，通常被用于系统控制；敏感指令，通常被用作 IO或者 IO相关的操作。\n特权指令如下：\nCLTS -- Clear Task-Switched Flag HLT -- Halt Processor LGDT -- Load GDL Register LIDT -- Load IDT Register LLDT -- Load LDT Register LMSW -- Load Machine Status Word LTR -- Load Task Register MOV to/from CRn -- Move to Control Register n MOV to /from DRn -- Move to Debug Register n MOV to/from TRn -- Move to Test Register n 页级别保护 页级别的保护较为简单，分成有两种：\n 对可寻址的内存进行限制 类型检查  页机制中的寻址限制  PDE/PTE\n 在页机制中，特权等级被分为了两级：\n Supervisor level (U/S=0) ：对应操作系统的软件和相关数据 User level (U/S=1)：对于应用程序级别的过程和数据  页机制中的特权等级和段机制中的 CPL 相关联，CPL 处于 ring 0,1,2 代表处理器执行在 supervisor level， CPL 处于 ring 3 代表执行在 user level。\n当处理器执行在 user level ，只能寻址那些属于用户级别的页，如果处于 supervisor level ，那么处理器能够寻址所有的页。\n页机制中的类型检查 对于所有的页，定义了两种类型页，分别为只读的和可读可写类型的。当处于supervisor并且CR0寄存器中的WP位没有置位，所有的页都是可读可写的。而处于 user 级别，就需要对应读写位分情况讨论。处于 user 级别时，对于supervisor 的所有的页都是不可读写的。\n参考资料：\nIntel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1\n6.828 readings, Protection\n","date":"November 11, 2019","hero":"/images/default-hero.jpg","permalink":"/posts/sys/protection/","summary":"80386 下的保护模式划为5个部分：\n 类型检查 界限检查 可寻址域的限制 过程调用的限制 指令集的限制  事实上按照段页机制又需要分为段机制下的保护和页机制下的保护。\n段级别的保护 段描述符中存储了保护参数，当段描述符到段寄存器中和访问相应的段时，CPU 会自动启用保护机制进行检测。\n 段描述符格式\n 上图中一共有三种段，除了常被应用程序使用的数据段和可执行段外，还有一种用作门（gate）的描述符。\n当段寄存器加载一个段的时候，不仅仅只是加载了段的基地址，还会加载其他的保护机制所需要用到的信息。在段寄存器的不可见部分存储了段基地址，界限，特权等级，所以在保护机制在检查合法性时没有额外的时钟周期损耗。\n段机制的类型检查 描述符中的 TYPE 域用来区分不同描述符的格式和描述符的作用。\n  在数据段的 writable bit 代表正在执行的指令可否写入到该段。\n  代码段中的 readable bit 代表正在执行的指令能否读取该段中的数据，例如操作数为常量的情况。\n一个可读可执行的段可以被两种形式加载：\n 通过 CS 寄存器，例如 ljmp cs:addr 加载到通用段寄存器中    类型检查会在两种情况下进行：\n  当描述符被加载到到段寄存器时，相应的段寄存器只能加载对应的描述符种类，例如：\n CS 寄存器只能加载可执行的段 不可读但是可执行的段不能被加载到数据段寄存器中 只有科协的数据段能被加载到SS寄存器    当指令显式或者隐式地引用段寄存器，相应的段只能被预先定义好的方式来使用，例如：\n 不能尝试往可执行的段中写入 不能往w位未置位的数据段中写入 不能读取r位未置位的可执行段（数据段默认可读）    段机制的界限检查 故名思意，界限（limit）域在描述符中被处理器阻止程序寻址到超出段界限外的地方，与段界限相关的还有 G (granularity) bit，对于数据段，还有 E-bit (expansion-direction bit) 和 the B-bit (big bit)。","tags":null,"title":"Protection Mechanism on 80386"},{"categories":["env"],"contents":" 将博客从 hexo 迁到了 hugo，主要原因是文章越来越多，hexo build速度就显得力不从心了，hexo 很多主题都不再维护，甚至很少有新的主题发布出来，而 hugo 相反，随着golang热度的上涨，社区也很活跃，其主题的更新在官网可以看出来相对频繁。我目前使用的主题是由zzossig 提供的Zzo主题。\n Hugo 总览 看到比较合适的主题，有需要自己定制的话，可以简单过一遍Hugo的一个官方教程(大概3-4小时)：\n https://www.youtube.com/watch?v=qtIqKaDlqXo\u0026amp;list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3\n Hugo 的安装和环境配置 Hugo 提供了较为详细的官方教程，安装过程非常详细，如果是在windows上安装，可以下载二进制文件到任意目录下，并且将改目录添加到PATH环境变量即可。\nHugo 的基本使用 将hugo的环境搭建完成后博客根目录进行初始化：\nhugo version mkdir Sites cd Sites hugo new site sitename 然后需要去主题页找一个合适的主题，并且下载到Sites/sitename/themes目录，或者在Sites/sitename目录下执行：\ngit init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 然后将配置文件中的主题设置为下载到themes目录中的主题文件夹名字：\necho \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 像hexo一样，hugo提供了本地预览的功能，在 Sites/sitename目录下运行，然后就可以访问localhost:1313来访问博客了：\n$ hugo server Building sites … | EN | KO -------------------+-----+------ Pages | 54 | 10 Paginator pages | 3 | 0 Non-page files | 0 | 0 Static files | 209 | 209 Processed images | 0 | 0 Aliases | 11 | 1 Sitemaps | 2 | 1 Cleaned | 0 | 0 Built in 5641 ms Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at //localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop Hugo 与 Github 如果单单运行hugo并且不添加仍和参数，hugo就会将博客的静态文件全部生成到sitename/public内，然后与githubname.github.io仓库进行关联，然后将代码推上去，就可以正常访问了。\n其他 Hugo 静态生成主要由两个部分组成，一个是list template，用于生成类似于目录页的页面，另一个是single template，类似于每一篇博客展现内容的页面。这两个页面一般是被嵌入在一个叫baseof.html的模板中。\nMarkdown 图床 最开始用微博+chrome插件， 后来微博开启了防盗链， 转移到了七牛+picGo https://www.cnblogs.com/Dozeer/p/10965508.html\n","date":"September 18, 2019","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hugo%E9%85%8D%E7%BD%AE/","summary":"将博客从 hexo 迁到了 hugo，主要原因是文章越来越多，hexo build速度就显得力不从心了，hexo 很多主题都不再维护，甚至很少有新的主题发布出来，而 hugo 相反，随着golang热度的上涨，社区也很活跃，其主题的更新在官网可以看出来相对频繁。我目前使用的主题是由zzossig 提供的Zzo主题。\n Hugo 总览 看到比较合适的主题，有需要自己定制的话，可以简单过一遍Hugo的一个官方教程(大概3-4小时)：\n https://www.youtube.com/watch?v=qtIqKaDlqXo\u0026amp;list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3\n Hugo 的安装和环境配置 Hugo 提供了较为详细的官方教程，安装过程非常详细，如果是在windows上安装，可以下载二进制文件到任意目录下，并且将改目录添加到PATH环境变量即可。\nHugo 的基本使用 将hugo的环境搭建完成后博客根目录进行初始化：\nhugo version mkdir Sites cd Sites hugo new site sitename 然后需要去主题页找一个合适的主题，并且下载到Sites/sitename/themes目录，或者在Sites/sitename目录下执行：\ngit init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 然后将配置文件中的主题设置为下载到themes目录中的主题文件夹名字：\necho \u0026#39;theme = \u0026#34;ananke\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 像hexo一样，hugo提供了本地预览的功能，在 Sites/sitename目录下运行，然后就可以访问localhost:1313来访问博客了：\n$ hugo server Building sites … | EN | KO -------------------+-----+------ Pages | 54 | 10 Paginator pages | 3 | 0 Non-page files | 0 | 0 Static files | 209 | 209 Processed images | 0 | 0 Aliases | 11 | 1 Sitemaps | 2 | 1 Cleaned | 0 | 0 Built in 5641 ms Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode.","tags":["config"],"title":"Hugo is comming !"},{"categories":["sys"],"contents":"最近这段时间有一些空闲时间，可以开始做下6.824，目前是Spring 2018，最新的2019也快出了，提前刷下notes和paper。\n分布式系统是关于多个计算机系统共同合作并且进行存储大量的网站数据，执行mapreduce，端对端共享的一种系统，大量的关键基础设施都是分布式的。\n分布式系统的优点是能够组织物理上分离的实体，通过isolation取得系统安全，通过replication获取容错机制，通过并行CPUs/mem/disk/net来比例提升系统速度。\n当然也有些缺点，这些过程中必须需要处理大量的并发部件，必须应对部分组件失效，以及很难获取一些潜在的性能。\nMapReduce(2004) input is divided into M files [diagram: maps generate rows of K-V pairs, reduces consume columns] Input1 -\u0026gt; Map -\u0026gt; a,1 b,1 c,1 Input2 -\u0026gt; Map -\u0026gt; b,1 Input3 -\u0026gt; Map -\u0026gt; a,1 c,1 | | | | | -\u0026gt; Reduce -\u0026gt; c,2 | -----\u0026gt; Reduce -\u0026gt; b,2 ---------\u0026gt; Reduce -\u0026gt; a,2  对于输入的文件，首先将其分为 M 个文件，对于每一个文件调用一个 Map()作为一次作业，每一个Map()调用产生一组 \u0026lt;k2, v2\u0026gt;键值对(图中的一行)作为中间数据。\nMapReduce聚集键为 k2 的所有中间值，将其传输给Reduce()调用，并且以 \u0026lt;k2, v3\u0026gt; 的集合作为最终输出存入到Reduce的输出文件中。也就形成了最后的形式API形式：\nmap(k1, v1) -\u0026gt; list(k2, v2) reduce(k2, list(v2) -\u0026gt; list(k2, v3)]  MapReduce 隐藏了很多关键的细节，l如启动处于服务器上的软件，跟踪任务是否完成，数据的移动，从错误中恢复等。\nMapReduce 过程 Paper中共分为7个步骤：\n MapReduce将输入文件分成M份，并且开始在集群的机器上运行该程序的拷贝。 其中有该程序拷贝的Master节点会为集群中剩下的workers分配任务，其中有M份map任务和R份reduce工作，并且master将会为处于闲置状态的worker分配map或者reduce任务 worker被赋予了map任务将会从对应的input分片中读取内容，并且将从中解析出的k/v键值对传递到user-defined函数中。(这些由map()产生的k/v对被缓冲在内存中) 这些中间值将会被周期性的写到worker的本地磁盘，并且被partitioning function分成R份区域。这些被写到磁盘的键值对的位置将会被传回给master，并且可靠地将这些定位推进到reduce worker 当reduce worker被Master告知了这些键值对的定位，使用RPC读取这些在map worker本地磁盘缓冲的数据，当reduce worker读取到了所有的中间值，接下来会根据key值进行分组。 reduce worker将会遍历这些排序好的中间值，并且将遇到的每一个独一无二的key值，传递到user的Reduce function中，该函数的输出最后会附加到最终输出中去。 当所有map和reduce的任务完成后，master将会唤醒user program，此时 MapReduce调用已经返回到用户代码中。  其中 没有reduce worker会在map任务完成之前被调用。\n中间值将只会在网络中出现一次，map从分布式文件系统中进行本地复制，执行Map然后写本地磁盘，通知Master通知reduce worker从该位置远程读取数据，然后写到reduce worker的本地磁盘。\n根据以上的条件，有一种非常坏的情况就是N-1台服务器等待最后一台服务器完成任务，整个系统都在等待其完成任务。解决办法是使得任务数目要多余主机数，master需要递送新的任务给已经完成任务的workers,最后的结果是较快的servers会比较慢的servers完成更多的工作,但是绝对时间是相同的。\n容错处理  Map worker 崩溃 master多次ping崩溃的主机仍没有回应，并且Map的输出已经丢失了，但是后面的每一个reduce任务都需要该结果。如果reduce worker已经完全拉取了中间值，并且在reduce的过程中又发生了crash，则会强制执行失效map。 Reduce worker 崩溃 如果在worker上的任务已经完成则没有关系，因为已经存储到了分布式文件系统中了，如果是在执行过程中发生了崩溃，则在新的worker上启动未完成的工作。 Reduce 在输出结果集发生了崩溃 在reduce工作完成前是不可见的，整个reduce到输出文件都是保持原子性的，这保证master重新在其他地方执行任务。  RPC Client: z = fn(x, y) Server: fn(x, y) { compute return z }  RPC简单来说就是客户端通过tcp连接调用远程服务器中的函数并且获取值的一个过程，GoLang中自带了rpc库。如果rpc库调用失败，可能有几种情况，比如服务器根本没有收到这个请求，可能收到了请求并且执行了相关调用，但是崩溃在发送之前，或者在发送后该数据包迷失在了网络中。\n最简单的方法模式的“尽最大努力交付”：\n 客户端调用rpc，并且等待 如果没有响应，则重传 重传多次无果，返回错误值  尽最大努力交付这种模式只适合一些多次操作不会进行写操作的调用，比如读操作，检查db记录是否被插入等等。\nGFS(2003) GFS支持一些常见的文件操作，例如create, delete, open, close, read, write等，另外还有snapshot和record append的操作。\nGFS的结构 一个GFS集群由一个master节点和多个能被clients访问的chunkservers组成。通常是是一些商业linux机器运行着用户级别的服务器进程，并且可以让clients和chunkserver的进程运行在同一个机器上面。\n文件被分成固定大小的chunksize(一般为64MB), 并且每一个chunk都在创建期间被master一个全局不可变的chunk handle，并且默认情况下，每一个chunk都有三份备份。\nmaster负责维护整个系统的metadata，其中包括了命名空间，访问控制信息，文件到文件系统的映射信息，以及当前状态chunk服务器的位置，并且使用周期性的HeartBeat消息来给予指令或者收集chunk的状态。\nclient不会从master节点读写数据，取而代之的是获取chunkserver的信息，并且缓冲这些信息在一段时间内，并且进行接下来的系列操作。\nGFS的读取操作:\n 首先，client将文件名和字节偏移转化为chunk索引，然后发送给master一个包含文件名和该索引的请求。master回复对应的chunk handle和各个备份的位置。client缓冲这些信息，以文件名和chunk index作为key值 然后，client发送请求到其中的一个备份去，一般选择最近的，这个请求中包含了chunk内偏移，然后chunk将数据回复给clients。  GFS的写操作：\n 客户端请求master获取一份持有lease的chunk server master回复主备份的节点id和其他备份的位置，client缓冲这些数据。并且在这些备份地址不可达的时候，重新请求master节点。 client推送数据到到所有的拷贝，并且chunkserver将会缓冲这些数据到基于LRU的缓冲区直到数据被使用或者超时。 一旦所欲的拷贝都回复确认收到了该数据，client将会发送写请求到主拷贝节点，主拷贝将会复制一串连续的数字给所接收到的数据变动，并且将这连续的数据变动应用到本地。 主拷贝将会向前推送写请求到所有的第二级拷贝，并且所有的拷贝对数据的变动与拷贝相同 第二级拷贝将会回复主拷贝已经完成了这个操作 主拷贝将会回复client，在变动过程中发生了任何错误都会回复给client。  Raft(2014) 推荐下这个视频，结合那篇paper一起看比较容易理解 https://www.youtube.com/watch?v=YbZ3zDzDnrw\nraft 协议主要是可理解性，相对于paxos来说简单了很多，raft也是提供了在非拜占庭错误(non-Byzantine fault)下一种新的并发模型。\n当clients向其中一个sever提交一个操作的时候，该操作首先会被放入log中，然后使其他的servers也记录该操作，当大多数的机器正确回复了请求后，那么该操作就会被提交到该服务器的状态机，从而完成一个完整的操作，当多个操作开始执行的时候，都会以相同的顺序进行执行。\nraft中所有的server在某一时刻会扮演三种角色中的一种： Leader：　处理client的交互，日志复制，并且同一时刻，只会有一个leader\nFollower：　完全处于被动状态，不会产生RPC，但是会回应即将到来的RPC\nCandidate：　将会被选举成一个新的leader\n在raft协议中，时间被分为以term为单位的时间片段，term有如下的性质：\n 每一期被分为选举时间和普通操作时间。 每一期最多有一个leader 有些时期可能没有leader，之后提到的一些选举失败的情况中会出现。 每一个server中都会维护一个当前期数的值，用于server发生crash或者unreachable的时候  期数在raft中是个非常重要的概念，用于指示server中哪些数据已经过时了\nRaft　大体上可以分成６个部分\n1.Leader election  最开始的时候，所有的服务器在raft中以follower的角色启动 follower期待来自leader或者candidates的rpc leader必须发送心跳包(空的AppendEntries　RPC)来维护自己的权威性 如果electionTimeout到了并且没有接收到rpc，那么  follower将会假定leader崩溃了 follower开始新的选举 timeout的时长通常为100-500ms    选举的过程：\n 自增当前的期数 从follower改变至candidate状态 为自己投票 发送RequestVote RPC到其他服务器，如果没有收到回复，那么一直重传至：  接受到大多数的服务器的投票，那么该服务器变成leader并且发送心跳包到其他服务器 接收到来自合法leader的RPC，那么该服务器回到follower的状态 没有任何一个服务器赢得该轮选举，那么自增期数，开始新的一轮选举(splite vote　term的产生)，新开始的一轮的时期通常选为electionTimeout T~2T之间    2.Normal operation 每一个日志条目(log entry)由三个部分组成：index, term和command，并且都会存储在稳定的存储介质中，例如磁盘。\nlog的并发处理:　1. 如果在不同的服务器上面日志条目有相同的index和term，那么表示这些条目存储了相同的命令并且之前的条目也是准确的。2.　如果一个条目是被committed的，那么之前的所有条目也是被committed的\n一个条目被称之为committed则说明这个条目已经被存储在了大多数的服务器上面，并且最终会在集群每个服务器的状态机上执行。\n正常运行过程：\n client发送一个命令到leader leader将会把这个命令附加到其log上 leader发送AppendEntries RPC到follower 一旦一个新的entry是committed，那么代表:  leader把这个命令应用到状态机上并且返回结果给client leader将会给已经提交该条目发送接下来的AppendEntries RPC follower把该命令提交到自己的状态机上面    每一个AppendEntries RPC会包含需要附加位置之前一个的index, term，如果不相符合，follower将会拒绝这个请求。\n3.leader changes leader发生改变最重要的一点是，leader的log总是对的，在follower中发生冲突的条目将会被删除。\n在选举期间，candidate最有可能是包含了的最多已经committed条目的服务器，在RequestVote RPC中，包含了candidate最后一个条目的index和term，收到该请求的服务器将会与自己的最后期数进行对比，如果自己的期数等于candidate的期数或者期数相等但是自己的最后的索引大于candidate的索引，那么将会否决投票，这样就保证leader拥有最完整的log。\n修复follower的log，新的leader必须使follower的log与自己的一致，删除那些不想管的条目并且填充缺少的条目，leader会为每一个follower保持一个nextIndex，初始值为(1 + leader\u0026rsquo;s last index)，当一个一个AppendEntries RPC失败了，对应的nextIndex将会进行递减并且重新尝试。如果follower覆盖了不一致的条目，那么follower将会删除接下来所有的条目。\n4.Neutralizing old leader 假设出现这种情况，需要使得旧的leader无效：\n 暂时性地从网络中断开 剩下的其他服务器选举出一个新的leader 旧的leader重新连接到集群网络并且尝试去提交日志条目  terms用来检测过时的leader或者candidate，每个rpc中都包含有sender的期数，如果发送者的期数更低，那么rpc将会被接受者拒绝，并且发送方将会转变为follower并且更新其自己的期数。相反，如果接受者的期数更低，那么接收者变成follower，并且更新自己的期数然后正常处理rpc\n5.clients interaction  client发送命令到leader，如果不知道leader的位置，联系任何一个已知的服务器，最终将会重定向到leader处。 除非命令已经被状态机logged，committed，并且exectued，leader不会进行回复该请求。 如果一个请求超时了，client需要重新发送命令到其他的服务器。  但是多次重新发送同一个命令会引起多次执行，所以client必须嵌入一个独一无二的id到每一个指令中去，服务器也将会接受该id到日志条目中去，在接收新来的指令之前，leader会检查其日志的该id，如果找到了，将会无视新的指令，但是会返回原来执行过的结果。\n6.configuration changes 配置发生改变是指，该集群中某些机器失效了或者需要新的机器来代替原来的机器等等更改集群物理配置的一些改变。集群配置变更不能直接发生变化，例如决策的处理等等。\nraft使用2-phase的途径来处理这种情况：\nC(old)表示需要在旧配置上的大多数服务器进行决策，而C(old)+C(new)代表需要在旧配置的大多数服务器上通过并且同时需要在新配置的大多数服务器上通过决策。\n","date":"January 15, 2019","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6.824-notesmapreducegfsraft/","summary":"最近这段时间有一些空闲时间，可以开始做下6.824，目前是Spring 2018，最新的2019也快出了，提前刷下notes和paper。\n分布式系统是关于多个计算机系统共同合作并且进行存储大量的网站数据，执行mapreduce，端对端共享的一种系统，大量的关键基础设施都是分布式的。\n分布式系统的优点是能够组织物理上分离的实体，通过isolation取得系统安全，通过replication获取容错机制，通过并行CPUs/mem/disk/net来比例提升系统速度。\n当然也有些缺点，这些过程中必须需要处理大量的并发部件，必须应对部分组件失效，以及很难获取一些潜在的性能。\nMapReduce(2004) input is divided into M files [diagram: maps generate rows of K-V pairs, reduces consume columns] Input1 -\u0026gt; Map -\u0026gt; a,1 b,1 c,1 Input2 -\u0026gt; Map -\u0026gt; b,1 Input3 -\u0026gt; Map -\u0026gt; a,1 c,1 | | | | | -\u0026gt; Reduce -\u0026gt; c,2 | -----\u0026gt; Reduce -\u0026gt; b,2 ---------\u0026gt; Reduce -\u0026gt; a,2  对于输入的文件，首先将其分为 M 个文件，对于每一个文件调用一个 Map()作为一次作业，每一个Map()调用产生一组 \u0026lt;k2, v2\u0026gt;键值对(图中的一行)作为中间数据。\nMapReduce聚集键为 k2 的所有中间值，将其传输给Reduce()调用，并且以 \u0026lt;k2, v3\u0026gt; 的集合作为最终输出存入到Reduce的输出文件中。也就形成了最后的形式API形式：","tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft"},{"categories":["sys"],"contents":"数据组件   消息队列\nRedis: https://github.com/antirez/redis\nApache Kafka\n  主数据库\n//todo\n  全文索引\nElasticsearch: https://github.com/elastic/elasticsearch\nApache Solr\n  内存缓存\nMemcached: https://github.com/memcached/memcached\n  ","date":"January 11, 2019","hero":"/images/default-hero.jpg","permalink":"/posts/sys/data-intensive-system/","summary":"数据组件   消息队列\nRedis: https://github.com/antirez/redis\nApache Kafka\n  主数据库\n//todo\n  全文索引\nElasticsearch: https://github.com/elastic/elasticsearch\nApache Solr\n  内存缓存\nMemcached: https://github.com/memcached/memcached\n  ","tags":["distributed system"],"title":"Data-Intensive System"},{"categories":["sys"],"contents":"goroutine部分 goroutine的一些tricks，比如\nfunc Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // 注意括号 - 必须调用该函数。 }  直接在go关键字后面接一个lambada表达式作为例程。\ngoroutine通常和channal一起使用，Unix的管道是基于生产-消费者模型，而channal则使用CSP(Communicating Sequential Process)进行构建。信道没有数据的时候会进行阻塞，利用这种条件可以实现一些信号量机制。\nvar sem = make(chan int, MaxOutstanding) func handle(r *Request) { sem \u0026lt;- 1 // 等待活动队列清空。 process(r) // 可能需要很长时间。 \u0026lt;-sem // 完成；使下一个请求可以运行。 } func Serve(queue chan *Request) { for { req := \u0026lt;-queue go handle(req) // 无需等待 handle 结束。 } }  例如这样一段代码可以实现最大接受请求数量为MaxOutstanding,当新的请求到达时，req := \u0026lt;-queue从阻塞中恢复并且执行goroutine处理请求，再往sem里面写入内容时，会因为队列满了而阻塞，当然这样也有局限性，当有大量请求到达的时候，会不停地新生成新的goroutine，占用系统资源。\nfunc Serve(queue chan *Request) { for req := range queue { req := req // 为该Go程创建 req 的新实例。 sem \u0026lt;- 1 go func() { process(req) \u0026lt;-sem }() } }  解决方案是在循环的routine中尝试往信道中写入内容，这样可以正确实现队列的大小限制。考虑去掉req := req这一行，req变量在每个循环中都被赋予不同的值，但是实际上底层使用的同样的内存，相应的goroutine后的函数闭包可以引用该作用域的变量并且保持和修改，所以每个新生成的goroutine都会使用同一个变量，造成比较严重的错误。\n Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.\n 另外，并发(concurrency)和并行(parallelism)是两种单独的意思，并发是多个独立地执行程序的组合，即一次性解决大量的事情，而并行是同时执行某些相关连的计算。\n反射相关 变量的最基本信息就是类型和值：反射包的 Type 用来表示一个 Go 类型，反射包的 Value 为 Go 值提供了反射接口。这对于没有源代码的包尤其有用。这是一个强大的工具，除非真得有必要，否则应当避免使用或小心使用。\n实际上，反射是通过检查一个接口的值，变量首先被转换成空接口。这从下面两个函数签名能够很明显的看出来：\nfunc TypeOf(i interface{}) Type func ValueOf(i interface{}) Value  接口的值包含一个 type 和 value。\n结构体，集合设计 https://go.fdos.me/11.14.html (golang中一些关于结构体的设计技巧)\n常见错误 50种常见错误 (在awesome-go仓库里面翻到的，有空可以看看)\n翻译版本\n并发控制库 Context库 (该作者其他的帖子也可以看看，干货较多)\n","date":"January 10, 2019","hero":"/images/default-hero.jpg","permalink":"/posts/sys/effective-go/","summary":"goroutine部分 goroutine的一些tricks，比如\nfunc Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // 注意括号 - 必须调用该函数。 }  直接在go关键字后面接一个lambada表达式作为例程。\ngoroutine通常和channal一起使用，Unix的管道是基于生产-消费者模型，而channal则使用CSP(Communicating Sequential Process)进行构建。信道没有数据的时候会进行阻塞，利用这种条件可以实现一些信号量机制。\nvar sem = make(chan int, MaxOutstanding) func handle(r *Request) { sem \u0026lt;- 1 // 等待活动队列清空。 process(r) // 可能需要很长时间。 \u0026lt;-sem // 完成；使下一个请求可以运行。 } func Serve(queue chan *Request) { for { req := \u0026lt;-queue go handle(req) // 无需等待 handle 结束。 } }  例如这样一段代码可以实现最大接受请求数量为MaxOutstanding,当新的请求到达时，req := \u0026lt;-queue从阻塞中恢复并且执行goroutine处理请求，再往sem里面写入内容时，会因为队列满了而阻塞，当然这样也有局限性，当有大量请求到达的时候，会不停地新生成新的goroutine，占用系统资源。\nfunc Serve(queue chan *Request) { for req := range queue { req := req // 为该Go程创建 req 的新实例。 sem \u0026lt;- 1 go func() { process(req) \u0026lt;-sem }() } }  解决方案是在循环的routine中尝试往信道中写入内容，这样可以正确实现队列的大小限制。考虑去掉req := req这一行，req变量在每个循环中都被赋予不同的值，但是实际上底层使用的同样的内存，相应的goroutine后的函数闭包可以引用该作用域的变量并且保持和修改，所以每个新生成的goroutine都会使用同一个变量，造成比较严重的错误。","tags":["distributed system"],"title":"Effective Go"},{"categories":null,"contents":"前言 最近想深入下数据库原理，在知乎和Google发现有几门开源的好课值得去学习。我选择的是6.830，首先是之前有刷过6.828，相对来说比较熟悉，不过实现是选择的是java，这也就是我为什么写博客的理由。另外也被人推荐的CMU15445,这门课程稍微浏览了下主页，是使用C++来实现的，并且课件PPT和视频都非常良心。\n这是头一次认真接触JAVA，我使用的是《JAVA核心技术　卷１》,是一本相对来说比较方便C/C++程序员入坑的书，这篇博客也会根据这本书的目录作为大纲进行梳理。\n基本结构 基本类型大多数语言其实差不了太多，不做太多废话，但是字符串的操作更加接近与python那一类的语言，自动拼接、垃圾回收之类的。\n字符串 字符串判断为空：\nif (str.length() == 0) or if (str.equals(\u0026quot;\u0026quot;))  虽然可以进行字符串拼接，但是效率比较低，可以使用StringBuilder类:\nStringBuilder builder = new StringBuilder(); builder.append(ch); builder.append(str); builder.toString();  作用域 JAVA的作用域和C/C++不同，内部块中的同名变量名不会覆盖外部块的变量名，甚至无法通过编译。所以在内部块中需要取不同的变量名，但在class中，可以使用this指针来指定变量。\n数组 JAVA的数组都是分配在堆上，这又是和C/C++不同的一点：\nJAVA中的:\nint[] a = new int[100];  等同于C/C++中的:\nint* a = new int[100];  不同于:\nint a[100];  并且数组的完整拷贝通过方法Arrays.copyOf():\nnewArr = Arrays.copyOf(oldArr, oldArr.lenght());  也可以通过这个方法来扩展数组：\nArr = Arrays.copyOf(Arr, 2 * Arr.lenght());  对象与类 OO应该是JAVA的重点，OOP三个特性：\n 封装：用一个类将实现和使用分开，只保留接口与外部进行联系。 继承：子类自动继承其父类的属性和方法，并且可以添加新的方法和属性。 多态：虽然多个子类都有同一个方法，但是子类的子类实例化之后都可以获得完全不同的结果。  通过下面的方法实例化一个类：\nnew Date();  如果想使用类中的一个方法：\nSystem.out.println(new Date().toString());  final 关键字 const关键字相当于const关键字即不可变的意思，并且在构造一个类的时候必须要被初始化。\nstatic 关键字 static关键字其实也很类似，将static理解为类的方法和域即可而不是对象的方法和域。 例如:\nclass Employee { ... public static currentId; public static int getId() { return currentId; } ... } 调用使用\nint id = Employee.curremtID; int id = Employee.getId(); main方法 有意思的是java的每一个类里面都可以有main函数，这方便了java为每一个类做单元测试，自己在coding的时候也确实经常用到类的main函数进行测试。\n初始化块 初始化块也非常有意思，直接在类域里面输入大括号就能在调用构造器的时候执行。例如：\nclass Employee { private int id; // initializeation block  { id = 1; } } 类继承 java中继承的关键字是extends,并且注意子类中的方法不能直接访问超类中的private域，所以需要通过在超类中准备访问器，利用super关键字来获取private域，构造函数也是如此。\nclass Manager extends Employee{ public Manager(String name) { super(name); ... // other initialization  } } 强制转化 强制转化可以发生在类的子类和超类转化中，进行类型转化的唯一原因是：在暂时忽视对象的实际类型后，使用对象的全部功能。并且，将一个子类的引用赋值给超类的时候，编译器是允许的，但是将一个超类赋值给一个子类变量，必须进行类型转化。\n对于测试强制类型转化，可以使用下面的tricks:\nif (staff instanceof Manager) { boss = (Manager) staff; ... } 意思是，如果staff是Manager的一个实例，那么可以发生强制转化，当然必须是一个继承链才能成立。\n抽象类 抽象类的意义是提供一个较高层次的抽象，作为基类的存在，关键词是abstract。抽象类中的方法只是充当占位的角色，真正对方法的实现发生在子类中，并且抽象类不能被实例化。\n如果子类实现了全部的抽象方法，那么子类就不是抽象的。但若子类只定义了部分抽象类或不定义抽象类的方法，子类也必须标记为抽象类。\n受保护访问 protected关键词可以使得子类能够访问该域，但是外部代码不行，不过通常都是谨慎使用protected类，因为违背了OOP提倡的数据封装原则。\n继承的设计技巧  将公共操作和域放在超类中 不使用protected 使用继承实现\u0026quot;is-a\u0026quot;关系 除非所有的继承方法都有意义，否则不使用继承 覆盖方法时，不要改变预期行为 使用多态，而非类型信息  接口、lambda、内部类 java提供的这三种机制是用来弥补类和类继承一些地方的不灵活性而创立的高级技术。\n接口 书上给了一个很好的理解接口的解释：”如果类遵从某个特定的接口，那么就履行这项服务“。即如果要调用数组的排序服务，那么这个数组中的类需要提供一个不同对象之间进行比较的接口。\n比如，用Employee类提供接口,关键词是implements，之后跟随的是要提供的接口:\nclass Employee implements Compareble\u0026lt;Employee\u0026gt; { public int compareTo(Employee other) { ... // implements  } ... } 当然，在某一处提供了接口的代码，类似于声明的作用：\npublic interface Comparable { int compareTo\u0026lt;Object other\u0026gt; } 其中Object类是所有类的超类。\n接口不是类，所以不能被实例化，但是可以声明接口的变量：\nComparable x;  然后引用实现了接口的类对象：\nx = new Employee(...);  接口不能包含实例域和静态方法，但是可以包含常量。\n接口概念对于抽象类来说是不同的，抽象类只能用在继承链之中，每个子类只能继承一个超类，但是接口可以实现多个，提高了代码复用。\n深拷贝和浅拷贝 java每个变量其实可以理解为一个指针或者引用，它们引用一个内存空间作为对象实例的存储位置，但是对象实例中也可能引用了其他的对象。\n浅拷贝就是单单拷贝该变量引用的内存部分，但是深拷贝会将该对象内部所引用的对象也拷一份。\n比如：\nclass Employee implements Cloneable { ... public Employee clone() { Employee cloned = (Employee) super.clone(); cloned.hireDay = (Date) hireDay.clone(); } } 这样就是深拷贝，在拷贝完本身的内容后还会递归拷贝所引用对象的内存。\nlambda表达式 lambda就是一个代码块，表达形式为 (参数) -\u0026gt; 表达式。 例如:\nComparator\u0026lt;String\u0026gt; comp = (first, second) -\u0026gt; first.length() - second.length();  如果出现如下类似的lambda表达式:\nx-\u0026gt;System.out.println(x) 那么可以简写为:\nSystem.out::println lambda表达式中的一些限制：\n 只能引用不会改变的变量 表达式捕获的变量必须是实际上的最终变量 lambda中的局部变量不能与外部变量重名  可以使用Runable来保存一个lambda,类似于回调：\nRunable an = (int a, int b)-\u0026gt;System.out.println(a+b); ... ... an.run(); 内部类 顾名思义，内部类就是定义在一个class内部的类，使用原因：\n 内部类方法可以访问该类定义所在作用域中的数据，包括私有数据 内部类可以对同一类中的其他类隐藏起来 若想定义一个回调函数，使用匿名内部类会比较便捷  内部类其实是相对于所在类的一个独立的类，当new操作符新建一个实体的时候，并不会实体化内部类，内部类需要独立进行实例化。不过，内部类和所在类建立了一定的联系使得内部类可以访问外围类的数据。\n内部类的初始化语法稍微有点复杂：\nouterObject.new InnerClass(construction parmeter)  例如：\nTalkingClock jabberer = new TalkingClock(1000, true); TalkingClock.TimePrinter listener = jabberer.new TimerPrinter(); 内部类的一些限制：\n 内部类声明所有的静态域必须要final，对于每一个外围类只需要有一个静态域的实例，若不是final，则分别会有单独的内部类实例。 类似于lambda，访问外围局部变量也需要保证被引用的局部变量是事实上的final,内部类引用的时候，实际上创建了一份备份，防止外围类被垃圾回收的时候，引用出错，并且声明为final使得内部类和外围类引用的同一个实体。  有一种方法来绕过这个限制，使用长度为1的数组：\nint[] conuter new int[1]; for (int i = 0; i \u0026lt; dates.length; i++) dates[i] = new Date() { public int compareTo(Date other); return super.compareTo(other); }; 匿名内部类 匿名内部类是一种很方便的工具来扩充某个接口，它的语法如下：\nnew SuperType(construction parameters) { inner class methods and data } 常用的使用方式为\nPerson queen = new Person(\u0026#34;Mary\u0026#34;); // normal object Person count = new Person(\u0026#34;Dracula\u0026#34;) { ... }; // a object extending Person ","date":"November 18, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/jvm%E7%9B%B8%E5%85%B3/core-java-for-database/","summary":"前言 最近想深入下数据库原理，在知乎和Google发现有几门开源的好课值得去学习。我选择的是6.830，首先是之前有刷过6.828，相对来说比较熟悉，不过实现是选择的是java，这也就是我为什么写博客的理由。另外也被人推荐的CMU15445,这门课程稍微浏览了下主页，是使用C++来实现的，并且课件PPT和视频都非常良心。\n这是头一次认真接触JAVA，我使用的是《JAVA核心技术　卷１》,是一本相对来说比较方便C/C++程序员入坑的书，这篇博客也会根据这本书的目录作为大纲进行梳理。\n基本结构 基本类型大多数语言其实差不了太多，不做太多废话，但是字符串的操作更加接近与python那一类的语言，自动拼接、垃圾回收之类的。\n字符串 字符串判断为空：\nif (str.length() == 0) or if (str.equals(\u0026quot;\u0026quot;))  虽然可以进行字符串拼接，但是效率比较低，可以使用StringBuilder类:\nStringBuilder builder = new StringBuilder(); builder.append(ch); builder.append(str); builder.toString();  作用域 JAVA的作用域和C/C++不同，内部块中的同名变量名不会覆盖外部块的变量名，甚至无法通过编译。所以在内部块中需要取不同的变量名，但在class中，可以使用this指针来指定变量。\n数组 JAVA的数组都是分配在堆上，这又是和C/C++不同的一点：\nJAVA中的:\nint[] a = new int[100];  等同于C/C++中的:\nint* a = new int[100];  不同于:\nint a[100];  并且数组的完整拷贝通过方法Arrays.copyOf():\nnewArr = Arrays.copyOf(oldArr, oldArr.lenght());  也可以通过这个方法来扩展数组：\nArr = Arrays.copyOf(Arr, 2 * Arr.lenght());  对象与类 OO应该是JAVA的重点，OOP三个特性：\n 封装：用一个类将实现和使用分开，只保留接口与外部进行联系。 继承：子类自动继承其父类的属性和方法，并且可以添加新的方法和属性。 多态：虽然多个子类都有同一个方法，但是子类的子类实例化之后都可以获得完全不同的结果。  通过下面的方法实例化一个类：","tags":["Java"],"title":"Core Java for DataBase"},{"categories":["sys"],"contents":"这篇文章是针对APUE习题11-2的writeup，进程在开启线程后，不同线程需要完成不同的工作，然后在运行中可能引用同一个元素，举一个例子，当多个线程创建后，需要从消息队列中获取一个作业信息的结构体来部署作业工作，但是可能出现第一个线程获取到一个作业之后，在将此作业从作业队列中删除之前，另外一个线程获取了这个作业，然后同样从队列中删除这个作业的操作，那么这个作业就会被删除两次，在C中通常是用链表实现，往往这样做的结果就是指针访问不存在的对象，引发段错误，从而发生非同步性的修改。\n在完成这道题目之前，先对结构体做一些简单的修改，新增两个元素，作业函数指针和要进行累加的数字。\nstruct job { struct job *j_next; struct job *j_prev; pthread_t j_id; /** job */ int (*j_add)(int); int j_num; }; 然后写一个简单的作业函数，完成j_num的累加工作，已经初始化结构体job的作业分配函数，并且将这个作业加入到作业队列中去：\n 累加函数  int add(int i) { int sum; sum = 0; while (i) sum += i--; return sum; }  作业分配  struct job * job_alloc(struct queue *qp, int num) { struct job *jp; if ((jp = (struct job *)malloc(sizeof(struct job))) == NULL) return (NULL); jp-\u0026gt;j_add = add; jp-\u0026gt;j_num = num; jp-\u0026gt;j_id = pthread_self(); job_insert(qp, jp); return (jp); } 然后可以创建一个线程去完成作业分配工作，生成一个待执行的作业队列，虽然在这里使用主线程来创建会更好。\n 开启线程以及队列初始化  struct queue qn; int err; pthread_t tid1, tid2; queue_init(\u0026amp;qn); setbuf(stdout, NULL); err = pthread_create(\u0026amp;tid1, NULL, th_func1, \u0026amp;qn); if (err != 0) err_exit(err, \u0026#34;thread create error\u0026#34;); pthread_join(tid1, NULL);  线程例程  void * th_func1(void *arg) { job_alloc((struct queue *)arg, 10); job_alloc((struct queue *)arg, 9); job_alloc((struct queue *)arg, 8); job_alloc((struct queue *)arg, 7); return ((void *)0); } 题目中有提到，需要将线程挂起然后修改作业对应的线程ID，之后要继续执行进行验证，在这里先排除信号量，因为信号量是用在多进程同步，异常的一种机制；所以选择条件变量实现线程的唤醒操作，然后定义一个枚举量来判断多线程处于挂起还是运行状态，如果线程发现这个全局枚举量是处于运行状态，从作业队列中用job_find找到一个作业，并且使用job_remove从作业队列中移除。\n 条件变量和枚举量  /** thread suspend mutex*/ pthread_cond_t jready = PTHREAD_COND_INITIALIZER; pthread_mutex_t statmtx = PTHREAD_MUTEX_INITIALIZER; pthread_barrier_t b; enum status { STOP = 0, RUNNING = 1 }; static enum status t1st = STOP;  作业线程例程  void * th_func2(void *arg) { struct job *jp; int sum; pthread_mutex_lock(\u0026amp;statmtx); while (t1st == STOP) { printf(\u0026#34;thread %lu is waiting resource..\\n\u0026#34;, (unsigned long)pthread_self()); pthread_cond_wait(\u0026amp;jready, \u0026amp;statmtx); /** when the pthread recived the signal, it will test the while loop confidion fisrt*/ } printf(\u0026#34;thread %lu is going to run\\n\u0026#34;, (unsigned long)pthread_self()); pthread_mutex_unlock(\u0026amp;statmtx); jp = job_find((struct queue *)arg, pthread_self()); job_remove((struct queue *)arg, jp); /** processing job */ sum = jp-\u0026gt;j_add(jp-\u0026gt;j_num); printf(\u0026#34;thread %lu caculate %d\\n\u0026#34;, (unsigned long)pthread_self(), sum); printf(\u0026#34;return = %d, tid = %lu\\n\u0026#34;, pthread_barrier_wait(\u0026amp;b), (unsigned long)pthread_self()); 全局枚举量已经将状态设置为了暂停状态，所以线程一进入例程，就将挂起等待条件变量发生改变，恢复函数应该将枚举量提前设置为运行状态，因为当pthread_cond_wait()函数在接收到条件变量发生变化时，只是唤醒线程，不能跳出while循环。\n 修改线程ID  int modify_tid(struct queue *qp, pthread_t tid1, pthread_t tid2) { struct job *jp; pthread_rwlock_wrlock(\u0026amp;qp-\u0026gt;q_lock); for (jp = qp-\u0026gt;q_head; jp != NULL; jp = jp-\u0026gt;j_next) if (pthread_equal(jp-\u0026gt;j_id, tid1)) break; jp-\u0026gt;j_id = tid2; pthread_rwlock_unlock(\u0026amp;qp-\u0026gt;q_lock); return 0; } 在线程唤醒之前，将ID修改为tid2指定的数值，让新创建的线程能在工作队列中找到设置好的对应作业。\n 线程恢复  void th_resume(void) { if (t1st == STOP) { pthread_mutex_lock(\u0026amp;statmtx); t1st = RUNNING; pthread_cond_broadcast(\u0026amp;jready); printf(\u0026#34;thread resume signal send..\\n\u0026#34;); pthread_mutex_unlock(\u0026amp;statmtx); } } 简单地把状态设置为运行，并且广播条件变量已经发生了改变。\n 多线程创建和恢复运行线程  pthread_barrier_init(\u0026amp;b, NULL, 4+1); for (int i = 0; i \u0026lt; 4; i++) { err = pthread_create(\u0026amp;tid2, NULL, th_func2, \u0026amp;qn); if (err != 0) err_exit(err, \u0026#34;thread create error\u0026#34;); modify_tid(\u0026amp;qn, tid1, tid2); } th_resume(); pthread_barrier_wait(\u0026amp;b); 11-2-preposition.c\n多个线程按照想象中的情况从作业队列中取出不同的作业，然后从队列中删去通过job_find()找到的作业，并且调用登记在结构体中的函数进行累加，最后在pthread_barrier_wait()处进行同步。值得注意的是，虽然在这里一共开了4个线程，但是调用pthread_barrier_init()进行初始化的时候，将屏障需要等待的线程数设置为5，因为是把主线程也算了进去。还有一个有意思的地方是，总有一个线程在到达屏障的时候返回-1，是因为这个值实际上代表的是PTHREAD_BARRIER_SERIAL_THREAD宏，说明这个线程来执行多个线程的归并操作。\n通过书上给的代码，已经实现了一个多线程处理作业队列的操作，并且修改了暂停线程的ID，使得对应线程能从工作队列中得到作业。那么回到题目问到的问题上，这样会对job_remove产生什么影响？试想这样一种情况，当一个线程已经被唤醒了，然后去调用job_find函数寻找相应ID的作业，使得线程的工作指针jp指向改结构体，但是此时发生了调度或者系统拥塞事件，这时调用了修改之前修改线程id的函数modify_tid，使得描述该作业的结构体的线程ID被填写为另外一个线程的线程ID，现在的情况就变成两个线程的工作指针jp都指向了同一个结构体，并且准备执行job_remove，这时候任意一个线程先执行，后者都会产生段错误（一般是对NULL指针解引用）。现在修改之前代码来模拟这种情况:\n11-2-exception.c\n 模拟拥塞或者调度  jp = job_find((struct queue *)arg, pthread_self()); sleep(5); job_remove((struct queue *)arg, jp);  修改ID  err = pthread_create(\u0026amp;tid1, NULL, th_func1, \u0026amp;qn); if (err != 0) err_exit(err, \u0026#34;thread create error\u0026#34;); pthread_join(tid1, NULL); err = pthread_create(\u0026amp;tid2, NULL, th_func2, \u0026amp;qn); if (err != 0) err_exit(err, \u0026#34;thread create error\u0026#34;); modify_tid(\u0026amp;qn, tid1, tid2); th_resume(); sleep(1); /** important here*/ th_suspend(); err = pthread_create(\u0026amp;tid3, NULL, th_func2, \u0026amp;qn); if (err != 0) err_exit(err, \u0026#34;thread create error\u0026#34;); modify_tid(\u0026amp;qn, tid2, tid3); th_resume(); sleep(10); 结果和前面所述的情况一样，两次remove引发了段错误。\n根据提示，可以使用引用计数和一个嵌入结构体的互斥量来解决这个问题，在job_find()的时候对引用计数进行加一，在job_remove的时候检查引用计数，知道引用计数为0才实际从作业队列中移除。\n 修改结构体  struct job { struct job *j_next; struct job *j_prev; pthread_t j_id; /**mutex and reference count*/ pthread_mutex_t j_mtx; int j_count; /** job */ int (*j_add)(int); int j_num; };  job_find  struct job * job_find(struct queue *qp, pthread_t id) { struct job *jp; if (pthread_rwlock_rdlock(\u0026amp;qp-\u0026gt;q_lock) != 0) return (NULL); for (jp = qp-\u0026gt;q_head; jp != NULL; jp = jp-\u0026gt;j_next) { printf(\u0026#34;head %p now %p \\n|-job_id %lu cur_id %lu\\n\u0026#34;, qp-\u0026gt;q_head, jp, (unsigned long)jp-\u0026gt;j_id, (unsigned long)id); if (pthread_equal(jp-\u0026gt;j_id, id)) { pthread_mutex_lock(\u0026amp;jp-\u0026gt;j_mtx); jp-\u0026gt;j_count++; pthread_mutex_unlock(\u0026amp;jp-\u0026gt;j_mtx); break; } } pthread_rwlock_unlock(\u0026amp;qp-\u0026gt;q_lock); return (jp); }  job_remove  void job_remove(struct queue *qp, struct job *jp) { pthread_mutex_lock(\u0026amp;jp-\u0026gt;j_mtx); if (jp-\u0026gt;j_count == 1) { /** avoid deadlock*/ pthread_mutex_unlock(\u0026amp;jp-\u0026gt;j_mtx); pthread_rwlock_wrlock(\u0026amp;qp-\u0026gt;q_lock); pthread_mutex_lock(\u0026amp;jp-\u0026gt;j_mtx); if (jp-\u0026gt;j_count != 1) { jp-\u0026gt;j_count--; pthread_mutex_unlock(\u0026amp;jp-\u0026gt;j_mtx); pthread_rwlock_unlock(\u0026amp;qp-\u0026gt;q_lock); } if (jp == qp-\u0026gt;q_head) { qp-\u0026gt;q_head = jp-\u0026gt;j_next; if (qp-\u0026gt;q_tail == jp) qp-\u0026gt;q_tail = NULL; else jp-\u0026gt;j_next-\u0026gt;j_prev = jp-\u0026gt;j_prev; } else if (jp == qp-\u0026gt;q_tail) { qp-\u0026gt;q_tail = jp-\u0026gt;j_prev; jp-\u0026gt;j_prev-\u0026gt;j_next = jp-\u0026gt;j_next; } else { jp-\u0026gt;j_prev-\u0026gt;j_next = jp-\u0026gt;j_next; jp-\u0026gt;j_next-\u0026gt;j_prev = jp-\u0026gt;j_prev; } pthread_mutex_unlock(\u0026amp;jp-\u0026gt;j_mtx); pthread_rwlock_unlock(\u0026amp;qp-\u0026gt;q_lock); } else { jp-\u0026gt;j_count--; pthread_mutex_unlock(\u0026amp;jp-\u0026gt;j_mtx); } } 并且稍微修改下线程的例程，重新检测线程ID是否发生了改变：\nwhile (1) { jp = job_find((struct queue *)arg, pthread_self()); sleep(5); job_remove((struct queue *)arg, jp); if (jp-\u0026gt;j_id == pthread_self()) break; } 11-2.c\n运行结果如下，现在两个线程可以正常的从作业队列中取作业页并且执行工作了，但是这并不是最好调度方式，如果发生了这样的问题，很大程度上是接口没有设计好，应对这样的问题书中也做了提醒，要为结构体的空间留下空位，以便以后进行拓展。\n","date":"October 15, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/sys/thread-synchronization/","summary":"这篇文章是针对APUE习题11-2的writeup，进程在开启线程后，不同线程需要完成不同的工作，然后在运行中可能引用同一个元素，举一个例子，当多个线程创建后，需要从消息队列中获取一个作业信息的结构体来部署作业工作，但是可能出现第一个线程获取到一个作业之后，在将此作业从作业队列中删除之前，另外一个线程获取了这个作业，然后同样从队列中删除这个作业的操作，那么这个作业就会被删除两次，在C中通常是用链表实现，往往这样做的结果就是指针访问不存在的对象，引发段错误，从而发生非同步性的修改。\n在完成这道题目之前，先对结构体做一些简单的修改，新增两个元素，作业函数指针和要进行累加的数字。\nstruct job { struct job *j_next; struct job *j_prev; pthread_t j_id; /** job */ int (*j_add)(int); int j_num; }; 然后写一个简单的作业函数，完成j_num的累加工作，已经初始化结构体job的作业分配函数，并且将这个作业加入到作业队列中去：\n 累加函数  int add(int i) { int sum; sum = 0; while (i) sum += i--; return sum; }  作业分配  struct job * job_alloc(struct queue *qp, int num) { struct job *jp; if ((jp = (struct job *)malloc(sizeof(struct job))) == NULL) return (NULL); jp-\u0026gt;j_add = add; jp-\u0026gt;j_num = num; jp-\u0026gt;j_id = pthread_self(); job_insert(qp, jp); return (jp); } 然后可以创建一个线程去完成作业分配工作，生成一个待执行的作业队列，虽然在这里使用主线程来创建会更好。","tags":null,"title":"线程同步"},{"categories":["algorithm"],"contents":"CLRS快撸完一半了，所以趁开学前做下小总结，CLRS研究问题的方式和平时的感觉有那么些不太一样，但是接触久了就会慢慢习惯，主要注重算法的运行时间和算法可行性。初阶学习目标是掌握几种重要的排序算法和课堂中没有学到的数据结构。\n首先还要推荐一下usfca的这个算法可视化的网站：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html\n排序算法 排序算法在系统学习之前，只会冒泡排序，非常简单但是时间复杂度为O(n^2)的算法，是一种没有怎么优化过的想法。\n插入排序 插入排序(insert sort)是学习CLRS最先接触的算法，可以理解为将序列中的元素插入到一个已经排序好的队列中去。提供一个序列的起始位置(be)和长度(len)，循环从起始位置的下一个元素开始迭代，作为需要插入的数值(key)，将所有大于关键字元素后移一位，最后在放入对应的位置。期望运行时间(n^2)。\nfor (int i = be + 1; i \u0026lt; len; i++) { int key = a[i]; int j = i - 1; while (j \u0026gt;= 0 \u0026amp;\u0026amp; a[j] \u0026gt; key) { a[j+1] = a[j]; j--; } a[j+1] = key; } 归并排序 归并排序(merge sort)是接触分治法接触到的算法，这种方法是将需要解决的问题细分为细小的问题，然后递归求解这些子问题，直接求解，最后将这些子问题的解合并成原问题的解。应用到排序算法中的话就是将待排序的元素分成n/2两个子序列，然后递归解决子序列的顺序问题，最后合并两个已排序的子序列，形成排序好的队列。期望运行时间(nlgn)。\n首先是归并过程的辅助函数:\nvoid SortAlgorithm::mergeArray(int p, int q, int r) { int n1 = q - p + 1; int n2 = r - q; int L[n1], R[n2]; int i1, i2; for (int i = 0; i \u0026lt; n1; i++) L[i] = a[p+i]; for (int i = 0; i \u0026lt; n2; i++) R[i] = a[q+i+1]; i1 = 0; i2 = 0; for (int k = p; k \u0026lt;= r; k++) { if ((L[i1] \u0026lt;= R[i2] \u0026amp;\u0026amp; i1 \u0026lt; n1 )|| i2 == n2) { a[k] = L[i1]; i1++; } else { a[k] = R[i2]; i2++; } } } 前面两个for循环是赋值递归过程已经排好的两个子数组left和right，然后根据i1和i2所指向的数组元素大小放入到原来的数组中去，完成两个子数组的归并。\n然后是一个将问题分解的递归过程:\nvoid SortAlgorithm::mergeSort(int p, int r) { int q; if (p \u0026lt; r) { q = (r + p) / 2; mergeSort(p, q); mergeSort(q+1, r); mergeArray(p, q, r); } } 主定理 //todo\n堆排序 堆的性质比较简单，以最大堆为例，父节点必须大于等于子节点的值。另外还有个重要的推论：叶子节点的下标分别是n/2+1，　n/2+2, ｎ/2+3, \u0026hellip;, n。其中，堆排序的最坏运行时间期望是(nlgn)。\n实现堆的过程首先是:\n 位置关系和辅助函数  inline int PARENT(int i) { return i / 2; } inline int LEFT(int i) { return i * 2; } inline int RIGHT(int i) { return i * 2 + 1; } inline void pSwap(int \u0026amp;x, int \u0026amp;y) { int temp = x; x = y; y = temp; } 堆的维护过程  将指定节点与左右节点相互比较，让三个节点中最大的节点成为父节点。\nvoid SortAlgorithm::maxHeapify(int i) { int l = LEFT(i); int r = RIGHT(i); int lagest; if (l \u0026lt; arrayLength() \u0026amp;\u0026amp; a[i-1] \u0026lt; a[l-1]) lagest = l; else lagest = i; if (r \u0026lt; arrayLength() \u0026amp;\u0026amp; a[lagest-1] \u0026lt; a[r-1]) lagest = r; if (lagest != i) { pSwap(a[i-1], a[lagest -1]); maxHeapify(lagest); } } 建立堆  将一个已有的序列形成堆，利用由下往上的方法建立。\nvoid SortAlgorithm::bulidMaxHeap() { for (int i = arrayLength()/2; i \u0026gt;= 1; i--) maxHeapify(i); } 堆排序  建成好的堆的根节点是这个序列的最大值，所以，将这个节点先排除出来，然后再进行堆化，可以找出次最大值，依次类推得到一个排好序的队列。\nvoid SortAlgorithm::heapSort() { for (int i = arrayLength(); i \u0026gt;= 2; i--) { pSwap(a[0], a[i-1]); maxHeapify(1); len--; } } 先将最大值根节点与数组的端节点交换，然后将长度减少1，对根节点堆化，重新形成最大堆。\n快速排序 快排是一种使用广泛的排序，虽然最坏运行情况是时间复杂度是(n^2)，但是在元素不用的情况下，期望时间复杂度是(nlgn)，并且，快速排序的过程中不用不会用到临时数组作为存储，也就是说，快速排序是原址排序的。快排的思想和归并一样，先将问题进行分解再归并。\n快排的代码不长，代码比想象中要神奇。\n首先是原址重排：\nint SortAlgorithm::partitionArray(int p, int r) { int key = a[r-1]; int i = p - 1; for (int k = p; k \u0026lt;= r; k++) { if (a[k-1] \u0026lt; key) { i++; pSwap(a[i-1], a[k-1]); } } pSwap(a[i+1-1], a[r-1]); return i+1; } 这个函数的作用就是将(p-\u0026gt;r)的数组进行划分，把数组端点的值作为划分界限，也叫主元。然后递归下去，将每一个小区域进行排序，完成排序。\n然后是分治的过程：\nvoid SortAlgorithm::quickSort(int p, int r) { if (p \u0026lt; r) { int q = partitionArray(p, r); quickSort(p, q-1); quickSort(q+1, r); } } ps:是先进行分治然后再细分的。\n计数排序 基数排序(count sort)也是一种比较神奇的算法，要用到三个数组。时间复杂度为(k+n)。\nvoid SortAlgorithm::countSort() { // the size fo array c must  // bigger than the maximum number  // in the array a.  int length = arrayLength(); int b[length], c[length]; for (int i = 0; i \u0026lt; length; i++) { c[i] = 0; b[i] = 0; } for (int i = 1; i \u0026lt;= length; i++) c[a[i-1]]++; for (int i = 1; i \u0026lt; length; i++) c[i] = c[i-1] + c[i]; for (int i = length; i \u0026gt;= 1; i--) { b[c[a[i-1]]-1] = a[i-1]; c[a[i-1]]--; } for (int i = 0; i \u0026lt; length; i++) a[i] = b[i]; } 计数排序的主要用第2，3，4个循环进行排序，其中a[i]对应着序列的值，C[i]对应在数组B中最后填充的位置。每当填充一个，C[i]就会进行减1操作，实际上就是对应在数组B中的位置往前面移动一位。\n基数排序 基数排序(radix)在针对数值不大的情况是一种很好的排序算法，其中会用到一种稳定的排序算法作为子算法排序，虽然用到了其他的算法，但是更加重要的其想法。针对数值的相应位进行比较排序。\n用到了三个辅助函数:\nint getBase(int n) { int d = 0; while (n/10 != 0) n /= 10, d++; return d; } int power(int base,int p) { if (p == 0) return 1; if (p == 1) return base; int result = power(10, p/2); if (p % 2 == 1) return base * result * result; else return result * result; } int getNumber(int n, int d) { if (d == 0) return n % 10; return (n % power(10, d+1)) / power(10, d); } getBase()获得元素的基数,\npower获取以base为底,p为幂值的数值,\ngetNumber()获取对应位数的值。\n然后进行对应数位的排序移位:\nvoid SortAlgorithm::radixSort() { int maxBase = 0; int d; int b[arrayLength()]; for (int i = 0; i \u0026lt; arrayLength(); i++) { d = getBase(radixArr[i]); maxBase = maxBase \u0026gt; d ? maxBase : d; } for (int i = 0; i \u0026lt; maxBase+1; i++) { for (int j = 0; j \u0026lt; arrayLength(); j++) b[j] = getNumber(radixArr[j], i); dependInsertSort(b, 0, arrayLength()); } } 数据结构 散列表 二叉搜索树 二叉搜索树建立好后就已经是一个排序好的序列了，只要执行中序遍历，就是顺序序列。首先声明这样一个结构体来代表叶节点。\ntypedef struct treenode { treenode(int value); int key; struct treenode *left; struct treenode *right; struct treenode *p; //parent }node; 以及用来整合二叉树操作的类，其中包含一个数据来存放树的根节点。\nclass BinarySearchTree { public: BinarySearchTree(); void treeInsert(node *z); void inorderTreeWalk(node *x); node* getRoot(); node* searchNode(int value); node* treeMin(node *x); node* treeMAX(node *x); node* successor(node *x); void treeDelete(node *z); void transplant(node* u, node* v); private: node *root; }; 二叉搜索树中的删除操作要分情况讨论:\n 如果节点没有孩子节点，那么直接替换该节点为null即可。 如果只有一个孩子，那么用孩子节点进行替换。 如果有两个孩子，那么寻找该节点的后继（顺序序列的下一个值）来代替该节点，并且后继节点一定在该节点的右子树中。  首先是要一个辅助过程tansplant来帮助删除，即用u的双亲来代替v的双亲。\nvoid BinarySearchTree::transplant(node *u, node *v) { // v -\u0026gt; u  if (u-\u0026gt;p == NULL) root = v; else if (u == u-\u0026gt;p-\u0026gt;left) u-\u0026gt;p-\u0026gt;left = v; else u-\u0026gt;p-\u0026gt;right = v; if (v != NULL) v-\u0026gt;p = u-\u0026gt;p; } 然后就是根据三种情况来删除节点:\nvoid BinarySearchTree::treeDelete(node *z) { if (z-\u0026gt;left == NULL) transplant(z, z-\u0026gt;right); else if (z-\u0026gt;right == NULL) transplant(z, z-\u0026gt;left); else { node *y = treeMin(z-\u0026gt;right); if (y-\u0026gt;p != z) { transplant(y, y-\u0026gt;right); y-\u0026gt;right = z-\u0026gt;right; y-\u0026gt;right-\u0026gt;p = y; } transplant(z, y); y-\u0026gt;left = z-\u0026gt;left; y-\u0026gt;left-\u0026gt;p = y; } } 红黑树 红黑树是一种平衡树，大致意思就是树的节点会分散得比较平均。相比二叉搜索树来说，执行一些动态集合操作比如插入删除，搜索的时候执行会比较快，可以保证最差情况下，动态集合操作的时间复杂度为nlgn。\n红黑树的性质：\n 每个节点都是红色或者黑色的。 根节点是黑色的。 每个叶节点都是黑色的(nil)。 如果一个节点是红色的，那么两个子节点都是黑色的。 从某个节点出发，到其叶子节点的简单路径上，所包含的黑色节点相同。  所以引申出一颗有n个及诶单的红黑树的高度最高为2lg(n+1)。\n实现红黑树的插入操作之前，需要用到一个旋转操作来保持二叉搜索树性质: 左旋操作：\nvoid rbtree::LeftRotate(rbnode *x) { rbnode *y = x-\u0026gt;right; x-\u0026gt;right = y-\u0026gt;left; if (y-\u0026gt;left != NULL) y-\u0026gt;left-\u0026gt;p = x; y-\u0026gt;p = x-\u0026gt;p; if (x-\u0026gt;p == NULL) root = y; else if (x == x-\u0026gt;p-\u0026gt;left) x-\u0026gt;p-\u0026gt;left = y; else x-\u0026gt;p-\u0026gt;right = x; y-\u0026gt;left = x; x-\u0026gt;p = y; } 右旋操作：\nvoid rbtree::RightRotate(rbnode *y) { rbnode *x = y-\u0026gt;left; y-\u0026gt;left = x-\u0026gt;right; if (x-\u0026gt;right != NULL) x-\u0026gt;right-\u0026gt;p = y; x-\u0026gt;p = y-\u0026gt;p; if (y-\u0026gt;p == NULL) root = x; else if (y == y-\u0026gt;p-\u0026gt;left) x = y-\u0026gt;p-\u0026gt;left; else x = y-\u0026gt;p-\u0026gt;right; x-\u0026gt;right = y; y-\u0026gt;p = x; } 然后是插入操作，和二叉搜索树一样，通过和节点比对大小确定插入的位置，但是多出一个把新的节点涂色的过程，新的节点会被涂成红色，方便进行平衡二叉树，插入操作完成后，要对红黑树的性质进行检查，并且修复RBT。\n插入操作实现：\nvoid rbtree::RBInsert(rbnode* z) { rbnode *x, *y; y = NULL; x = root; while (x != NULL) { y = x; if (z-\u0026gt;key \u0026lt; x-\u0026gt;key) x = x-\u0026gt;left; else x = x-\u0026gt;right; } z-\u0026gt;p = y; if (y == NULL) root = z; else if (z-\u0026gt;key \u0026lt; y-\u0026gt;key) y-\u0026gt;left = z; else y-\u0026gt;right = z; z-\u0026gt;c = RED; z-\u0026gt;left = NULL; z-\u0026gt;right = NULL; RBinsertFixup(z); } 新插入的节点是红色，如果此时其父节点也是红色，那么就违反了性质4，因此要进行红黑树的修复操作，红黑树的插入修复有三种情况： （假定新插入的节点为z，父节点为z.p,叔节点为y）\n a. z节点的叔节点y是红色的，那么将z.p和y都着为黑色，z.p.p着为红色，并且将z指向z.p.p   b. z的叔节点y是黑色，并且z是一个右孩子，那么对z的父节点z.p进行左旋操作。   c. z的叔节点y是黑色，并且z是一个左孩子，那么就将z.p着为黑色，z.p.p着为红色，对z.p执行右旋操作。   以上只是针对一边的情况，另外一侧镜像对称操作，下面是修复操作的实现：\nvoid rbtree::RBinsertFixup(rbnode* z) { rbnode *y; printf(\u0026#34;node : %d %s\\n\u0026#34;, z-\u0026gt;key, z-\u0026gt;c ? \u0026#34;RED\u0026#34;:\u0026#34;BLACK\u0026#34;); while (z-\u0026gt;p != NULL \u0026amp;\u0026amp; z-\u0026gt;p-\u0026gt;p != NULL \u0026amp;\u0026amp; z-\u0026gt;p-\u0026gt;c == RED) { if (z-\u0026gt;p == z-\u0026gt;p-\u0026gt;p-\u0026gt;left) { y = z-\u0026gt;p-\u0026gt;p-\u0026gt;right; /*case 1*/ if (y != NULL \u0026amp;\u0026amp; y-\u0026gt;c == RED) { //uncle node is red  z-\u0026gt;p-\u0026gt;c = BLACK; y-\u0026gt;c = BLACK; z-\u0026gt;p-\u0026gt;p-\u0026gt;c = RED; z = z-\u0026gt;p-\u0026gt;p; } else { if (z == z-\u0026gt;p-\u0026gt;right) { /*case 2*/ z = z-\u0026gt;p; LeftRotate(z); } /*case 3*/ z-\u0026gt;p-\u0026gt;c = BLACK; z-\u0026gt;p-\u0026gt;p-\u0026gt;c =RED; RightRotate(z-\u0026gt;p-\u0026gt;p); } }else { y = z-\u0026gt;p-\u0026gt;p-\u0026gt;left; if (y != NULL \u0026amp;\u0026amp; y-\u0026gt;c == RED) { z-\u0026gt;p-\u0026gt;c = BLACK; y-\u0026gt;c = BLACK; z-\u0026gt;p-\u0026gt;p-\u0026gt;c = RED; z = z-\u0026gt;p-\u0026gt;p; } else { if (z == z-\u0026gt;p-\u0026gt;left) { z = z-\u0026gt;p; RightRotate(z); } z-\u0026gt;p-\u0026gt;c = BLACK; z-\u0026gt;p-\u0026gt;p-\u0026gt;c = RED; LeftRotate(z-\u0026gt;p-\u0026gt;p); } } } root-\u0026gt;c = BLACK; } 实现删除操作之前，要准备两个辅助函数，一个用来更换父节点，一个用来寻找节点的后继。\n首先是transplant将u的父节点的子节点更换为v的操作：\nvoid rbtree::rbTransplant(rbnode *u, rbnode *v) { if (u-\u0026gt;p == NULL) root = v; else if (u == u-\u0026gt;p-\u0026gt;left) u-\u0026gt;p-\u0026gt;left = v; else u-\u0026gt;p-\u0026gt;right = v; if (v != NULL) v-\u0026gt;p = u-\u0026gt;p; } 寻找某个节点后继即寻找左孩子的右子树：\nrbnode * rbtree::minimum(rbnode *x) { while (x-\u0026gt;left != NULL) x = x-\u0026gt;left; return x; } 删除操作也和二叉搜索树想类似，如果只有一个节点就简单删除；否则，寻找后继节点来替代被删除的节点，但是红黑树需要对颜色进行跟踪，如果被替换的节点y原来是黑色，那么就引起了黑高变化，因此会进行红黑树修复操作。\nvoid rbtree::rbDelete(rbnode *z) { rbnode *x, *y = z; color origin = y-\u0026gt;c; if (z-\u0026gt;left == NULL) { x = z-\u0026gt;right; rbTransplant(z, z-\u0026gt;right); } else if (z-\u0026gt;right == NULL) { x = z-\u0026gt;left; rbTransplant(z, z-\u0026gt;left); } else { y = minimum(z-\u0026gt;right); origin = y-\u0026gt;c; x = y-\u0026gt;right; if (y-\u0026gt;p == z) { if (x != NULL) x-\u0026gt;p = y; } else { rbTransplant(y, y-\u0026gt;right); y-\u0026gt;right = z-\u0026gt;right; y-\u0026gt;right-\u0026gt;p = y; } rbTransplant(z, y); y-\u0026gt;left = z-\u0026gt;left; if (y-\u0026gt;left != NULL) y-\u0026gt;left-\u0026gt;p = y; y-\u0026gt;c = z-\u0026gt;c; free(z); } if (origin == BLACK) rbDeleteFixup(x); } 删除修复工作有些复杂，这里没有理解为什么这么做，先记下来：\n x的兄弟节点w是红色，那么改变w和x.p的颜色，然后对x.p做一次左旋。  x的兄弟节点w是黑色，且w的两个子节点都是黑色，那么将w着为黑色并且将x指向x.p。 x的兄弟节点w是黑色，且w的左孩子是红色的，w的右孩子是黑色的，那么交换w和w.left的颜色，并且对w执行右旋。 x的兄弟节点w是黑色，且w的右孩子是红色的，那么将w的颜色着为x.p的颜色，w.right和x.p都着为黑色，并且对x.p执行左旋。  同样的，以上情况只针对左子树，右子树的处理镜像对称。\n删除操作的实现：\nvoid rbtree::rbDeleteFixup(rbnode *x) { rbnode *w; while (x != root \u0026amp;\u0026amp; x-\u0026gt;c == BLACK) { if (x == x-\u0026gt;p-\u0026gt;left) { w = x-\u0026gt;p-\u0026gt;right; if (w-\u0026gt;c == RED) { //case 1  w-\u0026gt;c = BLACK; x-\u0026gt;p-\u0026gt;c = RED; LeftRotate(x-\u0026gt;p); w = x-\u0026gt;p-\u0026gt;right; } if (w-\u0026gt;left-\u0026gt;c == BLACK \u0026amp;\u0026amp; w-\u0026gt;right-\u0026gt;c == RED) { // case 2  w-\u0026gt;c = RED; x = x-\u0026gt;p; } else { if (w-\u0026gt;right-\u0026gt;c == BLACK) { // case 3  w-\u0026gt;left-\u0026gt;c = BLACK; w-\u0026gt;c = RED; RightRotate(w); w = x-\u0026gt;p-\u0026gt;right; } // case 4  w-\u0026gt;c = x-\u0026gt;p-\u0026gt;c; x-\u0026gt;p-\u0026gt;c = BLACK; w-\u0026gt;right-\u0026gt;c = BLACK; LeftRotate(x-\u0026gt;p); x = root; } } else { w = x-\u0026gt;p-\u0026gt;left; if (w-\u0026gt;c == RED) { w-\u0026gt;c = BLACK; x-\u0026gt;p-\u0026gt;c = RED; RightRotate(x-\u0026gt;p); w = x-\u0026gt;p-\u0026gt;left; } if (w-\u0026gt;left-\u0026gt;c == RED \u0026amp;\u0026amp; w-\u0026gt;right-\u0026gt;c == BLACK) { w-\u0026gt;c = RED; x = x-\u0026gt;p; } else { if (w-\u0026gt;left-\u0026gt;c == BLACK) { w-\u0026gt;right-\u0026gt;c = BLACK; w-\u0026gt;c = RED; LeftRotate(w); w = x-\u0026gt;p-\u0026gt;left; } w-\u0026gt;c = x-\u0026gt;p-\u0026gt;c; x-\u0026gt;p-\u0026gt;c = BLACK; w-\u0026gt;left-\u0026gt;c = BLACK; RightRotate(x-\u0026gt;p); x = root; } } } x-\u0026gt;c = BLACK; } 扩展数据结构 区间树 动态统计树 动态规划 最长公共子序列问题 这个问题为了求出两个字符序列xy中最长的公共子序列(LCS)，用i和j分别代表xy的长度，解决这个问题的方法是分别从字符序列的一段开始比较，分成两种情况：\n 如果x[i] == y[j]，那么说明这个字符是公共字符，属于LCS。那么，接下来只要将这个字符加入到LCS中，并且将序列xy的长度进行减１，继续求出剩下序列的LCS。 如果x[i] != y[j]，那么说明x[i-1]和y[j] 或者 x[i]和y[j-1]存在LCS。  这样可以得到递归式：\n 当x[i] == y[j]时，C[i][j] = C[i-1][j-1]+1 当x[i] != y[j]时，C[i][j] = max{C[i-1][j], C[i][j-1]}  首先定义了一个方向的枚举类型：\nenum direction { LEFT = 0, UP, UpperLeft }; LCS问题用递归的方法更加容易理解和操作：\nint DynamicProgramming::LCSlengthRecursive(int i, int j) { if (i == 0 || j == 0) return 0; if (strA[i-1] == strB[j-1]) c[j][i] = LCSlengthRecursive(i-1, j-1) + 1; else { int x, y; x = LCSlengthRecursive(i-1, j); y = LCSlengthRecursive(i, j-1); c[j][i] = x \u0026gt; y ? x : y; } return c[j][i]; } 然后发现决策树里多次重复出现求同样的子问题的情况，那么可以去掉这些重复的操作，进行一下优化。\nint DynamicProgramming::LCSlengthRecursive(int i, int j) { if (c[j][i] == 0){ if (i == 0 || j == 0) return 0; if (strA[i-1] == strB[j-1]) c[j][i] = LCSlengthRecursive(i-1, j-1) + 1; else { int x, y; x = LCSlengthRecursive(i-1, j); y = LCSlengthRecursive(i, j-1); c[j][i] = x \u0026gt; y ? x : y; } } return c[j][i]; } 但是迭代的速度更快：\nvoid DynamicProgramming::LCSlengthIterate() { int i = 0, j = 0; for (i = 1; i \u0026lt; m; i++) c[0][i] = 0; for (i = 0; i \u0026lt; n; i++) c[i][0] = 0; /*CASE DILIVER*/ for (i = 1; i \u0026lt; n; i++) for (j = 1; j \u0026lt; m; j++) if (strA[j-1] == strB[i-1]) { c[i][j] = c[i-1][j-1] + 1; b[i][j] = UpperLeft; } else if (c[i][j-1] \u0026gt;= c[i-1][j]) { c[i][j] = c[i][j-1]; b[i][j] = LEFT; } else { c[i][j] = c[i-1][j]; b[i][j] = UP; } } PrintLCS(b, c, m, n); } 这个函数后半部分是做LCS各种情况的派发的，两层for循环，内层代表这个表格的x轴，外层代表表格的y轴，将i和j所指的元素进行比较，如果相同根据第一种情况从子问题中获取最优解，也就是长度分别为i-1和长度为j-1的子序列获取LCS，并且由于ij所指定位置相等，该位置进行自增。数组C用来记录LCS的长度，数组B用来LCS的路径。\n在准备输出LCS的时候，想起来要传递两个二维数组，才能递归输出，然后踩到了一个关于二维数组与二级指针转换问题的坑，一种更好的解决办法是把这一部分准备二维数组的操作放入到构造函数内去，并且在析构函数中释放掉：\n/*constructor*/ DynamicProgramming::DynamicProgramming(string s1, string s2) : strA(s1), strB(s2), lcs(\u0026#34;\u0026#34;) , m(strA.length()+1), n(strB.length()+1) { c = (int **) malloc (sizeof(int *[m]) * n); *b = (direction *)malloc(sizeof(direction) * m * n); *c = (int *)malloc(sizeof(int) * m * n); for (int y = 1; y \u0026lt; n; y++ ) { b[y] = b[y-1] + m; c[y] = c[y-1] + m; } } /*destructor*/ DynamicProgramming::~DynamicProgramming() { //dtor  free(*c); free(*b); free(c); free(b); } 。输出递归函数根据数组B所记录的方向进行输出，得到LCS：\nvoid DynamicProgramming::PrintLCS(direction **b, int **c, int x, int y) { if (x == 0 || y == 0) return ; if (b[y-1][x-1] == UpperLeft) { PrintLCS(b, c, x-1, y-1); cout \u0026lt;\u0026lt; strB[y-2] \u0026lt;\u0026lt;endl; } else if (b[y-1][x-1] == LEFT) PrintLCS(b, c, x-1, y); else PrintLCS(b, c, x, y-1); } 贪心算法 贪心问题是每一步都选择最优解,从而达到最有解的情况，相比于动态规划，其编程复杂性比较低。\n活动选择问题 该问题是从起始时间和结束时间不同的多个活动中，选取尽量多的活动，那么贪心的运用就是，先将该活动序列以结束时间进行排序，然后依次选择合适的结束时间早的活动，得到最优解。\n递归实现：\nvoid ActivitySelect::recursive_selector(int k, int n) { int m = k + 1; while (m \u0026lt; n \u0026amp;\u0026amp; f[k] \u0026gt; s[m]) m++; if (m \u0026lt;= n) { greedy_sequence.push_back(m); recursive_selector(m, n); } } 迭代版本：\nvoid ActivitySelect::iterative_selector(int n) { int k = 1; greedy_sequence.push_back(k); for (int m = 2; m \u0026lt;= n; m++) if (s[m] \u0026gt;= f[k]) { greedy_sequence.push_back(m); k = m; } } 为了方便实现并集操作，这里选择将结果的集合用vector来处理。\n霍夫曼编码 霍夫曼编码常用于压缩数据，是在给定字符频率的情况下，获取最优的压缩率，霍夫曼树向左下降就是编码添加0，向右即为1，为了取得较好的压缩率，所以，频率高的关键字应该在接近树根的位置，相应地，频率低的节点应该在叶子节点附近。\n其结构体定义也比较简单，二叉树节点中加入键值和频率即可：\ntypedef struct huffmantree{ huffmantree() = default; huffmantree(char c, int f) : freq(f), character(c){} int freq; char character; struct huffmantree *left; struct huffmantree *right; }hfnode; 因为霍夫曼树每次建立一个新节点都要从需要编码的队列中找出最小的元素，所以，需要完成一个最小堆来减少时间消耗。只需要几个简单的集合操作即可:\n 堆的维护  void minHeapify(hfnode* a, int len, int i) { int r = _Right(i); int l = _Left(i) ; int minimum; if (l \u0026lt; len \u0026amp;\u0026amp; a[l-1].freq \u0026lt; a[i-1].freq) minimum = l; else minimum = i; if (r \u0026lt; len \u0026amp;\u0026amp; a[r-1].freq \u0026lt; a[minimum-1].freq) minimum = r; if (minimum != i) { myswap(a[minimum-1], a[i-1]); minHeapify(a, len, minimum); } }  建立堆  void buildHeap(hfnode* a, int len) { for (int i = len/2; i \u0026gt;= 1; i--) minHeapify(a, len, i); }  抽取最小值  hfnode\u0026amp; extractmin(hfnode* heap, int \u0026amp;len) { myswap(heap[0], heap[len-1]); len--; minHeapify(heap, len, 1); return heap[len]; }  插入  void heapInsert(hfnode* heap, int \u0026amp;len, hfnode\u0026amp; z) { heap[len++] = z; buildHeap(heap, len+1); } 建立霍夫曼树的过程就是，首先尽量选频率小的元素作为叶子，然后分配一个新的节点作为它们的父节点，该父节点的频率值为子节点频率和，最后将该父节点重新放回最小堆，循环再次从堆中抽取两个最小值，形成下一个节点，依次类推知道得到最后的根节点，其频率应该为1。\n实现如下：\nhfnode * Huffmantranslations::buildHuffmanTree(hfnode arr[], int len) { int n = len; for (int i = 1; i \u0026lt; n; i++) { hfnode x = extractmin(arr, len); hfnode y = extractmin(arr, len); hfnode *z = new hfnode; z-\u0026gt;left = \u0026amp;x; z-\u0026gt;right = \u0026amp;y; z-\u0026gt;freq = x.freq + y.freq; heapInsert(arr, len, *z); printf(\u0026#34;%d %d\\n\u0026#34;, x.freq, y.freq); } return \u0026amp;arr[0]; } 高级数据结构 B树 B树主要的用途是用来进行优化磁盘操作，减少慢速设备和快速设备之间的速度差是很有必要的，所以在该算法中会有出现磁盘操作，虽然没有进行对应的操作，但是有必要知道什么时候进行读写，磁盘页只会在内存中留着极少数量。 性质：\n  节点属性\n x.n代表存储在节点x中的节点个数 x.key[i]以非降序排放 x.leaf判断是否为叶子节点 有x.n+1个指针(x.c)指向该节点的孩子节点    节点x.key[i]分割孩子节点的关键字\n  每个节点的最大和最小关键字又最小度数(minumum degree)决定，最小度数为２时是最简单的Ｂ树，即２－３－４树。\n 除了根节点，每个节点必须有t-1个关键字 除了根节点，每个节点必须有t个孩子节点 树非空，根节点必须要有关键字 每个节点最多2t-1个关键字，即有2t个孩子节点    在实现过程中，自己有用到算法可视化进行辅助编写，但是里面的概念和书上有点不同，比如t=2时，应该选中max.degree=4，并且选中Preemtive Split优先分离选项。\n首先是树的节点定义：\ntypedef struct btreenode { int n; // the number of key  bool leaf; /* both key and child pointer need to be allocated according to the value __n__ */ struct btreenode **cp; // point to the child pointer  void ** diskpage; char *key; // point to the key area }bnode; 刚开始定义的时候，以为关键字大小是变化的，需要进行动态分配，实际上使用数组会方便很多，但是要提前知道度数。\n然后是创建B树的根节点，二叉树是向下进行增长的，新的节点加入到叶子节点然后再进行其他的操作，而Ｂ树是向上进行增长的，所以，除了前面几个节点是叶子节点，并且所有的树高都是同样的。\nbnode* Btree::BTree_Create() { bnode* x = new bnode; x-\u0026gt;leaf = true; x-\u0026gt;n = 0; x-\u0026gt;key = new char[2 * t - 1 + 1]; x-\u0026gt;cp = new bnode*[2 * t + 1]; // abort the first element of the array;  DiskRead(x); root = x; return x; } 然后是进行插入操作，但是在这之前需要完成一个分类节点的辅助函数，当一个节点的最大元素数量大于2t-1的时候，那么就需要进行分裂操作，将该节点变为两个各含t-1个元素的节点，并且将中间关键字提升到父节点去。 分列函数的实现:\nvoid Btree::BTree_SplitChild(bnode *x, int i) { bnode* z = Allocate_Node(); bnode* y = (x-\u0026gt;cp)[i]; z-\u0026gt;leaf = y-\u0026gt;leaf; z-\u0026gt;n = t-1; for (int j = 1; j \u0026lt;= t-1; j++) (z-\u0026gt;key)[j] = (y-\u0026gt;key)[j+t]; // j+t = j + (t-1) + 1  if (y-\u0026gt;leaf == false) for (int j = 1; j \u0026lt;= t; j++) (z-\u0026gt;cp)[j] = (y-\u0026gt;cp)[j+t]; y-\u0026gt;n = t-1; for (int j = x-\u0026gt;n + 1; j \u0026gt;= i+1; j--) (x-\u0026gt;cp)[j+1] = (x-\u0026gt;cp)[j]; (x-\u0026gt;cp)[i+1] = z; for (int j = x-\u0026gt;n; j \u0026gt;= i; j--) (x-\u0026gt;key)[j+1] = (x-\u0026gt;key)[j]; (x-\u0026gt;key)[i] = (y-\u0026gt;key)[t]; printf(\u0026#34;split-\u0026gt;[%c]\\n\u0026#34;, (x-\u0026gt;key)[i]); x-\u0026gt;n++; DiskWrite(x); DiskWrite(y); DiskWrite(z); } 参数i的作用是定位孩子节点，(x-\u0026gt;key)[i]是提升子节点关键字的位置，(y-\u0026gt;key)[t]用t进行定位，得到需要被提升的关键字。除此之外，如果不是叶子情况，那么孩子节点都需要进行对应赋值。\n然后开始插入过程：\nvoid Btree::BTree_Insert(char key) { bnode* r = root; if (r-\u0026gt;n == 2 * t - 1) { bnode *s = Allocate_Node(); root = s; s-\u0026gt;leaf = false; s-\u0026gt;n = 0; (s-\u0026gt;cp)[1] = r; BTree_SplitChild(s,1); BTree_Insert_NONFULL(s, key); } else BTree_Insert_NONFULL(r, key); } 因为Ｂ树是向上进行增长的，所以，分裂一般是在根节点发生的。比如，最小度数t=２的情况，根节点当插入了３个值准备进行第４个值的插入操作的时候，就会分配一个新的节点作为新的根节点，分裂，并且提升子关键字。\n保证x.leaf正确性的理由是，从Insert函数分配的新根节点都是false值，但是在split函数中的是通过兄弟节点进行赋值才获取的值，也就是说，只有叶子节点的兄弟节点才是叶子节点。\n完成这些准备后，才开始真正的插入操作过程：\nvoid Btree::BTree_Insert_NONFULL(bnode *x, char k) { int i = x-\u0026gt;n; if (x-\u0026gt;leaf == true) { while (i \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; (x-\u0026gt;key)[i]) { (x-\u0026gt;key)[i+1] = (x-\u0026gt;key)[i]; i--; } printf(\u0026#34;insert : %c\\n\u0026#34;, k); (x-\u0026gt;key)[i+1] = k; x-\u0026gt;n++; DiskWrite(x); } else { while (i \u0026gt;= 1 \u0026amp;\u0026amp; k \u0026lt; (x-\u0026gt;key)[i]) i--; i += 1; DiskRead((x-\u0026gt;cp)[i]); if ((x-\u0026gt;cp)[i]-\u0026gt;n == 2 * t - 1) { BTree_SplitChild(x, i); if (k \u0026gt; (x-\u0026gt;key)[i]) // the new key comes from child node  i += 1; } BTree_Insert_NONFULL((x-\u0026gt;cp)[i], k); } } 由此可见，插入函数是不断地把关键字插入到叶子节点去，如果某个叶子节点满了的话，那么就会分裂该节点并且，提升一个关键字到父节点，如果该父节点也满了，那么递归进行分裂。在执行分裂后有一个小细节，如果从子节点提升的关键字比ｉ小，那么就要把这个节点插入到这个节点的右孩子中去，所以ｉ执行了加１的操作。\n然后是删除操作了： 书上没有给出删除操作的伪代码，但是给出了不同情况的解决办法，我以我的理解对这些情况进行了扩充：\n 如果关键字ｋ在叶子节点ｘ中，并且该节点的元素不少于t-1，那么简单从ｘ中删除该关键字。 如果关键字ｋ在内部节点ｘ中，那么分三种情况:  a.　如果该节点的左子节点包含大于等于t个关键字，那么可以从左子节点中找出前驱k'（最后一个元素）代替ｘ节点中的ｋ，然后递归删除左子节点中的k'。 b.　如果左子节点只含有t-1个关键字，那么从右子节点中找出后继k'（第一个元素），然后递归删除k'。 c.　如果左右子节点的关键字都是t-1个关键字，那么将k和右子节点都合并到左子节点，左子节点中的元素变为 2t-1　，然后释放右子节点并且递归删除k。   如果不在内部节点ｘ（叶子节点）中，那么需要在子节点中去删除,又可以分成两种情况：  a.　如果孩子节点只有ｔ-1个关键字，但是前一个或者后一个子节点拥有至少t个关键字，那么就需要借一个关键字，也就是ｘ中的关键字k1下降到孩子节点中，然后从其他子节点中去偷取一个关键字k2，并且删除原来的k2关键字。 b.　如果相邻的子节点也都是只含有t-1关键字，那就要进行合并存在k的节点和任意一个节点，并且从x中下降一个关键字到新节点去，然后再简单删除关键字k。    下面是删除操作的实现：\nint Btree::BTree_Delete(bnode* x, char k) { int j = 1; // find k;  while (j \u0026lt;= x-\u0026gt;n \u0026amp;\u0026amp; k \u0026gt; (x-\u0026gt;key)[j]) j++; /** case 1: key \u0026#39;k\u0026#39; is in the node x, and node x is a leaf node*/ if (x-\u0026gt;leaf \u0026amp;\u0026amp; x-\u0026gt;n \u0026gt; t-1) { printf(\u0026#34;case 1\\n\u0026#34;); j += 1; // left shift  while (j \u0026lt;= x-\u0026gt;n) { (x-\u0026gt;key)[j-1] = (x-\u0026gt;key)[j]; j++; } x-\u0026gt;n--; // set nil  while ((j-1) \u0026lt; 2 * t ) { (x-\u0026gt;key)[j-1] = 0; j++; } printf(\u0026#34;remove [%c]\\n\u0026#34;, k); DiskWrite(x); return 0; } else if (k == (x-\u0026gt;key)[j] \u0026amp;\u0026amp; !(x-\u0026gt;leaf)) { /** case 2: node x is not a leaf node, it need keep the number of elements greater than t-1*/ bnode* y = (x-\u0026gt;cp)[j]; bnode* z = (x-\u0026gt;cp)[j+1]; DiskRead(y); DiskRead(z); if (y-\u0026gt;n \u0026gt;= t) { /** case 2a: y node \u0026gt;= t-1 + 1, the precursor replaces the x-\u0026gt;key.*/ printf(\u0026#34;precursor: %c\\n\u0026#34;, (y-\u0026gt;key)[y-\u0026gt;n]); (x-\u0026gt;key)[j] = (y-\u0026gt;key)[y-\u0026gt;n]; BTree_Delete(y, (y-\u0026gt;key)[y-\u0026gt;n]); } else if (z-\u0026gt;n \u0026gt;= t) { /** case 2b: z node \u0026gt;= t-1 +1, the successor replaces the x-\u0026gt;key.*/ printf(\u0026#34;successor: %c\\n\u0026#34;, (z-\u0026gt;key)[1]); (x-\u0026gt;key)[j] = (z-\u0026gt;key)[1]; BTree_Delete(z, (z-\u0026gt;key)[1]); } else { /** case 2c: both y and z don\u0026#39;t have extra key, merge k and z into node y, and simply delete k in the node z finally.*/ printf(\u0026#34; case 2c \\n\u0026#34;); int i; //merge k into y  (y-\u0026gt;key)[y-\u0026gt;n+1] = k; y-\u0026gt;n += 1; //merge node z into y  for (i = 1; i \u0026lt;= t-1; i++) (y-\u0026gt;key)[y-\u0026gt;n+i] = (z-\u0026gt;key)[i]; for (i = 1; i \u0026lt;= t; i++) (y-\u0026gt;cp)[y-\u0026gt;n+i+1] = (z-\u0026gt;cp)[i]; y-\u0026gt;n = 2 * t - 1; delete z; //deleting key is in the node x  for (i = j; i \u0026lt;= x-\u0026gt;n; i++) (x-\u0026gt;key)[i] = (x-\u0026gt;key)[i+1]; (x-\u0026gt;key)[x-\u0026gt;n] = 0; for (i = j+1; i \u0026lt;= x-\u0026gt;n+1; i++) (x-\u0026gt;cp)[i] = (x-\u0026gt;cp)[i+1]; (x-\u0026gt;key)[x-\u0026gt;n+1] = NULL; x-\u0026gt;n--; if (x-\u0026gt;n == 0) { delete x; root = y; } //deleting key is in the node y  BTree_Delete(y, k); DiskWrite(y); DiskWrite(z); } } else { /** case 3: the key isn\u0026#39;t in the node, it need to recursively find the corresponding key */ printf(\u0026#34;case 3 \\n\u0026#34;); bnode *ch; int r; //find the node recursively  if (k != (x-\u0026gt;key)[j]) { // it will return when the node  // does have the key.  ch = (x-\u0026gt;cp)[j]; r = BTree_Delete(ch, k); if (r == 0) return 0; } else return j; bnode* pre = (x-\u0026gt;cp)[j-1]; bnode* nxt = (x-\u0026gt;cp)[j+1]; DiskRead(ch); DiskRead(pre); DiskRead(nxt); printf(\u0026#34;p: %p\\n\u0026#34;, nxt); /** case 3a: node doesn\u0026#39;t have enough key, steeling key from brother node */ if (pre \u0026amp;\u0026amp; pre-\u0026gt;n \u0026gt;= t) { printf(\u0026#34;case 3a1\\n\u0026#34;); for (int i = r; i \u0026gt; 1; i--) (ch-\u0026gt;key)[i] = (ch-\u0026gt;key)[i-1]; (ch-\u0026gt;key)[1] = (x-\u0026gt;key)[j-1]; (x-\u0026gt;key)[j-1] = (pre-\u0026gt;key)[pre-\u0026gt;n]; BTree_Delete(pre, (pre-\u0026gt;key)[pre-\u0026gt;n]); DiskWrite(ch); DiskWrite(pre); } else if (nxt \u0026amp;\u0026amp; nxt-\u0026gt;n \u0026gt;= t) { printf(\u0026#34;case 3a2\\n\u0026#34;); for (int i = r; i \u0026lt; nxt-\u0026gt;n; i++) (ch-\u0026gt;key)[i] = (ch-\u0026gt;key)[i+1]; (ch-\u0026gt;key)[nxt-\u0026gt;n] = (x-\u0026gt;key)[j]; (x-\u0026gt;key)[j] = (nxt-\u0026gt;key)[1]; BTree_Delete(nxt, (nxt-\u0026gt;key)[1]); DiskWrite(ch); DiskWrite(nxt); } else { /** case 3b: both of the brother node haven\u0026#39;t enough key, steeling key from the parent node*/ printf(\u0026#34;case 3c\\n\u0026#34;); for (int i = r; i \u0026lt; (t-1)+1-1; i++) (ch-\u0026gt;key)[i] = (ch-\u0026gt;key)[i+1]; if (pre == NULL) { //merge next child node  (ch-\u0026gt;key)[t] = (x-\u0026gt;key)[j]; for (int i = 1; i \u0026lt;= t-1; i++) (ch-\u0026gt;key)[i+t] = (nxt-\u0026gt;key)[i]; delete nxt; BTree_Delete(x, (x-\u0026gt;key)[j]); DiskWrite(ch); } else { // merge previous node  (pre-\u0026gt;key)[t] = (x-\u0026gt;key)[j-1]; for (int i = 1; i \u0026lt;= t-1-1; i++) (pre-\u0026gt;key)[i+t] = (ch-\u0026gt;key)[i]; delete ch; BTree_Delete(x, (x-\u0026gt;key)[j-1]); DiskWrite(pre); } } return 0; } } 对应情况１，x-\u0026gt;leaf \u0026amp;\u0026amp; x-\u0026gt;n \u0026gt; t-1保证是删除的叶子节点，并且能够进行简单删除。对应情况２，k == (x-\u0026gt;key)[j] \u0026amp;\u0026amp; !(x-\u0026gt;leaf)保证关键字是在节点ｘ内的，并且是个内部节点。情况３用来处理删除叶子节点的关键字，但是没有额外关键字的情况。\n写完后发现，实现删除操作的代码过长了，占了200行左右，后来写博客进行总结的时候，发现删除操作和插入操作存在逆向的过程，插入的过程有分裂，而删除的过程有合并的过程，应该可以重写以上代码，分离出一个合并的过程。\n","date":"September 9, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/","summary":"CLRS快撸完一半了，所以趁开学前做下小总结，CLRS研究问题的方式和平时的感觉有那么些不太一样，但是接触久了就会慢慢习惯，主要注重算法的运行时间和算法可行性。初阶学习目标是掌握几种重要的排序算法和课堂中没有学到的数据结构。\n首先还要推荐一下usfca的这个算法可视化的网站：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html\n排序算法 排序算法在系统学习之前，只会冒泡排序，非常简单但是时间复杂度为O(n^2)的算法，是一种没有怎么优化过的想法。\n插入排序 插入排序(insert sort)是学习CLRS最先接触的算法，可以理解为将序列中的元素插入到一个已经排序好的队列中去。提供一个序列的起始位置(be)和长度(len)，循环从起始位置的下一个元素开始迭代，作为需要插入的数值(key)，将所有大于关键字元素后移一位，最后在放入对应的位置。期望运行时间(n^2)。\nfor (int i = be + 1; i \u0026lt; len; i++) { int key = a[i]; int j = i - 1; while (j \u0026gt;= 0 \u0026amp;\u0026amp; a[j] \u0026gt; key) { a[j+1] = a[j]; j--; } a[j+1] = key; } 归并排序 归并排序(merge sort)是接触分治法接触到的算法，这种方法是将需要解决的问题细分为细小的问题，然后递归求解这些子问题，直接求解，最后将这些子问题的解合并成原问题的解。应用到排序算法中的话就是将待排序的元素分成n/2两个子序列，然后递归解决子序列的顺序问题，最后合并两个已排序的子序列，形成排序好的队列。期望运行时间(nlgn)。\n首先是归并过程的辅助函数:\nvoid SortAlgorithm::mergeArray(int p, int q, int r) { int n1 = q - p + 1; int n2 = r - q; int L[n1], R[n2]; int i1, i2; for (int i = 0; i \u0026lt; n1; i++) L[i] = a[p+i]; for (int i = 0; i \u0026lt; n2; i++) R[i] = a[q+i+1]; i1 = 0; i2 = 0; for (int k = p; k \u0026lt;= r; k++) { if ((L[i1] \u0026lt;= R[i2] \u0026amp;\u0026amp; i1 \u0026lt; n1 )|| i2 == n2) { a[k] = L[i1]; i1++; } else { a[k] = R[i2]; i2++; } } } 前面两个for循环是赋值递归过程已经排好的两个子数组left和right，然后根据i1和i2所指向的数组元素大小放入到原来的数组中去，完成两个子数组的归并。","tags":["algorithm"],"title":"算法与数据结构总结"},{"categories":["sys"],"contents":"文件类型 stat函数簇(fstat,lstat, lstat, fstatat)是用来获取文件状态的函数，需要提前定义一个结构体struct stat来获取这些文件的特殊信息。 文件类型包括普通文件，目录文件，块特殊文件,字符特殊文件，ＦＩＦＯ，套接字，符号链接。可以向函数(S_ISREG(), S_ISDIR()\u0026hellip;)传入结构体中的st_stat获取文件类型。\n文件访问权限  读权限允许我们读取目录，获得在该目录下的文件名列表，但是当某个目录是　路径名　的一部分的时候，必须有该目录的可执行权限。 在目录下创建一个文件，是需要对该目录有写权限和执行权限，删除一个文件也是一样，但是不需要对该文件有读写权限。  书上有一个关于access的实例，虽然有些文件可以不能通过可读权限，但是open()函数仍然能打开但是不能用read()等方法进行读操作。\n文件系统 现代unix和以前学的有些不同，其中JOS不支持inode，但是还是有相似的地方。重新翻了下前面的文章。文件系统都有一个boot块用来自启，紧接着的是叫做super块来描述文件系统的性质，例如目录地址，上次检错时间等。现代unix在之后的磁盘块中以超级块副本，配置信息，Ｉ节点图，bitmap，ｉ节点，数据块依次排开构成文件系统。JOS就要简化了一些，因为不存在ｉnode，所以数据和目录都是放在bitmap后的数据块中。\n硬链接是指inode的引用计数，当计数为０时才是真正从磁盘中擦去该目录项，保存在结构体stat的st_nlink中。\ninode节点包含了文件所有信息，文件类型，文件访问权限位，文件长度，指向文件数据块的指针（JOS中的FILE结构体）。\n$ mkdir test  该命令执行后，会创建一个新的文件目录，任何新目录创建后的引用数都为２．该test目录在创建后，父目录中的test指向该目录，以及test目录中的 .　也指向该目录，所以引用计数为２。\n以此类推，其父目录的引用计数应该为３，１是该目录的父目录的指向，２是该目录下.文件的指向，３是test文件中..的指向。所以没创建一个文件目录，该目录的引用计数都会增加１。\nunlink 当文件的引用计数为０时，就会从磁盘中擦去，像vim打开一个文件，填入内容保存后，就会在该目录下引用了这个普通文件，引用计数为１，使用unlink可以解除即删去该文件。\n当一个程序用open()打开一个文件后，马上调用unlink()，那么只有当进程关闭改文件或者进程终止的时候，文件内容才被删除。\nif (open(\u0026quot;tempfile\u0026quot;, O_RDWR) \u0026lt; 0) err_sys(\u0026quot;open error\u0026quot;); if (unlink(\u0026quot;tempfile\u0026quot;) \u0026lt; 0) err_sys(\u0026quot;unlink errorr\u0026quot;); 符号链接 符号链接是一种与硬链接相比较限制宽松的链接方式，不用接触到文件系统底层。\n使用命令ln来创建一个符号链接\n$ln -s ~/file file  然后使用 ls -l 查看文件\nlrwxrwxrwx 1 moonlight users 26 Aug 14 16:07 sp -\u0026gt; /home/moonlight/hotspot.py  可以看到对一个文件的链接，但是使用cat命令确并不存在。\n文件的时间 最后访问时间(st_atim) ： 文件数据最后被read操作的最后一次时间。\n最后修改时间(st_mtim) ： 文件数据内容最后被write操作修改的最后一次时间。\n状态修改时间(st_ctim) ： 文件inode中信息(权限等)被修改的最后一次时间。\n读目录 这个两百多行的代码是当给定一个目录是，递归获取其目录下的所有文件，首先放在最前面的:\ntypedef int Myfunc(const char *, const struct stat *, int); 是定义了一个返回类型为int，参数是const char*,const struct stat和int的函数指针类型。 然后声明:\nstatic Myfunc myfunc; 声明了一个类型为Myfunc，变量名为myfunc的函数指针，其中static关键词的作用是用于限定函数作用域。\n接下来函数myftw为路径分配一段内存空间来存取路径大小，其中path_alloc是一个第二章的一个实例程序，用于兼容性地分配路径长度。\nfullpath = path_alloc(\u0026amp;pathlen); 此语句的作用是分配一段路径名长度加1的内存空间，最后一个字节存取/目录符号，然后进行赋值等操作后执行这个程序的主体dopath()。\n这个函数的主要作用应该是分类文件，首先lstat获取文件信息，然后判断是否为目录文件，如果不是目录文件，直接跳转到myfunc进行更加细分的文件类型判断（如普通文件，符号文件，块文件，FIFO，字符文件，套接字等）。\nfunc()是一种回调函数，当调用者将函数指针在调用的时候填入实参的位置时，那么函数就已经被登记，等func()进行调用的时候就相当于调用被登记的函数。\n如果是目录文件，那么进行递归的准备工作，例如重新分配长度等。\nfullpath[n++] = `/`; fullpath[n] = 0; 该语句的作用是将目录符号进行填充，然后用null截断文件路径。\nwhile ((dirp = readdir(dp)) != NULL) { if (strcmp(dirp-\u0026gt;d_name, \u0026#34;.\u0026#34;) == 0 || strcmp(dirp-\u0026gt;d_name, \u0026#34;..\u0026#34;) == 0) continue; strcpy(\u0026amp;fullpath[n], dirp-\u0026gt;d_name); if ((ret = dopath(func)) != 0) break; } 循环体用于遍历整个文件目录，然后将文件名复制到准备好的目录路径上，在递归查询这个新的文件路径。\nfullpath[n-1] = 0; 这个语句的作用就是截断文件目录符号，返回查询上级目录的文件。\n设备特殊文件 每个文件系统所在的存储设备由主次设备号表示，主设备号表示设备驱动程序，次设备号表示特定的子设备，数据类型是dev_t。通常使用major,minor两个宏来访问主次设备号。st_dev存储了文件系统的设备号，st_rdev是只有块设备和字符设备才拥有的属性。\n× minor和major宏是包含在文件/usr/include/sys/sysmacros.h中所以需要inlude \u0026lt;sys/sysmacros.h\u0026gt;。\nd\nwriteup 4.1 stat会跟随符号链接所指向的文件\n4.６ 首先用下面的程序创建一个空洞文件：\n#include \u0026#34;apue.h\u0026#34;#include \u0026lt;fcntl.h\u0026gt; int main(int argc, char *argv[]) { int fd = 0; char buf1[] = \u0026#34;abcdefg\u0026#34;; char buf2[] = \u0026#34;ABCDEFG\u0026#34;; off_t off = 65536; size_t memsz = off + strlen(buf1) + strlen(buf2); char* buf3 =(char*) malloc(memsz); memset(buf3, 32, memsz); /*hole file*/ if ((fd = open(\u0026#34;file.hole\u0026#34;, O_CREAT | O_RDWR, S_IRUSR | S_IWUSR)) \u0026lt; 0) err_sys(\u0026#34;error open\u0026#34;); int n = strlen(buf1); if (write(fd, buf1, n) != n) err_sys(\u0026#34;error write buf1\u0026#34;); if (lseek(fd, off, SEEK_CUR) \u0026lt; 0) err_sys(\u0026#34;error seek\u0026#34;); n = strlen(buf2); if (write(fd, buf2, n) != n) err_sys(\u0026#34;error write buf2\u0026#34;); close(fd); /*nohole file*/ if ((fd = open(\u0026#34;file.nohole\u0026#34;, O_CREAT | O_RDWR, S_IRUSR | S_IWUSR)) \u0026lt; 0) err_sys(\u0026#34;error open\u0026#34;); if (write(fd, buf3, memsz) != memsz) err_sys(\u0026#34;error write buf3\u0026#34;); free(buf3); close(fd); exit(0); } 会创建一个file.hole和file.nohole的文件，使用du命令(disk usage)和ls来分别查看实际磁盘使用数，和在文件系统中使用的数量。\n[moonlight@ArchLinux c4]$ ll file.* -rw------- 1 moonlight users 65550 Aug 23 16:46 file.hole -rw------- 1 moonlight users 65550 Aug 23 16:46 file.nohole [moonlight@ArchLinux c4]$ du file.* 8\tfile.hole 68\tfile.nohole 现在可以做下前面那一章的实验，分别使用cp和cat重定向到一个文件。\n[moonlight@ArchLinux c4]$ cp file.hole hole.cp [moonlight@ArchLinux c4]$ cat file.hole \u0026gt; hole.cat [moonlight@ArchLinux c4]$ ll hole* -rw-r--r-- 1 moonlight users 65550 Aug 23 16:59 hole.cat -rw------- 1 moonlight users 65550 Aug 23 16:59 hole.cp [moonlight@ArchLinux c4]$ du hole.* 68\thole.cat 8\thole.cp cat遇到文件空洞会进行填０操作，而cp遇到文件空洞则是跳过，所以占用的实际磁盘块不同，文件系统的逻辑大小不会发生改变。Linux的read()遇见空洞也是跳过，所以可以完成一个类似程序。\n#include \u0026#34;apue.h\u0026#34;#include \u0026lt;fcntl.h\u0026gt;#define BFSZ 4096  int main(int argc, char *argv[]) { int fd1, fd2; int n; char buf[BFSZ]; if (argc != 3) err_sys(\u0026#34;usage: cp file1 file2\u0026#34;); if ((fd1 = open(argv[1], O_RDONLY)) \u0026lt; 0) err_sys(\u0026#34;open file error :%s\u0026#34;, argv[1]); if ((fd2 = open(argv[2], O_RDWR|O_TRUNC|O_CREAT, S_IRUSR|S_IWUSR)) \u0026lt; 0) err_sys(\u0026#34;open file error :%s\u0026#34;, argv[2]); while ((n = read(fd1, buf, BFSZ)) != 0) { if (write(fd2, buf, n) != n) err_sys(\u0026#34;write error\u0026#34;); } exit(0); } 4.17 注: 删除文件需要有该目录的可写权限和可执行权限。\n","date":"August 14, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/sys/apue-file-and-directory/","summary":"文件类型 stat函数簇(fstat,lstat, lstat, fstatat)是用来获取文件状态的函数，需要提前定义一个结构体struct stat来获取这些文件的特殊信息。 文件类型包括普通文件，目录文件，块特殊文件,字符特殊文件，ＦＩＦＯ，套接字，符号链接。可以向函数(S_ISREG(), S_ISDIR()\u0026hellip;)传入结构体中的st_stat获取文件类型。\n文件访问权限  读权限允许我们读取目录，获得在该目录下的文件名列表，但是当某个目录是　路径名　的一部分的时候，必须有该目录的可执行权限。 在目录下创建一个文件，是需要对该目录有写权限和执行权限，删除一个文件也是一样，但是不需要对该文件有读写权限。  书上有一个关于access的实例，虽然有些文件可以不能通过可读权限，但是open()函数仍然能打开但是不能用read()等方法进行读操作。\n文件系统 现代unix和以前学的有些不同，其中JOS不支持inode，但是还是有相似的地方。重新翻了下前面的文章。文件系统都有一个boot块用来自启，紧接着的是叫做super块来描述文件系统的性质，例如目录地址，上次检错时间等。现代unix在之后的磁盘块中以超级块副本，配置信息，Ｉ节点图，bitmap，ｉ节点，数据块依次排开构成文件系统。JOS就要简化了一些，因为不存在ｉnode，所以数据和目录都是放在bitmap后的数据块中。\n硬链接是指inode的引用计数，当计数为０时才是真正从磁盘中擦去该目录项，保存在结构体stat的st_nlink中。\ninode节点包含了文件所有信息，文件类型，文件访问权限位，文件长度，指向文件数据块的指针（JOS中的FILE结构体）。\n$ mkdir test  该命令执行后，会创建一个新的文件目录，任何新目录创建后的引用数都为２．该test目录在创建后，父目录中的test指向该目录，以及test目录中的 .　也指向该目录，所以引用计数为２。\n以此类推，其父目录的引用计数应该为３，１是该目录的父目录的指向，２是该目录下.文件的指向，３是test文件中..的指向。所以没创建一个文件目录，该目录的引用计数都会增加１。\nunlink 当文件的引用计数为０时，就会从磁盘中擦去，像vim打开一个文件，填入内容保存后，就会在该目录下引用了这个普通文件，引用计数为１，使用unlink可以解除即删去该文件。\n当一个程序用open()打开一个文件后，马上调用unlink()，那么只有当进程关闭改文件或者进程终止的时候，文件内容才被删除。\nif (open(\u0026quot;tempfile\u0026quot;, O_RDWR) \u0026lt; 0) err_sys(\u0026quot;open error\u0026quot;); if (unlink(\u0026quot;tempfile\u0026quot;) \u0026lt; 0) err_sys(\u0026quot;unlink errorr\u0026quot;); 符号链接 符号链接是一种与硬链接相比较限制宽松的链接方式，不用接触到文件系统底层。\n使用命令ln来创建一个符号链接\n$ln -s ~/file file  然后使用 ls -l 查看文件\nlrwxrwxrwx 1 moonlight users 26 Aug 14 16:07 sp -\u0026gt; /home/moonlight/hotspot.py  可以看到对一个文件的链接，但是使用cat命令确并不存在。\n文件的时间 最后访问时间(st_atim) ： 文件数据最后被read操作的最后一次时间。","tags":["unix","file","c/c++"],"title":"apue-file and directory"},{"categories":["sys"],"contents":"写在前面的话 暑期撸了一阵子算法导论，在红黑树的删除操作卡主了，暂时放下算法，稍微看看别的计算机知识，APUE是一本关于Linux下C语言API的书籍，中间穿插了关于UNIX操作系统的知识，趁这个机会，利用6.828的知识，来提高下在linux下的编程水平，比完赛回来后，换成了arch linux，这是一款非常轻量级的操作系统，比较适合用来做自己的开发环境，另一方面也减少了游戏对自己的干扰。 本书第一章节主要讲的标准输入输出的一些基本操作，第二章提到了一些POSIX的标准，快速浏览一遍就好。\n学习笔记  文件描述符 文件描述符这个概念已经比较熟悉了，是一个 0~OPEN_MAX-1 的正整数，也是一个程序中方便操作的对象。一般来说，0代表的标准输入，1代表标准输出，2代表的是标准错误输出。\nopen()标志位 O_RDONLY : 只读打开\nO_WRONLY : 只写打开，后面会发现如果尝试读取只写的文件会出现乱码\nO_RDWR : 读写打开\nO_EXEC : 只执行打开\nO_SEARCH : 用于搜索*\n以上是打开文件必须选择的标志\nO_APPEND : 附加\nO_CLOEXEC: 这个以前做过验证: 链接\nO_CREAT : 不存在就创建\nO_EXCL : 在创建文件时，如果指定了该标志位，文件存在，那么open返回失败值\nO_DIRECTORY: 目录判断\nO_NOFOLLOW: 需要是非链接文件\nO_NOBLOCK : 以非阻塞模式打开FIFO，块设备，字符特殊文件\nO_SYNC : 每次write都需要写入磁盘(同步写)，然后等待磁盘返回\nO_TRUNC: 打开已存在的文件，并且将长度截为0，也就是原来的文件内容不能再进行访问，文件变为新文件,需要有写权限。\n*O_TTY_INIT/O_DSYNC/O_RSYNC 还不清楚\n习题 writeup 3.3 在该题目中，fd1和fd2当然都指向同一个文件表，因为执行了dup操作，所以相关的文件描述符标志等信息都会被复制，对于fd3，我理解为这是打开的同一个文件，在自己尝试写出的代码中，可以反复打开同一个文件多次，但是不会指向同一个文件表项。\n首先打开两个相同的文件\n\tfd1 = open(\u0026quot;file\u0026quot;, O_RDONLY); fd2 = open(\u0026quot;file\u0026quot;, O_RDONLY); 然后读取分别读取fd1，fd2几个字符，再用lseek()获取当前文件偏移。\nread(fd1, buf, 3); off1 = lseek(fd1, 0, SEEK_CUR); read(fd2, buf, 5); off2 = lseek(fd2, 0, SEEK_CUR); 结果显示这两个文件偏移off1和off2并没有相互叠加。\nread: abc read: abcde fd1 off: 3, fd2 off: 5 这就是说明，一个程序用open()打开文件多次的话，不同的fd会指向不同的文件表项，其中包含了“当前文件偏移量”，及时都是指向的同一个文件。\n3.6 我自己测试的程序实际上是可以任意位置读写的，和书上的答案有所不同。首先是打开文件，然后用lseek()定位到一个任意位置开始读取一定长度的字符:\nlseek(fd, 1, SEEK_SET); read(fd, buf, 32); printf(\u0026quot;read file(seek (1)):%s\\n\u0026quot;, buf); 然后再一次使用lseek()继续定位一个位置，再进行写操作。\nlseek(fd, 1, SEEK_SET); write(fd, buf2, sizeof(buf2)/sizeof(*buf2)); 实际上，lseek可以定位到任意位置，也就是可以大于文件字符大小，造成文件空洞的现象。\n","date":"August 11, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/sys/apue-chapter3/","summary":"写在前面的话 暑期撸了一阵子算法导论，在红黑树的删除操作卡主了，暂时放下算法，稍微看看别的计算机知识，APUE是一本关于Linux下C语言API的书籍，中间穿插了关于UNIX操作系统的知识，趁这个机会，利用6.828的知识，来提高下在linux下的编程水平，比完赛回来后，换成了arch linux，这是一款非常轻量级的操作系统，比较适合用来做自己的开发环境，另一方面也减少了游戏对自己的干扰。 本书第一章节主要讲的标准输入输出的一些基本操作，第二章提到了一些POSIX的标准，快速浏览一遍就好。\n学习笔记  文件描述符 文件描述符这个概念已经比较熟悉了，是一个 0~OPEN_MAX-1 的正整数，也是一个程序中方便操作的对象。一般来说，0代表的标准输入，1代表标准输出，2代表的是标准错误输出。\nopen()标志位 O_RDONLY : 只读打开\nO_WRONLY : 只写打开，后面会发现如果尝试读取只写的文件会出现乱码\nO_RDWR : 读写打开\nO_EXEC : 只执行打开\nO_SEARCH : 用于搜索*\n以上是打开文件必须选择的标志\nO_APPEND : 附加\nO_CLOEXEC: 这个以前做过验证: 链接\nO_CREAT : 不存在就创建\nO_EXCL : 在创建文件时，如果指定了该标志位，文件存在，那么open返回失败值\nO_DIRECTORY: 目录判断\nO_NOFOLLOW: 需要是非链接文件\nO_NOBLOCK : 以非阻塞模式打开FIFO，块设备，字符特殊文件\nO_SYNC : 每次write都需要写入磁盘(同步写)，然后等待磁盘返回\nO_TRUNC: 打开已存在的文件，并且将长度截为0，也就是原来的文件内容不能再进行访问，文件变为新文件,需要有写权限。\n*O_TTY_INIT/O_DSYNC/O_RSYNC 还不清楚\n习题 writeup 3.3 在该题目中，fd1和fd2当然都指向同一个文件表，因为执行了dup操作，所以相关的文件描述符标志等信息都会被复制，对于fd3，我理解为这是打开的同一个文件，在自己尝试写出的代码中，可以反复打开同一个文件多次，但是不会指向同一个文件表项。\n首先打开两个相同的文件\n\tfd1 = open(\u0026quot;file\u0026quot;, O_RDONLY); fd2 = open(\u0026quot;file\u0026quot;, O_RDONLY); 然后读取分别读取fd1，fd2几个字符，再用lseek()获取当前文件偏移。\nread(fd1, buf, 3); off1 = lseek(fd1, 0, SEEK_CUR); read(fd2, buf, 5); off2 = lseek(fd2, 0, SEEK_CUR); 结果显示这两个文件偏移off1和off2并没有相互叠加。","tags":["file","c/c++","I/O"],"title":"apue-file I/O"},{"categories":["sys"],"contents":"这章节是完成一个网络驱动程序，现在系统中已经存在了文件系统里，所以可以添加一个网络栈，是基于82540EM芯片(E1000)。这章节内容比我想象中难，虽然之前概览了一下，但是实际做起来的时候涉及到的概念和知识超出我现在所掌握的。\n准备 git\n$ git add . $ git commit -am \u0026#34;lab 5 done\u0026#34; $ make handin $ git pull $ git checkout -b lab6 origin/lab6 $ git merge lab5 Auto-merging lib/fd.c Auto-merging kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c Auto-merging inc/lib.h Auto-merging fs/serv.c Merge made by the \u0026#39;recursive\u0026#39; strategy. boot/main.c | 1 - fs/bc.c | 22 +- fs/fs.c | 73 +- .... user/faultio.c | 2 +- user/forktree.c | 1 + user/sh.c | 9 +- user/testfile.c | 5 + 33 files changed, 14503 insertions(+), 111 deletions(-) 除了完成网卡驱动，还需要 1.创建一个系统调用接口来访问驱动。 2.实现服务器和驱动网络栈传输数据包的代码。 3.完成一个web服务器\n数据包调试\ntcpdump -XXnr qemu.pcap 或者使用wireshark也行。\n网络服务 从零开始实现一个网络栈(协议栈)是一件非常困难的事情。所以会用到一个轻量级的开源的TCP/IP协议簇LwIP(lightweight IP)来实现接下来的工作。在这里需要把LwIP看成一个黑箱，它是实现了BSD的套接字接口到了输出端口和输入端口。\\\n所以网络服务实际上就是4个环境(进程)的结合：\n  核心网络服务器环境(套接字分发和LwIP) 套接字调用调度工作方式很像文件服务，用户环境使用存根stubs(lib/nsipc.c)发送IPC信息到核心网络环境。i386_init创建一个NS_TYPE_NS类型的NS环境，然后扫描envs这个全局变量可以找到特殊的环境。对于任何一个用户环境，网络服务中的调度器调用合适的由LwIP提供的BSD套接字接口函数。 普通的用户环境使用lib/sockets中的函数发送sokets，这是基于文件描述符的套接字API。就像之前使用磁盘中的文件一样，用户环境使用套接字也是通过文件描述符。像connect，accept操作指定接收类型为套接字，而read，write等操作是通过接收普通的文件描述符，所以可通过LwIP为开启的套接字生成的独一无二的ID映射到对应的文件描述符上。 文件服务和网络服务中的IPC分发工作即使相同，但有一点关键不同的在于BSD套接字调用accept和recv能够无尽的阻塞。如果分发器让LwIP执行一个阻塞操作，这整个系统都会被阻塞，所以网络服务使用用户级别的线程去避免阻塞整个服务。对于到来的IPC消息，分发器创建一个线程并且处理这个请求。如果线程阻塞了，那么只有该线程被置为睡眠状态而其他线程仍在运行。\n  输出环境 当用户环境的套接字服务函数被调用，IwIP将会生成一个被网卡传输的数据包。核心网络环境将通过IPC信息并把要发送的包作为共享页给输出环境，那么接下来输出环境将会接收这些信息并且将这些包通过网卡驱动发送出去。\n  输入环境 网卡收到包之后需要注入到LwIP中去，对于每一个通过设备驱动接收到的包，输入环境将会把这些包调出内核空间并且用IPC将包发送到核心服务环境中去。\n  计时器环境 计时器环境周期性的发送NSREQ_TIMER到核心网络服务提醒计时器已经过期了，这个环境被用作多种网络的超时报告。\n  初始化并且发送包 现在内核还没有时间的概念，现在需要加上这个，时钟中断是每10ms发送一次，所以当时钟中断发生的时候，自增一个变量让时间前进。\n练习 1 当时钟中断发生的时候，调用time_tick来自增时间 实现sys_time_msec使得用户环境能获取当前时间\ntrap.c\n# trap_dispatch()  if (tf-\u0026gt;tf_trapno == IRQ_OFFSET + 0) { time_tick(); lapic_eoi(); //cprintf(\u0026#34;clock interrput: \u0026#34;);  sched_yield(); } sys_time_msec\nstatic int sys_time_msec(void) { // LAB 6: Your code here.  //panic(\u0026#34;sys_time_msec not implemented\u0026#34;);  return time_msec(); } 网卡接口 接下来就是准备写网卡驱动，但是需要知道硬件和接口怎么在软件中表示。\n练习 2 练习2的任务阅读Intel手册关于E1000的部分，章节2概览，章节3和14细节。 E1000是一种非常复杂的设备并且拥有很多优越的特性，只需要利用很少的一部分E1000的特性和接口就能完成工作。 这里不得不重新审视下驱动，驱动程序是计算机操作和控制特殊类型的被附加到计算机的设备，为硬件提供软件的接口，使得操作系统或者其他程序能访问硬件功能(hardware function)但是不需要直到使用硬件的细节。绝大多数驱动都是运行在内核态，操作硬件资源，访问底层资源。\n第二章节我关注了几个点\n DMA Engine and Data FIFO DMA 寻址 网络数据都是字节流，所以确认处理器处理的方式和网卡控制器需要以相同的方式处理字节流，PCI是使用的little-endian，低位字节排放在内存的低地址端。  以太网控制器中有几个存放以太网物理地址的寄存器，两个32位的寄存器组成地址，RAH(Receive Address High)和RAL(Receive Address Low)。 // todo： 为什么mac地址是6个字节？并不方便两个寄存器处理。\n以太网帧从外部发来后，字节流从左往右对应，处理数据。比如地址00_AA_00_11_22_33h，除去帧的其他部分，首先出现在总线上的是最低有效位的0bit位。这里涉及到了一个组播比特位，详情可看这里，组播的话该最先出现的位会被置为1。最后处理完后在缓冲区的情况如下:\n顺便复习下mac帧的结构和作用\n中断 也就是外部中断发送到I/O APIC，接收到外部中断后，cpu开始执行相应的外部中断处理程序，在这，就是处理网络包。 卸载检验和 以太网控制器会将IP分组,TCP/UDP数据报中的检验和卸载下来，硬件会自动计算，插入并且检测检验和，但是检验和的值是由软件提供的。 缓冲和描述符结构 驱动会分配传输和接收缓冲，并且会形成一个描述符指向缓冲的地址和状态。驱动为硬件准备一个队列缓冲用来接收，一旦合法的数据包到达后，接收了数据的缓冲将为驱动所有。为了传输数据包，驱动自身会维护一个队列缓冲，当这个缓冲中数据已经可以准备发送时，驱动将会把这个缓冲提交给硬件，然后硬件接下来就会读取缓冲中的数据并且以FIFO的方式发送数据包。 描述符指定了1. 缓冲物理地址 2. 缓冲长度 3. 缓冲状态和命令信息 4. 指向数据包尾部的指针 5. 数据包的类型 6. 硬件需要对数据包的操作(VLAN或者卸载检验和)  PCI 接口 E1000网卡是PCI(Peripheral Component Interconnect)设备，这意味着网卡是插在主板PCI总线上的，PCI总线包含了地址数据中断线，允许CPU和PCI设备进行交互，并且PCI设备能读写内存。PCI设备需要在使用前被发现并且初始化。\n发现过程就是通过遍历PCI总线寻找附加的设备，初始化过程就是分配I/O和内存空间并且商榷IRQ线的使用权。当找到设备的时候，可以读到设备的vendor ID和device ID。JOS中使用这两个键在pci_attach_vendor中找寻值。并且将这两个键组合成一个结构体，并包含一个回调函数执行设备初始化。\nstruct pci_func { struct pci_bus *bus; uint32_t dev; uint32_t func; uint32_t dev_id; uint32_t dev_class; uint32_t reg_base[6]; uint32_t reg_size[6]; uint8_t irq_line; }; 反映了初始化的寄存器，其中reg_base基地址寄存器BARs（Base Address Registers），reg_size应该类似于基地址偏移确认IO端口。\n当pci_device结构体中的函数被调用的时候，设备已经被发现了，但是仍没被启用。这意味着PCI仍然没有为设备分配资源，例如内存空间，IRQ线，基地址寄存器等在结构体中的信息也没有被填入，所以需要调用pci_func_enable来完成这些工作。\n练习 3 实现一个附加函数去初始化E1000 如果在pci_attach_vendor数组找到了PCI设备，提供一个入口来触发初始化函数(确定该PCI键是放在{0, 0, 0}结束标志前的)。 vendor ID和device ID信息:\n然后通过pci_func_enable函数来启动pci设备，完成kern/e1000.c和kern/e1000.h 启动时先从i386_init开始执行到pci_init，再紧接着调用pci_bus_scan将总线中的设备扫描出来，并且把这些信息存到一个临时的pci_func结构体中，最后调用pci_attach函数在pci_attach_class或者pci_attach_vendor用vendorID和DeviceID找寻相应的attach function并且调用这个回调函数。 pci_attach_match\nif (list[i].key1 == key1 \u0026amp;\u0026amp; list[i].key2 == key2) { int r = list[i].attachfn(pcif); 这里就是在list(class或者vendor数组)用键索引，然后调用attachfn来完成启动。\ne1000.c #include \u0026lt;kern/e1000.h\u0026gt; // LAB 6: Your driver code here //extern struct pci_func; int e1000_attach(struct pci_func *pcif) { pci_func_enable(pcif); return 1; } pci.c struct pci_driver pci_attach_vendor[] = { { 0x8086, 0x100e, \u0026amp;e1000_attach }, { 0, 0, 0 }, }; 内存映射IO 软件与E1000芯片通过MMIO(memory-mapped I/O)，之前已经接触过两次，CGA控制台和LAPIC，控制和请求都是通过读写这些内存。但是实际上这些读写操作不会通过DRAM，而是直接操作到设备上去。init过程中，JOS先执行的内存映射，也就是说之前映射这些IO内存的读写是通过bus(?)直接进行的，往LAPIC映射的内容写入值，就是发送IPC信息。\npci_func_enable选定一个合适的MMIO区域为E1000使用，并且存储基地址和偏移到BAR 0(reg_base[0]和reg_size[0])中，然后这部分物理内存地址将会赋值给设备，和之前一样，MMIO区域通常是一个很高的物理地址，所以需要将其映射到MMIOBASE中，虽然LAB4中已经使用了这部分区域，但是设置了一个静态变量static uintptr_t base在映射之后会自增映射后的大小，保证不会被重写覆盖。\n练习4 在attach function中，通过调用为E1000的BAR 0创建一个虚拟内存的映射\nstruct pci_func; extern void *mmio_map_region(physaddr_t, size_t); int e1000_attach(struct pci_func *pcif) { volatile uint32_t *mmio_e1000; //negotiates an MMIO region  pci_func_enable(pcif); //map to MMIOBASE  mmio_e1000 = mmio_map_region(pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;base: %x size: %x \\n\u0026#34;, pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;E1000 STATUS REGISTER VALUE: %x\\n\u0026#34;, *(mmio_e1000+2)); return 1; } pci_func_enable已经填入了合适的地址到了BAR0中去了，简单调用mmio_e1000就好。文件kern/pcireg.h中的状态寄存器偏移为0x04但是Hint提供的偏移是0x08,验证后是后者正确。 映射的地址指针应该声明为volatile，防止编译器优化让缓存记录访问改地址的值。 文档Table 13-5指出了该寄存器的6,7位的值表达了最大传输速度，1000MB/s对应的位设置应该10与0x80080783转换为二进制后6，7位的值相同。\nDMA 传输数据包通过读写上个练习中被映射的内存块是一种办法，但是这样太慢了，因为E1000自身需要缓冲包数据。所以E1000使用直接内存访问DMA(Direct Memory Access)来进行内存读写而不需要唤醒CPU。 CPU首先初始化数据传输，然后CPU去执行其他操作，当数据接收完后从DMA控制器发送一个中断告诉CPU已经传输完成了，这样就可以达到异步传输，从而提高处理速度。 驱动为传输和接收队列分配内存，设置DMA描述符，并让E1000定位这些队列，所以接下来的任务将会是异步执行。 为了发送数据包，驱动程序将会复制数据包到在传输队列的下一个DMA描述符中去并且告诉E1000有数据包可以进行发送了，E1000会在空闲状态的时候将数据从描述符中复制出来。相同地，当E1000接收到了数据包，E1000将数据复制到接收队列的下一个DMA描述符去，驱动有机会便会读取这个数据包对应的描述符。 接收和传输队列是非常相似的，都是由描述符序列组成，虽然这些描述符的确切结构各不相同，但每个描述符都包含一些标志和包含分组数据的缓冲区的物理地址。队列由环形数组组成，实现着队列用到的head pointer 和 tail pointer以及数据包缓冲的地址都必须是物理地址，因为硬件直接使用DMA访问内存而不会通过MMU。\n发送数据包 E1000的接收功能和发送功能是相互独立的，首先必须为发送数据包初始化网卡，接下来的步骤在手册section 14.5。\n 设置传输队列 精确的结构体设置在章节section 3.4，描述符的结构体的设置在section 3.3.3 暂时不关系TCP的卸载特性，只需要关注遗留传输描述符格式(legacy transmit descriptor format)  C 结构体 使用C结构体描述E1000结构是很方便的，像之前的Trapframe结构体能够精确的安置数据在内存中，并且能在不同数据域填充空字节，虽然e1000没有这样的问题。如果遭遇了域对齐的问题，查看GCC的packed attribute。 合法传输描述符应该如下:\n63 48 47 40 39 32 31 24 23 16 15 0 +---------------------------------------------------------------+ | Buffer address | +---------------+-------+-------+-------+-------+---------------+ | Special | CSS | Status| Cmd | CSO | Length | +---------------+-------+-------+-------+-------+---------------+ 驱动应该为传输描述符数组和描述符所指的数据包缓冲保留内存空间，例如将描述符结构体声明为一个全局变量。 最简单的办法去处理数据包缓冲区是在驱动初始化的时候为数据包缓冲保留空间，将复制的数据包复制到这个预先分配的缓冲区中。以太网包最大大小为1518字节，缓冲区应该分配这么多。很多复杂先进的驱动能够动态分配缓冲区缓冲(能够在网络利用率很低的时候减少内存消耗)，甚至直接在用户态下提供缓冲。\n练习5 实现14.5中的初始化步骤，13节提供了初始化步骤中的寄存器信息。 3.3.3和3.4提供传输描述符和传输描述符数组。\n初始化传输\n  为传输描述符链分配一个内存区域，并且需要保证这部分内存是16byte内存对齐。\n  设置传输描述符基地址寄存器TDBAL/TDBAH(Transmit Descriptor Base Address)，32位只使用TDBAL。\n  设置传输描述符长度寄存器TDLENR保存描述符环的大小，值必须是128字节对齐的\n  传输描述符头尾寄存器TDH/TDT在加电后被硬件或者以太网控制器初始化为0B，驱动需要确认写入了0B到这两个寄存器。\n  初始化传输控制寄存器TCTL\n TCTL.EN(enable)置为1b TCTL.PSP(Pad Short Packet)置为1b 配置碰撞阈值TCTL.CT(Collision Threshold)为以太网标准值10h，半双工模式(half duplex mode) 配置碰撞距离TCTL.COLD，全双工设置为40h，1000Mb/s半双工的值应该为200h，10/100Mb/s的值应该设置为40h    配置Transmit IPG寄存器，设置为最小合法数据包间隔legal Inter Packet Gap。\n  struct TD transmit_desc_list[32] __attribute__ ((aligned (PGSIZE))) = { 0 }; struct packet buffer[32] __attribute__ ((aligned (PGSIZE))) = { 0 }; #define PBUFSZ 2048 volatile uint32_t *mmio_e1000; int e1000_attach(struct pci_func *pcif) { //negotiates an MMIO region  pci_func_enable(pcif); desc_init(); //map to MMIOBASE  mmio_e1000 = mmio_map_region(pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;base: %x size: %x \\n\u0026#34;, pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;E1000 STATUS REGISTER VALUE: %x\\n\u0026#34;, *(mmio_e1000+2)); //ex5: transmition initilizes  transmit_init(); return 1; } static void desc_init() { int i; for(i = 0; i \u0026lt; 32; ++i) { memset(\u0026amp;transmit_desc_list[i], 0, sizeof(struct TD)); transmit_desc_list[i].addr = PADDR(\u0026amp;buffer[i]); transmit_desc_list[i].status = TXD_STAT_DD; // transmit_desc_list[i].cmd = TXD_CMD_RS | TXD_CMD_EOP;  } } int transmit_init() { //TD Base Address register  pciw(E1000_TDBAL, PADDR(transmit_desc_list)); pciw(E1000_TDBAH, 0); //TD Descriptor Length register  pciw(E1000_TDLEN, 32 * sizeof(struct TD)); //TD head and tail register  pciw(E1000_TDH, 0x0); pciw(E1000_TDT, 0x0); //TD control register  pciw(E1000_TCTL, TCTL_EN | TCTL_PSP | (TCTL_CT \u0026amp; (0x10 \u0026lt;\u0026lt; 4)) | (TCTL_COLD \u0026amp; (0x40 \u0026lt;\u0026lt; 12))); //Transmit Inter Packets Gap register  pciw(E1000_TIPG, 10 | (8 \u0026lt;\u0026lt; 10) | (12 \u0026lt;\u0026lt; 20)); return 0; } 现在传输已经被初始化了，需要完成一部分代码使得用户空间能通过系统调用发送数据包。为了传输数据包，必须将数据包放在传输队列的尾部，即复制数据包的数据到下一个数据包的缓冲并且更新TDT寄存器告知网卡已经有另外一个数据包在传输队列中了。(TDT是传输描述符数组的索引，不是字节偏移)\n然而，传输队列只有这么大，传输队列可能会完全被塞满。为了检测这种情况，需要从E1000芯片中获取一些反馈。文档说明TDH寄存器是不知道信任的，但是如果设置了在传输描述符CMD域RS bit位，接下来，当网卡已经发送了这个描述符的数据包后，网卡将会设置文件描述符状态域的DD比特位，那么这很安全去回收这个描述符，并且使用这个描述符去传输另一个包。\n如果用户调用传输系统调用，但是下个描述符没有设置DD比特位，接下来的代码需要解决这种情况，可以仅仅通过丢弃这个包来实现。网络协议能够恢复部分(重传)，但是如果一瞬间丢掉了大量的包，网络协议将可能不能恢复。取而代之的方法是需要告诉用户环境需要重新尝试，就像之前完成的sys_ipc_try_send。\n练习6 完成一个函数传输数据包通过检测下一个描述符是否被释放，复制数据包数据到下一个描述符，更新TDT。保证你解决了当传输队列还是满的情况。\nint transmit(void *addr, size_t len) { uint32_t tail = mmio_e1000[E1000_TDT]; struct TD *next_desc = \u0026amp;transmit_desc_list[tail]; if ((next_desc-\u0026gt;status \u0026amp; TXD_STAT_DD) != TXD_STAT_DD) return -1; if (len \u0026gt; PBUFSZ) len = PBUFSZ; memmove(\u0026amp;buffer[tail], addr, len); next_desc-\u0026gt;length = len; next_desc-\u0026gt;status \u0026amp;= !TXD_STAT_DD; mmio_e1000[E1000_TDT] = (tail+1) % 32; cprintf(\u0026#34;status register value: %x\\n\u0026#34;, *(mmio_e1000+2)); cprintf(\u0026#34;send : %s\\n\u0026#34;, addr); return 0; } 现在可以检测传输代码。发送少量包直接通过内核调用传输函数。使用make E1000_DEBUG=TXERR,TX qemu去测试，能够看到 e1000: index 0: 0x271f00 : 9000002a 0作为传输包。每一行都会给出传输数组的索引，传输描述符的缓冲地址，cmd/cso/length和special/css/status域。 当QEMU允许的时候，执行tcpdump -XXnr qemu.pcap查看发送出去的数据包内的数据。 可以在monitor.c中添加一个测试函数，执行发送函数。执行完后，E1000的DEBUG命令回自动保存这个流量包到qemu.pcap文件中。\n练习7 为数据包的传输创建一个系统调用，并且检查传输过去的指针。\nlib/syscall.c\nint sys_transmit(void *addr, size_t len) { return syscall(SYS_transmit, 1, (uint32_t)addr, len, 0, 0, 0); } kern/syscall.c\n// transmit packets // return -1 if the transmition failed. static int sys_transmit(void *addr, size_t len) { user_mem_assert(curenv, addr, len, PTE_U); return transmit(addr, len); }  sudo apt-get remove \u0026ndash;auto-remove qemu-system-x86 git clone http://web.mit.edu/ccutler/www/qemu.git -b 6.828-2.3.0\n网络服务器 现在拥有了一个系统调用的接口从设备驱动这端传输数据，现在可以用来发送数据包了。这个输出帮助环境的目标是做接下来这个循环：接收NSREQ_OUTPUT 来自网络服务器内核的IPC消息和利用前面写的系统调用来发送IPC消息。 NSREQ_OUTPUT IPC消息由low_level_output函数来发送，依附于LwIP栈。每一个IPC都会包含一个由union Nsipc和struct jif_pkt组成。 结构体jif_pkt中的jp_len表示了数据包的长度。所有接下来的字节是数据包的内容。这个长度为0的数组一C语言的一个小技巧，就好像jp_data就是指向结构体的末尾，因为缓冲区是没有提前声名长度的。因为C语言不会做数组边界检查，只要保证在这个结构体后面有足够的未使用的内存，就能使用jp_data来指定任意数组大小。 注意当传输队列中没有足够的空间的时候，设备驱动，输出环境和网络服务内核的交互。网络服务内核利用IPC发送数据包到输出环境。如果输出环境环境因为设备驱动没有足够的缓冲而被暂停，那么网络服务将会被阻塞直到输出环境接收了IPC调用。\n练习8 实现net/output.c中的功能\nvoid output(envid_t ns_envid) { binaryname = \u0026#34;ns_output\u0026#34;; union Nsipc output; int perm; envid_t envid; // LAB 6: Your code here:  // - read a packet from the network server  // - send the packet to the device driver  while (1) { if (ipc_recv(\u0026amp;envid, \u0026amp;nsipcbuf, \u0026amp;perm) != NSREQ_OUTPUT) continue; while (sys_transmit(nsipcbuf.pkt.jp_data, nsipcbuf.pkt.jp_len) \u0026lt; 0); } } 使用tcpdump打开pcap.qemu，这样就能看到发出ARP数据包。\n  Q1:How did you structure your transmit implementation? In particular, what do you do if the transmit ring is full? 在循环队列中不断检测下一个描述符的位置是否合法，通过while循环多次访问直到空闲。\n PartB: 接收数据包 就像发送数据包，现在将配置E1000芯片来接收数据包并且提供接收描述符队列和接收描述符。手册3.2章节描述了数据包如何工作，包括接收队列结构体和接收描述符，以及初始化进程的细节(章节14.4)。\n练习9 阅读手册3.2章节 通常数据的接收需要识别在线缆上的数据包，过滤地址，以FIFO方式存储数据，从接收缓存传输到主存中去，并且更i新年接收描述符。\n 包地址过滤 硬件存储即将到来的包到主存中通过过滤规则管理。如果没有足够的空间，硬件将会选择丢弃数据包，并且指出这个数据包丢失了。一般来说，只有号的数据包被接收，比如数据包没有CRC错误，符号错误，队列错误，长度错误，对齐错误等等。当然，如果设置了相关控制寄存器(RCTL.SBP)，那么这些坏包能被接收到(RDESC.ERRORS)接收描述符中。 接收描述符 一旦数据包被以太网控制器接收了，硬件将会存储数据包到指定的缓冲并且填写长度，包的检验和，状态，错误等状态域。长度是整个被写入缓冲区的长度包括CRC校验位。软件必须读取多个描述符确认数据包是完整的。 接受描述符状态域 状态信息指出描述符是否被使用了和相关的缓冲是否是数据包的最后一个。 捕捉接收描述符 描述符捕捉策略是被设计去支持通过PCI总线的大量数据包的。捕捉算法尝试去最大利用PCI带宽通过缓冲线。 当一个芯片缓冲区是空的，一旦任意描述符可以使用，一次捕捉将会发送，软件将会写入到tail指针。当缓冲区几乎要空的时候，只要有足够的有效描述符就会执行一次预先捕捉并且没有其他更高优先级的PCI活动。  回写接收描述符的避免 关于回写: 一种称为“穿透”(Write-Through)模式，在这种模式中高速缓存对于写操作就好像不存在一样，每次写时都直接写到内存中，所以实际上只是对读操作使用高速缓存，因而效率相对较低。 另一种称为“回写”(Write-Back)模式，写的时候先写入高速缓存，然后由高速缓存的硬件在周转使用缓冲线时自动写入内存，或者由软件主动地“冲刷”有关的缓冲线。 接收描述符队列结构 软件通过写到队尾指针来添加有效的描述符，当一个数据包到达的时候，硬件将会存储这个数据包，并且自增头指针。当头指针域尾指针相等的时候，队列环就处于空的状态。硬件停止存储数据包到系统内存中直到然间前进了尾指针，让更多接收缓冲可用。 头尾指针分别引用一个16Bytes的内存块。 图中阴影部分表示描述符已经存储了到来的数据包但是未被软件识别。 地址过滤器 MAC：mac地址过滤器检测MAC目的地址来保证该地址是否有效，接收配置的设置决定了哪一个物理地址被接收。 IPv4：检测有效的IPv4头，域值应该为4. UDP/TCP:检测合法的UDP/TCP头，原型值分别为11h和06h。 SNAP/VLAN/IPv6 接收队列与传输队列非常相似，除了接收队列需要等待被即将到来的数据包填满。因此，当网络是空闲状态的时候，传输队列应该是空的，而接收队列的缓冲区应该是满的(尾指针和头指针相等)。 当E1000芯片就收到了数据包，首先检测器是否满足网卡配置的过滤规则。否则，E1000会尝试从接受队列中取回下一个接收描述符。如果头指针已经等于了尾指针，那么说明接收兑率已经没有空闲的描述符，所以会丢弃数据包。如果有空闲的描述符，将会复制数据包数据到描述符所指到的缓冲区，并且设置描述符DD域和EOP域的状态比特位，并且自增头指针。 E1000如果接收到了一个数据包大于一个接受描述符的数据包缓冲，那么将会尽可能多的从接收队列中获取描述符并且存储完整的数据包内容。为了指出这种情况发生了，那么这个数据包所用的描述符都会标记DD比特位，但是EOP状态为只有最后一个描述符标记了。你能处理这种可能发生的可能性，也可以简单地不接受这种大数据包来保证所接收到缓冲区的数据包不会大于标准的以太网数据包1518字节。  练习10 设置好接受队列并且根据手册14.4章节配置E1000(跳过中断和CRC) 默认情况下，网卡会过滤所有的数据包，所以必须去配置接收地址寄存器拥有一个MAC地址为了让数据包能够寻址到该网卡。可以使用QEMU默认的MAC地址52:54:00:12:34:56，MAC地址的字节序是从低序写到高序的，所以52:54:00:12在低32比特，而34:56在高16位。 E1000只支持一个特定的接收缓冲区大小，如果数据包缓冲区足够大并且禁用了长数据包的接收，你不用担心数据包旋转在多个接收缓存。就像传输队列，数据缓冲必须是连续的物理内存。 这里必须使用至少128接收描述符。\n 设置地址接收寄存器为QEMU的MAC地址，从左往右代表从低到高字节序，并且需要设置RAH寄存器的‘Address valid’标志位。 设置接收循环队列的基地址寄存器RDBAH/RDBAL 设置描述符长度寄存器RDLEN 设置队列头尾指针，与传输队列不同，接收队列的头指针与尾指针相等代表没有描述符可用，会发生丢包的情况 设置一些相关的控制寄存器。  接收描述符\nstruct RD { uint64_t addr; uint16_t length; uint16_t checksum; uint8_t status; uint8_t errors; uint16_t special; }__attribute__((packed)); //same as lapicw(), read after write.  int e1000_attach(struct pci_func *pcif) { //negotiates an MMIO region  pci_func_enable(pcif); desc_init(); //map to MMIOBASE  mmio_e1000 = mmio_map_region(pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;base: %x size: %x \\n\u0026#34;, pcif-\u0026gt;reg_base[0], pcif-\u0026gt;reg_size[0]); cprintf(\u0026#34;E1000 STATUS REGISTER VALUE: %x\\n\u0026#34;, *(mmio_e1000+2)); //ex5: transmition initilizes  transmit_init(); //ex10: reception inistiizes  recv_init(); return 1; } static void desc_init() { int i; // transmit  for(i = 0; i \u0026lt; 32; ++i) { memset(\u0026amp;transmit_desc_list[i], 0, sizeof(struct TD)); transmit_desc_list[i].addr = PADDR(\u0026amp;buffer[i]); transmit_desc_list[i].status = TXD_STAT_DD; transmit_desc_list[i].cmd = TXD_CMD_RS | TXD_CMD_EOP; } // receive  for (i = 0; i \u0026lt; RECVNUM; ++i) { memset(\u0026amp;recv_desc[0], 0, sizeof(struct RD)); recv_desc[i].addr = PADDR(\u0026amp;rbuf[i]); recv_desc[i].status = RXD_STAT_DD | RXD_STAT_EOP; } } int recv_init() { //Receive Address Register  //pciw(E1000_RA, 0x52540012);  pciw(E1000_RA, 0x12005452); pciw(E1000_RA+1, 0x5634 | E1000_RAV); //Multicast Table Array  for (int i = 0; i \u0026lt; 128; i++) pciw(E1000_MTA+i, 0); //Base Address register  pciw(E1000_RDBAL, PADDR(recv_desc)); pciw(E1000_RDBAH, 0); // Descriptor Length  pciw(E1000_RDLEN, sizeof(struct RD) * RECVNUM); // head and tail register  pciw(E1000_RDH, 0); pciw(E1000_RDT, RECVNUM-1); pciw(E1000_RCTL, RCTL_EN | RCTL_LPE | RCTL_LBM_NO | RCTL_SZ_2048 | RCTL_SECRC); return 0; } 完成这部分驱动后，即使没有完成接收数据包的代码，运行make E1000_DEBUG=TX,TXERR,RX,RXERR,RXFILTER run-net_testinput将会发送一个ARP数据包可以看到如下的内容。\n现在已经准备好了来接收数据包，为了能够接收到一个数据包，你的驱动将会跟踪下一个已经接收到了数据包的下一个描述符。和传输一样，文档所陈述的RDH寄存器不可以信赖，所以为了知道一个数据包已经被分发，必须读取描述符的DD状态位。如果DD位被被设置了，那么就能复制数据包的数据到描述符缓冲区，并且告诉E1000描述符已经空闲通过自增队列的尾指针。\n如果DD比特位没有被设置，那么就没有数据包被接收了，这等于当传输队列是满的情况。面对这种情况，可以返回一个重试的错误信息，要求调用者重新尝试。虽然这种方法适合全满的传输队列，因为这是一个瞬时情况，但是不太适合空的接收队列，因为接收队列可能长时间出去一个空队列状态。第二种途径就是暂停调用的环境知道有数据包在接受队列中需要处理。这种策略与sys_ipc_recv非常相似，就像IPC的情况，因为每个CPU只会拥有一个内核栈，一旦离开内核，那么这个内核栈将会丢失。所以需要设置一个FLAG指出这个环境已经被接收队列暂停了并且记录系统调用的参数。这种方法的确定是很复杂的，E1000必须只是去省常接收中断并且驱动必须恢复被阻塞而等待的环境。\n练习11 完成一个函数从E1000接收数据包并且添加一个用户环境能使用的系统调用。\nint recv(void *addr,size_t len) { uint32_t tail = (mmio_e1000[E1000_RDT] + 1) % RECVNUM; struct RD *next_desc = \u0026amp;recv_desc[tail]; //cprintf(\u0026#34;tail value :%d\\n\u0026#34;, tail) ;  if ((next_desc-\u0026gt;status \u0026amp; RXD_STAT_DD) != RXD_STAT_DD) return -1; if (next_desc-\u0026gt;length \u0026lt; len) len = next_desc-\u0026gt;length; memcpy(addr, \u0026amp;rbuf[tail], len); next_desc-\u0026gt;status \u0026amp;= !RXD_STAT_DD; mmio_e1000[E1000_RDT] = tail; return next_desc-\u0026gt;length; } 网络服务的接收数据包 再网络服务的输入环境中，需要使用新的接收心痛调用来接收数据包并且传递到网络服务的核心环境通过使用NSREQ_INPUT IPC消息，这些IPC消息需要有一个页面附加一个union Nsipc，数据包来填充其struct jif_pkt域。\n练习12 完成 net/input.c\n#define RDBUF 10 void input(envid_t ns_envid) { binaryname = \u0026#34;ns_input\u0026#34;; // LAB 6: Your code here:  // - read a packet from the device driver  // - send it to the network server  // Hint: When you IPC a page to the network server, it will be  // reading from it for a while, so don\u0026#39;t immediately receive  // another packet in to the same physical page.  int i, r; struct jif_pkt *head, *pkt = (struct jif_pkt*)\u0026amp;nsipcbuf; // 10 buffers  for (i = 0; i \u0026lt; RDBUF; ++i) if ((r = sys_page_alloc(0, (void *)((uint32_t)pkt + i * PGSIZE), PTE_U | PTE_P | PTE_W)) \u0026lt; 0) panic(\u0026#34;alloc error\u0026#34;); i = 0; head = pkt; while (1) { while((r = sys_recv((void *)((uint32_t)pkt + sizeof(pkt-\u0026gt;jp_len)), PGSIZE - sizeof(pkt-\u0026gt;jp_len))) \u0026lt; 0) { sys_yield(); // cprintf(\u0026#34;return value: %d\\n\u0026#34;, r);  } //cprintf(\u0026#34;pkt : %x | [i] : %d \\n\u0026#34;, pkt, i);  pkt-\u0026gt;jp_len = r; ipc_send(ns_envid, NSREQ_INPUT, pkt, PTE_P | PTE_U); pkt = (struct jif_pkt *)((uint32_t)pkt + PGSIZE); if (i++ == RDBUF-1) { pkt = head; i = 0; } } } 运行make E1000_DEBUG=TX,TXERR,RX,RXERR,RXFILTER run-net_testinput能够收到下面这个消息\nSending ARP announcement... Waiting for packets... e1000: index 0: 0x26dea0 : 900002a 0 e1000: unicast match[0]: 52:54:00:12:34:56 input: 0000 5254 0012 3456 5255 0a00 0202 0806 0001 input: 0010 0800 0604 0002 5255 0a00 0202 0a00 0202 input: 0020 5254 0012 3456 0a00 020f 0000 0000 0000 input: 0030 0000 0000 0000 0000 0000 0000 0000 0000 testinput只会发送一个数据包，但是评分脚本会有5个数据包 为了更加深入测试网络代码，JOS提供了一个叫做echosrv的守护进程来设置回显服务通过TCP服务的端口7。\n Q2: How did you structure your receive implementation? In particular, what do you do if the receive queue is empty and a user environment requests the next incoming packet?\n 结构体的的定义根据手册来定义就行，如果接收队列是空的，那么该环境自己放弃时间片，调用调度算法，等下一个时间片周期再来检测是否有数据包。\n网页服务 网页服务以其最简单的形式发送内容给请求的客户端。JOS已经一共了非常简单的网络服务在user/httpd.c中。这个代码框架解决了即将到来的连接并且解析HTTP头。\n练习13 网络服务缺失了发送内容到客户端的代码，完成send_file和send_data。\nstatic int send_data(struct http_request *req, int fd) { // LAB 6: Your code here.  //panic(\u0026#34;send_data not implemented\u0026#34;);  int r; char buf[512]; while ((r = read(fd, buf, 512)) \u0026gt; 0) if (write(req-\u0026gt;sock, buf, r) != r) return -1; return 0; } static int send_file(struct http_request *req) { int r; off_t file_size = -1; int fd; struct Stat fst; // open the requested url for reading  // if the file does not exist, send a 404 error using send_error  // if the file is a directory, send a 404 error using send_error  // set file_size to the size of the file  // LAB 6: Your code here.  //cprintf(\u0026#34;url: %s \\n\u0026#34;, req-\u0026gt;url);  //panic(\u0026#34;send_file not implemented\u0026#34;);  if ((fd = open(req-\u0026gt;url, O_RDONLY)) \u0026lt; 0) return send_error(req, 404); if ((r = fstat(fd, \u0026amp;fst)) \u0026lt; 0) return send_error(req, 404); file_size = fst.st_size; if (fst.st_isdir) return send_error(req, 404); if ((r = send_header(req, 200)) \u0026lt; 0) goto end; if ((r = send_size(req, file_size)) \u0026lt; 0) goto end; if ((r = send_content_type(req)) \u0026lt; 0) goto end; if ((r = send_header_fin(req)) \u0026lt; 0) goto end; r = send_data(req, fd); end: close(fd); return r; } 从最开始的概览图可以知道，这里是属于用户环境的程序，struct http_request中的socket相当于一个文件描述符，当把内容写到这个文件缓冲区，并且调用文件系统的回调函数，网络服务核心发送IPC消息到输出辅助环境。最开始接收到数据包的适合，利用http_request_parse函数获取文件路径，然后这个程序尝试去打开文件看能否打开，来判断文件的存在。然后发送HTTP头，HTTP头大小，类型以及\\r\\n的http头结束符。最后再将HTTP包主体传过去，也就是通过URL所指定的文件。\n最后可以通过浏览器访问这个网站\nmake grade make[1]: Leaving directory '/home/moonlight/lab' testtime: OK (9.9s) pci attach: OK (1.7s) testoutput [5 packets]: OK (3.1s) testoutput [100 packets]: OK (2.8s) Part A score: 35/35 testinput [5 packets]: OK (3.1s) testinput [100 packets]: OK (2.2s) tcp echo server [echosrv]: OK (2.6s) web server [httpd]: http://localhost:26002/: OK (1.8s) http://localhost:26002/index.html: OK (1.8s) http://localhost:26002/random_file.txt: OK (2.8s) Part B score: 70/70 Score: 105/105  you have a file system, no self respecting OS should go without a network stack.\n ","date":"May 28, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/","summary":"这章节是完成一个网络驱动程序，现在系统中已经存在了文件系统里，所以可以添加一个网络栈，是基于82540EM芯片(E1000)。这章节内容比我想象中难，虽然之前概览了一下，但是实际做起来的时候涉及到的概念和知识超出我现在所掌握的。\n准备 git\n$ git add . $ git commit -am \u0026#34;lab 5 done\u0026#34; $ make handin $ git pull $ git checkout -b lab6 origin/lab6 $ git merge lab5 Auto-merging lib/fd.c Auto-merging kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c Auto-merging inc/lib.h Auto-merging fs/serv.c Merge made by the \u0026#39;recursive\u0026#39; strategy. boot/main.c | 1 - fs/bc.c | 22 +- fs/fs.c | 73 +- .... user/faultio.c | 2 +- user/forktree.c | 1 + user/sh.c | 9 +- user/testfile.","tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)"},{"categories":["sys"],"contents":"这个实验主要是实现spawn库函数用来读取并运行可执行文件，然后扩充操作系统的内核和库 ，使得足以在控制台上运行shell。实现这些特性需要一个文件系统，而接下来就会介绍一个简单的可读写的文件系统。\n准备 git\n $ find . -name \u0026quot;*.swp\u0026quot; | xargs rm $ git add . $ git commit -m \u0026quot;lab4 done\u0026quot; $ git pull $ git merge lab4 Auto-merging kern/trap.c CONFLICT (content): Merge conflict in kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c CONFLICT (content): Merge conflict in kern/init.c Auto-merging kern/env.c CONFLICT (content): Merge conflict in kern/env.c Auto-merging inc/lib.h Automatic merge failed; fix conflicts and then commit the result. 解决conflict，并且确认pingpong, primes, 和forktree这三个用户程序可以正常运行。\n 文件系统 这里将使用一个比实际更简单的文件系统，但这足以提供一些基本的特点：创建，读取，写入和删在除文件在一个具有层级结构的文件结构。\n到目前为止已经完成了单用户操作系统，能够提供足够的保护去捕获bug但是不会阻止来自其他可疑用户的操作。新的文件系统暂时不支持硬链接(hard link),符号链接(symbolic links),时间戳(time stamps)或者特殊设备文件(device files).\n磁盘文件系统的结构：大多数UNIX文件系统将磁盘空间分成两类，inode区域和data区域。UNIX文件系统给每一个文件都赋予一个inode值，文件的inode保持这个文件的临界元数据(critical meta-data)例如文件的stat属性和指向数据块的指针。数据区域被分成了更大的data block，文件系统将文件数据和目录元数据存储在其中。目录的入口包含了文件名和指向inode的指针。一个文件能被硬链接只有多个文件目录入口引用了这个文件的inode。因为这里不支持硬链接，所以可以做一个方便的转化：完全不使用inode而简单地存储所有的文件的元数据在目录入口来描述每个文件。\n文件和目录逻辑上组成了一连串的数据块(data block)，可能被散布在磁盘也有可能在一个环境的虚拟地址空间所映射的物理内存上。文件系统隐藏了这些数据块的存放细节，为在一个绝对的文件偏移提供了接口方便读写字节流。文件系统对目录的修改表现为创建文件或者删除文件。这里的文件系统云溪用户环境读取目录的元数据，这意味着用户环境能自己扫描文件目录而不是依赖于一个二外的调用。这样做也有缺点，现代大多是UNIX的变体都不推荐使用它，这使得应用程序依赖于文件目录的格式，这让在没有改变或者编译应用程序的情况下很难改变文件系统内部存放。\n扇区和块 大多数磁盘不支持字节粒度的读写而是通过读写一个扇区单元。JOS中，每个区块都是512字节。文件系统实际上在块的单元分配和使用磁盘存储。注意：sector取决于磁盘硬件，然而block的大小是操作系统使用磁盘的一个大小。所以文件系统的块大小必须是块的整数倍。\nsuperblock 文件系统通常保留一个确定位置(最前面或者最末尾)的磁盘块来保存描述文件系统特性的元数据。任何元数据被要求找到根目录，文件系统上次被增减的时间，上次检查错误的时间等等。在这里的文件系统中将会有一个确定的superblock，它将总是在block1的位置，被定义在stuct Super。Block0通常被用来保存boot loaders和分区表(partition tables)。大多是实际的文件系统维护多个superblock，散布在disk中，所以其中的一个块发生了损毁或者介质错误，其他的superbloock仍能被找到。\n 文件元数据\n在这个文件系统中，meta-data的存放在stuct File中定义了。其中包含了文件名，文件大小，文件类型(普通文件或者目录)，以及一个指针指向下一个包含文件的块，因为不支持inode，所以这些元数据被存储在了目录入口，为了简化，将会直用File这一个结构体去表示即在磁盘和内存的元数据。\n结构体中f_direct数据包含了文件空间的前十个块，称之为文件的直接块。从小到大共40KB，这意味着这10个块号可以被这个File结构体直接引用。对于更大的文件，分配一个额外的磁盘块，被称作文件的间接块(indirect block)，能够保存1024个额外的块号。所以，文件系统因此能允许文件最大到1034个块已经大于了4M，当然实际的文件系统通常支持多个double-和triple indrect block。\n目录 vs. 普通文件 文件系统中的File结构体既能表示一个普通文件也能表示一个目录。它们的区别在于结构体的。type，两者的管理方法基本相同，除了目录文件不会解析普通文件的数据块，但是他会解析文件对目录文件的描述和子目录。\nsuperblock包含了一个File结构体，Super结构体中的root域保存了系统根目录的元数据。目录文件的内容是一系列File结构体，所有在根目录下的子目录也许会有多个File结构体用来表示次次级目录。\nx86使用EFLAGS寄存器中的IOPL位来决定在保护模式下的代码是否被允许执行例如in或者out这样的指令。因为所有的在x86 IO空间的IDE(Integrated Drive Electronics)磁盘寄存器都需要访问，而不是被映射到内存。给予文件系统的IO权限是为了能偶个访问所有的寄存器，同时是一种办法来控制其他用户环境的代码是否有权限来访问I/O空间。\n 练习1    if (type == ENV_TYPE_FS) env-\u0026gt;env_tf.tf_eflags |= FL_IOPL_3; 一开始的想法是使用privilige 0，也就是FL_IOPL_0，但是出错了。\n Indicates the I/O privilege level (IOPL) of the currently running program or task. The CPL of the currently running program or task must be less than or equal to the IOPL to access the I/O address space. This field can only be modified by the POPF and IRET instructions when operating at a CPL of 0.\n 解释是当前用户环境的CPL(current privilege level)必须小于或等于IOPL等级才行。普通用户环境默认被初始化为0，而CPL是3，所以正常的进程是不能直接执行IO操作的。在后面的测试spawnfaultio测试中有测试。如果需要文件系统能进行IO，则将IOPL值置为3即可。\n Q1:Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why?\n 前面的实验中有想过，每当一个环境开始运行的时候，也就是调用env_run函数的适合都会执行iret以恢复寄存器状态。\n 块高速缓存\n在这个文件系统中，将会在处理器的虚拟内存系统中实现一个简单的缓冲区，代码在fs/bc.c 文件系统将会限制可操作的磁盘大小是3G或者更少，保留一个够大的3GB区域在文件系统的内存空间，从0x10000000 (DISKMAP) 到 0xD0000000 (DISKMAP+DISKMAX)，作为一个映射在内存的磁盘版本。例如，block0被映射在0x1000000，block1映射在0x10001000等等。diskaddr函数实现了从块号到虚拟内存的转换，并且做了一些正常的检测。\n文件系统拥有其自己的虚拟内存空间独立于其他所有的用户环境，并且文件系统的仅需要做的一件事就是实现文件访问，有理由去保留大多数文件系统的内存空间。\n当然，读取整个磁盘到内存中将会花费相当长的时间，所以实现一种demand paging仅仅分配那些需要相应块号对应的页，以可信的方式引发一个页错误，再分配。通过这种方式，能假定整个磁盘是在内存中。\n 练习2  实现fs/bc.c中的bc_pgfault函数和flush_block函数 bc_pgfault是一个页错误处理handler，就像之前的cow fork，希望从磁盘读取页会产生页错误。 1.addr 也许不是与block边界对齐的。 2.ide_read 是在扇区操作不是块。 flush_block 函数如果有必要的话需要写一个块到磁盘中，如果没有block cache或者不是\u0026quot;dirty\u0026quot;状态(5.2.4.3),fluash_block什么也不会做。\n ide_write\nint ide_write(uint32_t secno, const void *src, size_t nsecs) { int r; assert(nsecs \u0026lt;= 256); ide_wait_ready(0); outb(0x1F2, nsecs); //sector count  outb(0x1F3, secno \u0026amp; 0xFF); //sector number  outb(0x1F4, (secno \u0026gt;\u0026gt; 8) \u0026amp; 0xFF); //clinder low  outb(0x1F5, (secno \u0026gt;\u0026gt; 16) \u0026amp; 0xFF); //clinder high  outb(0x1F6, 0xE0 | ((diskno\u0026amp;1)\u0026lt;\u0026lt;4) | ((secno\u0026gt;\u0026gt;24)\u0026amp;0x0F)); //select driver 1  outb(0x1F7, 0x30); // CMD 0x30 means write sector  for (; nsecs \u0026gt; 0; nsecs--, src += SECTSIZE) { if ((r = ide_wait_ready(1)) \u0026lt; 0) return r; outsl(0x1F0, src, SECTSIZE/4);//data register  } return 0; } 这个函数和ide_read基本相同，往磁盘寄存器内读写数据，设置读写计数器，读写的扇区号，柱面等等，然后通过一个for循环读取写入数据。CPU之前已经将相应的内存页在UVPT中标记为了dirty状态，也就是页重写标志位，当把内容读到内存中去的适合发生页错误，引发陷入从而分配一个新的物理页，并且写入数据。JOS用bc_pgfault作为handler处理这种页错误，代码如下。\n# bc_pgfault  // Allocate a page in the disk map region, read the contents  // of the block from the disk into that page.  // Hint: first round addr to page boundary. fs/ide.c has code to read  // the disk.  //  // LAB 5: you code here:  addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); if ((r = sys_page_alloc(0, addr, PTE_P|PTE_U|PTE_W)) \u0026lt; 0) panic(\u0026#34;in sys_page_alloc, %e\u0026#34;, r); if ((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS) \u0026lt; 0)) panic(\u0026#34;in ide_read , %e\u0026#34;, r);  flush_content的主要作用就是把数据写回到磁盘中去，然后清楚PTE_D页面重写标记为，代码如下：\nvoid flush_block(void *addr) { uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if (addr \u0026lt; (void*)DISKMAP || addr \u0026gt;= (void*)(DISKMAP + DISKSIZE)) panic(\u0026#34;flush_block of bad va %08x\u0026#34;, addr); // LAB 5: Your code here.  addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); if (!va_is_mapped(addr)) return; if (!va_is_dirty(addr)) return; if ((r = ide_write(blockno*BLKSECTS, addr, BLKSECTS)) \u0026lt; 0) panic(\u0026#34;ide_write fault : %e\u0026#34;, r); if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] \u0026amp; PTE_SYSCALL)) \u0026lt; 0) panic(\u0026#34;map fault : %e\u0026#34;, r); //panic(\u0026#34;flush_block not implemented\u0026#34;); } fs_init函数是一个范例使用block cache，初始化后super存储指向磁盘映射范围的指针。在此之后，就能从super结构体读取数据就好像是从磁盘读取一样。\n Challenge:淘汰机制.\n 块位图(Block Bitmap) 在fs_init设置好了bitmap指针后，可以将bitmap看作一个比特数组，其中一位对应着在磁盘中的一个块。例如，block_is_free就是检测一个跟定的块是否在bitmap中被标记。\n 练习3  使用free_block作为一个范例去实现alloc_block函数，如果能在位图里找到空闲的磁盘块，标记其已经被使用，并且返回块号。当分配好了块，需要马上改变磁盘中的的位图块，使用flush_block函数，使得文件系统在内存的内容和在硬盘中内容一致。\n int alloc_block(void) { // The bitmap consists of one or more blocks. A single bitmap block // contains the in-use bits for BLKBITSIZE blocks. There are // super-\u0026gt;s_nblocks blocks in the disk altogether. // LAB 5: Your code here. //panic(\u0026quot;alloc_block not implemented\u0026quot;); int i; for (i = 2; i \u0026lt; super-\u0026gt;s_nblocks; i++) if (block_is_free(i)) { bitmap[i/32] ^= 1\u0026lt;\u0026lt;(i%32); flush_block(bitmap); return i; } return -E_NO_DISK; } 块的位图将每一个整形的bit最为一个块的使用标志，3G区域共3GB/4KB个块，所对应的位图共96KB。PS：位图中置0表示已经使用。\n 文件操作 在文件fs/fs.c中提供了一些函数管理File结构体的函数，解释结构体，扫描管理目录文件的入口，从根目录遍历整个文件系统。\nfs_init()：找到JOS的磁盘，全局变量super block指向第1号扇区在内存中的映射(第0号扇区是bootloader)，bitmap指向第2号扇区所对应在内存中的映射。\nstatic int file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc) 找到文件结构体中的文件块号对应的全局文件块号，将块号存在*ppdiskbno中，如果没有根据alloc的值判断是否分配。\nint file_get_block(struct File *f, uint32_t filebno, char **blk) 获得一个文件结构体文件块号所对应在内存中的映射，把结果存在*blk中。\nstatic int dir_lookup(struct File *dir, const char *name, struct File **file) 通过file_get_block获得这个目录文件结构体所在的块，再用一个文件一个文件结构体的对照文件名，直到相等再把file指向这个找到的文件。\nstatic int dir_alloc_file(struct File *dir, struct File **file) 首先现在目录本身的结构体中寻找可以用的空文件结构体，如果找不到则新分配一个块并且目录文件大小也会增加，file指向这个空闲的文件结构体。\nwalk_path()：和HOMEWORK中做的命令解释器很像，从根目录开始迭代，例如/usr/bin就会被一步一步地解析为 super-\u0026gt;usr-\u0026gt;bin，usr和bin分别作为目录和文件返回。\nfile_create(const char *path, struct File **pf) 在path目录下创建一个文件，通过指针返回一个文件，并且会把文件写回磁盘。\nfile_open() file_read() file_write() 都是基本的文件操作，不过要注意的是，文件的写操作只是写在了磁盘所映射的内存，没有存回磁盘，所以应该需要flush操作。\nfile_free_block()：在块的位图上释放文件块\nfile_truncate_blocks()：缩小文件大小，释放掉保持的磁盘块，但是不会修改结构体中的f-\u0026gt;f_size的值。 file_set_size()：设置文件的大小，并且写回磁盘。\nfile_flush()把一个单独的文件写回磁盘而fs_sync()将整个内存映射都写回磁盘。\n练习4 实现file_block_walk和file_get_block函数。 file_block_walk通过一个在文件内的偏移，映射结构体所直接指向的块或者间接指向的块。 file_get_block更及进一步地映射实际的磁盘块，如果有必要的话分配一个新磁盘块。 代码如下：\nfile_block_walk() static int file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc) { // LAB 5: Your code here.  //panic(\u0026#34;file_block_walk not implemented\u0026#34;);  int r; // cprintf(\u0026#34;filebno %d\\n\u0026#34;, filebno);  if (filebno \u0026gt; NDIRECT + NINDIRECT) return -E_INVAL; if (filebno \u0026lt; NDIRECT) { if (ppdiskbno) *ppdiskbno = f-\u0026gt;f_direct + filebno; return 0; } //cprintf(\u0026#34;indirect: %08x logic: %d\\n\u0026#34;, f-\u0026gt;f_indirect, !f-\u0026gt;f_indirect);  if (!f-\u0026gt;f_indirect) { if (alloc) { if ((r = alloc_block()) \u0026lt; 0) return r; memset(diskaddr(r), 0, BLKSIZE); f-\u0026gt;f_indirect = r; flush_block(diskaddr(r)); } else return -E_NOT_FOUND; } *ppdiskbno = (uint32_t *)diskaddr(f-\u0026gt;f_indirect) + filebno - NDIRECT; //cprintf(\u0026#34;fileno : %d -\u0026gt; diskno: %x -\u0026gt; %x\\n\u0026#34;, filebno, *ppdiskbno, **ppdiskbno);  return 0; } 做的后面踩了前面的坑，diskaddr的返回类型需要坐下强制类型转换，void *指针类型p与uint32_t的n相加等于p + n * 1，而这里需要的是整形指针相加的结果p + n * 4。\nfile_get_block() int file_get_block(struct File *f, uint32_t filebno, char **blk) { // LAB 5: Your code here.  //panic(\u0026#34;file_get_block not implemented\u0026#34;);  uint32_t *bno; int r; if ((r = file_block_walk(f, filebno, \u0026amp;bno, 1)) \u0026lt; 0) return r; // allocate a block if the block number is zero  // meaning that it hasn\u0026#39;t refered to any block by now.  if (*bno == 0) { if ((r = alloc_block()) \u0026lt; 0) return r; *bno = r; memset(diskaddr(r), 0, BLKSIZE); flush_block(diskaddr(r)); } // *bno is the number of blocks  *blk = diskaddr(*bno); return 0; } 做到这里可以发现，当往文件写内容的适合，实际是先写入内存的缓冲区的，只有最后执行了flush操作，才会真正把内容保存到磁盘中去。\n 文件系统接口 现在有必要为文件系统自己提供一些功能/接口，必须文件系统能够被其他用户环境使用。因为其他环境不能直接调用文件系统环境中的函数，所以通过远程程序调用RPC(remote procedure call)能访问文件系统的接口。\n Regular env FS env +---------------+ +---------------+ | read | | file_read | | (lib/fd.c) | | (fs/fs.c) | ...|.......|.......|...|.......^.......|............... | v | | | | RPC mechanism | devfile_read | | serve_read | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | fsipc | | serve | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | ipc_send | | ipc_recv | | | | | ^ | +-------|-------+ +-------|-------+ | | +-------------------+ 在点线之下是从普通用户环境发送到文件系统环境的一个读请求。开始的时候，read工作在任何文件描述符上，并且分发到合适的设备读函数，这里是使用的devfile_read函数，当然还有其他各种的设备类型比如管道。devfile_read实现了读对磁盘上文件的操作，这个函数和其他devfile_*函数是实现了客户端这边的文件系统的操作，并且所有的工作几乎相同，绑定参数到request结构体，并且调用fsipc发送IPC请求和解析返回的值。fsipc函数完成了发送请求到服务端和接收回复的细节。\n文件系统服务端代码在fs/serv.c中，服务端循环serve函数，接收来自IPC的请求，分发请求到合适的handler函数，并且将访问的结果通过IPC返回。在读操作的例子中，serve分发请求到serve_read，这个函数将会关注IPC的读请求细节，例如解包request结构体后调用file_read去执行文件读操作。\n回顾JOS的IPC机制，让一个环境发送一个32位的数字，并且有选择性的分享页。为了从客户端到服务端发送一个请求，这里使用32位的数字去指定request类型，并且存储request参数到union Fsipc所在的共享页上去。在客户端，总是将共享页放在fsipcbuf处；在服务端，将即将到来的请求页映射在fsreq(0x0ffff000)处。\n服务端也会通过IPC发送回复消息，将ipc参数中的32位值设置为相关函数的返回值。大多数RPC都会有它们自己的返回类型，FSREQ_READ和FSREQ_STAT总是返回数据，这两个函数将数据写到客户端所发送的request页上。但是不需要通过IPC发送这个页，因为客户端已经分享了这个物理页。当然，例如FSREQ_OPEN分享给客户端一个新的Fd页,将会很快的返回文件描述符指定的页。\n练习5 实现serve_read serve_read的艰苦工作已经被file_read实现了，它只需要位文件的读提供RPC的接口，可以参照serve_set_size函数。\nint serve_read(envid_t envid, union Fsipc *ipc) { struct Fsreq_read *req = \u0026amp;ipc-\u0026gt;read; struct Fsret_read *ret = \u0026amp;ipc-\u0026gt;readRet; struct OpenFile *o; int r; char buf[PGSIZE]; size_t read_count, remainder; if (debug) cprintf(\u0026#34;serve_read %08x %08x %08x\\n\u0026#34;, envid, req-\u0026gt;req_fileid, req-\u0026gt;req_n); // Lab 5: Your code here:  // same as before, find the file firstly.  if ((r = openfile_lookup(envid, req-\u0026gt;req_fileid, \u0026amp;o)) \u0026lt; 0) return r; if ((r = file_read(o-\u0026gt;o_file, ret-\u0026gt;ret_buf, req-\u0026gt;req_n, o-\u0026gt;o_fd-\u0026gt;fd_offset)) \u0026lt; 0) return r; o-\u0026gt;o_fd-\u0026gt;fd_offset += r; //memcpy(ret, buf, PGSIZE);  return r; } 关于偏移的到结束的大小，这里不用再做判断了，已经file_read函数中实现了。\n练习6 实现serve_write\nstatic ssize_t devfile_write(struct Fd *fd, const void *buf, size_t n) { // Make an FSREQ_WRITE request to the file system server. Be  // careful: fsipcbuf.write.req_buf is only so large, but  // remember that write is always allowed to write *fewer*  // bytes than requested.  // LAB 5: Your code here  //panic(\u0026#34;devfile_write not implemented\u0026#34;);  int r; fsipcbuf.write.req_fileid = fd-\u0026gt;fd_file.id; fsipcbuf.write.req_n = n; memmove(fsipcbuf.write.req_buf, buf, n); if ((r = fsipc(FSREQ_WRITE, NULL)) \u0026lt; 0) return r; return r; } 这两个实现比较简单，跟着指导做就好，但不能仅仅满足于函数天空，这些函数都是一层一层包装上去的，省去了背后的原理和操作，例如设置页位\u0026quot;dirty状态\u0026quot;，引发页错误分配映射，避免磁盘全部映射而占据大量内存空间。文件的读写操作都被简化了，在testfile.c源码中都是使用的write,open,read等被抽象的操作，而实际的过程比如write操作会被分发到devfile_write通过IPC发送写信号并且共享传递的页，文件系统进程收到写信号并将传递过来的页映射在一个固定的位置，找到文件描述符所指定的文件，然后将共享页buf中的内容复制到磁盘映射页上面，最后在关闭文件的时候flush进行保存；文件系统服务端这边处理完文件后，会把文件写操作的字节数返回做为操作成功的信号通过IPC返回给客户端，并且取消映射共享页。给人的直接感受就是，操作者通过write操作直接写入了文件中。\n产生子进程 spawn操作创建一个新的环境，从文件系统中读取程序镜像运行此程序，父进程独立于子进程继续运行。spwan函数的操作就像UNIX中fork后立马在子进程执行exec。\n练习7 spwan依赖于新的系统调用sys_env_set_trapframe来初始化新被创建的环境状态，完成这个函数后，尝试运行user/spanhello程序。\n通过fork和spawn分享库状态 UNIX文件描述符是一个泛指的概念，其中包含了pipe,控制台I/O等。在JOS中，每一种设备类型都有一个对应的struct Dev，使用指针实现读写等操作。对于这些设备类型，lib/fd.c实现了像UNIX的文件描述符的接口，每一个Fd结构体指定它自己的设备类型，fd.c中的函数分发分发各自的操作到相应的Dev结构体中去。 fd.c为每一个应用程序维护文件描述符表在它们各自的内存空间，地址起始于FDTABLE。这片4KB的页很值得为最多32个文件描述符保留在内存空间，使得应用程序能立即打开。在任意时刻，一个指定的文件描述符表页当且仅当对应的文件描述符是在被使用的。每一个文件描述符在这片区域还拥有一个可选的data page在地址FILEDATA处，设备可以用来使用。\n因为可能需要通过fork和spawn来分享文件描述符的状态，但是文件描述符的状态是保存在各自用户内存空间中的。现在，fork已经标记那些需要被复制的页为cow状态。这里需要不同的用户环境共享用户环境，与cow分配并复制不同，PTE_SHARE的标记意味着直接映射该物理帧，达到共享的效果。\n练习8 修改lib/fork.c中的duppage 实现lib/spawn.c中的copy_shared_pages函数\nva = pn*PGSIZE; //cprintf(\u0026#34;%x\\n\u0026#34;, va);  if (uvpt[pn] \u0026amp; PTE_SHARE) { if ((r = sys_page_map(thisenv-\u0026gt;env_id, (void *)va, envid, (void *)va, uvpt[pn] \u0026amp; PTE_SYSCALL)) \u0026lt; 0) return r; return 0; } static int copy_shared_pages(envid_t child) { // LAB 5: Your code here.  int32_t va; int r; for (va = 0; va \u0026lt; USTACKTOP; va += PGSIZE) if ((uvpd[PDX(va)] \u0026amp; PTE_P) \u0026amp;\u0026amp; (uvpt[PGNUM(va)] \u0026amp; PTE_P) \u0026amp;\u0026amp; (uvpt[PGNUM(va)] \u0026amp; PTE_SHARE)) { if ((r = sys_page_map(0, (void *)va, child, (void *)va, PTE_SYSCALL\u0026amp;uvpt[PGNUM(va)])) \u0026lt; 0) return r; } return 0; } 代码中的spawn已经实现了，并且加了很多注释，在这做下笔记。\n 打开程序文件 读取ELF文件头，检测它的魔数(magic number) 使用系统调用sys_exofork()创建一个新的环境 设置子进程的初始栈，例如传递的参数 调用init_stack()设置好栈页 映射程序的各个段到新环境的内存空间   如果ELF文件flag没有包含ELF_PROG_FLAG_WRITE，那么短包含了代码正文和只读的数据。 如果ELF文件flag包含了ELF_PROG_FLAG_WRITE，那么代表这个段包含了可读写的数据和bss段  调用sys_env_set_trapframe设置子程序的栈 调用sys_env_set_status表明程序可以确认运行了。  这里设置栈帧的时候，要压入像main(int argc, char **argv)中argc,argv两个参数，这里的操作给出了更加准确的答复(函数init_stack(envid_t child, const char **argv, uintptr_t *init_esp)。\nstring_size = 0; for (argc = 0; argv[argc] != 0; argc++) string_size += strlen(argv[argc]) + 1; 首先确定字符串总长度，并且包含每个字符串结尾的null字节。\nstring_store = (char*) UTEMP + PGSIZE - string_size; argv_store = (uintptr_t*) (ROUNDDOWN(string_store, 4) - 4 * (argc + 1)); string_store ~ UTEMP+PGSIZE用来存放参数中的字符串，argv_store ~ string_store存放argv[i]这个二维数组指向各自字符串的指针。\nif ((r = sys_page_alloc(0, (void*) UTEMP, PTE_P|PTE_U|PTE_W)) \u0026lt; 0) return r; for (i = 0; i \u0026lt; argc; i++) { argv_store[i] = UTEMP2USTACK(string_store); strcpy(string_store, argv[i]); string_store += strlen(argv[i]) + 1; } 设置栈帧的时候先在UTEMP这分配一个页面，然后才进行存放。这里有一点引起了我注意，argv_storep[i]也就是二维数组中的字符串指针都是指向USTACK的，但是字符串的内容还是存放在UTEMP~UTEMP+PGSIZE的范围中，因为最后程序正式开始执行的时候，指针不可能指向UTEMP，所以这里可以看作是一个小tricks。\nargv_store[-1] = UTEMP2USTACK(argv_store); argv_store[-2] = argc; *init_esp = UTEMP2USTACK(\u0026amp;argv_store[-2]); if ((r = sys_page_map(0, UTEMP, child, (void*) (USTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W)) \u0026lt; 0) goto error; if ((r = sys_page_unmap(0, UTEMP)) \u0026lt; 0) goto error; 接下来就是把argv_store这个在USTACK中对应的位置压栈，它指向字符串指针数组的开头，其次再压入的argc参数的个数，并将esp栈顶指针设置好后映射到USTACK去，解开UTEMP的映射回收内存页，这里就完成了栈的初始化。 PS: 这里的数组角标为负数时头次在C中见到，虽然理解不难，但是看到在python中常用的语法在C中出现还挺意外的。\n所以最后spawn出来的程序所拥有的栈结构如下：\n键盘接口 为了shell能工作，现在需要一种方式来打字。QEMU已经显示了输入到CGA(Color Graphics Adapter)和串口，但是到目前为止只能在内核的显示器上获取输入。从键盘的输入显示在图形窗口上，然而串口的输入会被显示到控制台上。kern/console.c已经完成键盘和串口驱动被用作内核的监视器，但是现在需要附加剩下的功能。 在代码中必定会接触到大量串口操作，与其外围寄存器相关，现在看着还是挺懵的，所以暂时不去关注端口的实现。\n Q: 串口中断和按键中断有什么区别\n 练习9 分发按键中断IRQ_OFFSET+IRQ_KBD和串口中断IRQ_OFFSET+IRQ_SERIAL。\n// Handle keyboard and serial interrupts.  // LAB 5: Your code here.  if (tf-\u0026gt;tf_trapno == IRQ_OFFSET + IRQ_KBD) { kbd_intr(); return; } if (tf-\u0026gt;tf_trapno == IRQ_OFFSET + IRQ_SERIAL) { serial_intr(); return; } 当键盘键入或者有串口中断发生的时候，串口和键盘分别通过各自的例程获取字符，并且调用cons_intr将字符放入结构体cons的缓冲区中，自增写端wpos。\nstatic struct { uint8_t buf[CONSBUFSIZE]; uint32_t rpos; uint32_t wpos; } cons; 在当程序需要进行获取输入的时候，会调用kern/console.c中的cons_getc()，这个函数首先会调用serial_intr()和kbd_intr()先获取串口或者键盘输入，然后通过将从缓冲区buf中获取一个字符，并且自增rpos读端。\n练习10 这个练习基本上就是高层的命令解释器的实现，hw2中已经实现过了。\n// LAB 5: Your code here.  //panic(\u0026#34;\u0026lt; redirection not implemented\u0026#34;);  if ((fd = open(t, O_RDONLY)) \u0026lt; 0) { cprintf(\u0026#34;open %s for read: %e\u0026#34;, t, fd); } if (fd != 0) { dup(fd, 0); close(fd); } break; 和\u0026gt;操作一样，代码基本相似，但是可以顺便看一下pipe和dup的实现。\ndup()\nint dup(int oldfdnum, int newfdnum) { int r; char *ova, *nva; pte_t pte; struct Fd *oldfd, *newfd; if ((r = fd_lookup(oldfdnum, \u0026amp;oldfd)) \u0026lt; 0) return r; close(newfdnum); newfd = INDEX2FD(newfdnum); ova = fd2data(oldfd); nva = fd2data(newfd); if ((uvpd[PDX(ova)] \u0026amp; PTE_P) \u0026amp;\u0026amp; (uvpt[PGNUM(ova)] \u0026amp; PTE_P)) if ((r = sys_page_map(0, ova, 0, nva, uvpt[PGNUM(ova)] \u0026amp; PTE_SYSCALL)) \u0026lt; 0) goto err; if ((r = sys_page_map(0, oldfd, 0, newfd, uvpt[PGNUM(oldfd)] \u0026amp; PTE_SYSCALL)) \u0026lt; 0) goto err; return newfdnum; } dup首先将新的文件描述符关闭，例如dup(fd, 0)会先将0也就是标准输出关闭(写回磁盘，取消物理帧的映射)，然后将fd所指向的数据块和文件描述符所占的页映射到根据文件描述符号转换到的虚存地址去，所以写入标准输出的内容可以写到fd所指向的文件中去了。 dup后一般有一个close()操作，这一步只是取消对物理块的引用而已，多出来文件描述符既不安全又不美观。\npipe()\nint pipe(int pfd[2]) { int r; struct Fd *fd0, *fd1; void *va; // allocate the file descriptor table entries  if ((r = fd_alloc(\u0026amp;fd0)) \u0026lt; 0 || (r = sys_page_alloc(0, fd0, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u0026lt; 0) goto err; if ((r = fd_alloc(\u0026amp;fd1)) \u0026lt; 0 || (r = sys_page_alloc(0, fd1, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u0026lt; 0) goto err1; // allocate the pipe structure as first data page in both  va = fd2data(fd0); if ((r = sys_page_alloc(0, va, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u0026lt; 0) goto err2; if ((r = sys_page_map(0, va, 0, fd2data(fd1), PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u0026lt; 0) goto err3; // set up fd structures  fd0-\u0026gt;fd_dev_id = devpipe.dev_id; fd0-\u0026gt;fd_omode = O_RDONLY; fd1-\u0026gt;fd_dev_id = devpipe.dev_id; fd1-\u0026gt;fd_omode = O_WRONLY; pfd[0] = fd2num(fd0); pfd[1] = fd2num(fd1); return 0; } pipe()首先引起注意的就是权限设置，这也是为什么一段只能读一段只能写。首先为每个描述符提供一个页存储文件结构体，再分配一个页给0一个数据页，将这个页映射到0和1文件描述符对应的数据页，并且将页标记为PTE_SHARE。在任意一段尝试读或者写的时候，触发页错误，使用bc_pgfault进行实际映射。最后进行权限设置，完成管道的创建。\nmake grade make[1]: Leaving directory \u0026#39;/home/moonlight/lab\u0026#39; internal FS tests [fs/test.c]: OK (1.9s) fs i/o: OK check_bc: OK check_super: OK check_bitmap: OK alloc_block: OK file_open: OK file_get_block: OK file_flush/file_truncate/file rewrite: OK testfile: OK (1.7s) serve_open/file_stat/file_close: OK file_read: OK file_write: OK file_read after file_write: OK open: OK large file: OK spawn via spawnhello: OK (1.2s) Protection I/O space: OK (1.3s) PTE_SHARE [testpteshare]: OK (2.0s) PTE_SHARE [testfdsharing]: OK (1.2s) start the shell [icode]: Timeout! OK (31.4s) testshell: OK (3.9s) primespipe: OK (11.1s) Score: 150/150 This completes the lab\n这一节实验代码量较小，但是实现了很多日常接触到的概念，例如管道，dup，文件描述符等。在完成实验的时候踩了很多坑，比如虽然通过了阶段性的测试，但是前面留下的错误代码影响到了后面的整个系统，仔细观察程序可以观察到代码都是一层一层抽象上去的，所以越是底层越需要仔细，考虑清楚corner case。每发生一个BUG都花了大量时间去寻找问题所在，这是很不应该的。\n","date":"May 20, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/","summary":"这个实验主要是实现spawn库函数用来读取并运行可执行文件，然后扩充操作系统的内核和库 ，使得足以在控制台上运行shell。实现这些特性需要一个文件系统，而接下来就会介绍一个简单的可读写的文件系统。\n准备 git\n $ find . -name \u0026quot;*.swp\u0026quot; | xargs rm $ git add . $ git commit -m \u0026quot;lab4 done\u0026quot; $ git pull $ git merge lab4 Auto-merging kern/trap.c CONFLICT (content): Merge conflict in kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c CONFLICT (content): Merge conflict in kern/init.c Auto-merging kern/env.c CONFLICT (content): Merge conflict in kern/env.c Auto-merging inc/lib.h Automatic merge failed; fix conflicts and then commit the result. 解决conflict，并且确认pingpong, primes, 和forktree这三个用户程序可以正常运行。","tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell"},{"categories":["sys"],"contents":"在这个实验中，将会在多个用户环境同时运行时实现抢占式多任务。\n part A:为JOS添加多处理器的支持，实现round-robin scheduling和增加基础的用户环境管理的系统调用，例如创建和销毁用户环境，分配和映射内存中的内容。 part B: 实现fork()函数，允许用户环境去添加一份自己环境的拷贝。 part C: 添加进程间的通信IPC(inter-process communication)，允许不同的用户环境各自通信和同步；添加硬件时钟中断和抢占任务。\n 准备开始 git\n#git rest --hard FETCH_HEAD git add -u git commit -m \u0026quot;\u0026quot; git pull git checkout -b lab4 origin/lab4 git merge lab3  confilcts in file config/lab.mk\n源文件描述 kern/cpu.h Kernel-private definitions for multiprocessor support kern/mpconfig.c Code to read the multiprocessor configuration kern/lapic.c Kernel code driving the local APIC unit in each processor kern/mpentry.S Assembly-language entry code for non-boot CPUs kern/spinlock.h Kernel-private definitions for spin locks, including the big kernel lock kern/spinlock.c Kernel code implementing spin locks kern/sched.c Code skeleton of the scheduler that you are about to implement  PART A: 多处理器支持(Multiprocessor Support )和协作式多任务(Cooperative Multitasking) 首先，会扩展JOS，使其能在多处理器系统上运行。然后实现一些JOS内核的系统调用，使得用户环境能创建额外的环境。通过实现cooperative round-robin scheduling，允许内核能切换到不同的用户环境，使用户环境自身让出CPU资源。 然后再part C中，将会实现 preemptive scheduling，这种调度算法允许内核从一个超出分配时间片的用户环境重新获取CPU的控制权。\nMultiprocessor Support JOS将会支持对称多处理SMP(symmetric multiprocessing)，这种多处理模型使得CPU能有对例如内存和IO总线等系统资源拥有平等的访问权。虽然所有的CPU在SMP中都一样，但是在执行启动进程期间，处理器会被分成两种。\n 引导处理器BSP(bootstrap processor)在启动操作系统的时候，初始化系统的时候使用。 应用程序处理器APs(application processos)仅当在操作系统已经启动好后，被BSP激活。 BSP处理器的选择取决于硬件和BIOS，到目前为止，JOS的代码都是运行在BSP处理器上的。  在SMP系统中，每个CPU都有一个附随的LAPIC单元(local APIC unit)，这些单元通过系统分发中断，LAPIC为其相关的CPU提供一个独一无二的标识符。 在这个实验中，将会使用LAPIC的以下功能：\n 通过读取APIC ID(LAPICT identifier)获取当前正在运行的CPU(cpunum()) 发送处理器之间的__STARTUP__中断IPI(interprocessor interrupt)当BSP启动APs的时候。 在part C中，LAPIC内置计时器去触发时钟中断，来支持抢占式多任务。  APIC(Adavanced Programmable Interrupt Controller) chapter 8:https://pdos.csail.mit.edu/6.828/2017/readings/ia32/IA32-3A.pdf Local APIC主要的作用分成两部分:\n 接收来自其他LAPIC的中断和外部的I/O APIC中断，或者发送中断。 在MP(multiple processor)系统中，在system bus发送接收处理器间中断IPI。  处理器访问它自己的LAPIC通过MMIO(memory-mapped I/O)，在MMIO中，一部分物理内存直接与IO设备的寄存器相连接，所以类似于ld/store的指令通常被用作间接访问外围设备的寄存器。Lab2为IO hole在物理地址0xA0000留了一部分内存空间用作VAG显示缓冲。LAPIC位于内存地址0xFE000000(4GB - 32MB)处，这个地址很高，所以不能直接通过KERNBASE映射。JOS的虚拟内存为MMIOBASE保留了4MB的空间，所以可以用来映射设备的内存。 另外Lapic所使用的内存应该是被设计为strong uncacheable的，而在 kern/lapic.c预先定义的ID，Version等信息可以在IA-32 Table8.1中查到。\n接下来的实验中将会介绍更多MMIO的区域，并且为外围设备实现一些基础的内存分配和映射。\n练习1  实现kern/pmap.c中的mmio_map_region() 研究kern/lapic.c中的lapic_init()\n  void * mmio_map_region(physaddr_t pa, size_t size) { static uintptr_t base = MMIOBASE; if (base + size \u0026gt; MMIOLIM) panic(\u0026#34;mmio memory space is not enough .\u0026#34;); uint32_t va = base; pa = ROUNDDOWN((uint32_t)pa, PGSIZE); size = ROUNDUP((uint32_t)size, PGSIZE); boot_map_region(kern_pgdir, base, size, pa, PTE_PCD|PTE_PWT|PTE_W); base += size; return (void *)va; //panic(\u0026#34;mmio_map_region not implemented\u0026#34;); } 可以发现这个函数的页权限的设计是使用了PTE_PCD|PTE_PWT，当CPU采用高速缓存时，它的写内存操作有两种模式，一种称为“穿透”(Write-Through)模式，在这种模式中高速缓存对于写操作就好像不存在一样，每次写时都直接写到内存中，所以实际上只是对读操作使用高速缓存，因而效率相对较低。另一种称为“回写”(Write-Back)模式，写的时候先写入高速缓存，然后由高速缓存的硬件在周转使用缓冲线时自动写入内存，或者由软件主动地“冲刷”有关的缓冲线。另外一点就是Cache Disable，防止这里的内存被CPU缓存，就是为了保证LAPIC被映射在内存上的寄存器值能够准确地被读取。\n注意lapic_init()开头几步，需要返回一个MMIO的地址\nApplication Processor Bootstrap 在启动APs之前，BSP首先需要收集关于多处理器系统的信息，比如CPU的数量，它们的APIC ID以及这些LAPIC单元对应的MMIO地址。kern/mpconfig.c中mp_init()通过读取BIOS内存块的MP configuration table获取这些信息。\nkern/init.c中的boot_aps()函数驱动AP的启动引导进程，APs在实模式下开始工作，就像之前的内核引导程序(boot/boot.S,)，boot_aps在实模式下复制一份AP entry code(kern/mpentry.S)到一个内存可以寻址的地方，所以一定程度上可以控制AP开始执行的内存地址；现在将把entry code复制到0x7000(MPENTRY_PADDR)，但实际上低于640KB未使用的页对齐的物理地址都可用。\n之后，boot_aps()一个一个激活应用处理器，通过发送STARTUP中断信号到这些处理器对应的LAPIC单元，并且初始化CS:IP(指向MPENTRY_PADDR)。安装完后，使得AP开启保护模式，分页机制，并调用启动例程mp_main()。boot_aps()等待AP发送一个Cpuinfo结构体中的CPU_STARTEDflag，然后再启动接下来的处理器。\n 练习2  将MPENTRY_PADDR从free_list中删除\n boot_aps():将MPENTRY的代码安装到内核中去，为每一个cpu准备相应的栈区。然后通过一个for循环初始化所以cpu，在循环体内用while循环等待cpu被启动好的信号。 lapic_startup(id, addr)然后发送IPI到APIC bus上，让相应AP的LAPIC收到这个中断，开始执行mpentry.S中的内容，开启保护模式，分页；加载数据段，代码段等。\n当mpentry执行到最后，调用mp_init()函数，初始化该AP的寄存器。 lapic_init():从处理器中获取lapic的相关信息 env_init_percpu():初始化每个处理器的段寄存器 trap_init_percpu():读取TSS和IDT 在最后，xchg()即发送CPU_STARTED信号给boot_aps()，完成一个cpu寄存器的初始化。 前面说过，部分设备的寄存器与内存是直接映射的，这里也是，lapic与内存直接相连，所以在lapic_startup函数中可以看到，向cpu发送命令都是通过在特定内存区域读写。\nvoid page_init(void) { size_t i; size_t allocated_pages = ((uint32_t)boot_alloc(0) - KERNBASE) / PGSIZE; size_t IOhole_pages = (EXTPHYSMEM - IOPHYSMEM) /PGSIZE; for (i = 1; i \u0026lt; npages; i++) { if(i == MPENTRY_PADDR/PGSIZE) continue; // BIOS  else if (i \u0026gt;= npages_basemem \u0026amp;\u0026amp; i \u0026lt; npages_basemem + allocated_pages + IOhole_pages){ continue; // see figure  } else { pages[i].pp_ref = 0; pages[i].pp_link = page_free_list; // a linkedlist for  page_free_list = \u0026amp;pages[i]; // that the pages is free .  } } } 练习就是把MPENTRY_PADDR从free_list中去除即可。\n Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S?\n MPBOOTPHYS是用来计算传递进去参数的绝对地址，这段代码在boot_aps内就被复制到了内存高地址，AP读取gdt的命令ldgdt是在开启保护模式之前，所以，需要使用物理地址来读取全局表，否则不能读取到。但是在boot.S中，代码就是工作在实模式下，可以直接读取。\n Per-cpu State and Initialization (manual 8.4.4) 在实现多处理系统的时候， 弄清每一个CPU所私有的部分和整个系统的共享是很重要的。kern/cpu.h中定义了cpu状态的结构体struct CpuInfo。cpunnum返回当前正在使用的ID，可以用作cpus数组的下标，当然也可以用宏thiscpu表示当前CPU结构体。\n需要关注的CPU状态：\n  内核栈\n 由于CPU能同时陷入内核，所以需要分离每一个CPU所对应的内核栈，阻止处理器对其他处理器在执行任务时相互影响，数组percpu_kstacks[NCPU][KSTKSIZE]存储了多个处理器所对应的内核栈地址。 Lab2中，已经将bootstack映射到KSTACKTOP，在这个实验中，需要映射每一个CPU的内核栈到这个区域，并且使用一个guard pages作为缓冲。CPU0使用KSTACKTOP，CPU1将使用KSTACKTOP - KSTKGAP，等等。inc/memlayout.h中有内存排布情况。    TSS和TSS descriptor 每个CPU的任务状态段TSS(task state segement)也需要被确认，CPU的TSS存储在cpus[i].cpu_ts中，TSS descriptor存储在GDT entry gdt[(GD_TSS0 \u0026gt;\u0026gt; 3) + i]中。\n  当前环境指针 因为每个CPU都同时运行着不同的用户进程，所以使用重新定义的curenv。使用thiscpu-\u0026gt;cpuenv来指向当前正在执行的环境。\n  系统寄存器 所有的寄存器，都是每一个CPU私有的，所都需要通过指令初始化，lcr3(),ltr(),lgdt(),lidt等都需要在每个CPU上执行一次。函数env_init_percpu和trap_init_percpu用来完成这项工作。\n   练习3  完成内核栈的内存映射\n  static void mem_init_mp(void) { size_t i; uint32_t kstacktop_i = KSTACKTOP; for (i = 0; i \u0026lt; NCPU; i++) { /*stack*/ boot_map_region(kern_pgdir, kstacktop_i - KSTKSIZE, KSTKSIZE, PADDR(percpu_kstacks[i]), PTE_W | PTE_P); kstacktop_i -= KSTKSIZE; /*guard gap*/ kstacktop_i -= KSTKGAP; } }  练习4  修改trap_init_percpu()，使得每个CPU都能使用。\n   thiscpu-\u0026gt;cpu_ts.ts_esp0 = (uint32_t)percpu_kstacks[thiscpu-\u0026gt;cpu_id]; thiscpu-\u0026gt;cpu_ts.ts_ss0 = GD_KD; thiscpu-\u0026gt;cpu_ts.ts_iomb = sizeof(struct Taskstate); // Initialize the TSS slot of the gdt. gdt[(GD_TSS0 \u0026gt;\u0026gt; 3) + thiscpu-\u0026gt;cpu_id] = SEG16(STS_T32A, (uint32_t) (\u0026amp;(thiscpu-\u0026gt;cpu_ts)), sizeof(struct Taskstate) - 1, 0); gdt[(GD_TSS0 \u0026gt;\u0026gt; 3) + thiscpu-\u0026gt;cpu_id].sd_s = 0; // Load the TSS selector (like other segment selectors, the // bottom three bits are special; we leave them 0) ltr(GD_TSS0 + (thiscpu-\u0026gt;cpu_id \u0026lt;\u0026lt; 3)); // Load the IDT lidt(\u0026amp;idt_pd); 根据之前ts全局变量的过程，为每一个CPU都初始化任务状态。 位移运算3位是因为每个描述符的大小是8字节(struct Segdesc)\n完成这里后，利用make qemu-nox CPUS=4可以发现其他cpu的成功启动\n$ make qemu-nox CPUS=4 *** *** Use Ctrl-a x to exit qemu *** qemu-system-i386 -nographic -drive file=obj/kern/kernel.img,index=0,media=disk,format=raw -serial mon:stdio -gdb tcp::26000 -D qemu.log -smp 4 6828 decimal is 15254 octal! Physical memory: 131072K available, base = 640K, extended = 130432K check_page_free_list() succeeded! check_page_alloc() succeeded! check_page() succeeded! check_kern_pgdir() succeeded! check_page_free_list() succeeded! check_page_installed_pgdir() succeeded! SMP: CPU 0 found 4 CPU(s) enabled interrupts: 1 2 SMP: CPU 1 starting SMP: CPU 2 starting SMP: CPU 3 starting [00000000] new env 00001000 kernel panic on CPU 0 at kern/trap.c:295: kernel page fault Welcome to the JOS kernel monitor! Type \u0026#39;help\u0026#39; for a list of commands. K\u0026gt; 自旋锁 现在代码在执行mp_main()最后的for死循环，在AP继续运行之前，首先要解决多个CPU同时执行内核代码的条件竞争的问题。最简单的方法是使用big kernel lock，一种当一个环境进入了内核态开启的全局锁，当退回到用户态的时候解锁。在这个模式下，用户态都能同时正确地使用可用的CPU，但是只能有一个环境能运行在用户态，其他尝试进入内核态的环境都会被强制等待。\n自旋锁(spinlock)是互斥(mutual exclusive)锁的一种实现形式，通过不断访问所需资源来判断临界资源资源是否被释放，优点是非常高效，临界资源一释放，等待的CPU将马上获得这份临界资源，所以适合那些保持锁时间短的情况，缺点是会持续占用CPU，浪费CPU时间。面对那些长时间占用临界资源的，应该使用信号量(semaphore)机制。\n前段时间专业课上提到了Swap，就算一个基本的自旋锁。 代码实现如下:\nvoid Swap(boolean \u0026amp;a, boolean \u0026amp;b) { boolean temp = a; a = b; b = temp; } # entry do { Key = true; while (Key == ture) Swap(Lock, Key); critical Section; Lock = false; non critical Section } while(1) JOS自旋锁的实现是在kern/spinlock的spin_lock()中:\nwhile (xchg(\u0026amp;lk-\u0026gt;locked, 1) != 0) asm volatile (\u0026#34;pause\u0026#34;); 在xchg()中，这段代码的意思就是将数值“1”和lk-\u0026gt;locked的值交换。\n asm volatile(\u0026quot;lock; xchgl %0, %1\u0026quot; : \u0026quot;+m\u0026quot; (*addr), \u0026quot;=a\u0026quot; (result) : \u0026quot;1\u0026quot; (newval) : \u0026quot;cc\u0026quot;); return result; lock : 将下个访问内存指令所引用的内存空间上锁\nxchgl %0, %1: \u0026quot;+m\u0026quot; (*addr), \u0026quot;=a\u0026quot; (result): \u0026quot;1\u0026quot; (newval)  *addr替代占位符%0，限定符\u0026quot;+m\u0026quot;代表可read-modify-write的内存变量，限定符\u0026quot;1\u0026quot;代表其后面的操作数去描述占位符%1。所以这句指令是将 *addr的值与 1进行交换，并且把结果输出到 *addr和result中。\ncc ：GNU文档解释，“As the condition codes will be changed, we are adding \u0026ldquo;cc\u0026rdquo; to clobberlist.”\n在while循环体内，pause指令只是减少处理器执行太快引起的电力损耗，类似与一个延时语句。\n 练习5  给合适的地方上锁\n  # i386_init()  // Acquire the big kernel lock before waking up APs  // Your code here:  lock_kernel(); // Starting non-boot CPUs  boot_aps(); # mp_main()  // Now that we have finished some basic setup, call sched_yield()  // to start running processes on this CPU. But make sure that  // only one CPU can enter the scheduler at a time!  //  // Your code here:  lock_kernel(); sched_yield(); # trap()  if ((tf-\u0026gt;tf_cs \u0026amp; 3) == 3) { // Trapped from user mode.  // Acquire the big kernel lock before doing any  // serious kernel work.  // LAB 4: Your code here.  assert(curenv); lock_kernel(); ... } # env_run()  //switch to user\u0026#39;s address space.  lcr3(PADDR(curenv-\u0026gt;env_pgdir)); //following operation will not implement the kernel  //data, releasing the kernel resources here.  unlock_kernel(); // pop trap frame , the environment return to the user mode.  env_pop_tf(\u0026amp;(curenv-\u0026gt;env_tf)); 完成这部分上锁的时候，可以看见在启动AP之前，内核是被BSP给锁定的，其他的CPU都还卡在自旋锁处进行循环。\n Q2:It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock.\n 当一个CPU陷入内核还在进行保存状态信息的时候，另一个CPU刚好发生中断，此时内核还未被上锁，在只有一个栈的情况下，会发生混乱。\nChallenge // fine-grained locking\n 练习6  实现Round-Robin Scheduling调度算法\n  这个调度算法就是在envs全局变量中找到第一个可以运行的程序，观察user/yield.c的程序，代码每一次循环产生一次系统调用，让CPU执行下一个env。 实现这个调度算法就是利用循环队列来做。\nvoid sched_yield(void) { // LAB 4: Your code here.  int i, cur_id, nxt; if (curenv) cur_id = ENVX(curenv-\u0026gt;env_id); else cur_id = 0; #ifdef SELF_DEBUG_INFO  cprintf(\u0026#34;cpuid %d \\n\u0026#34;, thiscpu-\u0026gt;cpu_id); #endif  for (i = 0; i \u0026lt; NENV; i++) { nxt = (i + cur_id) % NENV; if (envs[nxt].env_status == ENV_RUNNABLE) env_run(envs + nxt); } // there are no others environment to run.  if (curenv \u0026amp;\u0026amp; curenv-\u0026gt;env_status == ENV_RUNNING) env_run(curenv); // sched_halt never returns  sched_halt(); } 添加新的系统调用和创建多个这样的用户环境\n# syscall_dispatch()  case SYS_yield: sys_yield(); return 0; # i386_init() #if defined(TEST)  // Don\u0026#39;t touch -- used by grading script!  ENV_CREATE(TEST, ENV_TYPE_USER); #else  // Touch all you want.  ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); #endif // TEST*  Q3:In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context\u0026ndash;the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch?\n e在创建的时候会从kern_pgdir处复制一份，所以lcr3指令执行前后页表项是一样的。\n Q4:Whenever the kernel switches from one environment to another, it must ensure the old environment\u0026rsquo;s registers are saved so they can be restored properly later. Why? Where does this happen?\n env_run()通过poptask frame，而在调用trap()的时候就已经保存了相关寄存器信息。\nChallenge // stride scheduling 和 lottery scheduling\nSystem Calls for Environment Creation 虽然代码能在不同的用户环境中切换了，但是是依靠的内核初始化创建的环境。现在要做的就是实现在用户环境下创建和开始另一个新的用户环境。\nUnix中提供了最原始的fork()函数进行创建ixnd进程，fork复制整个父进程的内存空间去新建一个进程，唯一不同的就是它们的返回值，子进程返回0.\n在这个练习中，将为JOS实现更为原始的方法去创建新用户空间。\n 练习7  完成syscall.c\n  sys_exofork static envid_t sys_exofork(void) { // LAB 4: Your code here.  int r; struct Env *new_env; if ((r = env_alloc(\u0026amp;new_env, sys_getenvid())) \u0026lt; 0) return r; new_env-\u0026gt;env_tf = curenv-\u0026gt;env_tf; new_env-\u0026gt;env_status = ENV_NOT_RUNNABLE; // child env return 0  new_env-\u0026gt;env_tf.tf_regs.reg_eax = 0; return new_env-\u0026gt;env_id; sys_env_set_status static int sys_env_set_status(envid_t envid, int status) { // LAB 4: Your code here.  //panic(\u0026#34;sys_env_set_status not implemented\u0026#34;);  struct Env *e; int ret; /* must be ENV_RUNNABLE or ENV_NOT_RUNNABLE*/ if (status == ENV_RUNNABLE || status == ENV_NOT_RUNNABLE) ; else return -E_INVAL; /* check whether the caller env is env to be set*/ if ((ret = envid2env(envid, \u0026amp;e, 1)) \u0026lt; 0) return ret; e-\u0026gt;env_status = status; return 0; } sys_page_alloc static int sys_page_alloc(envid_t envid, void *va, int perm) { // LAB 4: Your code here.  //panic(\u0026#34;sys_page_alloc not implemented\u0026#34;);  int ret; struct PageInfo *pg; struct Env *e; /* * regist the page in the page directory */ /*check envid*/ if (envid2env(envid, \u0026amp;e, 1) \u0026lt; 0) return -E_BAD_ENV; /*check va*/ if ((uint32_t)va \u0026gt;= UTOP || (uint32_t)va % PGSIZE) return -E_INVAL; /* permission check */ if (perm \u0026amp; ~(PTE_U | PTE_P | PTE_AVAIL | PTE_W)) return -E_INVAL; /*allocating page and mapping*/ pg = page_alloc(ALLOC_ZERO); if (!pg) return -E_NO_MEM; if ((ret = page_insert(e-\u0026gt;env_pgdir, pg, va, perm ))) { page_free(pg); // failed, free page;  return ret; } return 0; } sys_page_map static int sys_page_map(envid_t srcenvid, void *srcva, envid_t dstenvid, void *dstva, int perm) { // LAB 4: Your code here.  //panic(\u0026#34;sys_page_map not implemented\u0026#34;);  /* * mapping */ pte_t *pte; // page table entry;  struct Env *src, *dst; struct PageInfo *pp; /*check env*/ if (envid2env(srcenvid, \u0026amp;src, 1) \u0026lt; 0 || envid2env(dstenvid, \u0026amp;dst, 1) \u0026lt; 0) return -E_BAD_ENV; /* check va */ if ((uint32_t)srcva \u0026gt;= UTOP || (uint32_t)srcva % PGSIZE || (uint32_t)dstva \u0026gt;= UTOP || (uint32_t)dstva % PGSIZE) return -E_INVAL; /* check address space*/ if ((pp = page_lookup(src-\u0026gt;env_pgdir, srcva, \u0026amp;pte)) == NULL) return -E_INVAL; /* check parameter permission */ if (perm \u0026amp; ~(PTE_P | PTE_U | PTE_AVAIL | PTE_W)) return -E_INVAL; /* pte permission check*/ if (!(*pte \u0026amp; PTE_W) \u0026amp;\u0026amp; (perm \u0026amp; PTE_W)) return -E_INVAL; return page_insert(dst-\u0026gt;env_pgdir, pp, dstva, perm ); } sys_page_unmap static int sys_page_unmap(envid_t envid, void *va) { struct Env *e; /*check env*/ if (envid2env(envid, \u0026amp;e, 1)) return -E_BAD_ENV; if ((uint32_t)va \u0026gt;= UTOP || (uint32_t)va % PGSIZE) return -E_INVAL; page_remove(e-\u0026gt;env_pgdir, va); return 0; // LAB 4: Your code here.  //panic(\u0026#34;sys_page_unmap not implemented\u0026#34;); } int32_t syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5) { #define SELF_DEBUG_INFO #ifdef SELF_DEBUG_INFO  cprintf(\u0026#34;call number:%d \\n\u0026#34;, syscallno); #endif  switch (syscallno) { case SYS_cputs: sys_cputs((char *)a1, a2); return 0; case SYS_cgetc: return sys_cgetc(); case SYS_getenvid: return sys_getenvid(); case SYS_env_destroy: return sys_env_destroy(a1); case SYS_yield: sys_yield(); return 0; case SYS_exofork: return sys_exofork(); case SYS_page_alloc: return sys_page_alloc(a1, (void *)a2, a3); case SYS_page_map: return sys_page_map(a1, (void *)a2, a3, (void *)a4, a5); case SYS_page_unmap: return sys_page_unmap(a1, (void *)a2); case SYS_env_set_status: return sys_env_set_status(a1 ,a2); default: return -E_INVAL; } } 两点问题:\n 注意在设置status的时候的逻辑短路问题。 exofork()中新的用户环境的eax应该置为0，以证明是子进程。  用户环境的代码执行完后，一个CPU会执行kernel monitor一直占用内核，而另外3个CPU都在卡在了trap中的那个自旋锁中。\nPART A done.\n Part B: Copy-On-Write Fork 最初Unix提供最基础的fork()系统调用去创建新的进程，forK()通过复制整个父进程的内存空间到子进程的内存中去，然而复制父进程到子进程是fork()操作开销最大的一个操作。通常情况下，fork()后子进程一般会马上调用exec()函数，用新的程序去替代子进程的内存空间。在这种情况下，复制父进程内存空间的时间开销很大程度上是不需要的，因为子进程仅有非常小的一部分被exec()所使用。\n在之后的版本中，Unix采用虚拟内存硬件这一机制，允许父子进程共享分别被映射到它们各自内存空间的内存，直到其中一个进程确实修改了这部分共享的内存，被称之为__copy on write__。为了这个机制，fork()不是复制被实际映射的页，而是复制描述内存空间的映射情况的页，同时标记这个页为只读。一旦这两个进程之一尝试去修改这部分被共享的页，该进程将会产生页错误。此时，Unix内核意识到这个页是一个\u0026quot;copy-on-write\u0026quot;的页需要被拷贝，于是分配一个新的私有的可写的页拷贝给这个产生页错误的进程。通过这种方式，这些分开的页的内容实际不会复制除非这些页确实别尝试写入。这个优化使得fork()后在子进程中执行exec()的开销更小，子进程可能只需要复制一个页(stack page)在调用exec()前。\nUser-level page fault handling 首先实现写时拷贝的fork()，需要知道被写保护的页。copy-on-write是多种可能处理页错误的方法之一。\n一种通用做法就是建立起一个内存空间指出当发生页错误的时候确定一些操作。比如，大多数Unix内核只为新进程的栈区映射一个单页面，分配和映射额外的栈页仅在该新进程栈增长和在栈地址中发生了未映射的栈区域时处理。通常unix内核需要确定对应处理方法当页错误发生在进程的不同区域。页错误发生在栈区通常分配和映射一个新的页帧给这个进程；页错误发生在程序的BSS区域通常分配一个新的页，并且将页内容全部置为0，并且映射到页表中去；页错误发生在可执行文件的.text区域将会从磁盘中读取相应的二进制文件，并且映射。\n这种处理办法虽然需要内核追踪一大堆信息，但是大大增加了程序的灵活性。\nNormal and Exception Stacks in User Environments 正常执行过程中，用户环境将会运行在正常用户栈中：即ESP寄存器最开始就指向了USTACKTOP，栈区数据被压入到USTACKTOP-PGSIZE和USTACKTOP-1这个范围中。当页错误发生在用户态下，内核将会重启这个用户环境，并且运行在一个被设计好的用户级别页错误解决办法(page fault handler)在一个不同的栈上，被称之为用户异常栈。大体上来说，JOS实现了在用户模式下的栈自动切换，同时，x86处理器已经实现了栈切换当发生从用户态到内核态发生转换的时候。\nJOS的异常栈也是只有PGSIZE，但是定义在了虚拟内存地址的UXSTACKTOP，所以在栈区UXSTACKTOP到UXSTACKTOP-1都是合法的。当运行在异常栈，用户级页错误handler能用普通的系统调用去映射新的页，调节映射情况并且修复这个导致页错误的问题。然后，这个handler将会return，通过汇编语言stub返回到发生页错误的代码处。\n任何一个用户程序需要支持用户级页错误将会需要去分配页给异常栈。\nInvoking the User Page Fault Handler 为了解决来自用户态的页错误，现在需要调用用户态在发送页错误时的trap-time状态。 如果没有页错误的handler被登记，JOS内核将会销毁这个用户进程，不然的话，内核将要设置下面这样的trap frame在该用户环境的异常栈上。\n\u0026lt;-- UXSTACKTOP trap-time esp trap-time eflags trap-time eip trap-time eax start of struct PushRegs trap-time ecx trap-time edx trap-time ebx trap-time esp trap-time ebp trap-time esi trap-time edi end of struct PushRegs tf_err (error code) fault_va \u0026lt;-- %esp when handler is run (_pgfault_handler argument) (eip pushed by call instruction) reserved 4-bytes \u0026lt;-- to ret, reserved for eip trap-time esp \u0026lt;-- we should adjust the esp(esp = esp-4) trap-time eflags trap-time eip ... new trap-time frame trap-time esi trap-time edi tf_err (error code) fault_va \u0026lt;-- esp 系统内核需要准备用户在异常栈上面执行page fault handler的准备，fault_va是导致页错误的虚拟地址。\n如果用户环境在执行异常处理的时候发生页错误，那么将要将trap-time frame压栈在tf-\u0026gt;tf_esp之下，而不是UXSTACKTOP。在这里，需要压入1个空的32-bit字，然后压入trap-time帧。\n为了确定tf-\u0026gt;tf_esp是否已经在用户异常栈了，只需要检查它是否在范围UXSTACKTOP-PGSIZE和UXSTACKTOP-1这个范围内即可。\n 练习9  实现page_fault_handler中的代码\n  程序的执行流梳理下：\n 首先用户程序使用sys_set_env_pgfault_handler()系统调用设置好页错误处理方法。 当用户程序发生页错误的时候，此时trap进入内核，通过trapdispatch()的分发错误机制，单独处理页错误。 因为是在用户环境下发生的页错误，内核将该用户环境的运行栈改成异常栈，  void page_fault_handler(struct Trapframe *tf) { ... // LAB 4: Your code here.  struct UTrapframe *utf; uint32_t uesp; cprintf(\u0026#34;user page fault\\n\u0026#34;); if (tf-\u0026gt;tf_esp \u0026lt;= UXSTACKTOP-1 \u0026amp;\u0026amp; tf-\u0026gt;tf_esp \u0026gt;= UXSTACKTOP-PGSIZE) uesp = tf-\u0026gt;tf_esp - sizeof(struct UTrapframe) - 4; else uesp = UXSTACKTOP - sizeof(struct UTrapframe); /* call upcall if current env has handler*/ if (curenv-\u0026gt;env_pgfault_upcall != NULL) { user_mem_assert(curenv, (void *)uesp, sizeof(struct UTrapframe), PTE_U|PTE_P|PTE_W); /*locates to the exception stack*/ utf = (struct UTrapframe *)uesp; /*construct User trap frame*/ utf-\u0026gt;utf_fault_va = fault_va; utf-\u0026gt;utf_err = tf-\u0026gt;tf_err; utf-\u0026gt;utf_regs = tf-\u0026gt;tf_regs; utf-\u0026gt;utf_eflags = tf-\u0026gt;tf_eflags; utf-\u0026gt;utf_eip = tf-\u0026gt;tf_eip; utf-\u0026gt;utf_esp = tf-\u0026gt;tf_esp; /*ready for handler paremeter*/ tf-\u0026gt;tf_esp = uesp; /*after trap , execute the handler routine*/ tf-\u0026gt;tf_eip = (uint32_t)curenv-\u0026gt;env_pgfault_upcall; env_run(curenv); } ... } 练习10  当发生页错误的时候，内核通过设置eip指向_pgfault_upcall来调用汇编代码，并且调用已经注册好的handler，该练习的任务就是当handler执行完后，用户如何返回到错误时的状态去。\n  .globl _pgfault_upcall _pgfault_upcall: // Call the C page fault handler. pushl %esp // function argument: pointer to UTF movl _pgfault_handler, %eax call *%eax addl $4, %esp // LAB 4: Your code here. subl $0x4, 0x30(%esp) # for push eip  movl 0x30(%esp), %ebx #regular esp  movl 0x28(%esp), %eax #eip  movl %eax, (%ebx) // Restore the trap-time registers. After you do this, you // can no longer modify any general-purpose registers. // LAB 4: Your code here. addl $0x8, %esp popal #regular registers  // Restore eflags from the stack. After you do this, you can // no longer use arithmetic operations or anything else that // modifies eflags. // LAB 4: Your code here. addl $0x4, %esp popfl // Switch back to the adjusted trap-time stack. // LAB 4: Your code here. popl %esp // Return to re-execute the instruction that faulted. // LAB 4: Your code here. ret 练习11  完成set_pgfault_handler()\n  void set_pgfault_handler(void (*handler)(struct UTrapframe *utf)) { int r; if (_pgfault_handler == 0) { // First time through!  // LAB 4: Your code here.  //panic(\u0026#34;set_pgfault_handler not implemented\u0026#34;);  if (sys_page_alloc(0, (void *)UXSTACKTOP-PGSIZE, PTE_W|PTE_U|PTE_P) \u0026lt; 0) panic(\u0026#34;memory allocation failed: On UXSTACKTOP\u0026#34;); } // Save handler pointer for assembly to call.  _pgfault_handler = handler; if (sys_env_set_pgfault_upcall(0, _pgfault_upcall) \u0026lt; 0) panic(\u0026#34;bad env\u0026#34;); } 通过一个callback function登记需要运行的handler，实现对不同情况的异常分发。\n#Implementing Copy-on-Write Fork 与之前练习中的dumbfork()不同的是，dumbfork()复制了整个父环境中的所有的页，但是fork()仅仅只会复制一个关于页映射的页，其他的页会在用户环境往这些被标记的页写入内容的时候，发生页错误，并且分配新页，复制页内容。\nfork()的控制流如下：\n 父环境安装pgfault()作为page fault handler，利用set_pgfault_handler()可以做到。 父环境调用sys_exofork()来创建子环境。 将每一个地址低于UTOP的状态为可写或者copy-on-write的页，使用duppage函数，映射到子环境的内存空间去，并且把自己的和子内存空间的页状态都标记COW状态。   异常栈不需要被映射，取而代之的是，父环境需要为子环境异常栈分配一个新的页。  为子环境设置页错误入口 将子环境标记为可运行状态。  每当父环境或者子环境尝试写入状态为cow的页时，将会引发页错误，页错误处理程序的控制流如下：\n 内核传递也错给_pgfault_，然后调用pgfault()来处理 pgfault()检查页错误的错误代码(FEC_WR)，并且页是否被标记为PTE_COW，如果不是，panic。 pgfault()分配一个新的页映射到一个临时位置，然后复制发生错误的页到临时页位置，然后再将这个临时位置映射到一个合适的位置，并且标记为可读可写，代替之前只读的映射。  练习12  实现fork,duppage,pgfault\n  fork() envid_t fork(void) { // LAB 4: Your code here.  //panic(\u0026#34;fork not implemented\u0026#34;);  set_pgfault_handler(pgfault); int r; envid_t envid; int32_t va; envid = sys_exofork(); if (envid \u0026lt; 0) panic(\u0026#34;sys_exofork error\u0026#34;); if (envid == 0) { // panic(\u0026#34;child\u0026#34;);  thisenv = \u0026amp;envs[ENVX(sys_getenvid())]; cprintf(\u0026#34;child: %d\\n\u0026#34;, thisenv-\u0026gt;env_id); return 0; } cprintf(\u0026#34;parent fork:%d -\u0026gt; %d\\n\u0026#34;, thisenv-\u0026gt;env_id, envid); for (va = 0; va \u0026lt; USTACKTOP; va += PGSIZE) if ((uvpd[PDX(va)] \u0026amp; PTE_P) \u0026amp;\u0026amp; (uvpt[PGNUM(va)] \u0026amp; (PTE_P|PTE_U)) ) duppage(envid, (uint32_t)PGNUM(va)); //panic(\u0026#34;1\u0026#34;);  if ((r = sys_page_alloc(envid, (void *)UXSTACKTOP-PGSIZE, PTE_P|PTE_U|PTE_W)) \u0026lt; 0) return r; extern void _pgfault_upcall(void); sys_env_set_pgfault_upcall(envid, _pgfault_upcall); if ((r = sys_env_set_status(envid, ENV_RUNNABLE)) \u0026lt; 0) return r; return envid; } duppage() static int duppage(envid_t envid, unsigned pn) { int r; uint32_t va; // LAB 4: Your code here.  //panic(\u0026#34;duppage not implemented\u0026#34;);  va = pn*PGSIZE; //cprintf(\u0026#34;%x\\n\u0026#34;, va);  if (uvpt[pn] \u0026amp; PTE_COW || uvpt[pn] \u0026amp; PTE_W) { if ((r = sys_page_map(thisenv-\u0026gt;env_id, (void *)va, envid, (void *)va, PTE_P|PTE_U|PTE_COW)) \u0026lt; 0) panic(\u0026#34;2\u0026#34;); if ((r = sys_page_map(thisenv-\u0026gt;env_id, (void *)va, thisenv-\u0026gt;env_id, (void *)va, PTE_P|PTE_U|PTE_COW)) \u0026lt; 0) panic(\u0026#34;3\u0026#34;); } else if ((r = sys_page_map(thisenv-\u0026gt;env_id, (void *)va, envid, (void *)va, PTE_U|PTE_P)) \u0026lt; 0) panic(\u0026#34;4\u0026#34;); return 0; } pgfault() static void pgfault(struct UTrapframe *utf) { void *addr = (void *) utf-\u0026gt;utf_fault_va; uint32_t err = utf-\u0026gt;utf_err; int r; //cprintf(\u0026#34;%d\\n\u0026#34;, err);  if (!(err \u0026amp; FEC_WR) || !(uvpt[PGNUM(addr)] \u0026amp; PTE_COW)) panic(\u0026#34;user page fault: write to non-copy-on-write page\u0026#34;); // LAB 4: Your code here.  //panic(\u0026#34;pgfault not implemented\u0026#34;);  addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); //cprintf(\u0026#34;thisenv-\u0026gt;envid : %d\\n\u0026#34;, thisenv-\u0026gt;env_id);  if ((r = sys_page_alloc(0, (void *)PFTEMP, PTE_P|PTE_U|PTE_W)) \u0026lt; 0) panic(\u0026#34;handler fault :haven\u0026#39;t memory \u0026#34;); memmove((void *)PFTEMP, addr, PGSIZE); if ((r = sys_page_map(0, (void *)PFTEMP, 0, addr, PTE_P|PTE_U|PTE_W)) \u0026lt; 0) panic(\u0026#34;handler fault: sys_page_map\u0026#34;); if ((r = sys_page_unmap(0, PFTEMP)) \u0026lt; 0) panic(\u0026#34;handler fault: sys_page_unmap\u0026#34;); } 两个问题： 1.在这，fork()是设置好子环境的相关上下文才调度到子环境中去的。\n thisenv-\u0026gt;env在duppage()中使用正常，但是在pgfault()会panic，于是观察系统调用信息：这个fork二叉树的根节点会在设置完子进程的信息后销毁，然后cpu调度新的任务。fork()函数中Hint告诉我注意修改子进程中的thienv的值。\nthisenv = \u0026amp;envs[ENVX(sys_getenvid())];\n  thisenv是一个全局(静态)变量，被放在程序的.data域，父环境已经标记这个页为cow状态，所以这个赋值写操作会引发页错误。然后页错误处理程序来为这个页做一个拷贝到该子环境内存空间中。所以当我使用三个系统调用sys_page_alloc,sys_page_map,sys_page_unmap并且传递thisenv-\u0026gt;env_id的时候，是被标记为cow的页发送读请求，结果读到的是父环境的内存内容。父环境已经被销毁了，所以程序在这儿被panic。 PS:父环境销毁的时候并不会回收实际页帧，每个页帧都要一个引用计数器，引用计数器的值在fork()的情境下，应该为2，所以不会被会受到free_list中去\nPART B done\n Part C: Preemptive Multitasking and Inter-Process communication (IPC) Clock Interrupts and Preemption 运行user/spin测试程序，这个程序fork出一个子进程，子进程一旦接手CPU后只是简单地永久循环。父进程和内核都不能再获得CPU，这对保护操作系统防范恶意代码和bug的影响当然不是个好情况，因为任何用户态的进程都能接管整个系统去执行一个死循环。为了允许内核去抢占一个正在执行的环境，强制地重新获取CPU，必须为JOS提供来自时钟硬件的外部硬件中断。\nInterrput discipline 外部中断又被称作IRQ(Interrupt Request Line)，有16种可能的IRQ，从0-15。picirq.c中的pic_init()映射IRQ 0-15映射到IDT的IRQ_OFFSET~IRQ_OFFSET+15。\ninc/trap.h文件中，IRQ_OFFSET 被定义为十进制的23，用IDT表的32-47对应IRQ的0~15中断。例如，时钟中断是IRQ的0号，IDT[IRQ_OFFSET+0]包含了再内核中的时钟的历程。IRQ_OFFSET，选用IRQ_OFFSET这个值是为了不覆盖处理器异常。\nJOS做了一个相对于xv6来说关键性的简化，外部中断_总是_在内核态的时候总是被关闭的。外部中断被eflags寄存器的IF位所控制。当这个bit位被置1时，外部中断被打开。当然这个flag值能被多种方法修改，但是由于JOS的简化，保存和恢复eflags寄存器只有一种单独的方式进入和离开用户态。\n在外部中断来临之前，必须保证FL_IF的标志位被设置，中断号通过处理器获得。否则，中断会被屏蔽，或者会被忽略直到中断位被重新开启。在bootloader的时候，就已经屏蔽了中断，并且到现在都没有重新开启它们。\n 练习13  修改kern/trapentry.S和kern/trap.c，在IDT中去初始化合适的入口，并且为IRQ提供合适的handler。 然后修改env_alloc()保证用户环境总是开启了中断响应。 去掉sti(set interrupt-enable flag)指令的注释，使得这个闲置CPU取消屏蔽中断。 处理器对于硬件中断不会push错误代码(通过CPU针脚和lapic的都不会)\n    for example, it is possible to invoke the page-fault handler through the INTR pin (by means of vector 14); however, this is not a true page-fault exception. It is an interrupt.\n  也就是说，之前的异常是通过中断产生的，在这个练习中，需要为每一个env都开启IF标志位，所以需要修改之前的handler，使得用户环境发生中断的时候，将IF清0，屏蔽中断。\ntrap.c //irq  void irq_handler0(); void irq_handler1(); void irq_handler2(); void irq_handler3(); void irq_handler4(); void irq_handler5(); void irq_handler6(); void irq_handler7(); void irq_handler8(); void irq_handler9(); void irq_handler10(); void irq_handler11(); void irq_handler12(); void irq_handler13(); void irq_handler14(); void irq_handler15(); SETGATE(idt[T_DIVIDE], 0, GD_KT, divid_entry, 0); SETGATE(idt[T_DEBUG], 0, GD_KT, debug_entry, 3); SETGATE(idt[T_NMI], 0, GD_KT, nmi_entry, 0); SETGATE(idt[T_BRKPT], 0, GD_KT, brkpt_entry, 3); SETGATE(idt[T_OFLOW], 0, GD_KT, oflow_entry, 0); SETGATE(idt[T_BOUND], 0, GD_KT, bound_entry, 0); SETGATE(idt[T_ILLOP], 0, GD_KT, illop_entry, 0); SETGATE(idt[T_DEVICE], 0, GD_KT, device_entry, 0); SETGATE(idt[T_DBLFLT], 0, GD_KT, dblflt_entry, 0); SETGATE(idt[T_TSS], 0, GD_KT, tss_entry, 0); SETGATE(idt[T_SEGNP], 0, GD_KT, segnp_entry, 0); SETGATE(idt[T_STACK], 0, GD_KT, stack_entry, 0); SETGATE(idt[T_GPFLT], 0, GD_KT, gpflt_entry, 0); SETGATE(idt[T_PGFLT], 0, GD_KT, pgflt_entry, 0); SETGATE(idt[T_FPERR], 0, GD_KT, fperr_entry, 0); SETGATE(idt[T_SYSCALL], 0, GD_KT, syscall_entry, 3); //irq handler mapping  SETGATE(idt[IRQ_OFFSET+0], 0, GD_KT, irq_handler0, 3); SETGATE(idt[IRQ_OFFSET+1], 0, GD_KT, irq_handler1, 3); SETGATE(idt[IRQ_OFFSET+2], 0, GD_KT, irq_handler2, 3); SETGATE(idt[IRQ_OFFSET+3], 0, GD_KT, irq_handler3, 3); SETGATE(idt[IRQ_OFFSET+4], 0, GD_KT, irq_handler4, 3); SETGATE(idt[IRQ_OFFSET+5], 0, GD_KT, irq_handler5, 3); SETGATE(idt[IRQ_OFFSET+6], 0, GD_KT, irq_handler6, 3); SETGATE(idt[IRQ_OFFSET+7], 0, GD_KT, irq_handler7, 3); SETGATE(idt[IRQ_OFFSET+8], 0, GD_KT, irq_handler8, 3); SETGATE(idt[IRQ_OFFSET+9], 0, GD_KT, irq_handler9, 3); SETGATE(idt[IRQ_OFFSET+10], 0, GD_KT, irq_handler10, 3); SETGATE(idt[IRQ_OFFSET+11], 0, GD_KT, irq_handler11, 3); SETGATE(idt[IRQ_OFFSET+12], 0, GD_KT, irq_handler12, 3); SETGATE(idt[IRQ_OFFSET+13], 0, GD_KT, irq_handler13, 3); SETGATE(idt[IRQ_OFFSET+14], 0, GD_KT, irq_handler14, 3); SETGATE(idt[IRQ_OFFSET+15], 0, GD_KT, irq_handler15, 3); trapentry.S TRAPHANDLER_NOEC(irq_handler0, 32); TRAPHANDLER_NOEC(irq_handler1, 33); TRAPHANDLER_NOEC(irq_handler2, 34); TRAPHANDLER_NOEC(irq_handler3, 35); TRAPHANDLER_NOEC(irq_handler4, 36); TRAPHANDLER_NOEC(irq_handler5, 37); TRAPHANDLER_NOEC(irq_handler6, 38); TRAPHANDLER_NOEC(irq_handler7, 39); TRAPHANDLER_NOEC(irq_handler8, 40); TRAPHANDLER_NOEC(irq_handler9, 41); TRAPHANDLER_NOEC(irq_handler10, 42); TRAPHANDLER_NOEC(irq_handler11, 43); TRAPHANDLER_NOEC(irq_handler12, 44); TRAPHANDLER_NOEC(irq_handler13, 45); TRAPHANDLER_NOEC(irq_handler14, 46); TRAPHANDLER_NOEC(irq_handler15, 47); env.c // Enable interrupts while in user mode.  // LAB 4: Your code here.  e-\u0026gt;env_tf.tf_eflags |= FL_IF; 此时为每一个用户进程响应外部中断。\n Handing Clock Interrupts 在user/spin程序中，在子程序一开始运行时就仅仅是一直循环，内核不能取回控制权，所以现在需要生成周期性的时钟中断，强制性地取回内核的控制权，并且切换到不同的用户环境。\n练习14  修改trap_dispatch()，使得当发生时钟中断的时候，调用不同的用户环境。\n  // Handle clock interrupts. Don\u0026#39;t forget to acknowledge the  // interrupt using lapic_eoi() before calling the scheduler!  // LAB 4: Your code here.  if (tf-\u0026gt;tf_trapno == IRQ_OFFSET + 0) { lapic_eoi(); sched_yield(); } eoi(end of interrupt):置为0表示该中断例程已经结束了。\n Inter-Process communication (IPC) 之前都是关注的操作系统的独立性，这种方式使得每个程序看似独占一台机器。另外一个重要的操作系统服务就是允许程序与其他的程序进行交互。Unix中的pipe模型就是一个很典型的例子。\n还有很多模型提供了IPC，关于这些模型哪个最好仍在争议中，取而代之的实现一个简单的IPC机制。\n首先为JOS kernel提供几个的系统调用(sys_ipc_recv和sys_ipc_try_send)提供一个简单的IPC机制，然后实现两个库函数包装系统调用。\n用户环境能发送给其他环境的“消息”由两部分组成：一个32-bit的值和一个可选的单页映射。相比单个32位整形，提供了一种更高效的通过传递页映射信息的方式，允许环境更方便设置共享内存。\nSending and Receiving Messages 为了接收信息，一个用户环境调用sys_ipc_recv。系统调用放弃CPU当前执行的用户环境，并且直到接收到信息之前不会再运行。当一个用户环境正在等待一个消息，任何其他的环境能给它发送消息(不需要特定的用户环境，不需要父子进程等)。换句话说，PART A中的检查对IPC不适用，因为IPC系统调用被设计得很安全：一个用户进程不会因为被接收消息而发生失灵。\n为了尝试发送一个值，用户环境调用sys_ipc_try_send发送接收者的环境id和需要发送的值。如果该id所指的环境确实在接收状态，那么发送方发送消息并且返回0。否则发送方返回-E_IPC_NOT_RECV指出目标环境现在不期望获得一个值。\n用户空间的库函数ipc_recv将会调用sys_ipc_recv并且寻找相关被接收的值。同样地，ipc_send将会重复地调用sys_ipc_try_send直到成功。\nTransferring Pages 当一个用户环境调用sys_ipc_recv使用了一个合法的dstva参数，那么这个环境将会愿意去接受一个页的映射。如果发送方发送了一个页，那么这个页将会被映射到接收方的dstva这个地址空间去。 如果接收方已经映射了页帧在dstva，那么先前的页映射将会被取消。\n当一个用户环境调用sys_ipc_try_send传递小于UTOP的参数srcva，这意味着发送方想将这个页映射到接收方的内存空间，并且设置权限位perm。成功IPC后，发送方保持之前的页映射，但是接收方映射了与发送方相同的页帧到dstva，这使得双方能共享同一个页。如果发送方或者接收方没有指出哪个页需要被发送，那么就没有页被发送。\n练习15  先实现sys_ipc_recv和sys_ipc_try_send,checkperm需要被置0，因为不一定需要父子关系才能引用。 实现ipc_recv和ipc_send，这是对系统调用的一个封装。 用user/pingpong和user/primes测试IPC机制。\n  sys_ipc_recv() static int sys_ipc_recv(void *dstva) { // LAB 4: Your code here.  //panic(\u0026#34;sys_ipc_recv not implemented\u0026#34;);  if ((uint32_t)dstva \u0026lt; UTOP \u0026amp;\u0026amp; (uint32_t)dstva % PGSIZE) return -E_INVAL; //mapping  //set status  curenv-\u0026gt;env_ipc_recving = true; curenv-\u0026gt;env_ipc_dstva = dstva; curenv-\u0026gt;env_status = ENV_NOT_RUNNABLE; sched_yield(); return 0; } sys_ipc_try_send() static int sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm) { // LAB 4: Your code here.  //panic(\u0026#34;sys_ipc_try_send not implemented\u0026#34;);  struct Env *dstenv; struct PageInfo *pp; pte_t *pte; //cprintf(\u0026#34;%x, val: %d\\n\u0026#34;, srcva, value);  if (envid2env(envid, \u0026amp;dstenv, 0) \u0026lt; 0) return -E_BAD_ENV; if (!dstenv-\u0026gt;env_ipc_recving) return -E_IPC_NOT_RECV; if (perm \u0026amp; ~PTE_SYSCALL) return -E_INVAL; // for page mapping checks //  if ((uint32_t)srcva \u0026lt; UTOP) { if ((uint32_t)srcva % PGSIZE) return -E_INVAL; if (!(pp = page_lookup(curenv-\u0026gt;env_pgdir, srcva, \u0026amp;pte))) return -E_INVAL; if (perm \u0026amp; PTE_W \u0026amp;\u0026amp; !(*pte \u0026amp; PTE_W)) return -E_INVAL; if (page_insert(dstenv-\u0026gt;env_pgdir, pp, dstenv-\u0026gt;env_ipc_dstva, perm) \u0026lt; 0) return -E_NO_MEM; } // update target env fields  dstenv-\u0026gt;env_ipc_recving = false; dstenv-\u0026gt;env_ipc_from = curenv-\u0026gt;env_id; dstenv-\u0026gt;env_ipc_value = value; dstenv-\u0026gt;env_ipc_perm = perm; dstenv-\u0026gt;env_status = ENV_RUNNABLE; dstenv-\u0026gt;env_tf.tf_regs.reg_eax = 0; return 0; } ipc_recv() int32_t ipc_recv(envid_t *from_env_store, void *pg, int *perm_store) { // LAB 4: Your code here.  //panic(\u0026#34;ipc_recv not implemented\u0026#34;);  int r; void *va; if (pg != NULL) va = pg; if (pg == NULL) va = (void *)-1; //system call failed  if (sys_ipc_recv(va) \u0026lt; 0) { *from_env_store = 0; *perm_store = 0; } //store infomation for caller  if (from_env_store) *from_env_store = thisenv-\u0026gt;env_ipc_from; if (perm_store) *perm_store = thisenv-\u0026gt;env_ipc_perm; return thisenv-\u0026gt;env_ipc_value; } ipc_send() void ipc_send(envid_t to_env, uint32_t val, void *pg, int perm) { // LAB 4: Your code here.  //panic(\u0026#34;ipc_send not implemented\u0026#34;);  int r; void *va; if (!pg) va = (void *)-1; else va = pg; while (1) { r = sys_ipc_try_send(to_env, val, va, perm); if (r == 0) break; if (r \u0026lt; 0 \u0026amp;\u0026amp; r != -E_IPC_NOT_RECV) panic(\u0026#34;error on send ipc_send, %e\u0026#34;, r); if (r == -E_IPC_NOT_RECV) sys_yield(); } } 梳理一个过程(pingpong程序)： sys_ipc_recv将当前env设置为不可运行状态后调用调度程序，发送方开始执行检查并且配置自己和接收方内存空间的页映射等相关信息，设置完后通过return返回到trap()函数，通过env_run()返回用户态，准备执行ipc_recv接收刚才接收方的消息，执行调度。接收方的用户环境已经设置为可运行状态，从而开始执行env_run，此时这个环境中eax的值还是之前系统调用号12，如果运行env_tf_pop会直接回到调用的地点引发错误。所以，发送方应该将接收方的eax置为0表示接收成功。\nmake grade make[1]: Leaving directory \u0026#39;/home/moonlight/lab\u0026#39; dumbfork: OK (1.4s) Part A score: 5/5 faultread: OK (0.9s) faultwrite: OK (1.0s) faultdie: OK (2.0s) faultregs: OK (2.0s) faultalloc: OK (1.0s) faultallocbad: OK (1.8s) faultnostack: OK (1.1s) faultbadhandler: OK (1.9s) faultevilhandler: OK (2.2s) forktree: OK (2.0s) Part B score: 50/50 spin: OK (1.9s) stresssched: OK (3.4s) sendpage: OK (1.8s) (Old jos.out.sendpage failure log removed) pingpong: OK (2.0s) (Old jos.out.pingpong failure log removed) primes: OK (13.9s) (Old jos.out.primes failure log removed) Part C score: 25/25 Score: 80/80 moonlight@ubuntu:~/lab$  Challenge 1:solute the ipc_send loop\n //todo here , reading IA32\n ipc_send use ipc_find_env firstly to find corrsponding env whose status is runnable call sys_ipc_try_send for the status of target env is running ,I should send an IPC interrupt using lapic_ipi() function in the file lapic.c. makes it runnable call sys_ipc_try_send    thread introduction : http://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-35.pdf\n  kernel design : https://github.com/fATwaer/fatwaer.github.io/tree/master/pdf/os/SRC-RR-35.pdf\n 总结 上面两篇paper非常值得一看，JOS到目前为止都没用到thread这个概念，但是在接下来的学习中是非常重要的，另外一直没有看完的是IA32手册，这份手册提供了很多操作系统的细节，虽然没必要全部读完，但是我觉得至少把个位数的章节读完是很有必要的。\nLab4到这里已经结束了，从5.7到5.19大概花了两周的时间，不同部分的代码依赖很强，一点不小心就会引发非常严重的错误。不过在这个实验中，第一次听说了回归测试这个概念，应该与单元测试功能相同，是为大型程序阶段性检测的一种技巧。JOS替换了进程的叫法，称之为“用户环境”。在实验中可以体会到，一个用户环境的创建包括很多过程，页表，页映射，当前执行的CPU，错误处理机制，正常栈，异常栈等等信息都要提前准备好才把这个进程设置为可运行状态，所准备的一切都是为一个需要执行的任务做下铺垫。\n","date":"May 7, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/","summary":"在这个实验中，将会在多个用户环境同时运行时实现抢占式多任务。\n part A:为JOS添加多处理器的支持，实现round-robin scheduling和增加基础的用户环境管理的系统调用，例如创建和销毁用户环境，分配和映射内存中的内容。 part B: 实现fork()函数，允许用户环境去添加一份自己环境的拷贝。 part C: 添加进程间的通信IPC(inter-process communication)，允许不同的用户环境各自通信和同步；添加硬件时钟中断和抢占任务。\n 准备开始 git\n#git rest --hard FETCH_HEAD git add -u git commit -m \u0026quot;\u0026quot; git pull git checkout -b lab4 origin/lab4 git merge lab3  confilcts in file config/lab.mk\n源文件描述 kern/cpu.h Kernel-private definitions for multiprocessor support kern/mpconfig.c Code to read the multiprocessor configuration kern/lapic.c Kernel code driving the local APIC unit in each processor kern/mpentry.S Assembly-language entry code for non-boot CPUs kern/spinlock.","tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking"},{"categories":["sys"],"contents":" 4月22日 - 5月2日\n PART A 这章的练习将会取实现一些基础的用户模式下的环境，也就是进程。在这章，创建一个用户环境，读取程序镜像并且运行。 这是关于这章节代码文件的介绍\ninc/env.h Public definitions for user-mode environments trap.h Public definitions for trap handling syscall.h Public definitions for system calls from user environments to the kernel lib.h Public definitions for the user-mode support library kern/env.h Kernel-private definitions for user-mode environments env.c Kernel code implementing user-mode environments trap.h Kernel-private trap handling definitions trap.c Trap handling code trapentry.S Assembly-language trap handler entry-points syscall.h Kernel-private definitions for system call handling syscall.c System call implementation code lib/Makefrag Makefile fragment to build user-mode library, obj/lib/ libjos.a entry.S Assembly-language entry-point for user environments libmain.c User-mode library setup code called from entry.S syscall.c User-mode system call stub functions console.c User-mode implementations of putchar and getchar, providing console I/O exit.c User-mode implementation of exit panic.c User-mode implementation of panic user/ * Various test programs to check kernel lab 3 code 内联汇编 简单描述:\n__asm__(汇编语句模板: 输出部分: 输入部分: 破坏描述部分)  具体详情\n文件概述 在文件inc/env.h中定义了Env结构体，用来存储一些关于用户环境(进程)的结构体。\nstruct Env { struct Trapframe env_tf; // Saved registers  struct Env *env_link; // Next free Env  envid_t env_id; // Unique environment identifier  envid_t env_parent_id; // env_id of this env\u0026#39;s parent  enum EnvType env_type; // Indicates special system environments  unsigned env_status; // Status of the environment  uint32_t env_runs; // Number of times environment has run  // Address space  pde_t *env_pgdir; // Kernel virtual address of page dir }; 在这个结构体中，env_status用来指示当前进程的状态，有以下几种定义在一个枚举类型里面。\nenum { ENV_FREE = 0, ENV_DYING, ENV_RUNNABLE, ENV_RUNNING, ENV_NOT_RUNNABLE }; 文件kern/env.c文件中，有三个文件域的定义。\nstruct Env *envs = NULL; // All environments struct Env *curenv = NULL; // The current env static struct Env *env_free_list; // Free environment list  envs指向保存所有Env结构体的内存页，并且指向虚拟内存UTOP。\ncurenv是字面意思，指向当前执行的进程。\nenv_free_list是一个链表表头，类似之前的page_free_list。\n练习1  分配NENV个Env结构体，并且用envs指针指向它们\n  // Make \u0026#39;envs\u0026#39; point to an array of size \u0026#39;NENV\u0026#39; of \u0026#39;struct Env\u0026#39;. envs = (struct Env *)boot_alloc(NENV * sizeof(struct Env)); memset(envs, 0, NENV * sizeof(struct Env)); // Map the \u0026#39;envs\u0026#39; array read-only by the user at linear address UENVS // (ie. perm = PTE_U | PTE_P). boot_map_region(kern_pgdir, UENVS, PTSIZE, PADDR(envs), PTE_U | PTE_P); 练习2  创建并且运行进程\n 完成以下函数:\nenv_init() Initialize all of the Env structures in the envs array and add them to the env_free_list. Also calls env_init_percpu, which configures the segmentation hardware with separate segments for privilege level 0 ( kernel) and privilege level 3 (user). env_setup_vm() Allocate a page directory for a new environment and initialize the kernel portion of the new environment's address space. region_alloc() Allocates and maps physical memory for an environment load_icode() You will need to parse an ELF binary image, much like the boot loader already does, and load its contents into the user address space of a new environment. env_create() Allocate an environment with env_alloc and call load_icode to load an ELF binary into it. env_run() Start a given environment running in user mode. As you write these functions, you might find the new cprintf verb %e useful -- it prints a description corresponding to an error code. For example, r = -E_NO_MEM; panic(\u0026quot;env_alloc: %e\u0026quot;, r); will panic with the message \u0026quot;env_alloc: out of memory\u0026quot;.  env_init() void env_init(void) { // Set up envs array  // LAB 3: Your code here.  int i; for (i = NENV - 1; i \u0026gt;= 0; i--) { // reversal order  envs[i].env_id = 0; envs[i].env_status = ENV_FREE; envs[i].env_link = env_free_list; env_free_list = \u0026amp;envs[i]; } // Per-CPU part of the initialization  env_init_percpu(); } env_setup_vm() static int env_setup_vm(struct Env *e) { int i; struct PageInfo *p = NULL; // Allocate a page for the page directory  if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM; // LAB 3: Your code here.  e-\u0026gt;env_pgdir = (pte_t *)page2kva(p); p-\u0026gt;pp_ref++; /* copy structs to UTOP*/ memcpy(e-\u0026gt;env_pgdir, kern_pgdir, PGSIZE); // UVPT maps the env\u0026#39;s own page table read-only.  // Permissions: kernel R, user R  e-\u0026gt;env_pgdir[PDX(UVPT)] = PADDR(e-\u0026gt;env_pgdir) | PTE_P | PTE_U; return 0; } region_alloc() static void region_alloc(struct Env *e, void *va, size_t len) { // LAB 3: Your code here.  // (But only if you need it for load_icode.)  //  // Hint: It is easier to use region_alloc if the caller can pass  // \u0026#39;va\u0026#39; and \u0026#39;len\u0026#39; values that are not page-aligned.  // You should round va down, and round (va + len) up.  // (Watch out for corner-cases!)  uintptr_t va_beg = ROUNDDOWN((uint32_t)va, PGSIZE); uintptr_t va_end = ROUNDUP((uint32_t)(va+len), PGSIZE); uintptr_t i; for (i = va_beg; i \u0026lt; va_end; i += PGSIZE) { /* maps each page to pa */ struct PageInfo *p; if (!(p = page_alloc(ALLOC_ZERO))) panic(\u0026#34;lack of free pages\u0026#34;); if ((page_insert(e-\u0026gt;env_pgdir, p, (void *)i, PTE_P | PTE_U | PTE_W)) == -E_NO_MEM) panic(\u0026#34;lack memmory\u0026#34;); } } load_icode() static void load_icode(struct Env *e, uint8_t *binary) { // LAB 3: Your code here.  /* user mode */ lcr3(PADDR(e-\u0026gt;env_pgdir)); struct Elf *elf = (struct Elf *)binary; /* check file format */ if (elf-\u0026gt;e_magic != ELF_MAGIC) panic(\u0026#34;load_icode() : format error \u0026#34;); if (elf-\u0026gt;e_entry == 0) panic(\u0026#34;load_icode() : ELF file loads failed\u0026#34;); e-\u0026gt;env_tf.tf_eip = elf-\u0026gt;e_entry; struct Proghdr *ph, *eph; ph = (struct Proghdr *)(binary + elf-\u0026gt;e_phoff); eph = ph + elf-\u0026gt;e_phnum; for (; ph \u0026lt; eph; ph++) { if (ph-\u0026gt;p_type == ELF_PROG_LOAD) { region_alloc(e, (void *)(ph-\u0026gt;p_va), ph-\u0026gt;p_memsz); memcpy((void *)ph-\u0026gt;p_va, (void *)binary + ph-\u0026gt;p_offset, (size_t)(ph-\u0026gt;p_filesz)); } } lcr3(PADDR(kern_pgdir)); // Now map one page for the program\u0026#39;s initial stack  // at virtual address USTACKTOP - PGSIZE.  // LAB 3: Your code here.  region_alloc(e, (void *)USTACKTOP-PGSIZE, PGSIZE); } env_create() void env_create(uint8_t *binary, enum EnvType type) { // LAB 3: Your code here.  struct Env * env; if (env_alloc(\u0026amp;env, 0) \u0026lt; 0) panic(\u0026#34;env_alloc error !\u0026#34;); load_icode(env, binary); env-\u0026gt;env_type = type; } env_run() void env_run(struct Env *e) { if (curenv != NULL \u0026amp;\u0026amp; curenv-\u0026gt;env_status == ENV_RUNNING) curenv-\u0026gt;env_status = ENV_RUNNABLE; curenv = e; curenv-\u0026gt;env_status = ENV_RUNNING; curenv-\u0026gt;env_runs++; lcr3(PADDR(curenv-\u0026gt;env_pgdir)); env_pop_tf(\u0026amp;(curenv-\u0026gt;env_tf)); // Hint: This function loads the new environment\u0026#39;s state from  // e-\u0026gt;env_tf. Go back through the code you wrote above  // and make sure you have set the relevant parts of  // e-\u0026gt;env_tf to sensible values.  // LAB 3: Your code here.  //panic(\u0026#34;env_run not yet implemented\u0026#34;); } 代码完成后应该还是会无限重启，因为，在执行完env_pop_tf的时候会去调用用户自己写的代码，但是会要用到从用户态到内核态的跳转，这部分代码并没有完成。\nstart (kern/entry.S) i386_init (kern/init.c) cons_init mem_init env_init trap_init (still incomplete at this point) env_create env_run env_pop_tf 在qemu上运行这个内核，如果调用了成功执行到env_pop_tf的话，基本成功了。此时，内核会去执行一个hello的二进制文件，但是会用到系统调用和使用int中断指令。但是此时的JOS并没有完成用户空间到内核空间的跳转。CPU发现没有办法解决这个的办法，于是生成一个__二重错误异常__，然后继续发现还是没有办法去处理这个错误机制，于是引发__三重错误异常__，这时候，CPU就会要重置，使得整个系统重新启动。这就是现在看到的无限重启的行为。\n用make-qemu和make gdb编译出内核，用break env_pop_tf在函数env_pop_tf处设置断点，单步执行，看能否能进入hello.asm中，地址在用户内存空间(0x08000000+)。然后在obj/user/hello.asm中找到sys_cputs中的int $0x30指令。如果成功执行到了这儿，说明之前的代码没有问题。\n练习3 阅读Chapter 9, Exceptions and Interrupts\n 中断是外部发给CPU的信号，而异常是CPU在自己处理命令时候出现的错误。 其中中断分为可屏蔽和不可屏蔽的。\n异常也有三种(Faults/Traps/Aborts)，Faults异常是在执行这条指令之前就被指出的错误，但是如果在执行的过程中遇到了faults级的错误，CPU将会让机器保存状态，并且允许被修正重新执行。\n第二种是Traps异常，是一种执行完后立即报告的异常，允许程序连续性执行，异常处理的返回地址就是trap指令后的那条。\n第三种是Aborts异常，这种异常不报告异常发生的精确位置，也不运行程序继续往下执行。往往是发生了严重的错误，例如硬件错误和不合法的数值。\nTable 9-1. Interrupt and Exception ID Assignments Identifier Description 0 Divide error 1 Debug exceptions 2 Nonmaskable interrupt 3 Breakpoint (one-byte INT 3 instruction) 4 Overflow (INTO instruction) 5 Bounds check (BOUND instruction) 6 Invalid opcode 7 Coprocessor not available 8 Double fault 9 (reserved) 10 Invalid TSS 11 Segment not present 12 Stack exception 13 General protection 14 Page fault 15 (reserved) 16 Coprecessor error 17-31 (reserved) 32-255 Available for external interrupts via INTR pin  IF(interrput-enable flag)是控制屏蔽外中断的标志位。当IF=0，中断会被屏蔽，IF=1，中断才会被接收。 CLI (Clear Interrupt-Enable Flag) and STI (Set Interrupt-Enable Flag) explicitly alter IF (bit 9 in the flag register).\nIF标志位被以下三种情况隐性影响：\n PUSHF存储所有flag，包括IF。在栈中的IF，可以被修改。 任务切换时，POP和IRET读取flag寄存器，因此，这步操作能修改IF 中断通过interrupt gates(?)能自动重置IF，也就关闭外中断。   设置段地址的时候也会发生中断，影响程式的执行。通常设置栈区的段的时候通常使用以下这一对指令。\nMOV SS, AX MOV ESP, StackTop 如果这时候发生中断或者异常，SS已经被设置成了AX，而ESP的值还没被传达到，栈指针，SS:ESP在处理中断和异常的时候是不正常的，所以80386CPU在处理这两条指令的时候会屏蔽NMI, INTR, debug exceptions, and single-step traps这些中断。\n练习4  编辑trapentry.S和trap.c安装中断向量，宏TRAPHADNLER和TRAPHANDLER_NOEC可以帮助安装向量，中断向量被定义在inc/trap.h中。然后提供一共_alltraps去准备堆栈。在函数trap_init()中初始化idt中断向量数组，并且使用SETGATE去指向相关的函数。\n  为不同的中断生成入口，两个宏的差别在于是否有error code。，如果有的话，硬件会自动将错误信息压栈。如果没有的话，宏TRAPHANDLER_NOEC会压入一个0值。\nTRAPHANDLER_NOEC(divid_entry, T_DIVIDE); TRAPHANDLER_NOEC(debug_entry, T_DEBUG); TRAPHANDLER_NOEC(nmi_entry, T_NMI); TRAPHANDLER_NOEC(brkpt_entry, T_BRKPT); TRAPHANDLER_NOEC(oflow_entry, T_OFLOW); TRAPHANDLER_NOEC(bound_entry, T_BOUND); TRAPHANDLER_NOEC(illop_entry, T_ILLOP); TRAPHANDLER_NOEC(device_entry, T_DEVICE); TRAPHANDLER(dblflt_entry, T_DBLFLT); TRAPHANDLER(tss_entry, T_TSS); TRAPHANDLER(segnp_entry, T_SEGNP); TRAPHANDLER(stack_entry, T_STACK); TRAPHANDLER(gpflt_entry, T_GPFLT); TRAPHANDLER(pgflt_entry, T_PGFLT); TRAPHANDLER_NOEC(fperr_entry, T_FPERR); TRAPHANDLER_NOEC(syscall_entry, T_SYSCALL); _alltraps将所有的寄存器状态保存，压栈。\n_alltraps: pushl %ds pushl %es pushal mov $GD_KD, %ax mov %ax, %es mov %ax, %ds push %esp call trap 根据练习提示，将段寄存器es和ds设置为GDT的kernel数据段，然后将esp压栈，调用trap。\n这里直接调用trap就行，调用函数的参数已经在堆栈中，跳转到函数开始的地方就是一个普通的函数调用。\n回顾之前的Lab2，在env_run()之前，会执行trap_init()，目的就是为了安装中断向量表。 trap.c/trap_init()中，将idt数组已知中断全部设置好，并将处理这个中断或者异常的handler安装到GDT中的.text域中，并且设置好权限。\nvoid trap_init(void) { extern struct Segdesc gdt[]; // LAB 3: Your code here.  void divid_entry(); void debug_entry(); void nmi_entry(); void brkpt_entry(); void oflow_entry(); void bound_entry(); void illop_entry(); void device_entry(); void dblflt_entry(); void tss_entry(); void segnp_entry(); void stack_entry(); void gpflt_entry(); void pgflt_entry(); void fperr_entry(); void syscall_entry(); SETGATE(idt[T_DIVIDE], 1, GD_KT, divid_entry, 0); SETGATE(idt[T_DEBUG], 1, GD_KT, debug_entry, 3); SETGATE(idt[T_NMI], 1, GD_KT, nmi_entry, 0); SETGATE(idt[T_BRKPT], 1, GD_KT, brkpt_entry, 3); SETGATE(idt[T_OFLOW], 1, GD_KT, oflow_entry, 0); SETGATE(idt[T_BOUND], 1, GD_KT, bound_entry, 0); SETGATE(idt[T_ILLOP], 1, GD_KT, illop_entry, 0); SETGATE(idt[T_DEVICE], 1, GD_KT, device_entry, 0); SETGATE(idt[T_DBLFLT], 1, GD_KT, dblflt_entry, 0); SETGATE(idt[T_TSS], 1, GD_KT, tss_entry, 0); SETGATE(idt[T_SEGNP], 1, GD_KT, segnp_entry, 0); SETGATE(idt[T_STACK], 1, GD_KT, stack_entry, 0); SETGATE(idt[T_GPFLT], 1, GD_KT, gpflt_entry, 0); SETGATE(idt[T_PGFLT], 1, GD_KT, pgflt_entry, 0); SETGATE(idt[T_FPERR], 1, GD_KT, fperr_entry, 0); SETGATE(idt[T_SYSCALL], 1, GD_KT, syscall_entry, 3); // Per-CPU setup  trap_init_percpu(); }  Q1:What is the purpose of having an individual handler function for each exception/interrupt? (i.e., if all exceptions/interrupts were delivered to the same handler, what feature that exists in the current implementation could not be provided?)\n 不同的权限组应该要有不同的解决办法。\n Q2:Did you have to do anything to make the user/softint program behave correctly? The grade script expects it to produce a general protection fault (trap 13), but softint\u0026rsquo;s code says int 14. Why should this produce interrupt vector 13? What happens if the kernel actually allows softint\u0026rsquo;s int 14 instruction to invoke the kernel\u0026rsquo;s page fault handler (which is interrupt vector 14)?\n user/softint用户程序中就只有一句:\nasm volatile (\u0026quot;int $14\u0026quot;);  用来产生page fault，但是这是用户程序产生的。一般产生页错误，查看page fault的处理办法page_fault_handler()中env_destroy(curenv);会将这个用户环境销毁。一般用户应该没有这样的权限。\n所以对于权限不够的用户，应该产生General protection fault 。\nThis concludes part A of the lab.\n PART B 这一部分解决__Page Faults, Breakpoints Exceptions, System Calls__\n_alltraps会调用traps traps可以分为四个部分\n 关闭中断  asm volatile(\u0026#34;cld\u0026#34; ::: \u0026#34;cc\u0026#34;); assert(!(read_eflags() \u0026amp; FL_IF)); 如果是用户模式，复制一份用户栈。   if ((tf-\u0026gt;tf_cs \u0026amp; 3) == 3) { assert(curenv); curenv-\u0026gt;env_tf = *tf; tf = \u0026amp;curenv-\u0026gt;env_tf; } last_tf = tf; 处理中断   trap_dispatch(tf); 如果这个用户环境未被销毁，那么继续执行。   assert(curenv \u0026amp;\u0026amp; curenv-\u0026gt;env_status == ENV_RUNNING); env_run(curenv);  练习5 , 6  让14号中断调用page_fault_handler()函数\n  breakpoint异常，3号中断通常是用来给调试器使用，它允许程序代码临时性地代替程序指令。在JOS中使用monitor()来执行处理异常。\n  page_fault_handler函数中通过fault_va = rcr2()获取页出错的虚拟地址。\n这两个练习都是在trap_dispatch中修改，代码如下。\n// Handle page fault exceptions.  if (tf-\u0026gt;tf_trapno == T_PGFLT) { page_fault_handler(tf); return ; } // after int 3 interrupt , this function  // uses panic() to output debugger infomations.  if (tf-\u0026gt;tf_trapno == T_BRKPT) { monitor(tf); return ; } Challenge //想做做不出来\u0026hellip;留个思路\n monitor中执行函数 激活tf栈中的eflags中TF位，开启单步调试 然后使用IRET返回中断，弹栈。 optional   Q1:The break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault?\n interrupt gate中DPL影响这两种情况，当调用的时候，eflags中的CPL的值大于DPL的时候会产生general protection fault，因为特权等级不够。\n Q2:What do you think is the point of these mechanisms, particularly in light of what the user/softint test program does?\n 用户不能产生14中断，特权级不够。\n练习7  完成系统调用\n  用户通过系统调用进入内核态，并且保存用户的状态信息，内核执行合适的处理代码，然后恢复到用户态，当然，也需要确定调用是从内核态到用户态还是内核自身调用系统函数。 JOS中系统调用的中断号是0x30，不会由计算机硬件产生，所以需要写好相应的调用代码。\n应用程序将会把系统调用的编号和系统调用的参数保存在寄存器中。system call number将会保存在%eax中，接下来最多五个参数分别保存在 %edx, %ecx, %ebx, %edi, %esi中。system call函数已经写好在了文件lib/syscall.c中。\ntrap_init() 在trap_init()中添加相应的handler:\nvoid syscall_entry(); ... ... SETGATE(idt[T_SYSCALL], 1, GD_KT, syscall_entry, 3); trap_dispatch() 然后在trap_dispatch()中为中断添加调用：\n// system call  if (tf-\u0026gt;tf_trapno == T_SYSCALL) { tf-\u0026gt;tf_regs.reg_eax = syscall( tf-\u0026gt;tf_regs.reg_eax, tf-\u0026gt;tf_regs.reg_edx, tf-\u0026gt;tf_regs.reg_ecx, tf-\u0026gt;tf_regs.reg_ebx, tf-\u0026gt;tf_regs.reg_edi, tf-\u0026gt;tf_regs.reg_esi); return ; }  syscall() 利用lib/syscall.c中的syscall进行转移到真正处理通用系统调用的文件中，根据inc/syscall.h中的enum定义分发到相应的系统调用的处理函数去。\n// Dispatches to the correct kernel function, passing the arguments. int32_t syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5) { // Call the function corresponding to the \u0026#39;syscallno\u0026#39; parameter.  // Return any appropriate return value.  // LAB 3: Your code here.  cprintf(\u0026#34;call number:%d \\n\u0026#34;, syscallno); switch (syscallno) { case SYS_cputs: sys_cputs((char *)a1, a2); return 0; case SYS_cgetc: return sys_cgetc(); case SYS_getenvid: return sys_getenvid(); case SYS_env_destroy: return sys_env_destroy(a1); default: return -E_INVAL; } } 完成这里，利用make run-hello检测自己的系统调用是否成功。\n练习8 用户程序从这里开始执行，确认好相关信息后跳转到 libmain执行。\n.text .globl _start _start: // See if we were started with arguments on the stack cmpl $USTACKTOP, %esp jne args_exist // If not, push dummy argc/argv arguments. // This happens when we are loaded by the kernel, // because the kernel does not know about passing arguments. pushl $0 pushl $0 args_exist: call libmain 1: jmp 1b 将libmain()改成\n// LAB 3: Your code here.  thisenv = envs + ENVX(sys_getenvid()); ENVX宏定义在env.h文件中。 然后接下来调用用户程序umain和exit()，umain就相当于平时执行的C程序中main函数，exit()执行系统调用函数sys_env_destroy()。\n练习9/10 修改kern/trap.c,当内核页错误的时候调用panic，检查tf_cs的低位。 阅读kern/pmap.c中user_mem_assert函数，并且实现user_mem_check函数。 修改kern/syscall.c，检查系统调用的参数。 修改kern/kdebug.c中的debuginfo_eip，调用user_mem_check检查usd,stabs,stabstr。\n 内存保护是操作系统的一个决定性的特性，确保程序的BUG不会影响到其他程序和操作系统自己。\n操作系统通常依赖硬件去实现内存保护，当程序使用一个非法的内存地址或者对指定的虚拟地址没有访问权，处理器会中断程序指令并且产生一个fault级别异常，然后陷入内核态，去处理这个操作。如果这个错误可以修复，内核通过代码修复，然后让程序继续运行，否则，摧毁该程序。\n一种常见的可以修复的错误就是栈增长，大多数系统初始化一个进程通常只会分配一个stack页，当程序使用这个分配好的栈的更下层的时候，内核将会自动分配更多的空间，当然会有一个分配的最大值。\n大多数系统调用接口让用户程序传递一个指针给系统内核，这个指针指向一个用户内存空间的一个可读可写的缓冲区。系统内核通过解引用这个指针和用户程序进行交互，但是存在以下两个问题。\n  内核态出现页错误比在用户态出现页错误可能更加严重，如果内核在操作自己的数据结构的时候发生了页错误，这是一个内核BUG，解决错误的handler此时应该panic。但是当内核解引用用户程序传递过来的指针的时候，内核需要确认这个指针的是属于该用户程序的。\n  内核的权限通常高于用户程序，用户可能会传递一个内核可以读取，但是该程序不能读取的内存地址。内核需要非常仔细的检查这类指针，因为这样可能会造成隐私信息泄露和破坏内核完整性。\n  page_fault_handler() // LAB 3: Your code here.(1)  if ((tf-\u0026gt;tf_cs \u0026amp; 3) == 0) panic(\u0026#34;kernel page fault\u0026#34;); 在8086模式下，寄存器CS,DS,ES等被称作段偏移，但是在保护模式下，CS,DS,ES等寄存器被用作段选择子，在GDT中选定相应的段，根据全局描述符中的信息，程序只能在相应的内存段中运行，读取，写入，否则会发生中断或者异常。\nuser_mem_check int user_mem_check(struct Env *env, const void *va, size_t len, int perm) { // LAB 3: Your code here.  if ((uintptr_t)va \u0026gt;= ULIM) { user_mem_check_addr = (uintptr_t) va; return -E_FAULT; } uintptr_t beg = ROUNDDOWN((uint32_t)va, PGSIZE); uintptr_t end = ROUNDUP((uintptr_t)va+len, PGSIZE); uintptr_t i; pte_t *phaddr_entry; for (i = beg; i != end; i += PGSIZE) { phaddr_entry = pgdir_walk(env-\u0026gt;env_pgdir, (void *)i, false); if ( phaddr_entry == NULL || !(*phaddr_entry \u0026amp; PTE_P) || (*phaddr_entry \u0026amp; perm ) != perm) { user_mem_check_addr = i \u0026lt; (uintptr_t)va ? (uintptr_t)va : i; cprintf(\u0026#34;%x\\n\u0026#34;, user_mem_check_addr); return -E_FAULT; } } return 0; } BUG ： 这里在调用pgdir_walk的时候把env-\u0026gt;env_pgdir写成了kern_pgdir，用户一般都不会有内核的地址空间的读写权限，导致make run相关程序的时候发生失败。\nsys_cputs() // Check that the user has permission to read memory [s, s+len).  // Destroy the environment if not.  // LAB 3: Your code here.  user_mem_assert(curenv, s, len, PTE_U); debuginfo_eip()  // Make sure this memory is valid. // Return -1 if it is not. Hint: Call user_mem_check. // LAB 3: Your code here. if (user_mem_check(curenv, usd, sizeof(struct UserStabData), PTE_U) \u0026lt; 0) return -1; stabs = usd-\u0026gt;stabs; stab_end = usd-\u0026gt;stab_end; stabstr = usd-\u0026gt;stabstr; stabstr_end = usd-\u0026gt;stabstr_end; // Make sure the STABS and string table memory is valid. // LAB 3: Your code here. if (user_mem_check(curenv, stabs, stab_end - stabs, PTE_U) \u0026lt; 0) return -1; if (user_mem_check(curenv, stabstr, stabstr_end - stabstr, PTE_U) \u0026lt; 0) return -1;  Q: run user/breakpoint, you should be able to run backtrace from the kernel monitor and see the backtrace traverse into lib/libmain.c before the kernel panics with a page fault. What causes this page fault? You don\u0026rsquo;t need to fix it, but you should understand why it happens.\n // todo\nmake grade make[1]: Leaving directory \u0026#39;/home/moonlight/lab\u0026#39; divzero: OK (1.3s) softint: OK (1.0s) badsegment: OK (1.1s) Part A score: 30/30 faultread: OK (0.9s) faultreadkernel: OK (1.9s) faultwrite: OK (1.1s) faultwritekernel: OK (1.7s) breakpoint: OK (1.4s) testbss: OK (1.7s) hello: OK (2.2s) buggyhello: OK (2.0s) buggyhello2: OK (2.1s) evilhello: OK (1.7s) Part B score: 50/50 Score: 80/80 This completes the lab.\n","date":"April 22, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/","summary":"4月22日 - 5月2日\n PART A 这章的练习将会取实现一些基础的用户模式下的环境，也就是进程。在这章，创建一个用户环境，读取程序镜像并且运行。 这是关于这章节代码文件的介绍\ninc/env.h Public definitions for user-mode environments trap.h Public definitions for trap handling syscall.h Public definitions for system calls from user environments to the kernel lib.h Public definitions for the user-mode support library kern/env.h Kernel-private definitions for user-mode environments env.c Kernel code implementing user-mode environments trap.h Kernel-private trap handling definitions trap.c Trap handling code trapentry.S Assembly-language trap handler entry-points syscall.h Kernel-private definitions for system call handling syscall.","tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments"},{"categories":["language"],"contents":"extern 从该文件外部获取变量定义，在文件域默认有extern属性。存储属性为static，也就是在文件执行前就被放在静态数据区。\nstatic 只在该文件域可以使用，存储属性为static。\n实例 extern.c\n#include \u0026lt;stdio.h\u0026gt; int k = 10; extern void print(void); int main() { printf(\u0026#34;k: %d\\n\u0026#34;, k); print(); } extern2.c\n#include \u0026lt;stdio.h\u0026gt; void print(void) { extern int k; printf(\u0026#34;extern int k: %d\\n\u0026#34;, k); } shell\n$ gcc -o ex extern.c extern2.c $ ./ex  函数指针数组 #include \u0026lt;stdio.h\u0026gt; static int print1(void) { printf(\u0026#34;function: print1()\\n\u0026#34;); } static int print2(void) { printf(\u0026#34;function: print2()\\n\u0026#34;); } static int (*arr[])(void) = { [0] print1, [1] print2, }; int (* foo)(void); int main(void) { foo = arr[0]; foo(); } __static int (*arr[])(void)__可以理解为arr[]数组中存有两个类型为__static int(void)__的函数指针\n static关键词可以设计__抽象数据类型ADT(abstract data type)__黑盒。\n可以设计一个这样的头文件作为接口： list.h\n/* ** ** headfile for ADT ** */ /* macro */ #define NAME_LEN 30 #define ADDR_LEN 100 #define PHONE_LEN 11  #define MAX_ADDRESSES 1000  /* interface declaration */ char const * lookup_address(char const *name); char const * lookup_phone(char const *name);  list.c\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026#34;list.h\u0026#34; /* static data type*/ static char name[MAX_ADDRESSES][NAME_LEN]; static char address[MAX_ADDRESSES][ADDR_LEN]; static char phone[MAX_ADDRESSES][PHONE_LEN]; static int find_entry(const char *name2find) { int entry; for (entry = 0; entry \u0026lt; MAX_ADDRESSES; entry += 1) if(strcmp(name2find, name[entry]) == 0) return entry; return -1; } const char * lookup_address(const char *name) { int entry; entry = find_entry(name); if(entry == -1) return NULL; else return address[entry]; } const char * lookup_phone(const char *name) { // ...  // ...  // implement  // ...  // ... } 这样调用接口就能获得数据，但是不能直接得到数据，有点像OOP编程的思想。当然，直接用数组作为数据存储的容器，这儿只是一个例子，改变自《pointers on c》。\n","date":"April 19, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/sys/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/","summary":"extern 从该文件外部获取变量定义，在文件域默认有extern属性。存储属性为static，也就是在文件执行前就被放在静态数据区。\nstatic 只在该文件域可以使用，存储属性为static。\n实例 extern.c\n#include \u0026lt;stdio.h\u0026gt; int k = 10; extern void print(void); int main() { printf(\u0026#34;k: %d\\n\u0026#34;, k); print(); } extern2.c\n#include \u0026lt;stdio.h\u0026gt; void print(void) { extern int k; printf(\u0026#34;extern int k: %d\\n\u0026#34;, k); } shell\n$ gcc -o ex extern.c extern2.c $ ./ex  函数指针数组 #include \u0026lt;stdio.h\u0026gt; static int print1(void) { printf(\u0026#34;function: print1()\\n\u0026#34;); } static int print2(void) { printf(\u0026#34;function: print2()\\n\u0026#34;); } static int (*arr[])(void) = { [0] print1, [1] print2, }; int (* foo)(void); int main(void) { foo = arr[0]; foo(); } __static int (*arr[])(void)__可以理解为arr[]数组中存有两个类型为__static int(void)__的函数指针","tags":["c/c++"],"title":"static,extern关键词和函数指针数组"},{"categories":["env"],"contents":"远程到本地  $ git fetch $ git merge origin/master  本地到远程  关联\ngit remote add origin git@github.com:haoxr/-faceDetection.git  提交到本地\n$ git add . $ git commit -m \u0026quot;commit infomation\u0026quot;  push\n$ git push -u origin master \u0026lt;- 第一次使用 $ git push origin master ","date":"April 17, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/","summary":"远程到本地  $ git fetch $ git merge origin/master  本地到远程  关联\ngit remote add origin git@github.com:haoxr/-faceDetection.git  提交到本地\n$ git add . $ git commit -m \u0026quot;commit infomation\u0026quot;  push\n$ git push -u origin master \u0026lt;- 第一次使用 $ git push origin master ","tags":null,"title":"Git 基础操作"},{"categories":["sys"],"contents":"Exercise 1: 内存初始化 在 lab1 中开启了分段和分页，并且初始化了内核页目录（地址存储在CR3中），于是有了下面这样的地址转换机制。\n 地址转换\n 首先通过相应段寄存器获得地址基址，然后以虚拟地址作为偏移获得线性地址。线性地址在通过一定的机制，获得实际的物理地址。\n线性地址转换过程:\n段翻译机制输出一个线性地址（Linear address） Linear address(LA)，用于接下来的转换，在 CR0 寄存器 PG 位未设置的时候，线性地址会被直接作为物理地址。\n// A linear address 'la' has a three-part structure as follows: // // +--------10------+-------10-------+---------12----------+ // | Page Directory | Page Table | Offset within Page | // | Index | Index | | // +----------------+----------------+---------------------+ // \\--- PDX(la) --/ \\--- PTX(la) --/ \\---- PGOFF(la) ----/ // \\---------- PGNUM(la) ----------/ // // The PDX, PTX, PGOFF, and PGNUM macros decompose linear addresses as shown. // To construct a linear address la from PDX(la), PTX(la), and PGOFF(la), // use PGADDR(PDX(la), PTX(la), PGOFF(la)). 首先取线性地址的高10位作为页目录索引(Page Directory Index)，共1024个，从 0 ~ 1023。再使用cr3寄存器中的高二十位定位内存中页目录的基址。\n在页目录和页表中，每个单元都是4bytes。 最后在页目录中的寻址组成为：\n每个索引只使用高20位进行寻址，因为页操作的最小粒度为4KB。只需要4个字节的前面20位进行寻址就行了，剩下的比特可以用作其他标志位。\n根据前十位索引获得相应的页目录项后，用其前20位作为一个4KB对齐的地址作为页表（Page Table）的基址。然后从线性地址中取出中间的10位作为的索引，得到相应的页表项（Page Table Entry）。\n继续从PTE中取出前20位得到4KB对齐的基址，然后从利用线性地址（LA）最后12位作为在这4K页内的偏移，组合得到32位的地址，即最终的物理地址。\n下面是JOS需要完成的内存布局。\n/* * Virtual memory map: Permissions * kernel/user * * 4 Gig --------\u0026gt; +------------------------------+ * | | RW/-- * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * : . : * : . : * : . : * |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| RW/-- * | | RW/-- * | Remapped Physical Memory | RW/-- * | | RW/-- * KERNBASE, ----\u0026gt; +------------------------------+ 0xf0000000 --+ * KSTACKTOP | CPU0\u0026#39;s Kernel Stack | RW/-- KSTKSIZE | * | - - - - - - - - - - - - - - -| | * | Invalid Memory (*) | --/-- KSTKGAP | * +------------------------------+ | * | CPU1\u0026#39;s Kernel Stack | RW/-- KSTKSIZE | * | - - - - - - - - - - - - - - -| PTSIZE * | Invalid Memory (*) | --/-- KSTKGAP | * +------------------------------+ | * : . : | * : . : | * MMIOLIM ------\u0026gt; +------------------------------+ 0xefc00000 --+ * | Memory-mapped I/O | RW/-- PTSIZE * ULIM, MMIOBASE --\u0026gt; +------------------------------+ 0xef800000 * | Cur. Page Table (User R-) | R-/R- PTSIZE * UVPT ----\u0026gt; +------------------------------+ 0xef400000 * | RO PAGES | R-/R- PTSIZE * UPAGES ----\u0026gt; +------------------------------+ 0xef000000 * | RO ENVS | R-/R- PTSIZE * UTOP,UENVS ------\u0026gt; +------------------------------+ 0xeec00000 * UXSTACKTOP -/ | User Exception Stack | RW/RW PGSIZE * +------------------------------+ 0xeebff000 * | Empty Memory (*) | --/-- PGSIZE * USTACKTOP ---\u0026gt; +------------------------------+ 0xeebfe000 * | Normal User Stack | RW/RW PGSIZE * +------------------------------+ 0xeebfd000 * | | * | | * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * . . * . . * . . * |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| * | Program Data \u0026amp; Heap | * UTEXT --------\u0026gt; +------------------------------+ 0x00800000 * PFTEMP -------\u0026gt; | Empty Memory (*) | PTSIZE * | | * UTEMP --------\u0026gt; +------------------------------+ 0x00400000 --+ * | Empty Memory (*) | | * | - - - - - - - - - - - - - - -| | * | User STAB Data (optional) | PTSIZE * USTABDATA ----\u0026gt; +------------------------------+ 0x00200000 | * | Empty Memory (*) | | * 0 ------------\u0026gt; +------------------------------+ --+ * * (*) Note: The kernel ensures that \u0026#34;Invalid Memory\u0026#34; is *never* mapped. * \u0026#34;Empty Memory\u0026#34; is normally unmapped, but user programs may map pages * there if desired. JOS user programs map pages temporarily at UTEMP. */ 首先是执行 i386_detect_memory() 探测内存，分别调用了3次读取CMOS寄存器的函数：\n\tbasemem = nvram_read(NVRAM_BASELO); extmem = nvram_read(NVRAM_EXTLO); ext16mem = nvram_read(NVRAM_EXT16LO) * 64; 追踪到 kclock.h 注释\n#define\tMC_NVRAM_START\t0xe\t/* start of NVRAM: offset 14 */ ... /* NVRAM bytes 7 \u0026amp; 8: base memory size */ #define NVRAM_BASELO\t(MC_NVRAM_START + 7)\t/* low byte; RTC off. 0x15 */ #define NVRAM_BASEHI\t(MC_NVRAM_START + 8)\t/* high byte; RTC off. 0x16 */ /* NVRAM bytes 9 \u0026amp; 10: extended memory size (between 1MB and 16MB) */ #define NVRAM_EXTLO\t(MC_NVRAM_START + 9)\t/* low byte; RTC off. 0x17 */ #define NVRAM_EXTHI\t(MC_NVRAM_START + 10)\t/* high byte; RTC off. 0x18 */ /* NVRAM bytes 38 and 39: extended memory size (between 16MB and 4G) */ #define NVRAM_EXT16LO\t(MC_NVRAM_START + 38)\t/* low byte; RTC off. 0x34 */ #define NVRAM_EXT16HI\t(MC_NVRAM_START + 39)\t/* high byte; RTC off. 0x35 */ 可以看到内存探测可以分为三部分\n base memory 0 ~ 1MB extended memory 1MB ~ 16MB extended memory 16MB ~ 4G  内存的初始化可以完成一部分，引导用的内存页分配函数以及准备为每一个页准备一个 PageInfo 结构体进行管理。\nboot_alloc(): // before the page_init(), it\u0026#39;s a temple allocater .  result = nextfree; nextfree = ROUNDUP(nextfree + n, PGSIZE); if((uint32_t )nextfree - KERNBASE \u0026gt;= 0xfffffff) panic(\u0026#34;out of ranges\u0026#34;); return result; mem_init(): //为每一个4K页面准备一个结构体进行管理。  pages = (struct PageInfo *)boot_alloc(npages * sizeof(struct PageInfo)); memset(pages, 0, npages * sizeof(struct PageInfo)); 根据 page_init() 注释，内存未使用情况应该如下图（白色部分）：\n在 boot_alloc() 函数中，内存是从 end 这个位置开始分配的：\nextern char end[]; nextfree = ROUNDUP((char *) end, PGSIZE); end 是由链接器自动产生的符号，指向内核的 .bss 段的结尾，所以 boot_alloc() 分配的内存都是从内核elf的bss段后开始分配的。\n以下内存不可以被分配（灰色部分）：\n 实模式下的 IDT 和 BIOS 数据结构 (page 0) IO hole （IOPHYSMEM ~ EXTPHYSMEM） 之前通过 boot_alloc() 分配掉用于存储页目录和页管理结构体的内存。  于是在初始化的时候，就将不可再分配的页的引用次数计为1。代码中出现的 basemem 实际上指 0 ~ 640K (从CMOS中读取出来的值)，而不是指广义上的 0 ~ 1MB。\nvoid page_init(void) { size_t i; size_t IOhole_pages = (EXTPHYSMEM - IOPHYSMEM) / PGSIZE; size_t allocated_pages = ((uint32_t)boot_alloc(0) - KERNBASE) / PGSIZE; for (i = 0; i \u0026lt; npages; i++) { if (i == 0) pages[i].pp_ref = 1; else if (i \u0026gt;= npages_basemem \u0026amp;\u0026amp; i \u0026lt; npages_basemem + IOhole_pages + allocated_pages) { pages[i].pp_ref = 1; } else { pages[i].pp_ref = 0; pages[i].pp_link = page_free_list; page_free_list = \u0026amp;pages[i]; } } } 页的分配和回收实现为单链表插入与删除。\nstruct PageInfo * page_alloc(int alloc_flags) { if (page_free_list == NULL) return NULL; struct PageInfo *newpage = page_free_list; page_free_list = page_free_list-\u0026gt;pp_link; newpage-\u0026gt;pp_link = NULL; if (alloc_flags \u0026amp; ALLOC_ZERO) memset(page2kva(newpage), 0, PGSIZE); return newpage; } void page_free(struct PageInfo *pp) { if(pp-\u0026gt;pp_link != NULL || pp-\u0026gt;pp_ref != 0) panic(\u0026#34;cann\u0026#39;t free or it\u0026#39;s free\u0026#34;); else { pp-\u0026gt;pp_link = page_free_list; page_free_list = pp; } } 这部分做到 check_page_free_list(1);\n$ make qemu-nox ... 6828 decimal is 15254 octal! Physical memory: 131072K available, base = 640K, extended = 130432K check_page_free_list() succeeded! check_page_alloc() succeeded! 练习2 了解x86保护机制和段页翻译.\n参考资料：\n  Intel 80386 Reference Manual: chapters 5 and 6 Intel® 64 and IA-32 Architectures Software Developer’s Manual   保护机制的产生实际上是为了探测和找到程序中可能出现的bug。\n练习3 使用QEMU和GDB查看内存 进入保护模式后可以通过\nctrl+a c  进入QEMU的监视器，查看内存情况。\n(QEMU) xp phisical address  查看物理地址信息\n(gdb) x/x virtual address  查看虚拟地址信息\n练习4 JOS中定义了两种针对于不同地址的数据类型,uintptr_t代表虚拟地址,physaddr_t表示物理地址,宏定义都为uint32_t。解引用(dereference)都要通过段页机制实现，所以如果对物理地址进行解引用，会有非预期的结果。\nQuestion\n Assuming that the following JOS kernel code is correct, what type should variable x have, uintptr_t or physaddr_t? mystery_t x; char* value = return_a_pointer(); *value = 10; x = (mystery_t) value;   根据上述对类型的描述，因为有解引用操作，x的类型应该为uintptr_t。\n引用计数 每一个 struct PageInfo 对应一个4KB物理页，对应一个页，如果计数到达了 0，说明这块内存将不再使用，一般来说，引用计数的值应该等于在 UTOP 以下的页表中出现的次数。因为高于 UTOP 的页表一般被内核所使用，不应该释放。\nPage Table Management 因为此时内核已经开启了页机制，所以不可能绕过这个机制，所使用的地址必须映射在页目录中的地址。\nPADDR(va) : virtual address - KERNELBASE， va 如果小于 KERNELBASE 则 panic。\nKADDR(pa) : physical address + KERNELBASE，pa 如果超出实际内存大小 则 panic。\n*page2kva(struct PageInfo ) : struct PageInfo pointer -\u0026gt; virtual address\npte_t * pgdir_walk(pde_t *pgdir, const void *va, int create) { size_t pgdir_index = PDX(va); size_t page_offset = PTX(va); pde_t dir_entry = pgdir[pgdir_index]; if (!(dir_entry \u0026amp; PTE_P)) { // get page table address which a pointer point to .  if(create){ struct PageInfo *allocated_page = page_alloc(ALLOC_ZERO); if(allocated_page == NULL) return NULL; // increment reference count  allocated_page-\u0026gt;pp_ref++; // the page physical address \tphysaddr_t pg_phyaddr = page2pa(allocated_page) ; // fill page table entry  pgdir[pgdir_index] = pg_phyaddr | PTE_P | PTE_W | PTE_U; } else { return NULL; } } // point to a page table  pte_t *pt_base = KADDR(PTE_ADDR(pgdir[pgdir_index])); return \u0026amp;(pt_base[page_offset]); } static void boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm) { pte_t *pte; // \u0026#39;size\u0026#39; is a multiple of PGSIZE.  size_t page_num = size / PGSIZE; uint32_t i; for(i = 0; i \u0026lt; page_num; i++) { pte = pgdir_walk(pgdir, (void *)va, true); if (pte == NULL) return; *pte = pa | perm | PTE_P; pa += PGSIZE; va += PGSIZE; } } struct PageInfo * page_lookup(pde_t *pgdir, void *va, pte_t **pte_store) { struct PageInfo *ret = NULL; pte_t *pte = pgdir_walk(pgdir, va, false); if(pte == NULL) return NULL; if((*pte \u0026amp; PTE_P) == 0) return NULL; ret = pa2page(PTE_ADDR(*pte)); if(pte_store != NULL) { *pte_store = pte; } return ret; } void page_remove(pde_t *pgdir, void *va) { // get page table entry and PageInfo. \tpte_t *pte = NULL; struct PageInfo* upage = page_lookup(pgdir, va, \u0026amp;pte); if(upage == NULL) return; // decrement reference count  // freeing it if there are no more refs \tpage_decref(upage); // flush page-translation cache about this page \ttlb_invalidate(pgdir, va); // clean pte \t*pte = 0 ; } int page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm) { // modify pde \tpte_t *entry = pgdir_walk(pgdir, va, true); if (entry == NULL) return -E_NO_MEM; // page colides \tpp-\u0026gt;pp_ref++; if (*entry \u0026amp; PTE_P) { // decrement and free \t// page invalidate in page_remove() \tpage_remove(pgdir, va); } // modify pte \t*entry = page2pa(pp) | perm | PTE_P; return 0; } Intel TLB 无效技术有两种方法：\n 向CR3寄存器写入值时，所有处理器自动刷新相对于非全局TLB表项 在Pentium Pro及以后的处理器中，invlpg 指令能使映射指定线性地址的单个TLB表项无效  练习4到此完成。\n练习5 Kernal Address Space\nJOS把线性地址分为两部分，低地址的用户环境(User enviroment - Processes)和高地址的内核，用户部分在Lab3中加载使用。内存分给内核从KERNBASE开始到内存结束共大约256MB。\n权限和错误隔离 为了防止用户代码的bug覆盖写内核数据或者代码导致崩溃，使用权限bit位限制用户代码的权限，使其只能访问其内存空间。对于用户级代码来说大于ULIM的是不允许访问的，属于内核的空间。内存地址[UTOP,ULIM) 对于User和Kernal都是只读的，用于内核暴露一部分只读数据结构给用户。\n完成 mem_init() 剩余的代码：\n// Map \u0026#39;pages\u0026#39; read-only by the user at linear address UPAGES boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), PTE_U | PTE_P); // Use the physical memory that \u0026#39;bootstack\u0026#39; refers to as the kernel boot_map_region(kern_pgdir, (KSTACKTOP-KSTKSIZE), KSTKSIZE, PADDR(bootstack), PTE_W | PTE_P); // Map all of physical memory at KERNBASE. boot_map_region(kern_pgdir, KERNBASE, 0xFFFFFFF, 0, PTE_W | PTE_P); 通过剩下几个测试\n$ make qemu-nox ... 6828 decimal is 15254 octal! Physical memory: 131072K available, base = 640K, extended = 130432K check_page_free_list() succeeded! check_page_alloc() succeeded! check_page() succeeded! check_kern_pgdir() succeeded! check_page_free_list() succeeded! check_page_installed_pgdir() succeeded! 然后将新填写的页目录地址重新加载到CR3寄存器内，在开启剩余一些CR0寄存器位。\nlcr3(PADDR(kern_pgdir)); cr0 = rcr0(); cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP; cr0 \u0026amp;= ~(CR0_TS|CR0_EM); lcr0(cr0); |PE|\n Question  Q2:What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point?    Q3:We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel\u0026rsquo;s memory? What specific mechanisms protect the kernel memory?\n与页目录和页表中的 User/supervisor flag 和 Read/write flag 有关\n “ When the processor is in user mode, it can write only to usermode pages that are read/write accessible. User-mode pages which are read/write or read-only are readable; supervisor-mode pages are neither readable nor writable from user mode. ”\n  Intel® 64 and IA-32 Architectures Software Developer’s Manual\n  4.11.3 Page Type\n 可以看到 jos 只有 UPAGES 以上 PTSIZE 的内存设置了 PTE_U，除了这个部分对于用户级别可以读，其他的部分都是不可读或写的。\n  Q5:How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down?\n2G\n  Q6: Revisit the page table setup in kern/entry.S and kern/entrypgdir.c. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary?\n mov $relocated, %eax jmp *%eax  jmp 完后就到了高地址，在临时的内核页目录中，同时将虚拟地址 [0 ~ 4MB) 和 [KERNELBASE ~ KERNELBASE+4MB) 映射了物理内存 [0 ~ 4MB)，所以即使 PE 置位后仍然能正常执行。在 lab2 中重新加载了新映射的 kern_pgdir，里面并没有映射 [0 ~ 4MB) 这一部分，继续在低地址执行但是页表里面并没有相应的项。\n  答案参考: https://github.com/Clann24/jos/tree/master/lab2\nChallenge 2  这个给JOS增加一个调试器，很有必要做一下，方便之后的学习。\n辅助函数 str2ptr() JOS中没有包含标准库，需要自己写一下字符串到整形的转换。\npde_t * str2ptr(char *str) { pde_t ptr; int temp, i; size_t length; length = strlen(str) ; ptr = 0; for (i = 2; str[i] != 0; i++) { if(str[i] \u0026lt;= \u0026#39;9\u0026#39;) temp = str[i] - \u0026#39;0\u0026#39;; else temp = str[i] - \u0026#39;a\u0026#39; + 10; ptr += temp * ( 1 \u0026lt;\u0026lt; (length - i - 1) * 4 ); } return (pde_t *)ptr; } mon_mapinfo() int mon_mapinfo(int argc, char **argv, struct Trapframe *tf) { extern pde_t *kern_pgdir; pde_t *pg_pa, *pg_va, size, iter; extern pte_t * pgdir_walk(pde_t *,const void *, int); if (argc \u0026lt; 3) { cprintf(\u0026#34;too few argument \\n\u0026#34;); return 0; } if (argv[1][0] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; argv[1][1] == \u0026#39;x\u0026#39;) { /* show address */ /*initialize some variables*/ size = str2ptr(argv[2]) - str2ptr(argv[1]); pg_va = str2ptr(argv[1]); /* use pgdir_walk function to get page entry */ for (iter = (pde_t)pg_va; iter \u0026lt;= (pde_t)str2ptr(argv[2]); iter += PGSIZE) { pg_pa = pgdir_walk(kern_pgdir, (void *)iter, false); if (pg_pa == (void *)0) cprintf(\u0026#34;0x%x: None\\n\u0026#34;, iter); else cprintf(\u0026#34;0x%x: %x\\n\u0026#34;, iter, *pg_pa \u0026amp; ~0xFFF); } } else if (strcmp(\u0026#34;set\u0026#34;, argv[1]) == 0) { /* set flag to Page Entry */ pte_t flag; pg_va = str2ptr(argv[2]); pg_pa = pgdir_walk(kern_pgdir, (void *)pg_va, false); if (pg_pa == (void *)0) { cprintf(\u0026#34;Error: Unallocated page\u0026#34;); return 0; } else { flag = (pte_t) str2ptr(argv[3]); cprintf(\u0026#34;set physical address %x: flag = %x -\u0026gt;\u0026#34;, *pg_pa \u0026amp; ~0xFFF, *pg_pa); flag \u0026amp;= 0xFFF; /* promise that the flag cann\u0026#39;t affect the address */ *pg_pa \u0026amp;= ~0xFFF; *pg_pa |= flag; cprintf(\u0026#34; %x\\n\u0026#34;, *pg_pa \u0026amp; 0xFFF); } } else { cprintf(\u0026#34;Usage error: showmapings \u0026#34;); cprintf(\u0026#34;smp 0xff00ff00 0xff00ff00\\n\u0026#34;); cprintf(\u0026#34;smp set 0xff00ff00 0x1\\n\u0026#34;); } return 0; } show K\u0026gt; smp 0xf0000000 0xf01000000 0xf0000000: 0 0xf0001000: 1000 0xf0002000: 2000 0xf0003000: 3000 0xf0004000: 4000 0xf0005000: 5000 0xf0006000: 6000 0xf0007000: 7000 0xf0008000: 8000 0xf0009000: 9000 ... 0xf00fe000: fe000 0xf00ff000: ff000 0xf0100000: 100000  正好说明虚拟地址__KERNBASE~0xFFFFFFFF__被映射到了__0x00000000~0x0FFFFFFF__\nset K\u0026gt; smp set 0xf0000000 0x1 set physical address 0: flag = 3 -\u0026gt; 1 ","date":"April 12, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/","summary":"Exercise 1: 内存初始化 在 lab1 中开启了分段和分页，并且初始化了内核页目录（地址存储在CR3中），于是有了下面这样的地址转换机制。\n 地址转换\n 首先通过相应段寄存器获得地址基址，然后以虚拟地址作为偏移获得线性地址。线性地址在通过一定的机制，获得实际的物理地址。\n线性地址转换过程:\n段翻译机制输出一个线性地址（Linear address） Linear address(LA)，用于接下来的转换，在 CR0 寄存器 PG 位未设置的时候，线性地址会被直接作为物理地址。\n// A linear address 'la' has a three-part structure as follows: // // +--------10------+-------10-------+---------12----------+ // | Page Directory | Page Table | Offset within Page | // | Index | Index | | // +----------------+----------------+---------------------+ // \\--- PDX(la) --/ \\--- PTX(la) --/ \\---- PGOFF(la) ----/ // \\---------- PGNUM(la) ----------/ // // The PDX, PTX, PGOFF, and PGNUM macros decompose linear addresses as shown.","tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management"},{"categories":["env"],"contents":"注： 博客已经从hexo迁移到了hugo，部分格式已经不能渲染出来。\ncategories和tags themes文件夹下面的_config.yml有一个memu选项，hiker是默认有归档选项的。但是分类和标签是空页面，本地访问会提示 GET ERROR 的404错误。在md文件有表示的情况下，像如下配置即可。\ntype: \u0026#34;categories\u0026#34; layout: \u0026#34;categories\u0026#34; comments: false type: \u0026#34;tags\u0026#34; layout: \u0026#34;tags\u0026#34; comments: false hexo-auto-category插件 在_post文件夹下面创建的文件夹，都会被当作一个category，并分别将各个文件夹下面的md文件自动加上相应的category标识。 安装 $ npm install hexo-auto-category --save\n$ hexo clean \u0026amp;\u0026amp; hexo g \u0026amp;\u0026amp; hexo s\n_config.yml配置\n# Generate categories from directory-tree # Dependencies: https://github.com/xu-song/hexo-auto-category # depth: the depth of directory-tree you want to generate, should \u0026gt; 0 auto_category: enable: true depth: github网址: https://github.com/xu-song/hexo-auto-category\nlive-2d 这是个非常有趣的插件，看板娘get！ 安装:\n$ npm install --save hexo-helper-live2d\n根据原github,修改hexo文件夹下面的_config.yml。 然后要安装相应的模组：\n$ npm install {your model's package name} 模组下载地址:https://github.com/xiazeyu/live2d-widget-models\nhexo-helper-qrcode 二维码\nInstall $ npm i -S hexo-helper-qrcode\nUsage\n\u0026lt;img src=\u0026#34;\u0026lt;%- qrcode(url) %\u0026gt;\u0026#34;\u0026gt; \u0026lt;!-- white margin, default 0 --\u0026gt; \u0026lt;img src=\u0026#34;\u0026lt;%- qrcode(url, { margin: 2 }) %\u0026gt;\u0026#34;\u0026gt; \u0026lt;!-- size of one module in pixels, default 6 --\u0026gt; \u0026lt;img src=\u0026#34;\u0026lt;%- qrcode(url, { size: 4 }) %\u0026gt;\u0026#34;\u0026gt; fontawesome 在md文档中加入矢量图\n\u0026lt;i class=\u0026quot;fa fa-twitter fa-2x\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; hugo 不支持\nfontwawesome : http://www.bootcss.com/p/font-awesome/design.html\nhexo-githus $ npm install --save hexo-githus {% github name repo commit-sha-1 [auto_expand = true | false] [width = 50%] %}  {% github fatwaer APUE-Practice-Code 6fb648e42bc1229199b80f1aba04280f9e5ad271 [width = 50%] %}\nhexo-sliding-spoiler shell\n$ npm install hexo-sliding-spoiler --save  __config.yml\nplugins: - hexo-sliding-spoiler markdown\n{% spoiler title %} content {% endspoiler %} {% spoiler title %} code test\nint main() { return 0; }  test bold {% endspoiler %}\n","date":"April 5, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hexo%E9%85%8D%E7%BD%AE/","summary":"\u003cp\u003e\u003cstrong\u003e注\u003c/strong\u003e： 博客已经从hexo迁移到了hugo，部分格式已经不能渲染出来。\u003c/p\u003e\n\u003ch2 id=\"categories和tags\"\u003ecategories和tags\u003c/h2\u003e\n\u003cp\u003ethemes文件夹下面的_config.yml有一个memu选项，hiker是默认有归档选项的。但是分类和标签是空页面，本地访问会提示 GET ERROR 的404错误。在md文件有表示的情况下，像如下配置即可。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003etype: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;categories\u0026#34;\u003c/span\u003e\nlayout: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;categories\u0026#34;\u003c/span\u003e\ncomments: false\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003etype: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;tags\u0026#34;\u003c/span\u003e\nlayout: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;tags\u0026#34;\u003c/span\u003e\ncomments: false\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","tags":["config"],"title":"hexo 配置"},{"categories":["sys"],"contents":" 3月14日 - 3月28日\n Exercise 1 熟悉x86汇编和AT\u0026amp;T汇编\n16-bit intel 8088 1MB = 1048576bit 内存地址: 0x00000 ~ 0xFFFFF 640KB(0x00000 ~ 0xA0000) 用户可用 参考资料\nGDB启动过程 首先打开一个终端到目的lab根文件夹 $ make qemu-nox-gdb 再打开一个新的终端窗口执行以下命令进行监听 $ make gdb\n以及一些常用的gdb命令 b: 0xffff: 在0xffff出下断点 c: continue to breakpoint si: 单步前进 x/5: 0xFFFFF 从0xFFFFF开始的5个命令\n Exercise 2 第一条指令: [f000:fff0] 0xffff0:\tljmp $0xf000,$0xe05b 当处理器重置时，会进入实模式并将CS设置为0xf000，IP设置为0xfff0(CS:IP=0xffff0)。 这个地址与BIOS的结束位置0x100000差16bytes。\n启动后追踪BIOS的部分代码 [f000:e05b] 0xffff0:\tljmp $0xf000,$0xe05b [f000:e05b] 0xfe05b:\tcmpl $0x0,%cs:0x6c48\t;把0与cs:6c48所指向内存的值比较 [f000:e062] 0xfe062:\tjne 0xfd2e1 ;与CS:0x6c48(f6c48)处的值与0比较，不是0跳转 [f000:e066] 0xfe066:\txor %dx,%dx ;dx清0 [f000:e068] 0xfe068:\tmov %dx,%ss ;ss置0,AT\u0026amp;T汇编mov指令反向 [f000:e06a] 0xfe06a:\tmov $0x7000,%esp ;esp设置为0x7000,实模式引导区位置 [f000:e070] 0xfe070:\tmov $0xf3691,%executed ;edx设置为0xf3691 [f000:e076] 0xfe076:\tjmp 0xfd165 ;跳转 0xfd165 [f000:d165] 0xfd165:\tmov %eax,%ecx [f000:d168] 0xfd168:\tcli ;屏蔽中断 [f000:d169] 0xfd169:\tcld ;DF设置为0，指在每次传送一次将esi和edi自动+1;std将DF设置为1,传送自减 [f000:d16a] 0xfd16a:\tmov $0x8f,%eax [f000:d170] 0xfd170:\tout %al,$0x70 ;将al中的值0x8f输出到外部设备0x70端口,NMI不可屏蔽中断使能位为1 [f000:d172] 0xfd172:\tin $0x71,%al ;将0x71端口的值输出到al,GDB查看寄存器信息看见eax值被清0 ;A20地址线使能,进入保护模式 [f000:d174] 0xfd174:\tin $0x92,%al [f000:d176] 0xfd176:\tor $0x2,%al [f000:d178] 0xfd178:\tout %al,$0x92 ;加载6个字节 [f000:d17a] 0xfd17a:\tlidtw %cs:0x6c38 ;加载中断向量表 -\u0026gt;idt寄存器 [f000:d180] 0xfd180:\tlgdtw %cs:0x6bf4 ;加载全局描述符表-\u0026gt;gdt寄存器 ;cr0寄存器置为1，进入保护模式 [f000:d186] 0xfd186:\tmov %cr0,%eax [f000:d189] 0xfd189:\tor $0x1,%eax [f000:d18d] 0xfd18d:\tmov %eax,%cr0 ;重新加载全局描述符GDT 0xfd190:\tljmpl $0x8,$0xfd198 0xfd198:\tmov $0x10,%ax 0xfd19b:\tadd %al,(%bx,%si) 0xfd19d:\tmov %ax,%ds 0xfd19f:\tmov %ax,%es 0xfd1a1:\tmov %ax,%ss 0xfd1a3:\tmov %ax,%fs  重新加载的 x86汇编复习 外围设备端口  软盘硬盘 磁盘的最小传输单元(sector)： 512bytes 16位机，在CD-ROM启动之前，后被扩展。xv6使用传统硬盘,512bytes/sector boot sector 在开机时被读入物理地址为 0x7c00 ~ 0x7dff\n Exercise 3  在0x7c00设置断点,对比源代码boot/boot.S，GDB，反汇编文件obj/boot/boot.asm 跟随boot/main.c文件的bootmain()函数到readsect()函数，弄清楚readsect()中的指令直至返回到bootmain()，确认从磁盘中读取kernel的for循环。跟随到bootloader完成引导。  boot/boot.S: 源代码 obj/boot/boot.asm: 反汇编代码 boot/main.c: 加载kernel的C代码\n boot.S 打开/lab/boot可以看到一段注释，CPU启动后，切换至保护模式。BIOS把磁盘第一个扇区读入内存0x7c00处，并且在实模式下执行，将CS:IP指向0:7c00。 代码基本有注释，有几个点得注意下:\ninb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.2  将外围设备0x64端口读1byte？到al中，0x64端口的第1位的 bit 1 = 1 input buffer full (input 60/64 has data for 8042)判断输入缓冲区是不是满的，再用test和jnz来循环等待。\nmovb $0xd1,%al # 0xd1 -\u0026gt; port 0x64 outb %al,$0x64  下次下入0x60的数据将会写入804x控制器。\nmovb $0xdf,%al # 0xdf -\u0026gt; port 0x60 outb %al,$0x60  0xdf写入到0x60中，让地址线A20使能，开启32位保护模式。\nlgdt gdtdesc  加载全局描述表，具体见:http://www.cnblogs.com/fatsheep9146/p/5115086.html\nljmp $PROT_MODE_CSEG, $protcseg  关于这个跳转有一个好的解释如下图。 是保护模式下的跳转方法。\nmovl $start, %esp  esp的值设置为0x7c00,准备开始执行boot loader 。\n main.c 在这个文件内补充了一个启动过程和DISK的排布: disk layout\n  boot.S和main.c是启动器，存储在磁盘的第一个扇区。\n  第二个扇区存储内核镜像。\n  内核镜像必须是ELF文件格式。 BOOT UP STEPS\n  CPU读取BIOS到内存中并且执行。\n  BIOS初始化设备，中断历程，并且读取第一个扇区并且跳转执行。\n  如果boot loader存储在第一个扇区，那么cpu由其接管。\n  boot.S开启保护模式，设置栈空间，调用bootmain()。\n  然后bootmain()接管cpu，读取内核并且跳转。\n#define ELFHDR ((struct Elf *) 0x10000) // scratch space ELFHDR为一个固定值 0x10000\nreadseg((uint32_t) ELFHDR, SECTSIZE8, 0); 把磁盘中的ELF文件头(5128=4MB？待解决)读到内存0x10000\nph = (struct Proghdr *) ((uint8_t *) ELFHDR + ELFHDR-\u0026gt;e_phoff); Proghdr结构体类型指针ph,指向Program Table表头\neph = ph + ELFHDR-\u0026gt;e_phnum; 指向表尾\nfor (; ph \u0026lt; eph; ph++) readseg(ph-\u0026gt;p_pa, ph-\u0026gt;p_memsz, ph-\u0026gt;p_offset); 根据这从磁盘读出的4MB ELF文件头，再从磁盘中读取ELF文件的数据段，代码段\u0026hellip;.\n((void (*)(void)) (ELFHDR-\u0026gt;e_entry))(); 暂时不清楚，跳到elf文件执行入口？\n   The ELF file contains headers that describe how these sections should be stored in memory .\n ELF文件: /ELF文件/ wiki-ELF: https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n GDB调试  readsect() 7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx  保存寄存器信息\n7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc \u0026lt;readseg\u0026gt;  偏移0x0,大小0x1000(512x8),装载的内存地址0x10000\n7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx   因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存\u0026gt;放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2\u0026gt;个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待)\n 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0\n7cee: 01 de add %ebx,%esi  从内存的开始到第一个扇区的结束。\n7cf0: 47 inc %edi  edi+1\n7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d \u0026lt;readseg+0x31\u0026gt;  while的判断条件。\ncall readsect call waitdisk ret   outb() 返回后直接进入 outb()中\noutb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset \u0026gt;\u0026gt; 8); outb(0x1F5, offset \u0026gt;\u0026gt; 16); outb(0x1F6, (offset \u0026gt;\u0026gt; 24) | 0xE0); outb(0x1F7, 0x20);  \u0026ldquo;通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。\u0026rdquo;\n insl() 7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx  edi = 0x10000 ecx = 0x80 edx = 0x1f0\nrepnz insl (%dx),%es:(%edi)  repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前\n执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。\n GDB查看内存信息: x/12xb 0x10000\n 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 \u0026lt;readseg+0x1b\u0026gt;  把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束\n7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret  恢复栈寄存器，返回到bootmain()\n if判断 7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 \u0026lt;bootmain+0x5c\u0026gt;  7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,\u0026lsquo;L\u0026rsquo;,\u0026lsquo;E\u0026rsquo;,0X7F。 7d38在文件内容不符合的条件下跳转。\n for循环读取 7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi  分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。\n7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx  切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。\n7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi  设定Program Table Headers结束地址？\n7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc \u0026lt;readseg\u0026gt;  这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。\n 内核跳转 7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-\u0026gt;e_entry))();  最后一步，转到内核的开始点。\n BIOS启动-\u0026gt;保护模式-\u0026gt;读取第一个扇区到内存-\u0026gt;跳转至0x7c00地址执行bootstrap-\u0026gt;加载磁盘中的系统内核elf文件到0x10000 -\u0026gt; 最后跳转到内核开始处。\n  问题   At what point does the processor start executing 32-bit code? What exactly causes the switch from 16- to 32-bit mode?\nmovl %cr0, %eax orl $CR0_PE_ON, %eax movl %eax, %cr0 开启cr0寄存器最低位\n  What is the last instruction of the boot loader executed, and what is the first instruction of the kernel it just loaded?\n   movl $start, %esp ; bootloader开始地址压栈 push %ebp ;准备readseg()的参数   Where is the first instruction of the kernel? 0x1000c How does the boot loader decide how many sectors it must read in order to fetch the entire kernel from disk? Where does it find this information? 在elf文件中，首先宏定义了一个结构体指针指向elf文件在内存中的加载处，然后利用elf文件提供的信息加载Program table Headers所指定的信息。ELFHDR-\u0026gt;e_phnum这个偏移加上基础地址就得到了文件头的个数。  Exercise 4 pointer.c c[1] = 300; *(c + 2) = 301; 3[c] = 302;  第三个输出的地方，有一个没有接触过的数组访问方法 “3[c]”的结果和“c[3]”的结果一样，有点类似于at\u0026amp;t汇编中的 mov 0x3(%ebx),eax ，也许是衍生出来的一种形式。\nb = (int *) a + 1; c = (int *) ((char *) a + 1);  b为一个为整形指针，b的值+1，int指针的值+4 而c为char形，c值+1，char形指针+1\nELF 查看文件头\nobjdump -h obj/kern/kernel objdump -x obj/kern/kernel  kernel Program Header:\nLOAD off 0x00001000 vaddr 0xf0100000 paddr 0x00100000 align 2**12 filesz 0x00007120 memsz 0x00007120 flags r-x LOAD off 0x00009000 vaddr 0xf0108000 paddr 0x00108000 align 2**12 filesz 0x0000a300 memsz 0x0000a944 flags rw-  STACK off 0x00000000 vaddr 0x00000000 paddr 0x00000000 align 2**4 filesz 0x00000000 memsz 0x00000000 flags rwx\nvadd(virturl address),paddr(physical address),LOAD(ELF object need to be loaded) align的大小表示是我在用python的时候想起来的，2**n 表示的是 2^n次方。\nExercise 5  LOAD address and LINKER address\n 关于link address 和load address,我在网上找到这样一个说法: load address，表示一个已确定对象的实际加载地址。如C中可执行程序的main函数的地址，在编译完成的时候其地址已经确认（当然在系统中这是一个逻辑地址） link address，表示一个未确定对象的应该加载的地址。如你使用C动态库中的printf函数的地址。在编译完成的时候不能确定其地址，因为它的实体是在动态链接库中，只能给它规定一个应该加载的地址，在程序加载的时候才能真正确认是否可以加载在这个地址上（可能出现动态库找不到的情况，这时候就加载错误了） VMA为link address,程序开始执行的地方；LMA为load address,将会被bootloader读取到的内存地址。\n跟着这个链接，改变boot/Makefrag的文件内容，原文件内容\n改-Ttext的参数，从0x7c00改为0x7e00\n原boot.asm(make后产生的)变为\n每个命令在这个asm文件内的地址都发生了变化。\n跟踪bootstrap,设置断点在0x7c00,si执行几步。\nlgdtw 0x7e64,本应该加载0x7c64的,但是内存区域内容没有内容\nljmp $0x8,$0x7e32,这是跳转到保护模式程序段的跳转命令，但是跳转失败\n我改变了boot/Makefrag中-Ttext的参数，把boot loader的link地址从0x7c00改成了0x7e00。由make命令从boot.S生成到boot.asm的文件中，命令的地址都发生了变化，但是BIOS默认读取boot到地址0x7c00，但是代码的性质，例如lgdtw加载全局描述符命令，已经发生了改变。代码本应被读到0x7e00执行，实际是在0x7c00执行，到最后一步一步的出错。\nExercise 6 objdump -f obj/kern/kernel 得到内核ELF文件中程序入口 0x0010000c\n这个练习的问题是：在0x7c00这个位置和在bootloader进入kernel的时候为什么从0x10000开始，8 word长的内存中内容不同？ 因为bootloader已经readseg()这个函数的时候，将ELF从磁盘读到了0x10000这个地址了。 (还是没弄清如何确认读多少个扇区)\n Exercise 7  kern/kernel.ld 存放link address 和load address ld文件格式：https://www.math.utah.edu/docs/info/ld_3.html  entry_pgdir 将虚拟地址0xf0000000~0xf0400000 映射到 0x00000000~0x00400000\n 文件 kern/entry.S\n 根据练习的引导，将断点设置在mov eax,cr0处，查看0x00100000和0xf0100000的内存空间。 运行前：\n运行后：\n地址0xf0100000被映射成功了，与0x00100000地址处内容相同。\n注释执行这个程序，往后面看几条汇编：\n0x100025:\tmov $0xf010002c,%eax 0x10002a:\tjmp *%eax  程序将会跳转到0xf010002c这个地址去，但是用gdb查看这个地址并没有指令：\n程序就会往非预期的方向前进。\n Exercise 8 阅读三个c文件： kern/printf.c lib/printfmt.c kern/console.c\n从文件名上猜测，printf文件应该是实现输出的主体，printfmt.c应该是一个写满方法的库，console.c应该和shell类似，输出内容和交互的主体。\nconsole.c cons_putc() 先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。\nstatic void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序：\nserial_putc() static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026amp; COM_LSR_TXRDY) \u0026amp;\u0026amp; i \u0026lt; 12800; i++) delay(); outb(COM1 + COM_TX, c); } COM1 + COM_LSR = 0x03FD ，COM_LSR_TXRDY = 0x20 = 0010 0000 根据这个链接查询端口，(inb(COM1 + COM_LSR) \u0026amp; COM_LSR_TXRDY)这一个判断条件就是取串口寄存器的第五位，判断transmitter holding register是否为空。 COM1 + COM_TX = 0X03F8 用for循环最多12800次来等待串口寄存器为空，然后执行outb，将参数 c 写入到串口transmitter holding register保存数据。\nlpt_putc() static void lpt_putc(int c) { int i; for (i = 0; !(inb(0x378+1) \u0026amp; 0x80) \u0026amp;\u0026amp; i \u0026lt; 12800; i++) delay(); outb(0x378+0, c); outb(0x378+2, 0x08|0x04|0x01); outb(0x378+2, 0x08); } 0378-037A 被叫做并行打印端口（parallel printer port） 0x378 : 数据端口 | 0x37A : 控制端口 !(inb(0x378+1) \u0026amp; 0x80) 用来判断端口是否闲置 outb(0x378+0, c); 写进数据端口？ 接下来，对输出进行初始化等，具体不明确。 bit 3 = 1 select printer bit 2 = 0 initialize printer bit 1 = 1 automatic line feed bit 0 = 1 strobe\ncga_putc() static void cga_putc(int c) { // if no attribute given, then use black on white \tif (!(c \u0026amp; ~0xFF)) c |= 0x0700; switch (c \u0026amp; 0xff) { ... } } 这种形式和颜色表示有关，一部分比特位控制背景颜色，一部分控制前景颜色，还有一部分负责字符数据。\ncga的相关注释\n以及what-is-the-function-of-0x0700-in-cga-putc\nif (crt_pos \u0026gt;= CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i \u0026lt; CRT_SIZE; i++) crt_buf[i] = 0x0700 | \u0026#39; \u0026#39;; crt_pos -= CRT_COLS; } 这段代码的作用当显示坐标超出了整个console的大小时进行的操作，先用memmove函数crt_buf + CRT_COLS复制crt_buf处，复制长度为CRT_SIZE - CRT_COLS，也就是把页面往上推了一行。然后在for循环中，将最后一行清空。\nvprintfmt vprintfmt(void (putch)(int, void), void *putdat, const char fmt, va_list ap) void (putch)(int, void): void (int, void ) 类型函数指针 putdat: 输出字符地址的指针 fmt : 指向格式化字符串 ap： 额外的参数 printf(fmt, ap);\nprint.c #include \u0026lt;inc/types.h\u0026gt;#include \u0026lt;inc/stdio.h\u0026gt;#include \u0026lt;inc/stdarg.h\u0026gt; static void putch(int ch, int *cnt) { cputchar(ch); *cnt++; } int vcprintf(const char *fmt, va_list ap) { int cnt = 0; vprintfmt((void*)putch, \u0026amp;cnt, fmt, ap); return cnt; } int cprintf(const char *fmt, ...) { va_list ap; int cnt; va_start(ap, fmt); cnt = vcprintf(fmt, ap); va_end(ap); return cnt; } cprintf(\u0026ldquo;string\u0026rdquo;, arg1, arg2)这个函数的调用方法和printf相似，应该就是最终调用函数。 关于ap这个变量，由下面这个程序：\n#include \u0026lt;stdarg.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; int sum(int, ...); int main() { printf(\u0026#34;sum :%d\\n\u0026#34;, sum(4, 15, 56, 10, 22) ); return 0; } int sum(int num_args, ...) { int val = 0; va_list ap; int i; printf(\u0026#34;%d\\n\u0026#34;, num_args); va_start(ap, num_args); for(i = 0; i \u0026lt; num_args; i++) { val += va_arg(ap, int); } va_end(ap); return val; }  补充十进制输出符号 “%o” 的代码片段  根据之前10进制的改就好了:\nnum = getuint(\u0026amp;ap, lflag); base = 8; goto number  题目:\n  Explain the interface between printf.c and console.c. Specifically, what function does console.c export? How is this function used by printf.c? printer.c中的函数是三个主要函数，cprintf()基本上算是c语言中printf()的复刻版，调用顺序：cprintf() -\u0026gt; vcprintf() -\u0026gt; putch() ,调用putch的时候就会发现会要用到console.c中接触底层的函数\tserial_putc(c)判断串口为空，lpt_putc(c)判断并行读写？cga_putc(c)负责最后的输出。\n  Explain the following from console.c: 已分析。\n  For the following questions you might wish to consult the notes for Lecture 2. These notes cover GCC\u0026rsquo;s calling convention on the x86. Trace the execution of the following code step-by-step:\nint x = 1, y = 3, z = 4; cprintf(\u0026ldquo;x %d, y %x, z %d\\n\u0026rdquo;, x, y, z);\n    In the call to cprintf(), to what does fmt point? To what does ap point?\n  List (in order of execution) each call to cons_putc, va_arg, and vcprintf. For cons_putc, list its argument as well. For va_arg, list what ap points to before and after the call. For vcprintf list the values of its two arguments.\n1.fmt-\u0026gt; \u0026ldquo;x %d, y %x, z %d\\n\u0026rdquo; , ap 应该是 x,y,z的集合 2.va_arg这个调用,是每次从ap这个list中取一个值，比如原来参数列表中有x, y, z三个参数, va_arg(ap, int)调用一次，就会取出一个参数x，原列表a中只剩y, z了 参考链接：http://www.cnblogs.com/fatsheep9146/p/5070145.html\n  Run the following code. unsigned int i = 0x00646c72; cprintf(\u0026ldquo;H%x Wo%s\u0026rdquo;, 57616, \u0026amp;i); What is the output? The output depends on that fact that the x86 is little-endian. If the x86 were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?  while (1) { while ((ch = *(unsigned char *) fmt++) != \u0026#39;%\u0026#39;) { if (ch == \u0026#39;\\0\u0026#39;) return; putch(ch, putdat); } 1.首先这一个循环输出所有普通字符，直到fmt指到 %(开始switch) 和 \\0(结束输出) 符号， 2.先是\u0026rsquo;x'16进制格式\ncase 'x': num = getuint(\u0026amp;ap, lflag); base = 16;  getuint函数:\nstatic unsigned long long getuint(va_list *ap, int lflag) { if (lflag \u0026gt;= 2) return va_arg(*ap, unsigned long long); else if (lflag) return va_arg(*ap, unsigned long); else return va_arg(*ap, unsigned int); } 返回一个根据ap列表中的参数,类型由flag控制。flag的值由\u0026rsquo;l\u0026rsquo;来自增,例如: \u0026ldquo;ld\u0026rdquo; ,\u0026ldquo;lld\u0026rdquo; 再调用 printnum(putch, putdat, num, base, width, padc); 这是个递归函数，根据base进制等参数输出数字。\n3.再是'%s\u0026rsquo;格式,输出参数i所在地址的字符串。\n57616 = 0xe110 ,所以会输出He110 x86是little-endian, i = 0x00646c72 , 实际在内存中存储是 72 6c 64 00 ,即 \u0026lsquo;r\u0026rsquo;, \u0026lsquo;l\u0026rsquo;, \u0026rsquo;d', \u0026lsquo;\\0\u0026rsquo; 最后的输出结果应该为: \u0026ldquo;He110 Worlds\u0026rdquo;\nIn the following code, what is going to be printed after \u0026lsquo;y=\u0026rsquo;? (note: the answer is not a specific value.) Why does this happen? cprintf(\u0026ldquo;x=%d y=%d\u0026rdquo;, 3);  这个问题和va_arg调用有关\n#include \u0026lt;stdarg.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; int out_range(int, ...); int main() { out_range(2,11,2); return 0; } int out_range(int num, ...) { int val = 0; int i; va_list ap; va_start(ap, num); for(i = 0; i \u0026lt; 3; ++i) { val = va_arg(ap, int); printf(\u0026#34;%d\\n\u0026#34;,val); } va_end(ap); } ### result 11 2 1577856 情况和数组越界类似。\nExercise 9 内核什么时候初始化堆栈，堆栈在内存的什么地方，内核如何为堆栈保留空间，哪一个指针指向堆栈的结束处？ 在内核的入口设置断点，跟随几条指令： mov $0x0,%ebp mov $0xf0110000,%esp call 0xf0100094 \u0026lt;i386_init\u0026gt; esp指向栈顶指针,entry.S最后定义了bootstrap的大小KSTKSIZE = 8 * PGSIZE = 8 * 4096 = 32KB 所以堆栈位于内存的0x0010800 ~ 0x0011000,堆栈向下增长,esp指向栈顶\nExercise 10-12 每个函数调用时，父函数先将参数压栈，使用call命令的时候，将eip压栈。然后进入子函数的时候，将原来的ebp压栈，把esp赋值给ebp，此时两寄存器都指向同一个地址。 接下来，子函数为程序分配内存空间，栈向下增长，即将esp减去一个值。 内存结构就是：\n+-----+ | ... | +-----+ | arg3| +-----+ | arg2| +-----+ | arg1| +-----+ | eip | +-----+ | ebp | +-----+\u0026lt;-(ebp) |unkn | +-----+\u0026lt;-(esp) int mon_backtrace(int argc, char **argv, struct Trapframe *tf) { // Your code here.  uint32_t *ebp = (uint32_t*)read_ebp(); struct Eipdebuginfo info; cprintf(\u0026#34;Stack backtrace:\\n\u0026#34;); for(; ebp != 0; ebp = (uint32_t*) *ebp) { cprintf(\u0026#34; ebp %x eip %x args %08x %08x %08x %08x %08x\\n\u0026#34;, ebp, *(ebp+1), *(ebp+2), *(ebp+3), *(ebp+4), *(ebp+5), *(ebp+6)); if(debuginfo_eip(*(ebp+1),\u0026amp;info) == 0) cprintf(\u0026#34; %s:%d: %.*s+%d\\n\u0026#34;, info.eip_file, info.eip_line, info.eip_fn_namelen, info.eip_fn_name, *(ebp+1) - info.eip_fn_addr); } return 0; } 接下来要补全debuginfo_eip()中二分查找行的操作，根据前面的代码和提示，补全代码。 stabs文档:http://www.sourceware.org/gdb/onlinedocs/stabs.html#Stab-Sections\nstab_binsearch(stabs, \u0026amp;lline, \u0026amp;rline, N_SLINE, addr); if(lline \u0026lt;= rline) { info-\u0026gt;eip_line = stabs[lline].n_desc; } else { return -1; } 最后一步是输出调试信息，debuginfo_eip()是通过结构体Eipdebuginfo的成员值来返回的。 这个结构体的定义在kern/kdebug.h中，根据结构体定义信息用cprintf输出就行了。练习最后提示了printf(\u0026quot;%.*s\u0026quot;,stringlength ,string)对练习中函数名输出有帮助。\n$ make grade\n总结  开机时候，ip指向一个高地址，执行跳转命令到BIOS的程序段，通过BIOS将磁盘的Boot加载到内存地址0x7c00处。 Boot程序加载全局描述符，将外围设备使能。进入保护模式，将扇区已ELF文件形式存在的系统内核加载到物理地址0x10000处，再通过ELF文件的程序入口，跳转到内核。 内核开始时候，打开分页操作，分配堆栈，并将物理地址从0x10000映射到虚拟地址0xf010000处。 最后就是理解系统调用时，堆栈的变化，还有修改一些类似printf函数的功能。  ","date":"March 14, 2018","hero":"/images/default-hero.jpg","permalink":"/posts/course-notes/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/","summary":"3月14日 - 3月28日\n Exercise 1 熟悉x86汇编和AT\u0026amp;T汇编\n16-bit intel 8088 1MB = 1048576bit 内存地址: 0x00000 ~ 0xFFFFF 640KB(0x00000 ~ 0xA0000) 用户可用 参考资料\nGDB启动过程 首先打开一个终端到目的lab根文件夹 $ make qemu-nox-gdb 再打开一个新的终端窗口执行以下命令进行监听 $ make gdb\n以及一些常用的gdb命令 b: 0xffff: 在0xffff出下断点 c: continue to breakpoint si: 单步前进 x/5: 0xFFFFF 从0xFFFFF开始的5个命令\n Exercise 2 第一条指令: [f000:fff0] 0xffff0:\tljmp $0xf000,$0xe05b 当处理器重置时，会进入实模式并将CS设置为0xf000，IP设置为0xfff0(CS:IP=0xffff0)。 这个地址与BIOS的结束位置0x100000差16bytes。\n启动后追踪BIOS的部分代码 [f000:e05b] 0xffff0:\tljmp $0xf000,$0xe05b [f000:e05b] 0xfe05b:\tcmpl $0x0,%cs:0x6c48\t;把0与cs:6c48所指向内存的值比较 [f000:e062] 0xfe062:\tjne 0xfd2e1 ;与CS:0x6c48(f6c48)处的值与0比较，不是0跳转 [f000:e066] 0xfe066:\txor %dx,%dx ;dx清0 [f000:e068] 0xfe068:\tmov %dx,%ss ;ss置0,AT\u0026amp;T汇编mov指令反向 [f000:e06a] 0xfe06a:\tmov $0x7000,%esp ;esp设置为0x7000,实模式引导区位置 [f000:e070] 0xfe070:\tmov $0xf3691,%executed ;edx设置为0xf3691 [f000:e076] 0xfe076:\tjmp 0xfd165 ;跳转 0xfd165 [f000:d165] 0xfd165:\tmov %eax,%ecx [f000:d168] 0xfd168:\tcli ;屏蔽中断 [f000:d169] 0xfd169:\tcld ;DF设置为0，指在每次传送一次将esi和edi自动+1;std将DF设置为1,传送自减 [f000:d16a] 0xfd16a:\tmov $0x8f,%eax [f000:d170] 0xfd170:\tout %al,$0x70 ;将al中的值0x8f输出到外部设备0x70端口,NMI不可屏蔽中断使能位为1 [f000:d172] 0xfd172:\tin $0x71,%al ;将0x71端口的值输出到al,GDB查看寄存器信息看见eax值被清0 ;A20地址线使能,进入保护模式 [f000:d174] 0xfd174:\tin $0x92,%al [f000:d176] 0xfd176:\tor $0x2,%al [f000:d178] 0xfd178:\tout %al,$0x92 ;加载6个字节 [f000:d17a] 0xfd17a:\tlidtw %cs:0x6c38 ;加载中断向量表 -\u0026gt;idt寄存器 [f000:d180] 0xfd180:\tlgdtw %cs:0x6bf4 ;加载全局描述符表-\u0026gt;gdt寄存器 ;cr0寄存器置为1，进入保护模式 [f000:d186] 0xfd186:\tmov %cr0,%eax [f000:d189] 0xfd189:\tor $0x1,%eax [f000:d18d] 0xfd18d:\tmov %eax,%cr0 ;重新加载全局描述符GDT 0xfd190:\tljmpl $0x8,$0xfd198 0xfd198:\tmov $0x10,%ax 0xfd19b:\tadd %al,(%bx,%si) 0xfd19d:\tmov %ax,%ds 0xfd19f:\tmov %ax,%es 0xfd1a1:\tmov %ax,%ss 0xfd1a3:\tmov %ax,%fs  重新加载的 x86汇编复习 外围设备端口  软盘硬盘 磁盘的最小传输单元(sector)： 512bytes 16位机，在CD-ROM启动之前，后被扩展。xv6使用传统硬盘,512bytes/sector boot sector 在开机时被读入物理地址为 0x7c00 ~ 0x7dff","tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC"},{"categories":["汇编语言"],"contents":"为了循环方便，我们设置SI为**-1**\nmov si,0FFFFh 我们数据判断ASCII值的大小，也就是CX的大小，通过CMP来设置标志位\nmov ax,97 cmp cx,ax jb s 相当于:** cx \u0026gt; 97 ? 继续执行 : 跳转 **\nmov ax,122 cmp cx,ax ja s 相当于:** cx \u0026lt; 122 ? 继续执行 : 跳转 **\n全部代码如下:\nassume cs:code data segment db \u0026#34;Beginner\u0026#39;s All-purpose Sybolic Instruction Code.\u0026#34;,0 data ends code segment begin: mov ax,data mov ds,ax mov si,0FFFFh call letterc mov ax,4c00h int 21h letterc: nop s:\tinc si mov cl,ds:[si] mov ch,0 jcxz break mov ax,97 cmp cx,ax jb s mov ax,122 cmp cx,ax ja s and cx,11011111b mov byte ptr ds:[si],cl loop s break: ret code ends end begin 实验结果如下：\n","date":"November 22, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab11/","summary":"\u003cp\u003e为了循环方便，我们设置\u003cstrong\u003eSI\u003c/strong\u003e为**-1**\u003c/p\u003e","tags":["Assembly"],"title":"《汇编语言》 Lab11"},{"categories":["汇编语言"],"contents":"实验10 一共3个小实验，分别完成三个函数。\n显示字符串 第一个很简单，详细可见Lab9\n代码如下:\nassume cs:codesg data segment db \u0026#34;welcome to masm!\u0026#34;,0 data ends codesg segment start: mov dh,8 mov dl,3 mov cl,2 mov ax,data mov ds,ax mov si,0 call show_str mov ax,4c00h int 21h show_str: mov al,dh mov bl,160 mul bl mov bx,ax ;行数 \tmov al,2 mul dl mov di,ax ;列数 \tmov ax,0B800h mov es,ax s: mov cl,ds:[si] mov ch,0 jcxz short break mov byte ptr es:[bx+di],cl mov byte ptr es:[bx+di+1],01110010b inc si add di,2 loop s break: nop\tret codesg ends end start 程序编译执行后的结果:\n解决除法溢出问题 计算公式:int(H/N)*65536 + [rem(H/N)+L]/N H:高八位 L:低八位 N:除数 int():取商 rem():取余\n代码如下:\nassume cs:codesg,ss:stack stack segment dw 0 stack ends codesg segment start: mov ax,4240h mov dx,000Fh mov cx,0Ah call divdw mov ax,4c00h int 21h divdw: mov bx,stack mov ss,bx mov sp,2 push ax ;先完成高八位的除法 \tmov ax,dx mov dx,0 div cx ;此时，dx中为余数，ax中为高位的商. \tpop bx push ax mov ax,bx ;ax为低八位的数值，dx为H/N的余数 \tdiv cx ;进行16位除法 \t;此时，dx最终结果的余数，ax中为低位的商  pop bx mov cx,dx mov dx,bx ret codesg ends end start 实验结果如下: ** DX = 0001H , AX = 86A0H , CX = 0 **\n数据显示 仔细观察下数据12666，在除法操作后，商为1266 \u0026gt; 2^8，所以得进行**16位除法 **\nmov dx,0 mov bx,10 div bx 整除后，dx为余数，ax中为商。 因为除10，余数为个位数，用dl的大小可传送数值.\nadd dl,30h mov byte ptr ds:[si],dl 由于进行除法后，余数是顺序存储，所以字符串是逆序的。 字符串尾是ds的开头，开始时，我们需要设置 ** si=1 ** 。\n除法的循环不是用的loop指令，而是直接用jmp指令是因为loop指令会对cx操作 而这段代码中，cx是来判断最后的商是否为0。 如果cx被传送的商为1，loop操作会使cx减1，此时cx变为0，直接结束了循环操作。\n全部代码如下:\nassume cs:code data segment db 10 dup(0) data ends code segment start: mov ax,12666 mov bx,data mov ds,bx mov si,1 call dtoc mov dh,8 mov dl,3 mov cl,2 call show_str mov ax,4c00h int 21h dtoc: mov dx,0 mov bx,10 sd:\tdiv bx ;进行16位除法，dx为余数，ax中为商 \tadd dl,30h ;数字加上30h为ASCII的值 \tmov byte ptr ds:[si],dl mov cx,ax jcxz short break mov dx,0 inc si jmp short sd ; 在这使用jmp而不适用loop  break: ret show_str: mov al,dh mov bl,160 mul bl mov bx,ax ;行数 \tmov al,2 mul dl mov di,ax ;列数 \tmov ax,0B800h mov es,ax mov al,cl s3: mov cl,ds:[si] jcxz short break2 mov byte ptr es:[bx+di],cl mov byte ptr es:[bx+di+1],al sub si,1 ;逆序输出 \tadd di,2 loop s3 break2: nop\tret code ends end start 如图，测试结果\n","date":"November 21, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab10/","summary":"\u003cp\u003e实验10 一共3个小实验，分别完成三个函数。\u003c/p\u003e","tags":["Assembly"],"title":"《汇编语言》 Lab10"},{"categories":["汇编语言"],"contents":"assume cs:codesg codesg segment mov ax,4c00h int 21h start: mov ax,0 s: nop nop mov di,offset s mov si,offset s2 mov ax,cs:[si] mov cs:[di],ax s0: jmp short s s1: mov ax,0 int 21h mov ax,0 s2: jmp short s1 nop codesg ends end start 其中\njmp short s 命令占用两个字节\n","date":"November 17, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab8/","summary":"assume cs:codesg codesg segment mov ax,4c00h int 21h start: mov ax,0 s: nop nop mov di,offset s mov si,offset s2 mov ax,cs:[si] mov cs:[di],ax s0: jmp short s s1: mov ax,0 int 21h mov ax,0 s2: jmp short s1 nop codesg ends end start 其中\njmp short s 命令占用两个字节","tags":["Assembly"],"title":"《汇编语言》 Lab8"},{"categories":["汇编语言"],"contents":"前言 王爽老师的《汇编语言》中练习习题8中，有要求在DOS实模式下操作汇编代码。 之前一直用的是windows 2003的CMD中自带的debug调试，所以趁这次机会，把DOS环境搭建一下。\n安装 安装方法和普通ISO文件安装方法差不多，首先选择ISO文件、对应的操作系统，然后用vmware的默认硬件甚至一步一步确定就行。\n接下来，启动虚拟机，会弹出一个选择页面，等待一段时间后会自动跳转到安装界面。\n然后会提示重新启动，跟着提示来，会提示一个错误：\n这应该是DOS支持的磁盘格式为FAT32，而现在的windows支持的硬盘格式是NTFS，两者格式不兼容导致的。 我们关闭虚拟机重新启动下，在下面这个界面按F2进入BIOS设置首先启动项：\n修改启动项 跟着以下步骤操作： img [class names] 1. → 移动选项卡至 \u0026lsquo;boot\u0026rsquo; 2. ↓ 移动选项至 \u0026lsquo;CD-ROM Drive\u0026rsquo; 3. 按住 \u0026lsquo;shift\u0026rsquo; 和 \u0026lsquo;+\u0026rsquo; 将选中的CD-ROM Drive向上移动 4. 按F10保存退出\n此时该虚拟机会重新启动，然后重新进入安装界面。 根据提示，一步一步按确定，基本都是肯定选项。 [注意]直到提示关于 \u0026lsquo;Adds-On\u0026rsquo; 额外的软件安装，在这里我们选择 \u0026lsquo;Cancel\u0026rsquo; 取消，不进行额外的操作。\n如图可见，安装成功，重新启动。 重新启动后发现，还是进入的安装界面，这是因为之前在BIOS内设置过优先启动项的缘故。 和之前的操作一样，在vmware动画界面按F2进入BIOS，用组合键 shift 和 - 将CD-ROM Drive恢复到原来的位置(默认是第三个)。\n好了，到现在完成了DOS的安装了，但是还有个问题，就是VMware并没有给DOS提供vmtools，所以物理机和虚拟机之间传输文件并不方便。\n文件传输 首先，我们先关闭DOS虚拟机，然后在左侧硬件配置处点击硬盘。\n根据红色箭头提示，点击映射。\n然后把**\u0026ldquo;以只读文件模式打开文件\u0026rdquo;**前面的勾去掉，然后关闭警告，打开我的电脑，可以发现本地多出一个磁盘\n打开后可以看到DOS的实际文件，也就是说，我们可以直接对DOS的文件进行操作。 我们可以把自己的要编译的汇编代码放进去。(图中\u0026quot;lab8.asm\u0026quot;)\n再断开连接，否则DOS将无法启动。 最后，我们再验证一下。\n如图，纯DOS系统里已经有了自己放进去的文件。\n DOS 7.10.iso 云盘链接 : http://pan.baidu.com/s/1slPZQot 密码: x0ht\n ","date":"November 17, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/","summary":"前言 王爽老师的《汇编语言》中练习习题8中，有要求在DOS实模式下操作汇编代码。 之前一直用的是windows 2003的CMD中自带的debug调试，所以趁这次机会，把DOS环境搭建一下。\n安装 安装方法和普通ISO文件安装方法差不多，首先选择ISO文件、对应的操作系统，然后用vmware的默认硬件甚至一步一步确定就行。\n接下来，启动虚拟机，会弹出一个选择页面，等待一段时间后会自动跳转到安装界面。\n然后会提示重新启动，跟着提示来，会提示一个错误：\n这应该是DOS支持的磁盘格式为FAT32，而现在的windows支持的硬盘格式是NTFS，两者格式不兼容导致的。 我们关闭虚拟机重新启动下，在下面这个界面按F2进入BIOS设置首先启动项：\n修改启动项 跟着以下步骤操作： img [class names] 1. → 移动选项卡至 \u0026lsquo;boot\u0026rsquo; 2. ↓ 移动选项至 \u0026lsquo;CD-ROM Drive\u0026rsquo; 3. 按住 \u0026lsquo;shift\u0026rsquo; 和 \u0026lsquo;+\u0026rsquo; 将选中的CD-ROM Drive向上移动 4. 按F10保存退出\n此时该虚拟机会重新启动，然后重新进入安装界面。 根据提示，一步一步按确定，基本都是肯定选项。 [注意]直到提示关于 \u0026lsquo;Adds-On\u0026rsquo; 额外的软件安装，在这里我们选择 \u0026lsquo;Cancel\u0026rsquo; 取消，不进行额外的操作。\n如图可见，安装成功，重新启动。 重新启动后发现，还是进入的安装界面，这是因为之前在BIOS内设置过优先启动项的缘故。 和之前的操作一样，在vmware动画界面按F2进入BIOS，用组合键 shift 和 - 将CD-ROM Drive恢复到原来的位置(默认是第三个)。\n好了，到现在完成了DOS的安装了，但是还有个问题，就是VMware并没有给DOS提供vmtools，所以物理机和虚拟机之间传输文件并不方便。\n文件传输 首先，我们先关闭DOS虚拟机，然后在左侧硬件配置处点击硬盘。\n根据红色箭头提示，点击映射。\n然后把**\u0026ldquo;以只读文件模式打开文件\u0026rdquo;**前面的勾去掉，然后关闭警告，打开我的电脑，可以发现本地多出一个磁盘\n打开后可以看到DOS的实际文件，也就是说，我们可以直接对DOS的文件进行操作。 我们可以把自己的要编译的汇编代码放进去。(图中\u0026quot;lab8.asm\u0026quot;)\n再断开连接，否则DOS将无法启动。 最后，我们再验证一下。\n如图，纯DOS系统里已经有了自己放进去的文件。\n DOS 7.10.iso 云盘链接 : http://pan.baidu.com/s/1slPZQot 密码: x0ht\n ","tags":["Assembly"],"title":"DOS实模式的搭建"},{"categories":["汇编语言"],"contents":"datasg segment db \u0026#39;1. display \u0026#39; db \u0026#39;2. brows \u0026#39; db \u0026#39;3. replace \u0026#39; db \u0026#39;4. modify \u0026#39; datasg ends 将数据段前四个字母改为大写字母 \u0026amp;nbsp代码如下:\nassume cs:codesg,ss:stacksg,ds:datasg stacksg segment dw 0,0,0,0,0,0,0,0 stacksg ends datasg segment db \u0026#39;1. display \u0026#39; db \u0026#39;2. brows \u0026#39; db \u0026#39;3. replace \u0026#39; db \u0026#39;4. modify \u0026#39; datasg ends codesg segment start: mov ax,stacksg mov ss,ax mov sp,16 mov ax,datasg mov ds,ax mov cx,4h mov bx,0 s1:\tpush cx mov cx,4 mov si,0 s2:\tmov al,[bx+3+si] and al,11011111b mov [bx+3+si],al inc si loop s2 add bx,16 pop cx loop s1 mov ax,4c00h int 21h codesg ends end start\t","date":"November 13, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab6/","summary":"datasg segment db \u0026#39;1. display \u0026#39; db \u0026#39;2. brows \u0026#39; db \u0026#39;3. replace \u0026#39; db \u0026#39;4. modify \u0026#39; datasg ends 将数据段前四个字母改为大写字母 \u0026amp;nbsp代码如下:\nassume cs:codesg,ss:stacksg,ds:datasg stacksg segment dw 0,0,0,0,0,0,0,0 stacksg ends datasg segment db \u0026#39;1. display \u0026#39; db \u0026#39;2. brows \u0026#39; db \u0026#39;3. replace \u0026#39; db \u0026#39;4. modify \u0026#39; datasg ends codesg segment start: mov ax,stacksg mov ss,ax mov sp,16 mov ax,datasg mov ds,ax mov cx,4h mov bx,0 s1:\tpush cx mov cx,4 mov si,0 s2:\tmov al,[bx+3+si] and al,11011111b mov [bx+3+si],al inc si loop s2 add bx,16 pop cx loop s1 mov ax,4c00h int 21h codesg ends end start\t","tags":["Assembly"],"title":"《汇编语言》 Lab6"},{"categories":["汇编语言"],"contents":"根据程序编译连接并用Debug加载、跟踪，然后回答问题。\n(1) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h,0789h,0abch,0defh,0fedh,0cbah,0987h data ends stack segment dw 0,0,0,0,0,0,0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop\tds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B4B\n(2) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h data ends stack segment dw 0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop\tds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B48\n(3) assume cs:code,ds:data,ss:stack code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop\tds:[0] mov ax,4c00h int 21h code ends data segment dw 0123h,0456h data ends stack segment dw 0,0 stack ends end start CS=0B48;SS=0B4C;DS=0B4B\n(4) 如果将(1)(2)(3)题目中最后一条伪指令“end start”改为“end”，则哪个程序可以正确执行？请说明原因。 (1)(2)可以，end是告诉编译器在此结束了代码的声明。\n(5) assume cs:code a segment db 1,2,3,4,5,6,7,8 a ends b segment db 1,2,3,4,5,6,7,8 b ends c segment db 0,0,0,0,0,0,0,0 c ends code segment start: mov bx,0 mov cx,8 s1:\tmov ax,a mov ds,ax\tmov dl,[bx]\tmov ax,c mov ds,ax\tmov [bx],dl inc bx loop s1\tmov bx,0 s2: mov ax,a mov ds,ax\tmov dl,[bx]\tmov ax,c mov ds,ax\tadd [bx],dl inc bx loop s2 mov ax,4c00h int 21h code ends end start 先将数据段a中的数据传送，再累加b数据段的数据，完成运算\n","date":"November 13, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab5/","summary":"根据程序编译连接并用Debug加载、跟踪，然后回答问题。\n(1) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h,0789h,0abch,0defh,0fedh,0cbah,0987h data ends stack segment dw 0,0,0,0,0,0,0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop\tds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B4B\n(2) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h data ends stack segment dw 0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop\tds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B48","tags":["Assembly"],"title":"《汇编语言》 Lab5"},{"categories":["汇编语言"],"contents":"assume cs:codesg codesg segment mov ax,2000 mov ss,ax mov sp,0 add sp,10 pop ax pop bx push ax push bx pop ax pop bx move ax,4c00 int 21 codesg ends end ","date":"November 13, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab1/","summary":"assume cs:codesg codesg segment mov ax,2000 mov ss,ax mov sp,0 add sp,10 pop ax pop bx push ax push bx pop ax pop bx move ax,4c00 int 21 codesg ends end ","tags":["Assembly"],"title":"《汇编语言》 Lab1"},{"categories":null,"contents":"There have serveral methods: /***overload function****/ void print(int* pi) { if (pi) cout \u0026lt;\u0026lt; *pi \u0026lt;\u0026lt; endl; } void print(const char* p) { if (p) while (*p) cout \u0026lt;\u0026lt; *p++; cout \u0026lt;\u0026lt; endl; } void print(const int* beg, const int* end) { while (beg != end) cout \u0026lt;\u0026lt; *beg++ \u0026lt;\u0026lt; endl; } void print(const int ia[], size_t size) { for (size_t i = 0; i != size; ++i) { cout \u0026lt;\u0026lt; ia[i] \u0026lt;\u0026lt; endl; } } void print(const int(\u0026amp;arr)[2]) { for (auto i : arr) cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } int main() { int i = 0, j[2] = {0, 1}; char ch[5] = \u0026#34;Getup!\u0026#34;; print(ch); print(begin(j), end(j)); print(\u0026amp;i); print(j, end(j) - begin(j)); print(const_cast\u0026lt;const int(\u0026amp;)[2]\u0026gt;(j)); } ","date":"June 2, 2017","hero":"/images/default-hero.jpg","permalink":"/posts/sys/c++/","summary":"There have serveral methods: /***overload function****/ void print(int* pi) { if (pi) cout \u0026lt;\u0026lt; *pi \u0026lt;\u0026lt; endl; } void print(const char* p) { if (p) while (*p) cout \u0026lt;\u0026lt; *p++; cout \u0026lt;\u0026lt; endl; } void print(const int* beg, const int* end) { while (beg != end) cout \u0026lt;\u0026lt; *beg++ \u0026lt;\u0026lt; endl; } void print(const int ia[], size_t size) { for (size_t i = 0; i != size; ++i) { cout \u0026lt;\u0026lt; ia[i] \u0026lt;\u0026lt; endl; } } void print(const int(\u0026amp;arr)[2]) { for (auto i : arr) cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } int main() { int i = 0, j[2] = {0, 1}; char ch[5] = \u0026#34;Getup!","tags":["c/c++"],"title":"C++ iterater"},{"categories":null,"contents":"这里是一名普通人（ID：pwaer）的博客，会在这里记录一些学习笔记和研究记录，正在践行着一些理念，帮助自己探索这个世界以及获得自由。\n日常希望自己会画画、唱歌、跳舞和摄影，梦想是去到北极甚至地外银河系漫游，但是在早十晚九地工作着，现在没有任何计划， 自认无趣也不够浪漫。身边有一台树莓派3B，总希望它能够在某一天能做一些有意思的事情。喜欢猫猫狗狗，在每天早晨和女朋友道完早安后， 会看一会狗狗和猫猫的视频再起床。\n\u0026ldquo;Learning Machine\u0026rdquo; 这个词和终身学习的概念非常接近，只是会将目标聚焦到每天每日， 让自己每天都会有新的收获，来源于芒格在南加州大学毕业典礼上的演讲，这个阶段的我在 这1小时多的演讲中收获不少我觉得有指导性的建议和道理，如果你看到这里，我也会推荐你看看。\nContact me Mail: fatwaer@gmail.com\n","date":"April 9, 2014","hero":"/images/default-hero.jpg","permalink":"/about/","summary":"这里是一名普通人（ID：pwaer）的博客，会在这里记录一些学习笔记和研究记录，正在践行着一些理念，帮助自己探索这个世界以及获得自由。\n日常希望自己会画画、唱歌、跳舞和摄影，梦想是去到北极甚至地外银河系漫游，但是在早十晚九地工作着，现在没有任何计划， 自认无趣也不够浪漫。身边有一台树莓派3B，总希望它能够在某一天能做一些有意思的事情。喜欢猫猫狗狗，在每天早晨和女朋友道完早安后， 会看一会狗狗和猫猫的视频再起床。\n\u0026ldquo;Learning Machine\u0026rdquo; 这个词和终身学习的概念非常接近，只是会将目标聚焦到每天每日， 让自己每天都会有新的收获，来源于芒格在南加州大学毕业典礼上的演讲，这个阶段的我在 这1小时多的演讲中收获不少我觉得有指导性的建议和道理，如果你看到这里，我也会推荐你看看。\nContact me Mail: fatwaer@gmail.com","tags":null,"title":"About Me"},{"categories":null,"contents":"“Just be patient”\n","date":"April 9, 2014","hero":"/images/default-hero.jpg","permalink":"/path/","summary":"“Just be patient”","tags":null,"title":"Path"},{"categories":null,"contents":"🕶 About Me  Tech.: OS(6.828), Distributed System(6.824), compile princeple and database in progress. Plat.: Centos/Ubuntu/ArchLinux/Rraspberry Pi Lang.: C/C++, Golang, Java, Python. Rust in TODO List(TODO = Never Do) Game.: Minecraft, Terraria, DarkSoul \u0026hellip;  Github: https://github.com/fatwaer\n","date":"April 9, 2014","hero":"/images/default-hero.jpg","permalink":"/posts/about/","summary":"🕶 About Me  Tech.: OS(6.828), Distributed System(6.824), compile princeple and database in progress. Plat.: Centos/Ubuntu/ArchLinux/Rraspberry Pi Lang.: C/C++, Golang, Java, Python. Rust in TODO List(TODO = Never Do) Game.: Minecraft, Terraria, DarkSoul \u0026hellip;  Github: https://github.com/fatwaer","tags":null,"title":"首页"},{"categories":null,"contents":"elasticsearch 文档创建和删除 创建和更新文档 官方提供的接口:\nPUT /\u0026lt;target\u0026gt;/_doc/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_doc/ PUT /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; 下面的例子利用PUT方法创建一个 id 为1的文档：\nPUT /index-001/_doc/1 { \u0026quot;title\u0026quot;: \u0026quot;Elasticsearch: The Definitive Guide\u0026quot;, \u0026quot;authors\u0026quot;: [ \u0026quot;clinton gormley\u0026quot;, \u0026quot;zachary tong\u0026quot; ], \u0026quot;summary\u0026quot;: \u0026quot;A distibuted real-time search and analytics engine\u0026quot;, \u0026quot;publish_date\u0026quot;: \u0026quot;2015-02-07\u0026quot;, \u0026quot;num_reviews\u0026quot;: 20, \u0026quot;publisher\u0026quot;: \u0026quot;oreilly\u0026quot; } 响应结构为：\n{ \u0026quot;_index\u0026quot; : \u0026quot;index-001\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_version\u0026quot; : 1, \u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 2, \u0026quot;successful\u0026quot; : 1, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;_seq_no\u0026quot; : 18, \u0026quot;_primary_term\u0026quot; : 1 } 其中，version字段为1，并且result的值为created。\n{ \u0026quot;_index\u0026quot; : \u0026quot;index-001\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_version\u0026quot; : 2, \u0026quot;result\u0026quot; : \u0026quot;updated\u0026quot;, .. } 如果重复对这个文档执行PUT操作，那么ES就会转变为更新，并且自增version字段。\n自动创建索引和文档并且设置为文档的 id，如果需要由 elasticsearch 创建唯一的索引id，不传入 id 即可。\nPOST /index-001/_doc { \u0026quot;title\u0026quot;: \u0026quot;Taming Text: How to Find, Organize, and Manipulate It\u0026quot;, \u0026quot;authors\u0026quot;: [ \u0026quot;grant ingersoll\u0026quot;, \u0026quot;thomas morton\u0026quot;, \u0026quot;drew farris\u0026quot; ], \u0026quot;summary\u0026quot;: \u0026quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization\u0026quot;, \u0026quot;publish_date\u0026quot;: \u0026quot;2013-01-24\u0026quot;, \u0026quot;num_reviews\u0026quot;: 12, \u0026quot;publisher\u0026quot;: \u0026quot;manning\u0026quot; } [result] { ... \u0026quot;_id\u0026quot; : \u0026quot;uhPDrXoBbcUNJeGl43Px\u0026quot;, \u0026quot;_version\u0026quot; : 1, \u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;, ... } PUT和POST操作都会索引文档并且自动创建索引以及和请求结构相关的mappings(类似数据库的表结构schema)。查询索引的信息如下：\nGET /\u0026lt;index_name\u0026gt; 通常会得到三个信息，aliases、mappings和settings\nGET /index-001 [result] { \u0026quot;index-001\u0026quot; : { \u0026quot;aliases\u0026quot; : {}, \u0026quot;mappings\u0026quot; : {}, \u0026quot;settings\u0026quot; : {} } } 查询文档 文档索引完成后，能够通过下面的查询查到新加入的文档：\nGET /\u0026lt;index_name\u0026gt;/_doc/1 GET /\u0026lt;index_name\u0026gt;/_search 删除文档 DELETE /\u0026lt;index\u0026gt;/_doc/\u0026lt;_id\u0026gt; 例如：\nDELETE /index-001/_doc/1 会返回一个结构体：\n{ \u0026quot;_index\u0026quot; : \u0026quot;index-001\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_version\u0026quot; : 9, \u0026quot;result\u0026quot; : \u0026quot;deleted\u0026quot;, ... } 如果找到了，会返回200OK，并且 found 判断是否存在文档，_version  字段在删除成功后会自增\n基础检索 准备查询数据 PUT /megacorp/employee/1 { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } PUT /megacorp/employee/2 { \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 32, \u0026quot;about\u0026quot; : \u0026quot;I like to collect rock albums\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;music\u0026quot; ] } PUT /megacorp/employee/3 { \u0026quot;first_name\u0026quot; : \u0026quot;Douglas\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Fir\u0026quot;, \u0026quot;age\u0026quot; : 35, \u0026quot;about\u0026quot;: \u0026quot;I like to build cabinets\u0026quot;, \u0026quot;interests\u0026quot;: [ \u0026quot;forestry\u0026quot; ] } simple_query_string 查询字符串(query_string) GET /megacorp/employee/_search?q=last_name:Smith  基础请求体查询(request_body) GET /megacorp/_search { \u0026quot;query\u0026quot; : { \u0026quot;match\u0026quot; : { \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot; } }, \u0026quot;from\u0026quot;: 0, \u0026quot;size\u0026quot;: 2, \u0026quot;_source\u0026quot;: [\u0026quot;first_name\u0026quot;, \u0026quot;last_name\u0026quot;], \u0026quot;sort\u0026quot;: [{\u0026quot;age\u0026quot;: \u0026quot;desc\u0026quot;}] } from,size 用于分页，_source 相当于select，sort对应order by\n查询返回结构 { \u0026quot;took\u0026quot; : 0, \u0026quot;timed_out\u0026quot; : false, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 1, \u0026quot;successful\u0026quot; : 1, \u0026quot;skipped\u0026quot; : 0, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 3, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.0, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } }, ... ] } } took 查询使用时间，timed_out 超时 _shards 表示在多少分片上查询成功了 hits: 为命中结果 包含了文档的id、相关性得分\n全文搜索(match) GET /megacorp/employee/_search { \u0026quot;query\u0026quot; : { \u0026quot;match\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } } } 查询在 about 属性上喜欢 rock climbing 的人。 rock albums和 rock climbing 都会被命中。如果字段是设置了 not_analyzed  或者是日期、数字、布尔，也会给定精确匹配的值。\n短语检索(match_phrase) GET /megacorp/employee/_search { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } } } 只有含有短语 rock climbing 的文档才被检索\n多字段查询(multi_match) 允许在多个字段上执行相同的查询\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;multi_match\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;like music\u0026quot;, \u0026quot;fields\u0026quot;: [\u0026quot;about\u0026quot;, \u0026quot;interests\u0026quot;] } } } [result] \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 3, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 0.7549127, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;2\u0026quot;, \u0026quot;_score\u0026quot; : 0.7549127, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 32, \u0026quot;about\u0026quot; : \u0026quot;I like to collect rock albums\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;music\u0026quot; ] } }, { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 0.55654144, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } }, { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;3\u0026quot;, \u0026quot;_score\u0026quot; : 0.3704521, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;Douglas\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Fir\u0026quot;, \u0026quot;age\u0026quot; : 35, \u0026quot;about\u0026quot; : \u0026quot;I like to build cabinets\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;forestry\u0026quot; ] } } ] } 范围查询(range) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;range\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 20, \u0026quot;lt\u0026quot;: 33 } } } } [result] \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 2, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.0, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } }, { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;2\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 32, \u0026quot;about\u0026quot; : \u0026quot;I like to collect rock albums\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;music\u0026quot; ] } } ] } gt: 大于 gte: 大于等于 lt: 小于 lte: 小于等于\n精确值查找(term/terms) term 查询被用于精确值匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;25\u0026quot; } } } } [result] \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 1, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.0, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } } ] } terms 查询是 term 的多值版本\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;age\u0026quot;: [\u0026quot;25\u0026quot;, \u0026quot;32\u0026quot;] } } } [result] \u0026quot;hits\u0026quot; : { \u0026quot;total\u0026quot; : { \u0026quot;value\u0026quot; : 2, \u0026quot;relation\u0026quot; : \u0026quot;eq\u0026quot; }, \u0026quot;max_score\u0026quot; : 1.0, \u0026quot;hits\u0026quot; : [ { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot; ] } }, { \u0026quot;_index\u0026quot; : \u0026quot;megacorp\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;employee\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;2\u0026quot;, \u0026quot;_score\u0026quot; : 1.0, \u0026quot;_source\u0026quot; : { \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 32, \u0026quot;about\u0026quot; : \u0026quot;I like to collect rock albums\u0026quot;, \u0026quot;interests\u0026quot; : [ \u0026quot;music\u0026quot; ] } } ] } 存在性查找(exsists/missing) 查找字段是否有值\n{ \u0026quot;exists\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;title\u0026quot; } } 前缀查询(match_prefix) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;first_name.keyword\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;J\u0026quot; } } } } 为什么要加入keyword？或者:\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: { \u0026quot;first_name.keyword\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;j\u0026quot; } } } } prefix 查询不做相关度评分计算，\n因为目前只有三条记录，分别是：\n\u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;first_name\u0026quot; : \u0026quot;Jane\u0026quot;, \u0026quot;first_name\u0026quot; : \u0026quot;Douglas\u0026quot;, 模糊查询和正则表达式(wildcard/regexp) 因为语句会被es分解成词，match查询的最小模糊匹配是词，利用模糊查询就能将模糊粒度降低到字母，如：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;wildcard\u0026quot;: { \u0026quot;about\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;c*\u0026quot; } } } } 或者:\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;regexp\u0026quot;: { \u0026quot;about\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;c.*\u0026quot; } } } } 数据在索引时的预处理有助于提高前缀匹配的效率，而通配符和正则表达式查询只能在查询时完成，尽管这些查询有其应用场景，但使用仍需谨慎。\nprefix 、 wildcard 和 regexp 查询是基于词操作的，像语句“Quick brown fox”如果设置了analyzed 就会被分解成 quick 、 brown 和 fox。\n{ \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;br.*\u0026quot; }}  语句能够检索到，但是下面这些组合了词语的查询不行\n{ \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;Qu.*\u0026quot; }} { \u0026quot;regexp\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;quick br*\u0026quot; }} 复合查询 复合查询使用 bool 查询来实现逻辑的组合，接受以下四种参数：\n must：文档 必须 匹配这些条件才能被包含进来。 must_not：文档 必须不 匹配这些条件才能被包含进来。 should: 如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter: 必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。  结构为：\n\u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ SUB_QUERY ], \u0026quot;must_not\u0026quot;: [ SUB_QUERY ] } } 例如：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ {\u0026quot;range\u0026quot;: { \u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 } }} ], \u0026quot;must_not\u0026quot;: [ {\u0026quot;match\u0026quot;: { \u0026quot;about\u0026quot;: \u0026quot;cabinets\u0026quot; }} ] } } } 过滤查询(filter) GET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: {\u0026quot;match\u0026quot; : {\u0026quot;about\u0026quot; : \u0026quot;like build\u0026quot;}}, \u0026quot;filter\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot; : {\u0026quot;range\u0026quot;: {\u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 }}} } } } } } 将查询移到 bool 查询的 filter 的 bool 语句中，例如像年龄这样的字段，只需要进行过滤，不需要放在查询做，所以可以放到filter中来优化查询性能。\n过滤查询(constant_score) constant_score 是filter的另外一种形式，通常用在只进行filter，而不用查询相关性分的情况。\n如下：\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;constant_score\u0026quot;: { \u0026quot;filter\u0026quot;: {\u0026quot;range\u0026quot;: {\u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 }}} } } } Kibana 会自动补全 boost:1.2\nGET /megacorp/_search { \u0026quot;query\u0026quot;: { \u0026quot;constant_score\u0026quot;: { \u0026quot;filter\u0026quot;: {\u0026quot;range\u0026quot;: {\u0026quot;age\u0026quot;: { \u0026quot;gte\u0026quot;: 30 }}}, \u0026quot;boost\u0026quot;: 1.2 } } } 总结 集群搜索原理 查询流程 通过URL限制搜索范围 参考  19 个很有用的 ElasticSearch 查询语句 elastic search guide  ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"/posts/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch/","summary":"elasticsearch 文档创建和删除 创建和更新文档 官方提供的接口:\nPUT /\u0026lt;target\u0026gt;/_doc/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_doc/ PUT /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; POST /\u0026lt;target\u0026gt;/_create/\u0026lt;_id\u0026gt; 下面的例子利用PUT方法创建一个 id 为1的文档：\nPUT /index-001/_doc/1 { \u0026quot;title\u0026quot;: \u0026quot;Elasticsearch: The Definitive Guide\u0026quot;, \u0026quot;authors\u0026quot;: [ \u0026quot;clinton gormley\u0026quot;, \u0026quot;zachary tong\u0026quot; ], \u0026quot;summary\u0026quot;: \u0026quot;A distibuted real-time search and analytics engine\u0026quot;, \u0026quot;publish_date\u0026quot;: \u0026quot;2015-02-07\u0026quot;, \u0026quot;num_reviews\u0026quot;: 20, \u0026quot;publisher\u0026quot;: \u0026quot;oreilly\u0026quot; } 响应结构为：\n{ \u0026quot;_index\u0026quot; : \u0026quot;index-001\u0026quot;, \u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;, \u0026quot;_id\u0026quot; : \u0026quot;1\u0026quot;, \u0026quot;_version\u0026quot; : 1, \u0026quot;result\u0026quot; : \u0026quot;created\u0026quot;, \u0026quot;_shards\u0026quot; : { \u0026quot;total\u0026quot; : 2, \u0026quot;successful\u0026quot; : 1, \u0026quot;failed\u0026quot; : 0 }, \u0026quot;_seq_no\u0026quot; : 18, \u0026quot;_primary_term\u0026quot; : 1 } 其中，version字段为1，并且result的值为created。","tags":null,"title":""},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]