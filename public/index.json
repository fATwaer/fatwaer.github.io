[{"categories":null,"content":"如果不使用任何同步机制（例如 mutex 或 atomic），在多线程中读写同一个变量，那么，程序的结果是难以预料的。简单来说，编译器以及 CPU 的一些行为，会影响到程序的执行结果： 即使是简单的语句，C++ 也不保证是原子操作。 CPU 可能会调整指令的执行顺序。 在 CPU cache 的影响下，一个 CPU 执行了某个指令，不会立即被其它 CPU 看见。 利用 C++ 的 atomic\u003cT\u003e 能完成对象的原子的读、写以及RMW（read-modify-write），而参数 std::memory_order 规定了如何围绕原子对象的操作进行排序。memory order 内存操作顺序其实是 内存一致性模型 (Memory Consistency Model)，解决处理器的 write 操作什么时候能够影响到其他处理器，或者说解决其他处理处理器什么时候能够观测到当且 写CPU/写线程 写入内存的值，有了 memory odering，我们就能知道其他处理器是怎么观测到 store 指令的影响的。 一致模型有很多种，在 Wikipedia 里面搜索 Consistency model 即可看到，目前 C++ 所用到有 Sequential Consistency 和 Relaxed Consistency 以及 Release consistency。 ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:0:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#"},{"categories":null,"content":"Memory Operation Ordering我们所编写的程序会定义一系列的 load 和 store 操作，也就是 Program ordering，这些 load 和 store 的操作应用在内存上就有了内存操作序(memory operation ordering)，一共有四种内存操作顺序的限制，不同的内存一致模型需要保持不同级别的操作限制，其中 W 代表写，R 代表读： W -\u003e R：写入内存地址 X 的操作必须比在后面的程序定义序列的读取地址 Y 之前提交 (commit), 以至于当读取内存地址 Y 的时候，写入地址 X 的影响已经能够在读取Y时被观测到。 R -\u003e R: 读取内存地址 X 的操作必须在后序序列中的读取内存地址 Y 的操作之前提交。 R -\u003e W：读取内存地址 X 的操作必须在后序序列中读取内存地址 Y 的操作之前提交。 W -\u003e W：写入内存地址 X 的操作必须在后续序列中写入内存地址 Y 的操作之前提交。 提交的意思可以理解为，后面的操作需要等前面的操作完全执行完才能进行下一个操作。 ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:1:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#memory--operation-ordering"},{"categories":null,"content":"Sequential consistency序列一致是 Leslie Lamport 提出来的，如果熟悉分布式共识算法 Paxos ，那么应该不陌生这位大科学家，而序列一致的定义是： the result of any execution is the same as-if （任何一种执行结果都是相同的就好像） the operations of all threads are executed in some sequential order （所有线程的操作都在某种次序下执行） the operations of each thread appear in this sequence in the order specified by their program （在全局序列中的，各个线程内的操作顺序由程序指定的一致） 组合起来：全局序列中的操作序列要和线程所指定的操作顺序要对应，最终的结果是所有线程指定顺序操作的排列，不能出现和程序指定顺序组合不出来的结果。 怎么做会违反 sequcential consistency（SC）？也就是 SC 的反例是什么？ 乱序执行 （out-of-order) 内存访问重叠，写A的过程中读取A，宽于计算机word的，64位机器写128位变量 更加形象的理解可以从内存的角度来看： 所有的处理器都按照 program order 发射 load 和 store 的操作，而内存一个地一个地从上面 4 个处理器中读取指令，并且仅当完成一个操作后才会去执行下一个操作，类似于多个 producer 一个 consumer 的情况。 （Lamport 一句话，让我为他理解了一下午） SC 需要保持所有的内存操作序（memory operation ordering），也是最严格的一种，并且 SC 是 c++ atomic\u003cT\u003e 默认的以一种内存模型，对应 std::memory_order_seq_cst，可以看到标准库中的函数定义将其设置为了默认值： bool load(memory_order __m = memory_order_seq_cst) const noexcept { return _M_base.load(__m); } ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:2:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#sequential-consistency"},{"categories":null,"content":"Relaxed Consistency松弛内存序，对应的 std::memory_order_relaxed，在 cppreference 上的说明是：“不保证同步操作，不会将一定的顺序强加到并发内存访问上，只保证原子性和修改顺序一致性”，并且通常用于计数器，比如 shared_ptr 的引用计数。 松弛内存序不再保证 W -\u003e R，不相互依赖的读写操作可以在 write 之前或者在同一时间段并行处理。（读内存并不是想象中的那么简单，有内存寻址过程，将内存数据映射到 cache block，发送不合法位用于缓存替换） 好处是什么？性能，执行命令的写操作的延迟都被抹去了，cpu 能够更快的执行完一段带有读写的指令序列。 具体实现是通过在 cpu 和 cache 之间加入一个 write buffer，如下图： 处理器 Write 命令将会发送到 Write Buffer，而 Read 命令就直接能访问 cache，这样可以省去写操作的延迟。Write Buffer 还有一个细节问题，放开 W -\u003e R 的限制是当 Write 和 Read 操作内存地址不是同一个的时候，R/W 才能同时进行甚至 R 能提前到 W 之前，但如果 Write Buffer 中有一个 Read 所依赖的内存地址就存在问题，Read 需要等在 Write buffer 中的 Write 执行完成才能继续吗？只需要 Read 能直接访问这个 Write Buffer，如下（注：这里的Load通常和Read等意，Store和Write等意）： ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:3:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#relaxed-consistency"},{"categories":null,"content":"Release Consistency在这种一致性下，所有的 memory operation ordering 都将不再维护，是最激进的一种内存一致模型，进入临界区叫做 Acquire ，离开临界区叫做 Release。所有的 memory operation ordering 都将不再维护，处理器支持特殊的同步操作，所有的内存访问指令必须在 fence 指令发送之前完成，在 fench 命令完成之前，其他所有的命令都不能开始执行。 Intel x86/x64 芯片在硬件层面提供了 total store ordering 的能力，如果软件要求更高级别的一致性模型，处理器提供了三种指令： mm_lfence：load fence，等待所有 load 完成 mm_sfence：store fence，等待所有 store 完成 mm_mfence：完全读写屏障 而在 ARM 架构上，提供的是一种非常松弛（very relaxed）内存一致模型。 PS. 曾经有个公司做出了支持 Sequential Consistency 的硬件，但是最终还是败给了市场。 ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:4:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#release-consistency"},{"categories":null,"content":"Acquire/ReleaseAcquire/release 对应 std::memory_order_acquire 和 std::memory_order_acquire，它们的语义解释如下： Acquire：如果一个操作 X 带有 acquire 语义，那么在操作 X 后的所有 load/store 指令都不会被重排序到操作 X 之前，其他处理器会在看到操作X后序操作的影响之前看到操作 X 的影响，也就是必须先看到 X 的影响，再是后续操作的影响。 Relase：如果一个操作 X 带有 release 语义，那么在操作 X 之前的所有 load/store 指令操作都不会被重排序到操作 X 之后，其他处理器会先看到操作 X 之前的操作。 Acquire/Release 常用在互斥锁(mutex lock)和自旋锁(spin lock)，获得一个锁和释放一个锁需要分别使用 Acquire 和 Release 语义防止指令操作被重排出临界区，从而造成数据竞争。 ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:5:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#acquirerelease"},{"categories":null,"content":"Acquire/ConsumeAcquire/Consume 对应 std::memory_order_acquire 和 std::memory_order_consume，两种内存模型的组合仅有 consume 不同于 release，不同点在于，假设原子操作 X， Release 会防止 X 之前的所有指令不会被重排到 X 之后，而 Consume 只能保证依赖的变量不会被重排到 X 之后，引入了依赖关系。 但是在 cppreference 上面写着，“释放消费顺序的规范正在修订中，而且暂时不鼓励使用 memory_order_consume 。”，所以暂时不对其做深入的研究。 ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:6:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#acquireconsume"},{"categories":null,"content":"Volatilevolatile 关键词通常会被拿出来说，因为通常会在并发编程中被错误使用： volatile 的翻译是“不稳定的，易发生变化的”，编译器会始终读取 volatile 修饰的变量，不会将变量的值优化掉，但是这不是用在线程同步的工具，而是一种错误行为，cppreference上面写道：“volatile 访问不建立线程间同步，volatile 访问不是原子的，且不排序内存，非 volatile 内存访问可以自由地重排到 volatile 访问前后。”（Visual Studio 是个例外）。 volatile 变量的作用是用在非常规内存上的内存操作，常规内存在处理器不去操作的时候是不会发生变化的，但是像非常规内存如内存映射I/O的内存，实际上是在和外围设备做串口通信，所以不能省去。（《modern effective c++》） ","date":"2022-04-25","objectID":"/c-atomic-%E5%92%8C-memory-ordering/:7:0","series":null,"tags":null,"title":"C++ Atomic 和 Memory Ordering","uri":"/c-atomic-%E5%92%8C-memory-ordering/#volatile"},{"categories":null,"content":"名词解释 移动语义：用不那么昂贵的操作代替昂贵的复制操作，也使得只支持移动变得可能，比如 unique_ptr，将数据的所有权移交给别人而不是多者同时引用。 完美转发：目标函数会收到转发函数完全相同类似的实参。 右值引用：是这两个机制的底层语言机制，形式是 Type\u0026\u0026，能够引用到“不再使用”的数据，直接用于对象的构造 要注意的是，形参一定是左值，即使类型是右值引用： void f(Widget\u0026\u0026 w) { /* w 在作用域内就是一个左值。 */ } 实现移动语意和完美转发的重要工具就是std::move 和 std::forward，std::move 和 std::forward 其实都是强制类型转换函数，std::move 无条件将实参转换为右值，而 std::forward 根据实参的类型将参数类型转化为左值或者右值到目标函数。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:1:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#名词解释"},{"categories":null,"content":"移动语义std::move(v) 相当于 static_cast\u003cT\u0026\u0026\u003e(v)，强制将类型转化为需要类型的右值，move 的具体实现为： template\u003ctypename T\u003e typename remove_reference\u003cT\u003e::type\u0026\u0026 move(T\u0026\u0026 param) { using ReturnType = typename remove_reference\u003cT\u003e::type\u0026\u0026; return static_cast\u003cReturnType\u003e(param); } 其中 typename remove_reference\u003cT\u003e::type\u0026\u0026 作用就是为了解决是当入参数是 reference to lvalue 的时候，返回类型ReturnType会因为引用折叠被推导为 T\u0026，remove_reference\u003cT\u003e::type 就是为了去除推导出的模版参数 T 的引用，从到强制得到 T\u0026\u0026。 如果没有remove_reference\u003cT\u003e，而是用 T\u0026\u0026 来代替函数返回值以及 static_cast\u003c\u003e，就会有下面的推导规则： 如果入参是 lvalue，那么 T 就会被推导成为 T\u0026，参数 param 的类型就变成了 T\u0026 \u0026\u0026，再通过引用折叠的规则，推导最终结果为 T\u0026，而根据表达式的 value category 规则，如果一个函数的返回值类型是左值引用，那么返回值的类型为左值，那么 std::move(v) 就不能实现需要的功能，做到强制右值转换。 如果入参是 rvalue，那么 T 会被直接推导成 T\u0026，参数 param 的类型也就变成了 T\u0026\u0026，函数返回的类型(type)也是 T\u0026\u0026，返回的值类别也是右值。 此外，在 c++14 能直接将 typename remove_reference\u003cT\u003e::type\u0026\u0026 替换为 remove_reference_t\u003cT\u003e\u0026\u0026。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:2:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#移动语义"},{"categories":null,"content":"完美转发std::forward\u003cT\u003e(v) 的使用场景用于函数需要转发不同左值或者右值的场景，假设有两个重载函数： void process(const Widget\u0026 lvalArg); void process(Widget\u0026\u0026 rvalArg); 有一个函数 LogAndProcess 会根据 param 左值或者右值的不同来区分调用不同函数签名的 process 函数： template\u003ctypename T\u003e void LogAndProcess(T\u0026\u0026 param) { // DoSomething logging(param); process(std::forward\u003cT\u003e(param)); } 这样使用 LogAndProcess 的时候就能区分： Widget w; LogAndProcess(w); // call process(const Widget\u0026); LogAndProcess(std::move(w)); // call process(Widget\u0026\u0026); 这里就有 emplace_back 一种常见的用错的情况，在代码中也经常看见，如果要将某个不用的对象a放到vector中： class A { A(A\u0026\u0026 a) {} }; A a; std::vector\u003cA\u003e vec; vec.push_back(a); 如果使用 push_back 就会造成一次拷贝，常见的错误做法是将其替换为 vector::emplace_back()： vec.emplace_back(a); 但是 emplace_back 的实现有 std::forward 根据实参数做转发，实参 a 实际上是个 lvaue，转发到构造函数时得到的也是左值的 a，就相当于调用赋值拷贝构造： vec[back()] = a; 解决方法其实只需要调用 std::move 做一次右值转换即可，就能完成数据的移动。 vec.emplace_back(std::move(a)); ","date":"2022-04-14","objectID":"/c-rvalue-reference/:3:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#完美转发"},{"categories":null,"content":"万能引用和右值引用万能引用和右值引用最大的区别在于万能引用会涉及模板的推导。但并不是说函数参数中有模板参数就是万能引用，例如 std::vector::push_back() 的函数签名是 push_back(T\u0026\u0026 x)， 但是 T 的类型在 std::vector\u003cT\u003e 声明的时候就已经确定了，在调用push_back 的时候不会涉及类型推导，而 std::vector 的 emplace_back 是确实存在推导的。另外即使类型是 T\u0026\u0026，但是如果有 const 修饰得到 const T\u0026\u0026，那么也不是一个合格的万能引用。 对于万能引用，如果是入参是右值引用，模版参数 T 的推导结果还是 T，而不是 T\u0026\u0026，这不是右值引用的特殊性，而是左值引用的特殊性， 模板函数的函数参数列表中包含 forwarding reference 且相应的实参是一个 lvalue 的情况时，模版类型会被推导为左值引用。 forwarding reference 是 C++ 标准中的词，翻译叫转发引用；《modern effective c++》的作者 Scott Meyers 将这种引用称之为万能引用（universal reference）。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:4:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#万能引用和右值引用"},{"categories":null,"content":"右值引用的重载有了右值引用后，就能通过 std::move 将左值转换为右值，完成目标对象的移动构造，省去大对象的拷贝，但是如果传递的参数是个左值，调用者不希望入参被移动，数据被移走，那就需要提供一个左值引用的版本，因为右值引用无法绑定左值。假设大对象是一个string，就会写出下面这种函数签名： void f(const std::string\u0026 s); void f(string\u0026\u0026 s); 一个参数没问题，我们学会了左值和右值的区别并给出了不同的函数重载，但是如果参数是两个 string，情况就变得复杂的，针对不同的情况，就需要提供四种函数签名和实现： void f(const std::string\u0026 s1, const std::string\u0026 s2); void f(const std::string\u0026 s1, string\u0026\u0026 s s2); void f(string\u0026\u0026 s s1, const std::string\u0026 s2); void f(string\u0026\u0026 s s1, string\u0026\u0026 s s2); 如果参数进一步增加，编码就会越来越复杂，遇到这种情况就可以使用万能引用处理，在函数体内对string做std::forward()即可： template\u003ctypename T1, typename T2\u003e void f(T1\u0026\u0026 s1, T2\u0026\u0026 s2); ","date":"2022-04-14","objectID":"/c-rvalue-reference/:5:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#右值引用的重载"},{"categories":null,"content":"万能引用的重载万能引用存在一个问题，过于贪婪而导致调用的函数不一定是想要的那个，假设 f() 除了要处理左值和右值的 string 外，还有可能需要处理一个整形，例如int，就会有下面这种方式的重载。 // 万能引用版本的 f()，处理左值右值 template\u003ctypename T\u003e void f(T\u0026\u0026 s) { std::cout \u003c\u003c \"f(T\u0026\u0026)\" \u003c\u003c std::endl; } // 整数类型版本的 f()，处理整形 void f(int i) { std::cout \u003c\u003c \"f(int)\" \u003c\u003c std::endl; } 如果用不同的整型去调用f()，就会发生问题： int i1; f(i1); // output: f(int) size_t i2; f(i2); // output: f(T\u0026\u0026) 如果参数是一个 int，那么一切正常，调用f(int)的版本，因为c++规定，如果一个常规函数和一个模板函数具备相同的匹配性，优先使用常规函数。 但是如果入参是个 size_t，那么就出现问题了，size_t 的类型和 int 并不相等，需要做一些转换才能变成int，那么就会调用到万能引用的版本。 如何限制万能引用呢？ 1、标签分派：根据万能引用推导的类型，f(T\u0026\u0026) 新增一个形参变成f(T\u0026\u0026, std::true_type)和f(T\u0026\u0026, std::false_type)，调用f(args, std::is_integral\u003cT\u003e()) 就能正确分发到不同的 f() 上。 2、模板禁用：std::enable_if 能强制让编译器使得某种模板不存在一样，称之为禁用，底层机制是 SFINAE std::_enable_if 的正确使用方法为： template\u003ctypename T, typename = typename std::enable_if\u003ccondition\u003e::type\u003e void f(T param) { } 应用到前面的例子上，希望整型只调用f(int)而 string 会调用 f(T\u0026\u0026)，就会有： void f(int i) { std::cout \u003c\u003c \"f(int)\" \u003c\u003c std::endl; } template\u003ctypename T, typename = typename std::enable_if\u003c std::is_same\u003c typename std::remove_reference\u003cT\u003e::type, std::string\u003e::value \u003e::type \u003e void f(T\u0026\u0026 s) { std::cout \u003c\u003c \"f(T\u0026\u0026)\" \u003c\u003c std::endl; } 模板的内容看上去比较长，其实只是在std::enable_if的condition内希望入参的类型为string，无论左值和右值，这样就完成了一个万能引用的正确重载。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:6:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#万能引用的重载"},{"categories":null,"content":"引用折叠在c++中，引用的引用是非法的，但是编译器可以推导出引用的引用的引用再进行折叠，通过这种机制实现移动语义和完美转发。 模板参数T的推导规则有一点就是，如果传参是个左值，T的推导类型就是T\u0026，如果传参是个右值，那么T推导结果就是T（不变）。引用的折叠规则也很简单，当编译器出现引用的引用后，结果会变成单个引用，在两个引用中，任意一个的推导结果为左值引用，结果就是左值引用，否则就是右值引用。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:7:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#引用折叠"},{"categories":null,"content":"返回值优化(RVO)编译器如果要在一个按值返回的函数省略局部对象的复制和移动，需要满足两个条件： 局部对象的类型和返回值类型相同 返回的就是局部对象本身 如果在return的时候对局部变量做std::move()，那么就会使得局部变量的类型和返回值类型不匹配，原本可以只构造一次的操作，变成了需要构造一次加移动一次，限制了编译器的发挥。 另外，如果不满足上面的条件二，按值返回的局部对象是不确定的，编译器也会将返回值当作右值处理，所以对于按值返回局部变量这种情况，并不需要实施std::move()。 ","date":"2022-04-14","objectID":"/c-rvalue-reference/:8:0","series":null,"tags":null,"title":"右值引用，移动语义，完美转发","uri":"/c-rvalue-reference/#返回值优化rvo"},{"categories":["机器学习"],"content":"异常检测异常检测是一种无监督学习算法，选定一些特征作为输入，输出为概率 $p(x)$ ，当 $p(x_{test}) \u003c \\epsilon$ 时，概率 $p$ 小于异常的阈值 $\\epsilon$ ， 那么判断样本为异常样本。使用场景有飞机引擎的异常检测，用户行为异常检测，数据中心的机器是否异常等。 高斯分布有两个参数，均值 $\\mu$ 和方差 $\\sigma$，在几何上分别控制分布的中心点和曲线陡峭程度。 ","date":"2022-03-03","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/:0:0","series":null,"tags":null,"title":"机器学习整理（异常检测和高斯分布）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/#异常检测"},{"categories":["机器学习"],"content":"计算过程高斯分布参数的计算过程： 选择可能会导致异常的特征作为输入，并且要满足高斯分布，如果不满足高斯分布，通常对数据取一次 $log$。 计算参数 $\\mu_j = \\dfrac{1}{m}\\sum_{j=1}^{m} x_j$ 和参数 $\\sigma^2=\\dfrac{1}{m} \\sum_{j=1}^{m}(x_j-\\mu_j)^2$ 。 当计算参数均值 $\\mu$ 和方差 $\\sigma$ 后就得到各特征的高斯分布，当有新的样本需要进行检测的时候，计算概率： $$ p(x) = \\prod_{j=1}^{n} p(x_j;\\mu_j, \\sigma^2_j) =\\prod_{j=1}^{n} \\dfrac{1}{\\sqrt{2\\pi}\\sigma_j} exp(-\\dfrac{(x_j-\\mu_j)^2}{2\\sigma^2}) $$ 其中，$\\prod$ 符号代表乘积，如果多个特征纬度的高斯概率相乘小于$\\epsilon$ ，那么就能判断该样本为异常样本。 异常检测算法的评估方法是通常是用 F1_score、召回率和精度，还有TP/FP/FN/TN来判断。 ","date":"2022-03-03","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/:1:0","series":null,"tags":null,"title":"机器学习整理（异常检测和高斯分布）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/#计算过程"},{"categories":["机器学习"],"content":"异常检测和逻辑回归的区别 监督学习：通常有大量的正负样本，基本不会出现严重的样本倾斜。 异常检测：只有极少量的异常样本，并且未来的异常情况和曾经的异常情况不相同。 异常检测的错误修正，如果异常检测预测失败了，需要找出原因，提取出新的特征加入到概率计算中去。 ","date":"2022-03-03","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/:2:0","series":null,"tags":null,"title":"机器学习整理（异常检测和高斯分布）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/#异常检测和逻辑回归的区别"},{"categories":["机器学习"],"content":"多变量高斯分布多变量高斯分布不再仅仅对单变量建模（输入$x_j$），不同变量之间变化会受到影响，计算过程中的参数也变成了均值矩阵 $\\mu$ 和协方差矩阵 $\\Sigma$。 均值矩阵 $\\mu$ : $$\\mu = \\dfrac{1}{m}\\sum_{j=1}^{m} x_j$$ 协方差矩阵 $\\Sigma$ : $$ \\Sigma = \\dfrac{1}{m}\\sum_{j=1}^{m} (x_i - \\mu)(x_i - \\mu)^T $$ 多变量高斯分布为： $$ p(x_i; u_i, \\Sigma) = \\dfrac{1}{(2\\pi)^\\dfrac{n}{2}|\\Sigma|^{\\dfrac{1}{2}}} exp(-\\dfrac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x-\\mu)) $$ 和普通的高斯分布的区别在于，多变量高斯分布的特征之间是会相互影响的，而普通高斯分布的概率计算是 $p(x1_,x_2,\\dots,x_n) = p(x_1) * p(x_2) * \\dots * p(x_n)$ ，不同特征之间是相互割裂的。 普通的高斯分布通常是以 $x_1=k1,x_2=k_2\\dots,x_n=k_n$ 轴对称的，其中 $k$ 为常量： 而多变量高斯分布的则不同，因为多特征之间会产生关联： 看上去多变量高斯分布会很好，但在实际中，多变量高斯分布的计算会更加复杂，并且有数学上的要求样本数量 $m$ 必须大于特征数量 $n$ ，实际使用过程中更是要求 $m » n$ 。原始高斯分布可以手动添加多个原始特征的组合作为一个新的特征输入，使得不同特质之间存在关联关系。 ","date":"2022-03-03","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/:3:0","series":null,"tags":null,"title":"机器学习整理（异常检测和高斯分布）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/#多变量高斯分布"},{"categories":["机器学习"],"content":"神经元神经网络由多个神经元组成，其中神经元由几个部分组成：输入、输入权重、输出和激活函数组成，类似于生物神经元的树突、轴突的组成。 神经元的输入由左边的神经元输出 $x$ 乘以权重 $w$ 并加和得到，输出的时候，类似于生物神经元的轴突，将神经元的输出通过激活函数才能传送给接下来的神经元。 常用的激活函数（activation function）是Sigmod，它的函数图像如下，在逻辑回归的时候使用过： 其中偏置单元 $b$ 是用于提高神经网络的灵活性而加入的，它的存在可以让激活函数更快或者更慢达到激活状态。 ","date":"2022-02-24","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:1:0","series":null,"tags":null,"title":"机器学习整理（神经网络）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#神经元"},{"categories":["机器学习"],"content":"神经网络多个神经元组层一个神经网络： 神经网络第一层是输入层（input），最后一层是输出层（output），而中间的就是神经网络的隐藏层（hidden layer） 神经网络的训练过程如下： 随机初始化权重 $w_i$ 代入执行前向传播得到神经网络的输出 $o_i$ 计算代价函数 $J(W)$ 执行反向传播，计算偏导数 $\\frac{\\partial J(W)}{\\partial w_i}$ ，依次更新网络的权重 将样本 $(x_i,y_i)$ 不断代入第2步到第4步。 ","date":"2022-02-24","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:2:0","series":null,"tags":null,"title":"机器学习整理（神经网络）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#神经网络"},{"categories":["机器学习"],"content":"前向传播前向传播的过程目的是计算出神经网络的输出： 首先开始计算 $net_0$ : $$ net_0 = w_0 * x_0 + w_2 * x_1 + b_0 * 1 $$ 到达隐藏层的神经元后，会通过激活函数作为神经元的输出 $a_0$： $$ a_0 = Sigmoid(net_0) = \\frac{1}{1-e^{-net_0}} $$ 计算该神经元后继续向前计算，和前面一层的计算类似： $$ o_0 = Sigmoid(w_4 * a_0 + w_6 * a_1 + b_2 * 1) $$ 按照这样的传播过程，这样就能计算出神经网络的输出 $o_1,o_2,\\dots,o_n$ ，即神经网络的前向传播，就像把样本 $x$ 代入$y = ax + b$里求出 $y$ 值的过程一样。 ","date":"2022-02-24","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:3:0","series":null,"tags":null,"title":"机器学习整理（神经网络）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#前向传播"},{"categories":["机器学习"],"content":"反向传播按照神经网络的训练过程，接下来是希望计算代价函数 $J(W)$ ，并求出 $J(W)$ 对 $w_i$ 的偏导数 $\\frac{\\partial J(W)}{\\partial w_i}$ ，并按照学习率 $a$ 更新参数： $$ w_i = w_i - a * \\frac{\\partial J(W)}{\\partial w_i} $$ 以更新 $w_5$ 为例，如果需要知道 $\\frac{\\partial J(W)}{\\partial w_5}$ 的值，根据链式求导法则： $$ \\frac{\\partial J(W)}{\\partial w_5} = \\frac{\\partial J(W)}{\\partial o_1 } * \\frac{\\partial o_1}{\\partial net_3} * \\frac{\\partial net_3}{\\partial w_5} $$ （1）首先求$\\frac{\\partial J(W)}{\\partial o_1 }$ ，其中代价函数 $J(W)$ ，如果是线性回归，那么表达式就是： $$ J(W) = \\frac{1}{2}\\sum_{i=1}^{m}(y_i - o_i)^2 = \\frac{1}{2}(y_0 - o_0)^2 + \\frac{1}{2}(y_1 - o_1)^2 $$ 其中对 $o_1$ 的偏导数为： $$ \\frac{\\partial J(W)}{\\partial o_1 } = 0 + 2 * \\frac{1}{2} (y_1 - o_1) * -1 = -(y_1 - o_1) $$ （2）然后是求 $\\frac{\\partial o_1}{\\partial net_3}$： $$ o_1 = Sigmoid(net_3) $$ 其中对 $net_3$ 的偏导数为： $$ \\frac{\\partial o_1}{\\partial net_3} = Sigmoid(net_3)' = Sigmoid (net_3) * (1 - Sigmoid(net_3) $$ 激活函数Sigmoid的函数 $f(x)$ 的导数等于 $f(x)*(1-f(x))$ ，见证明。 （3）最后是求 $\\frac{\\partial net_3}{\\partial w_5}$ : $$ net_3 = w_5 * a_0 + w_7 * a_1 + b_1 $$ $$ \\frac{\\partial net_3}{\\partial w_5} = a_0 * 1 + 0 = a_0 $$ 所以最终求得偏导项： $$ \\frac{\\partial J(W)}{\\partial w_5} = -(y_1 - o_1) * Sigmoid (net_3) * (1 - Sigmoid(net_3)) * a_0 $$ 而 $w_5$ 也能在反向传播中更新自己的权重，通过减去 $a * \\frac{\\partial J(W)}{\\partial w_5}$。 第三个导数项求偏导时都会等于上一层的激活函数的输出值，如果把前两个导数项 $\\frac{\\partial J(W)}{\\partial o_i } * \\frac{\\partial o_i}{\\partial net_i}$ 用符号 $\\delta_i$ 代替的话，那么：$$\\frac{\\partial J(W)}{\\partial w_5} = a_j\\delta_i$$ 如果要更新隐藏层的权重 $w_1$ ，则 $$ \\frac{\\partial J(W)}{\\partial w_1} = \\frac{\\partial J(W)}{\\partial a_0 } * \\frac{\\partial a_0}{\\partial net_0} * \\frac{\\partial net_0}{\\partial w_1} $$ 因为 $\\frac{\\partial J(W)}{\\partial a_0 }$ 同时受到 $o_0$ 和 $o_1$ 的影响，所以： $$ \\frac{\\partial J(W)}{\\partial w_1} = (\\frac{\\partial J(W)_0}{\\partial a_0 } + \\frac{\\partial J(W)_2}{\\partial a_0 }) * \\frac{\\partial a_0}{\\partial net_0} * \\frac{\\partial net_0}{\\partial w_1} $$ 其中 $J(W)_0$ 代表在 $o_0$ 的损失，计算和前面的规则类似，依次根据链式求导规则展开即可对给定的 $(x_i, y_i)$ 拟合。 ","date":"2022-02-24","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:4:0","series":null,"tags":null,"title":"机器学习整理（神经网络）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#反向传播"},{"categories":["机器学习"],"content":"其他资料在这里基本打开了神经网络的大门，虽然目前学到只是一个全连接网络和基本的BP算法，但是在这篇文章中可以看到还有支持增量学习的自适应谐振理论网络（ART），以及自动连接神经元的自我组织网络（SOM）等等网络架构。 其他我用到的资料： 一步一步进行反向传播： https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ 上文的在 cnblog 中文翻译： https://www.cnblogs.com/charlotte77/p/5629865.html Sigmoid 激活函数求导推导： https://zhuanlan.zhihu.com/p/215323317 bias 的作用： https://www.zhihu.com/question/305340182 ","date":"2022-02-24","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/:5:0","series":null,"tags":null,"title":"机器学习整理（神经网络）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#其他资料"},{"categories":["机器学习"],"content":"二分类问题问题定义：给定一些特征，给其分类之一。 假设函数 $h(x)$ 定义： $$ h(x) = g(\\theta^Tx) $$ $$ g(z) = \\dfrac{1}{1 +e^{-z}} $$ 决策边界： 当 $h(x) \u003e= 0.5$ 的时候，y 更有可能预测为 1。 当 $h(x) \u003c 0.5$ 的时候，y 更有可能预测为 0。 当 z 的值为 0，也就是 $\\theta^Tx$ = 0 时就是区分两种分类的决策边界。 决策边界可能是直线，也有可能是曲线、圆。 ","date":"2022-02-22","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/:1:0","series":null,"tags":null,"title":"机器学习整理（逻辑回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#二分类问题"},{"categories":["机器学习"],"content":"代价函数$g(x)$ 是一个“非凸函数”，如果将点距离公式带入到逻辑回归中，就会存在很多局部最优解。 新的代价函数定义： 定义的代价函数图像和原因如下： 如果预测是/接近 0，但是实际的y是 1，这样代价函数的值就会非常大，以此来惩罚（修正）代价函数，而我们需要将代价函数最小化才能计算出 $h(x)$ 的参数 θ。 因为总是存在 $y = 0 $ 或 $y = 1$ ，所以可以将代价函数合并： $$ J(\\theta) = -\\frac{1}{m} [\\sum_{i=1}^{m}y_ilog(h(x_i)) + (1-y_i)log(1-h(x_i)) ] $$ 梯度下降的算法和之前一致，只不过偏导数相对复杂一些。 ","date":"2022-02-22","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/:2:0","series":null,"tags":null,"title":"机器学习整理（逻辑回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#代价函数"},{"categories":["机器学习"],"content":"多分类问题将多个类别的分类，转化成一对一的分类（分类器），每一个分类器相当于在计算属于自己那个分类的逻辑回归。 进行预测时：选择 $max(h_i(x))$ 的分类器，也就是概率最高的一个，如图（右侧）。 ","date":"2022-02-22","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/:3:0","series":null,"tags":null,"title":"机器学习整理（逻辑回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/#多分类问题"},{"categories":["机器学习"],"content":"单元线性回归1、定义假设函数 $h(x) = \\theta_1x + \\theta_0$ 2、尝试用样本拟合假设函数，所有样本点到假设函数的距离，其中$m$为样本数量: $$sum = \\dfrac{1}{2m} \\sum_{1}^{m} (h(x_i) - y_i)^2$$ 3、当 sum 的值越小，假设函数的偏差就预测样本更加精确。这个表达式就是代价函数 $j(\\theta)$ ，目标就是最小化代价函数的值。 4、假设 $h(x)$ 没有常数项 $\\theta_0$ ， $h(x)$ 将会会是一个从原点出发的直线，不断变动 $\\theta_1$ 的值（斜率），带入样本 $(1, 1), (2, 2) , (3, 3)$ 可以发现代价函数 $j(\\theta)$是一个二次函数，并且在值为 1 的时候，代价函数 $h(x)$ 的值最小。 ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:1:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#单元线性回归"},{"categories":["机器学习"],"content":"梯度下降问题：为了将代价函数最小化，但是代价函数$J(\\theta)$在多维后不能可视化，所以需要一种方法来求得最小值。 梯度下降算法描述： 对于每一个 $\\theta_i$ 参数，不断减去代价函数$j(\\theta_0 \\cdots \\theta_n)$ 对 $\\theta_i$ 的偏导和学习率 $a$ ，直到收敛，收敛的意思是导数项为0，$\\theta_i$ 的值不再发生变化。 线性回归的梯度下降的代价函数总是一个凸函数，没有局部最优解，只有全局最优解。 ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#梯度下降"},{"categories":["机器学习"],"content":"学习率的取值1、学习率太大收敛不了，梯度下降的过程中，不断跳过最低点，需要适当调小学习率； 2、太小的话学习速度太慢 3、学习率总能到达局部最低点，即使学习率是固定的，因为接近最低解的时候，导数会自动变化。 4、调试梯度下降，保证梯度下降是在正确运行要求是每次迭代都需要降低 $J(\\theta)$ 的值，设定收敛阈值 $\\sigma$ 。 ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:3:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#学习率的取值"},{"categories":["机器学习"],"content":"多元线性回归当处理的问题的特征输入变成多个时，假设函数将会变成: $$ h(x) = \\theta_0x_0 + \\theta_1x_1 + \\cdots + \\theta_nx_n $$ 其中 $x_0$ = 1。 如果假设两个矩阵: $$ X = \\begin{bmatrix} x_0 \\ x_1 \\ \\cdots \\ x_n \\end{bmatrix}, \\Theta= \\begin{bmatrix} \\theta_0 \\ \\theta_1 \\ \\cdots \\ \\theta_n \\end{bmatrix} $$ 那么假设函数就能表示为： $$ h(x) = \\Theta^TX $$ ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:4:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#多元线性回归"},{"categories":["机器学习"],"content":"特征缩放将特征的值放到相同的规模上，如果不在同一规模，有可能要梯度下降很久。 面对这种问题，经验是将特征缩放到 -1 ~ 1 之间。 缩放的方法：均值归一化，特征值减去平均值除以特征的范围。 ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:5:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#特征缩放"},{"categories":["机器学习"],"content":"正规方程求解除了梯度下降的方法找到最优点，还可以直接通过求导数值为0的点计算出结果。当 $$J(\\theta_0, \\theta_1, \\cdots, \\theta_m) = \\dfrac{1}{2m} \\sum_{1}^{m} (h(x_i) - y_i)^2$$ 只要代价函数求得对每个 $\\theta$ 的偏导的值为 0 的点即可。 $$ \\dfrac{\\partial}{\\partial\\theta_j} J(\\theta_0, \\theta_1, \\cdots, \\theta_m) = \\cdots = 0 $$ 正规方程在求解大特征的时候需要求转置和矩阵的逆，但是在n小的时候求得比较快。（特征少的时候选择）。 ","date":"2022-02-21","objectID":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:6:0","series":null,"tags":null,"title":"机器学习整理（线性回归）","uri":"/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/#正规方程求解"},{"categories":null,"content":"拉链法的 unordered_map 和你想象中的不一样根据数组+拉链法的描述，我们很快能想到下面这样的拉链法实现的哈希表，但真的是这样吗？一起看下源码里的实现是怎么样的。 ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:1:0","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#拉链法的-unordered_map-和你想象中的不一样"},{"categories":null,"content":"深入STL源码代码不会骗人的，可以写一个简单的代码研究一下实现，然后通过gdb跟踪执行： #include \u003cvector\u003e#include \u003cunordered_map\u003e int main() { std::unordered_map\u003cint, int\u003e hashmap; hashmap[26] = 26; } 编译和打开gdbgui： g++ -g hashmap.cc -std=c++11 -o hashmap_test gdbgui -r -p 8000 ./hashmap_test gdb 跟进发现代码会走到 hashtable_policy.h 的 operator[] 函数中，代码我做了一些简化，只提取了关键代码： auto operator[](const key_type\u0026 __k) -\u003e mapped_type\u0026 { __hashtable* __h = static_cast\u003c__hashtable*\u003e(this); // 根据 key 获得 hashcode __hash_code __code = __h-\u003e_M_hash_code(__k); // 根据 key 和 hashcode 获得 bucket 的 index：n std::size_t __n = __h-\u003e_M_bucket_index(__k, __code); // 在 bucket n 内尝试找到节点key为k的节点 __node_type* __p = __h-\u003e_M_find_node(__n, __k, __code); if (!__p) { // 如果找到的节点为 nullptr，那么就重新分配一个节点并且将新节点插入到 hash 表中。 __p = __h-\u003e_M_allocate_node(k); return __h-\u003e_M_insert_unique_node(__n, __code, __p)-\u003esecond; } return __p-\u003e_M_v().second; } operator[]函数的功能是计算key的hash值，再通过hash值找到对应的bucket n，最后在这个bucket内查找是不是有一个key=k的节点， 如果没有找到需要的节点，就会新分配并且插入一个新的节点。 那么这个节点如何插入的呢？跟进下插入函数 _h-\u003e_M_insert_unique_node(__n, __code, __p): auto _M_insert_unique_node(__bkt, __code, __node, size_type __n_elt = 1) -\u003e iterator { // 判断是否需要 rehash const __rehash_state\u0026 __saved_state = _M_rehash_policy._M_state(); std::pair\u003cbool, std::size_t\u003e __do_rehash = _M_rehash_policy._M_need_rehash(_M_bucket_count, _M_element_count, __n_elt); if (__do_rehash.first) { _M_rehash(__do_rehash.second, __saved_state); __bkt = _M_bucket_index(this-\u003e_M_extract()(__node-\u003e_M_v()), __code); } this-\u003e_M_store_code(__node, __code); // Always insert at the beginning of the bucket. // 将节点插入到 bucket 的开始位置 _M_insert_bucket_begin(__bkt, __node); ++_M_element_count; return iterator(__node); } _M_insert_unique_node() 这个插入函数主要作用是判断如果新插入节点，这个hash表的负载会不会过高？需不需要重新扩容，完成扩容后通过_M_insert_bucket_begin()再插入到 bucket 的 begin 的位置，这里 rehash 的过程我们暂时不关注，先看下_M_insert_bucket_begin() 这个函数是怎么实现的： _M_insert_bucket_begin(size_type __bkt, __node_type* __node) { // 判断bucket n 是否为空 if (_M_buckets[__bkt]) { // Bucket is not empty, we just need to insert the new node // after the bucket before begin. // 如果 bucket 不为空，用头插法将节点插入到开头 __node-\u003e_M_nxt = _M_buckets[__bkt]-\u003e_M_nxt; _M_buckets[__bkt]-\u003e_M_nxt = __node; } else { // The bucket is empty, the new node is inserted at the // beginning of the singly-linked list and the bucket will // contain _M_before_begin pointer. // 如果节点不为空， __node-\u003e_M_nxt = _M_before_begin._M_nxt; _M_before_begin._M_nxt = __node; if (__node-\u003e_M_nxt) // 如果 __node-\u003e_M_nxt 也就是原来的 _M_before_begin._M_nxt 不为空， // 那么就要就要把 _M_before_begin._M_nxt 指向新的 node__。 // We must update former begin bucket that is pointing to // _M_before_begin. _M_buckets[_M_bucket_index(__node-\u003e_M_next())] = __node; // 将 _M_before_begin 赋值给 bucket n。 _M_buckets[__bkt] = \u0026_M_before_begin; } } 现在就到了插入节点的精彩部分了，当前 bucket 是否为空将函数划分成了两个部分，接下来将用图例的方式来展示整个插入过程。 ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:2:0","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#深入stl源码"},{"categories":null,"content":"插入第一个节点首先先看为空的情况: 在进入函数前，有： 预先创建好的(hashmap 构造函数) buckets 一个成员变量_M_before_begin 一个新分配出来的插入节点__p 当前插入的值为26，做完哈希计算n = 26 % 7 = 5，那么就会在bucket[5]做插入： 当 bucket[5] 为空的插入代码为： __node-\u003e_M_nxt = _M_before_begin._M_nxt; // ① _M_before_begin._M_nxt = __node; // ② if (__node-\u003e_M_nxt) _M_buckets[_M_bucket_index(__node-\u003e_M_next())] = __node; _M_buckets[__bkt] = \u0026_M_before_begin; // ③ ①、②两步就是经典链表的头插法，插入到两个节点中间。 因为这里 __node-\u003e_M_nxt 是指向nullptr的，具体的逻辑先跳过。 然后第③步将_M_before_begin的地址赋值给bucket[n] 于是得到了一个头插法后的链表： ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:2:1","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#插入第一个节点"},{"categories":null,"content":"插入同bucket的第二个节点如果尝试在同一个 bucket 插入一个新的值，因为当前 bucket 有值，代码就会走到_M_insert_bucket_begin()这个函数的前半部分： if (_M_buckets[__bkt]) { // Bucket is not empty, we just need to insert the new node // after the bucket before begin. // 如果 bucket 不为空，用头插法将节点插入到开头 __node-\u003e_M_nxt = _M_buckets[__bkt]-\u003e_M_nxt; _M_buckets[__bkt]-\u003e_M_nxt = __node; } 简化得到： 到目前为止和想象中的哈希表还是差不多的，不断的插入到一个 bucket 中，并且用链表连在一起，现在尝试插入一个节点到别的 bucket 中： ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:2:2","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#插入同bucket的第二个节点"},{"categories":null,"content":"在不同的bucket插入一个节点先会运行 bucket 为空的前两行，仍然是头插法后的结果： __node-\u003e_M_nxt = _M_before_begin._M_nxt; _M_before_begin._M_nxt = __node; 继续运行接下来的语句： if (__node-\u003e_M_nxt) // We must update former begin bucket that is pointing to // _M_before_begin. _M_buckets[_M_bucket_index(__node-\u003e_M_next())] = __node; _M_buckets[__bkt] = \u0026_M_before_begin; 此时，因为 _M_before_begin._M_nxt 不为空，并且赋值到了新节点 __node 的 _M_nxt 上，此时就会执行逻辑： _M_buckets[_M_bucket_index(__node-\u003e_M_next())] = __node; __node-\u003e_M_next() 也就是 key 为 12 的那个节点，其bucket_index 应该是5，所以bucket[5]的指针将会指向新插入的这个节点。 最后再将bucket[1] 指向 _M_before_begin，得到： 继续简化一下，最终其实会形成一个带哨兵节点的单链表，而每个 bucket 只存有一个指向该链表相应位置的指针，其中_M_before_begin就是这个哨兵节点： ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:2:3","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#在不同的bucket插入一个节点"},{"categories":null,"content":"最终结构 在bucket有值的时候，都是通过前一个指针和头插法插入到对应的 bucket 内。 如果 bucket 没有值，就会把哨兵节点切换到新的 bucket 中。 如: 这么复杂，有什么好处呢？ 遍历的时间复杂度。 假设在这种实现下，遍历整个 hashmap 只需要从 head 指针不断的像 head-\u003enext 移动至 nullptr，如果总共有 n 个元素，k个bucket，时间复杂度也只有 O(n)。 如果是最开始那种实现呢？每个bucket一个链表，需要判断所有 bucket 是否为空，并且遍历每个 bucket 内的链表，时间复杂度会到达 O(n + k)，而且哈希表为了避免哈希冲突，通常会有一个比较大的数组，表达式中的 k 的影响还是挺大的。 ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:2:4","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#最终结构"},{"categories":null,"content":"验证插入的代码已经理解了，验证一下理解的结构是不是真的是这样，再看下hashmap.find(key)的代码，find 的过程其实在 hashmap.operator[] 中已经有了，插入前判断是不是已经有节点了： auto operator[](const key_type\u0026 __k) -\u003e mapped_type\u0026 { __hashtable* __h = static_cast\u003c__hashtable*\u003e(this); // 根据 key 获得 hashcode __hash_code __code = __h-\u003e_M_hash_code(__k); // 根据 key 和 hashcode 获得 bucket 的 index：n std::size_t __n = __h-\u003e_M_bucket_index(__k, __code); // 在 bucket n 内尝试找到节点key为k的节点 __node_type* __p = __h-\u003e_M_find_node(__n, __k, __code); if (!__p) { // ... Do allocate and insert } return __p-\u003e_M_v().second; } 跟踪下函数 __h-\u003e_M_find_node(__n, __k, __code)，会调用 _M_find_before_node(__n, __k, __code): auto _M_find_before_node(size_type __n, const key_type\u0026 __k, __hash_code __code) const -\u003e __node_base* { // _M_buckets[__n] 存储了该 bucket 的 prev，如果不存在，那么这个 bucket 就是空的 __node_base* __prev_p = _M_buckets[__n]; if (!__prev_p) return nullptr; // 从 prev-\u003enext 开始，循环到 prev-\u003enext 为nullptr 或者 prev-\u003enext 的bucket号不是当前bucket 为止。 for (__node_type* __p = __prev_p-\u003e_M_nxt; ; __p = __p-\u003e_M_next()) { if (this-\u003e_M_equals(__k, __code, __p)) return __prev_p; // 循环结束判断 if (!__p-\u003e_M_nxt || _M_bucket_index(__p-\u003e_M_next()) != __n) break; __prev_p = __p; } return nullptr; } 现在判断当前 bucket[n] 是否有值，如果有值，就开始从 prev-\u003enext 开始遍历到 nullptr，或者 bucket 号不是当前bucket的节点。 比如，找一个bucket[2]内的节点的开始和结束： ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:3:0","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#验证"},{"categories":null,"content":"总结标准库内的 STL 的实现还是非常 Amazing 的，它的实现关键词有三个，数组、单链表和哨兵节点，在支持分桶的情况下，还支持了O(n)的遍历复杂度。 另外附上我的参考连接： 帮助我理解了_M_before_begin节点的作用 https://szza.github.io/2021/03/01/C++/2_/ ","date":"2022-02-05","objectID":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/:4:0","series":null,"tags":null,"title":"std::unorderd_map 物理结构详解","uri":"/stdunorderd_map-%E7%89%A9%E7%90%86%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/#总结"},{"categories":null,"content":"前言我使用二级标题来记录题号和题名，后面括号内的内容代表耗时和内存超过了多少人，如果数值比较低代表这道题目还是有研究空间。 比如 (51c, 72m) 代表耗时(consume) 超过了 51% 的人和内存占用(memory) 超过了 72%，很明显，还有更高效率的算法设计可以学习。 ","date":"2021-08-22","objectID":"/leetcode_dp/:1:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#前言"},{"categories":null,"content":"89. 房屋偷窃class Solution { public: int rob(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e dp(nums.size(), vector\u003cint\u003e(2, 0)); dp[0][0] = nums[0]; dp[0][1] = 0; for (int i = 1; i \u003c nums.size(); ++i) { dp[i][0] = dp[i-1][1] + nums[i]; dp[i][1] = std::max(dp[i-1][1], dp[i-1][0]); } return std::max(dp[nums.size()-1][0], dp[nums.size()-1][1]); } }; 0 代表偷窃，1 代表不偷窃。 ","date":"2021-08-22","objectID":"/leetcode_dp/:2:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#89-房屋偷窃"},{"categories":null,"content":"090. 环形房屋偷盗class Solution { public: int rob(vector\u003cint\u003e\u0026 nums) { if (nums.size() == 1) return nums[0]; if (nums.size() == 2) return std::max(nums[0], nums[1]); vector\u003cvector\u003cint\u003e\u003e dp(nums.size(), vector\u003cint\u003e(2, 0)); dp[1][0] = nums[1]; dp[1][1] = nums[0]; for (int i = 2; i \u003c nums.size()-1; ++i) { dp[i][0] = dp[i-1][1] + nums[i]; dp[i][1] = std::max(dp[i-1][1], dp[i-1][0]); } int max1 = std::max(dp[nums.size()-2][0], dp[nums.size()-2][1]); dp[1][0] = nums[1]; dp[1][1] = 0; for (int i = 2; i \u003c nums.size(); ++i) { dp[i][0] = dp[i-1][1] + nums[i]; dp[i][1] = std::max(dp[i-1][1], dp[i-1][0]); } int max2 = std::max(dp[nums.size()-1][0], dp[nums.size()-1][1]); return std::max(max1, max2); } }; 在89题的基础上进行分情况讨论，分别是偷窃 1 ~ n-1 和 2 ~ n。 ","date":"2021-08-22","objectID":"/leetcode_dp/:3:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#090-环形房屋偷盗"},{"categories":null,"content":"123. 买卖股票的最佳时机 IIIclass Solution { public: int maxProfit(vector\u003cint\u003e\u0026 prices) { using std::max; vector\u003cvector\u003cint\u003e\u003e dp (prices.size(), vector\u003cint\u003e(4, 0)); dp[0][0] = -1 * prices[0]; dp[0][2] = -1 * prices[0]; for (int i = 1; i \u003c prices.size(); ++i) { dp[i][0] = max(dp[i-1][0], -prices[i]); dp[i][1] = max(dp[i-1][1], dp[i-1][0] + prices[i]); dp[i][2] = max(dp[i-1][2], dp[i-1][1] - prices[i]); dp[i][3] = max(dp[i-1][3], dp[i-1][2] + prices[i]); } return dp[prices.size()-1][3]; } }; dp[i][0]~dp[i][3] 依次代表持有第一支股票的最高收益，卖出第一支的最高收益，持有第二支的最高收益，卖出第二支的最高收益。 这道题要注意 dp[0][2] 的初始化，对于 1,2,3,4,5 这种情况，卖出后再买入的第二支持有收益肯定是负，不能初始化为 0。 ","date":"2021-08-22","objectID":"/leetcode_dp/:4:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#123-买卖股票的最佳时机-iii"},{"categories":null,"content":"121. 买卖股票的最佳时机class Solution { public: int maxProfit(vector\u003cint\u003e\u0026 prices) { std::vector\u003cint\u003e dp(prices.size(), 0); if (prices.size() == 0) return 0; int min_price = prices[0]; for (int i = 1; i \u003c prices.size(); ++i) { min_price = std::min(min_price, prices[i]); dp[i] = std::max(dp[i-1], prices[i] - min_price); } return dp[prices.size()-1]; } }; 状态转移方程：dp[i]=max(dp[i−1],prices[i]−minprice) ","date":"2021-08-22","objectID":"/leetcode_dp/:5:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#121-买卖股票的最佳时机"},{"categories":null,"content":"53. 最大子序列和class Solution { public: int maxSubArray(vector\u003cint\u003e\u0026 nums) { vector\u003cint\u003e dp(nums.size()); dp[0] = nums[0]; int max_sum = nums[0]; for (int i = 1; i \u003c nums.size(); ++i) { dp[i] = std::max(dp[i-1] + nums[i], nums[i]); max_sum = std::max(max_sum, dp[i]); } return max_sum; } }; 状态转移的时候，如果当前的值加上前面的字符串序列让和降低了，那么就重新开始计算。 ","date":"2021-08-22","objectID":"/leetcode_dp/:6:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#53-最大子序列和"},{"categories":null,"content":"122. 买卖股票的最佳时机 IIclass Solution { public: int maxProfit(vector\u003cint\u003e\u0026 prices) { vector\u003cvector\u003cint\u003e\u003e dp(prices.size(), vector\u003cint\u003e(2)); dp[0][0] = -prices[0]; dp[0][1] = 0; for (int i = 1; i \u003c prices.size(); ++i) { dp[i][0] = std::max(dp[i-1][1] - prices[i], dp[i-1][0]); dp[i][1] = std::max(dp[i-1][0] + prices[i], dp[i-1][1]); } return dp[prices.size()-1][1]; } }; 如果 i 天可以买股票，前一天就需要卖出股票，也就是 dp[i-1][1]。 如果 i 天可以卖股票，那前一天需要持有股票，也就是 dp[i-1][0]。 ","date":"2021-08-22","objectID":"/leetcode_dp/:7:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#122-买卖股票的最佳时机-ii"},{"categories":null,"content":"62. 不同路径class Solution { public: int uniquePaths(int m, int n) { vector\u003cvector\u003cint\u003e\u003e dp(m, vector\u003cint\u003e(n)); for (int i = 0; i \u003c m; ++i) dp[i][0] = 1; for (int i = 0; i \u003c n; ++i) dp[0][i] = 1; for (int i = 1; i \u003c m; ++i) { for (int j = 1; j \u003c n; ++j) { dp[i][j] = dp[i][j-1] + dp[i-1][j]; } } return dp[m-1][n-1]; } }; 1、边上的位置只有一种方法走到，注意一下dp的初始。 2、状态转移为 dp[i][j] = dp[i][j-1] + dp[i-1][j] ","date":"2021-08-22","objectID":"/leetcode_dp/:8:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#62-不同路径"},{"categories":null,"content":"63. 不同路径class Solution { public: int uniquePathsWithObstacles(vector\u003cvector\u003cint\u003e\u003e\u0026 obstacleGrid) { if (obstacleGrid.size() == 0 || obstacleGrid[0].size() == 0) return 0; int m = obstacleGrid.size(); int n = obstacleGrid[0].size(); vector\u003cvector\u003cint\u003e\u003e dp(m, vector\u003cint\u003e(n)); for (int i = 0; i \u003c m \u0026\u0026 obstacleGrid[i][0] != 1; ++i) dp[i][0] = 1; for (int i = 0; i \u003c n \u0026\u0026 obstacleGrid[0][i] != 1; ++i) dp[0][i] = 1; for (int i = 1; i \u003c m; ++i) { for (int j = 1; j \u003c n; ++j) { if (obstacleGrid[i][j] == 1) continue; dp[i][j] = dp[i-1][j] + dp[i][j-1]; } } return dp[m-1][n-1]; } }; ","date":"2021-08-22","objectID":"/leetcode_dp/:9:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#63-不同路径"},{"categories":null,"content":"回文子串class Solution { public: string longestPalindrome(string s) { int n = s.size(); if (n == 1) return s; std::vector\u003cstd::vector\u003cbool\u003e\u003e dp(n, std::vector\u003cbool\u003e(n, false)); for (int i = 0; i \u003c n; ++i) { dp[i][i] = true; } int max_len = 1; int last_begin = 0; for (int len = 2; len \u003c= n; len++) { // i(max) = (i + len) - 1 \u003c n // = i \u003c n - len + 1 for (int i = 0; i \u003c n - len + 1; ++i) { int left = i; int right = i + len - 1; if (len == 2 \u0026\u0026 s[left] == s[right]) { dp[left][right] = true; max_len = len; last_begin = left; continue; } if (s[left] == s[right] \u0026\u0026 s[left+1] == s[right-1]) { dp[left][right] = dp[left+1][right-1]; if (dp[left][right]) { max_len = len; last_begin = left; } } } } return s.substr(last_begin, max_len); } }; 这题的做法是不断地增长长度，看是否可以找到最长的回文串。 dp[left][right] = dp[left+1][right-1]; 如果(left,right)的两端相等，那么同时缩短后的两端也是相等的。 边界情况有两种： left = right 的时候，也就是 len = 1 的时候，肯定是回文串 len = 2 的时候，比如 abb =\u003e (left=1,right=2)，他们递推的前一个是 (left=2,right=1)，在dp数组里面是不会被初始化的，所以要单独初始化。 class Solution { public: pair\u003cint, int\u003e expand(string s, int left, int right) { while (left \u003e= 0 \u0026\u0026 right \u003c s.size() \u0026\u0026 s[left] == s[right]) { ++right; --left; } return {left + 1, right - (left+1)}; } string longestPalindrome(string s) { int beg = 0, len = 0; for (int i = 0; i \u003c s.size(); ++i) { auto [left1, len1] = expand(s, i, i); auto [left2, len2] = expand(s, i, i+1); if (len1 \u003e len) { beg = left1; len = len1; } if (len2 \u003e len) { beg = left2; len = len2; } } return s.substr(beg, len); } }; 中心扩散：利用边界条件推导，并且用expand函数来确定检查扩散逻辑。 // todo: Manacher(马拉车)算法 ","date":"2021-08-22","objectID":"/leetcode_dp/:10:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#回文子串"},{"categories":null,"content":"10. 正则表达式匹配class Solution { public: bool isMatch(string s, string p) { int m = s.size(); int n = p.size(); vector\u003cvector\u003cbool\u003e\u003e dp(m+1, vector\u003cbool\u003e(n+1, false)); auto match = [\u0026](int i, int j) -\u003e bool { if (i == 0) { return false; } if(p[j-1] == '.') { return true; } return s[i-1] == p[j-1]; }; dp[0][0] = true; for (int i = 0; i \u003c= m; ++i) { // 以 i 长度结尾的字符串 for (int j = 1; j \u003c= n; ++j) { if (p[j-1] == '*') { if (match(i, j-1)) { dp[i][j] = dp[i-1][j] || dp[i][j-2]; } else { dp[i][j] = dp[i][j-2]; } } else { if (match(i, j)) dp[i][j] = dp[i-1][j-1]; } } } return dp[m][n]; } }; 状态转移方程：把 abc*d 中的 c*d 合为一体就比较好考虑了，比如要匹配的数据是 abd，这两个数据把 d 比较完成后，比较就是匹配 ab 和 ab(c*) 初始化：其实这道题的难点我觉得在初始化部分，就是当 i（字符串的长度）等于0的时候，是执行可以匹配的，才可以作为后面推导的基础，所以把dp数组的大小扩大了1圈。 边界：主要考虑下面这种情况，如果p[j-1] == ‘*’ \u0026\u0026 match(i, j-1) == false 的情况，这种情况下还是能递推完全没有(c*)的这种情况。 if (p[j-1] == '*') { if (match(i, j-1)) { } } ","date":"2021-08-22","objectID":"/leetcode_dp/:11:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#10-正则表达式匹配"},{"categories":null,"content":"368. 最大整除子集 (51c,72m)class Solution { public: vector\u003cint\u003e largestDivisibleSubset(vector\u003cint\u003e\u0026 nums) { std::sort(nums.begin(), nums.end()); vector\u003cint\u003e dp(nums.size()+1, 0); dp[0] = 0; int max_len = 0; int max_value = 0; for (int i = 1; i \u003c= nums.size(); ++i) { // dp[i] 为以第 i 个数结尾的最大整除子集的大小 for (int j = i; j \u003e 0; --j) { if (nums[i-1] % nums[j-1] == 0) { dp[i] = std::max(dp[j] + 1, dp[i]); } } if (max_len \u003c dp[i]) { max_len = dp[i]; max_value = nums[i-1]; } } vector\u003cint\u003e res; for (int i = dp.size()-1; i \u003e 0; --i) { if (dp[i] == max_len \u0026\u0026 max_value % nums[i-1] == 0 \u0026\u0026 max_len \u003e 0) { res.push_back(nums[i-1]); max_value = nums[i-1]; --max_len; } } return res; } }; 排序，使后面的值能够循环处理整除 记录最大值和最大子集大小，用于推导最终结果。 ","date":"2021-08-22","objectID":"/leetcode_dp/:12:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#368-最大整除子集-51c72m"},{"categories":null,"content":"983. 最低票价 (100c, 76m)class Solution { public: int mincostTickets(vector\u003cint\u003e\u0026 days, vector\u003cint\u003e\u0026 costs) { int total_days = days[days.size()-1]; vector\u003cint\u003e dp(total_days+1, 0); int travel_day_idx = 0; for (int i = 1; i \u003c= total_days; ++i) { if (days[travel_day_idx] != i) { dp[i] = dp[i-1]; } else { int cost = INT_MAX; cost = min(dp[max(i-1, 0)] + costs[0], cost); cost = min(dp[max(i-7, 0)] + costs[1], cost); cost = min(dp[max(i-30, 0)] + costs[2], cost); dp[i] = cost; travel_day_idx++; } } return dp[total_days]; } }; 和前几天关联的时候不要用这种方式，因为天数不够也是能买多天的票的，比如7天的票2元，1天的票7元这种case就会过不了。 if (i \u003e= 1) cost = min(dp[min(i-1, 0)] + costs[0], cost); if (i \u003e= 7) cost = min(dp[min(i-7, 0)] + costs[1], cost); if (i \u003e= 30) cost = min(dp[min(i-30, 0)] + costs[2], cost); dp 方程的解释：dp[i] 为第i天最小的出行开销，找到1，7，30天前最小的开销就好，如果某天不出行，开销和前天保持一致。 ","date":"2021-08-22","objectID":"/leetcode_dp/:13:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#983-最低票价-100c-76m"},{"categories":null,"content":"64. 最小路径和 (80c, 49m)class Solution { public: int minPathSum(vector\u003cvector\u003cint\u003e\u003e\u0026 grid) { int m = grid.size(); int n = grid[0].size(); vector\u003cvector\u003cint\u003e\u003e dp(m, vector\u003cint\u003e(n, 0)); dp[0][0] = grid[0][0]; for (int i = 1; i \u003c n; ++i) { dp[0][i] = dp[0][i-1] + grid[0][i]; } for (int i = 1; i \u003c m; ++i) { dp[i][0] = dp[i-1][0] + grid[i][0]; } for (int i = 1; i \u003c m; ++i) { for (int j = 1; j \u003c n; ++j) { dp[i][j] = std::min(dp[i][j-1], dp[i-1][j]) + grid[i][j]; } } return dp[m-1][n-1]; } }; 和不同路径一题一样的解法，初始化+定义转移方程即可解出来。 ","date":"2021-08-22","objectID":"/leetcode_dp/:14:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#64-最小路径和-80c-49m"},{"categories":null,"content":"095. 最长公共子序列 (57c,56m)class Solution { public: int longestCommonSubsequence(string text1, string text2) { int m = text1.size(); int n = text2.size(); vector\u003cvector\u003cint\u003e\u003e dp(m+1, vector\u003cint\u003e(n+1, 0)); for (int i = 1; i \u003c= m; ++i) { for (int j = 1; j \u003c= n; ++j) { if (text1[i-1] == text2[j-1]) { dp[i][j] = dp[i-1][j-1] + 1; } else { dp[i][j] = max(dp[i-1][j], dp[i][j-1]); } } } return dp[m][n]; } }; 经典问题：dp[i][j] 的定义为第 i 和第 j 结尾的字符的最小子序列长度。 ","date":"2021-08-22","objectID":"/leetcode_dp/:15:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#095-最长公共子序列-57c56m"},{"categories":null,"content":"1092. 最短公共超序列(34c,31m)class Solution { public: string shortestCommonSupersequence(string str1, string str2) { int m = str1.size(); int n = str2.size(); vector\u003cvector\u003cstring\u003e\u003e dp(m+1, vector\u003cstring\u003e(n+1)); for (int i = 1; i \u003c= m; ++i) { for (int j = 1; j \u003c= n; ++j) { if (str1[i-1] == str2[j-1]) { dp[i][j] = dp[i-1][j-1] + str1[i-1]; } else { int l1 = dp[i-1][j].size(); int l2 = dp[i][j-1].size(); if (l1 \u003e l2) dp[i][j] = dp[i-1][j]; else dp[i][j] = dp[i][j-1]; } // std::cout \u003c\u003c \"[\" \u003c\u003c dp[i][j] \u003c\u003c \"] \"; } // std::cout \u003c\u003c std::endl; } // return dp[m][n]; string lcs = dp[m][n]; int p1 = 0, p2 = 0; string scs; for (auto c : lcs) { while (p1 \u003c m \u0026\u0026 str1[p1] != c) { scs += str1[p1]; ++p1; } while (p2 \u003c n \u0026\u0026 str2[p2] != c) { scs += str2[p2]; ++p2; } scs += c; ++p1; ++p2; } scs += str1.substr(p1); scs += str2.substr(p2); return scs; } }; 通过 LCS 得到最长公共子序列 公共子序列的每一个字符是一个关键节点，相当于一个栅栏，两个序列在这个点同步了，先把公共节点前面的处理完，追加公共节点，再依此类推，最后再追加一下在公共子序列后面的字符。 ","date":"2021-08-22","objectID":"/leetcode_dp/:16:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#1092-最短公共超序列34c31m"},{"categories":null,"content":"72. 编辑距离(20c, 19m)class Solution { public: int minDistance(string word1, string word2) { int m = word1.size(); int n = word2.size(); vector\u003cvector\u003cint\u003e\u003e dp(m+1, vector\u003cint\u003e(n+1, 0)); for (int i = 0; i \u003c= m; ++i) { dp[i][0] = i; } for (int j = 0; j \u003c= n; ++j) { dp[0][j] = j; } for (int i = 1; i \u003c= m; ++i) { for (int j = 1; j \u003c= n; ++j) { if (word1[i-1] == word2[j-1]) { dp[i][j] = dp[i-1][j-1]; } else { dp[i][j] = std::min(dp[i-1][j-1], min(dp[i-1][j], dp[i][j-1])) + 1; } } } return dp[m][n]; } }; 题目中要注意的点： 1、word1和word2都是可以修改的。 2、给word1追加一个字符和给word2删除一个字符是等价的。 定义 dp[i][j] 为 word1 前i个元素和 word2 的前j个元素最小需要的变化操作数量。 状态转移： 如果 word1[i] = word2[j]： dp[i][j] = dp[i-1][j-1] 否则： 给 word1 追加：dp[i][j-1]+1，追加的字符补充在 word1 后面，即word1[i+1] = word2[j]，所以 word1[0:i] 需要和 word2[0:j-1] 相等。 给 word2 追加：dp[i-1][j]+1 给 word1 替换：dp[i-1][j-1]+1，替换使得 word1[i] = word2[j]，(i, j) 前面的操作次数加1即可。 并且取最小值即可。 最后初始化部分：一个字符串变成空串操作次数为字符串的长度。 ","date":"2021-08-22","objectID":"/leetcode_dp/:17:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#72-编辑距离20c-19m"},{"categories":null,"content":"72. 编辑距离(100c, 93m)class Solution { public: int minDistance(string word1, string word2) { int m = word1.size(); int n = word2.size(); // A if (m*n == 0) return n+m; // B // vector\u003cvector\u003cint\u003e\u003e dp(m+1, vector\u003cint\u003e(n+1, 0)); int dp[m+1][n+1]; for (int i = 0; i \u003c= m; ++i) { dp[i][0] = i; } for (int j = 0; j \u003c= n; ++j) { dp[0][j] = j; } for (int i = 1; i \u003c= m; ++i) { for (int j = 1; j \u003c= n; ++j) { if (word1[i-1] == word2[j-1]) { dp[i][j] = dp[i-1][j-1]; } else { dp[i][j] = std::min(dp[i-1][j-1], min(dp[i-1][j], dp[i][j-1])) + 1; } } } return dp[m][n]; } }; 前一种解法耗时和内存都很高，对比提交记录里面更加快速的答案，看到有几个优化点： A：如果任意一个是空串，那返回另外一个的长度即可。 B：dp[i][j] 的值由子结构确定，不需要和自己比较，不用走 memset 之类的初始化也可以得到最终的结果。 ","date":"2021-08-22","objectID":"/leetcode_dp/:18:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#72-编辑距离100c-93m"},{"categories":null,"content":"97. 交错字符串(79c, 57m)class Solution { public: bool isInterleave(string s1, string s2, string s3) { int m = s1.size(); int n = s2.size(); if (m + n != s3.size()) return false; vector\u003cvector\u003cbool\u003e\u003e dp (m+1, vector\u003cbool\u003e(n+1, false)); dp[0][0] = true; for (int i = 1; i \u003c= m; ++i) { dp[i][0] = (s3[i-1] == s1[i-1] \u0026\u0026 dp[i-1][0]); } for (int j = 1; j \u003c= n; ++j) { dp[0][j] = (s3[j-1] == s2[j-1] \u0026\u0026 dp[0][j-1]); } // i + j 是否能交错成非空 for (int i = 1; i \u003c= m; ++i) { for (int j = 1; j \u003c= n; ++j) { if (s3[i+j-1] == s1[i-1] \u0026\u0026 dp[i-1][j] != false) { dp[i][j] = true; } if (s3[i+j-1] == s2[j-1] \u0026\u0026 dp[i][j-1] != false) { dp[i][j] = true; } } } return dp[m][n]; } }; 单纯双指针是不行的，因为s1/s2同时碰到相同的字符的时候，选错指针移动就会错过合适的序列，除非加上回溯和其他方法。 dp 状态定义为，s1[0:i] 和 s2[0:j] 是否能交错成 s3[0:i+j] 的字符串，再关联 dp[i][j] 和前面一个子问题的关系，并且处理好初始化即可。 ","date":"2021-08-22","objectID":"/leetcode_dp/:19:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#97-交错字符串79c-57m"},{"categories":null,"content":"115. 不同的子序列(43c, 44m)class Solution { public: using ull = unsigned long long; int numDistinct(string s, string t) { int m = s.size(); int n = t.size(); if (m \u003c n) return 0; vector\u003cvector\u003cull\u003e\u003e dp (m + 1, vector\u003cull\u003e(n + 1, 0)); dp[0][0] = 1; for (int i = 1; i \u003c m; ++i) { dp[i][0] = 1; } for (int j = 1; j \u003c= n; ++j) { for (int i = 1; i \u003c= m; ++i) { if (s[i-1] == t[j-1]) { dp[i][j] = dp[i-1][j-1] + dp[i-1][j]; } else { dp[i][j] = dp[i-1][j]; } } } return dp[m][n]; } }; 这题中间值有溢出，扩大一下数据类型的范围。 这题的 dp 和编辑距离那题比较相似，dp[i][j] 代表前 i 和 j 个字符的子序列个数。如果不相等，只能让 i-1（删除掉i），因为 t 是 s 的子序列。如果相等，就会有两种情况，删除掉这个 i 字母，以及同时向前挪一格检查子结构。 ","date":"2021-08-22","objectID":"/leetcode_dp/:20:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#115-不同的子序列43c-44m"},{"categories":null,"content":"813. 最大平均值和的分组(7c, 38m)class Solution { public: double largestSumOfAverages(vector\u003cint\u003e\u0026 nums, int k) { int n = nums.size(); vector\u003cvector\u003cdouble\u003e\u003e dp(n + 1, vector\u003cdouble\u003e(k + 1, 0)); auto avg = [\u0026](int p1, int p2) -\u003e double { double res = 0.0; for (int i = p1; i \u003c= p2; ++i) { res += nums[i]; } return res / (p2 - p1 + 1); }; for (int i = 1; i \u003c= n; ++i) { for (int j = 1; j \u003c= min(i, k); ++j) { if (j == 1) { dp[i][j] = avg(0, i-1); continue; } for (int i0 = j - 1; i0 \u003c i; ++i0) { dp[i][j] = max(dp[i][j], dp[i0][j-1] + avg(i0, i-1)); } } } return dp[n][k]; } }; ","date":"2021-08-22","objectID":"/leetcode_dp/:21:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#813-最大平均值和的分组7c-38m"},{"categories":null,"content":"410. 分割数组的最大值(20c, 5m)class Solution { public: int splitArray(vector\u003cint\u003e\u0026 nums, int m) { int n = nums.size(); vector\u003cvector\u003cint\u003e\u003e dp(n + 1, vector\u003cint\u003e(m + 1, INT_MAX)); vector\u003cvector\u003cint\u003e\u003e sum(n + 1, vector\u003cint\u003e(n + 1, 0)); for (int i = 1; i \u003c= n; ++i) { for (int j = i; j \u003c= n; ++j) { sum[i][j] = sum[i][j-1] + nums[j-1]; } } for (int i = 1; i \u003c= n; ++i) { for (int j = 1; j \u003c= min(m, i); ++j) { if (j == 1) { dp[i][j] = sum[1][i]; continue; } for (int i0 = j - 1; i0 \u003c i; ++i0) { dp[i][j] = min(dp[i][j], max(dp[i0][j-1], sum[i0+1][i])); } } } return dp[n][m]; } }; 区间型dp，在最内层循环中，做了两个区间的约束和求值，即从（0 ～ i0）区间里面的最值和当前区间 (i0+1, i) 找到结果，通过不断移动 i0 来寻找。 ","date":"2021-08-22","objectID":"/leetcode_dp/:22:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#410-分割数组的最大值20c-5m"},{"categories":null,"content":"1335. 工作计划的最低难度 (66c, 24m)class Solution { public: int minDifficulty(vector\u003cint\u003e\u0026 jobDifficulty, int d) { int n = jobDifficulty.size(); if (n \u003c d) { return -1; } vector\u003cvector\u003cint\u003e\u003e dp (n + 1, vector\u003cint\u003e(d + 1, INT_MAX)); vector\u003cvector\u003cint\u003e\u003e max_cache(n + 1, vector\u003cint\u003e(n + 1, 0)); for (int i = 1; i \u003c= n; ++i) { for (int j = i; j \u003c= n; ++j) { max_cache[i][j] = max(max_cache[i][j-1], jobDifficulty[j-1]); } } for (int i = 1; i \u003c= n; ++i) { for (int j = 1; j \u003c= min(d, i); ++j) { if (j == 1) { dp[i][j] = max_cache[1][i]; continue; } for (int i0 = j - 1; i0 \u003c i; ++i0) { dp[i][j] = min(dp[i][j], dp[i0][j-1] + max_cache[i0+1][i]); } } } return dp[n][d]; } }; 和分割数组最大值几乎一样，dp方程有少许改动，dp求值的结果代表是所有工作日的难度。 ","date":"2021-08-22","objectID":"/leetcode_dp/:23:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#1335-工作计划的最低难度-66c-24m"},{"categories":null,"content":"516. 最长回文子序列class Solution { public: int longestPalindromeSubseq(string s) { int n = s.size(); vector\u003cvector\u003cint\u003e\u003e dp (n + 1, vector\u003cint\u003e(n + 1, 0)); for (int len = 1; len \u003c= n; ++len) { for (int i = 1; i + len - 1 \u003c= n ; ++i) { int j = i + len - 1; if (len == 1) { dp[i][j] = 1; } else if (s[i-1] == s[j-1]) { dp[i][j] = dp[i+1][j-1] + 2; } else { dp[i][j] = max(dp[i+1][j], dp[i][j-1]); } } } return dp[1][n]; } }; dp[i][j] 的定义为 i 到 j 最长的公共子序列，状态转移方程和最长公共子序列比较类似，检查端点，如果相同，同时向中心靠拢。不相同则找到最大值。 比如：“bbbab” 到计算逻辑为： 1-1(1) 2-2(1) 3-3(1) 4-4(1) 5-5(1) 1-2(2) 2-3(2) 3-4(2) 4-5(2) 1-3(3) 2-4(3) 3-5(3) 1-4(4) 2-5(4) 1-5(5) 首先计算好子问题的值，再递推开始字符索引为1，结束字符为n的结果。 ","date":"2021-08-22","objectID":"/leetcode_dp/:24:0","series":null,"tags":null,"title":"Leetcode: dp 专题","uri":"/leetcode_dp/#516-最长回文子序列"},{"categories":["notes"],"content":"相关性计算首先通过下面的更新语句，插入几条语句： PUT /megacorp/employee/1 { \"first_name\" : \"John\", \"last_name\" : \"Smith\", \"age\" : 25, \"about\" : \"I love to go rock climbing\", \"interests\": [ \"sports\", \"music\" ] } PUT /megacorp/employee/2 { \"first_name\" : \"Jane\", \"last_name\" : \"Smith\", \"age\" : 32, \"about\" : \"I like to collect rock albums\", \"interests\": [ \"music\" ] } PUT /megacorp/employee/3 { \"first_name\" : \"Douglas\", \"last_name\" : \"Fir\", \"age\" : 35, \"about\": \"I like to build cabinets\", \"interests\": [ \"forestry\" ] } 索引中目前一共三个文档： “I love to go rock climbing” “I like to build cabinets” “I like to collect rock albums” 如果使用下面下面的查询语句： GET /megacorp/_search { \"query\" : { \"match\" : { \"about\" : \"rock climbing\" } }, \"explain\" : true } 在 _search 的时候加上 explain 选项就能在结果中输出相关性计算解释。 \"_explanation\" : { \"value\" : 1.4167401, \"description\" : \"sum of:\", \"details\" : [ { \"value\" : 0.4589591, \"description\" : \"weight(about:rock in 0) [PerFieldSimilarity], result of:\", \"details\" : [ { \"value\" : 0.4589591, \"description\" : \"score(freq=1.0), computed as boost * idf * tf from:\", \"details\" : [ { \"value\" : 2.2, \"description\" : \"boost\", \"details\" : [ ] }, { \"value\" : 0.47000363, \"description\" : \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\", \"details\" : [ { \"value\" : 2, \"description\" : \"n, number of documents containing term\", \"details\" : [ ] }, { \"value\" : 3, \"description\" : \"N, total number of documents with field\", \"details\" : [ ] } ] }, { \"value\" : 0.44386417, \"description\" : \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\", \"details\" : [ { \"value\" : 1.0, \"description\" : \"freq, occurrences of term within document\", \"details\" : [ ] }, { \"value\" : 1.2, \"description\" : \"k1, term saturation parameter\", \"details\" : [ ] }, { \"value\" : 0.75, \"description\" : \"b, length normalization parameter\", \"details\" : [ ] }, { \"value\" : 6.0, \"description\" : \"dl, length of field\", \"details\" : [ ] }, { \"value\" : 5.6666665, \"description\" : \"avgdl, average length of field\", \"details\" : [ ] } ] } ] } ] }, { \"value\" : 0.95778096, \"description\" : \"weight(about:climbing in 0) [PerFieldSimilarity], result of:\", \"details\" : [ { \"value\" : 0.95778096, \"description\" : \"score(freq=1.0), computed as boost * idf * tf from:\", \"details\" : [ { \"value\" : 2.2, \"description\" : \"boost\", \"details\" : [ ] }, { \"value\" : 0.98082924, \"description\" : \"idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\", \"details\" : [ { \"value\" : 1, \"description\" : \"n, number of documents containing term\", \"details\" : [ ] }, { \"value\" : 3, \"description\" : \"N, total number of documents with field\", \"details\" : [ ] } ] }, { \"value\" : 0.44386417, \"description\" : \"tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\", \"details\" : [ { \"value\" : 1.0, \"description\" : \"freq, occurrences of term within document\", \"details\" : [ ] }, { \"value\" : 1.2, \"description\" : \"k1, term saturation parameter\", \"details\" : [ ] }, { \"value\" : 0.75, \"description\" : \"b, length normalization parameter\", \"details\" : [ ] }, { \"value\" : 6.0, \"description\" : \"dl, length of field\", \"details\" : [ ] }, { \"value\" : 5.6666665, \"description\" : \"avgdl, average length of field\", \"details\" : [ ] } ] } ] } ] } ] } 从返回结果中可以看到，其实相关性计算的分数是 rock 和 climbing 两个词语的相关性分数相加而成： $$ score = score(rock) + score(climbing) $$ 而每个词语的分数的计算公式为： $$ score(word) = boost * idf * tf $$ 其中 boost 在这里先可以理解为常量，重点在于词频 tf (Term Frequency) 和逆文档频率 idf (Inverse Document Frequency)。词频表示在这篇文档中出现的次数，出现次数越多也就更加相关，逆文档频率是指含有这个词的文档的数量的逆，也就是说这个词在所有文档中出现得越频繁，这个词就越不重要。 更加具体的计算公式在 explaination 中也描述得特别清晰： 其中 idf 的计算公式为： $$ ln(1 + \\frac{N - n + 0.5}{n + 0.5}) $$ n 为含有该词语文档的个数 N 为含有这个字段的文档总数（包括曾经被索引过的文档数） tf 的计算公式为： $$ \\frac{freq}{freq + k1 * (1 - b * \\frac{dl}{avg_dl})} $$ 公式中有k1，b 这两个常量，在这里先不用关系它们。变量有 freq 代表词语在文档中出现的频次，avgdl 平均文档长度，以及 dl 当前文档长度。我们可以稍微化简下公式： $$ \\frac{1}{1 + \\frac{k1 * (1 - b * \\frac{dl}{avg_dl})}{freq}} $$ 那么就能分析到，freq 越大，频次越高，文档也就越相关；dl 越大，值就会更小，文档就更加不相干；avgdl 越大，平局文档长度越长（词越稀有），文档就会越相关。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:1:0","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#相关性计算"},{"categories":["notes"],"content":"计算词 rock 在 doc_0 中的相关性计算: score = boost * idf * tf boost = 2.2 idf = ln(1 + (N - n + 0.5) / (n + 0.5)) = ln 1.6 = 0.47000363 n = 2 ：含有该词语文档的个数 N = 3： 含有这个字段的文档总数（包括曾经被索引过的文档数） tf = freq / (freq + k1 * (1 - b + b * dl / avgdl)) = 0.44386417 freq = 1：在文档中出现的次数 k1 * (1 - b + b * dl / avgdl) = dl / avgdl：文档长度变量，文档长度越长，更加相关。 b、k1 都是常参数，dl 是指该文档的字段长度 ，avgdl 指的是平均文档字段长度。 词 climbing 在 doc_0 中的相关性计算: boost = 2.2 idf = ln(1 + (N - n + 0.5) / (n + 0.5)) = ln 2.66 = 0.98082924 n = 1 ：含有该词语文档的个数 N = 3： 含有这个字段的文档总数（包括曾经被索引过的文档数） tf = 0.44386417 最终计算出的相关性分 = 2.2 * 0.47000363 * 0.44386417 + 2.2 * 0.98082924 * 0.44386417 = 1.4167401 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:1:1","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#计算"},{"categories":["notes"],"content":"ES 分片如何索引文档一篇文档会被分词分解成一个个词语，生成一个倒排索引，一个倒排索引是一个 Lucene 索引的段，多个段组成一个 Lucene 索引，而一个 Lucene 索引被称之为一个 ElasticSearch 的分片，将多个分片分布式存储形成了 ElasticSearch。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:0","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#es-分片如何索引文档"},{"categories":["notes"],"content":"ES 倒排索引的特性ES 的倒排索引在写入磁盘是 保持不变的，这样优势是： 不需要锁 因为不变性，内核不需要再读取磁盘，直接缓存到内存中请求内存。 对于某个索引 filter 缓存将会一直有效 缺点是因为不可变，新加入一个文档都需要重建索引，索引的数据量大小和更新频率可能只能选择其一。 为了保持不变性，可以增加新的索引反馈最近的修改，并且使得每个索引都会被查询到，在每一个分片上查询完结果后合并。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:1","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#es-倒排索引的特性"},{"categories":["notes"],"content":"索引更新流程1、新的文档被追加到内存索引缓存中，内存索引缓存会不时地提交到磁盘，此时在内存中，还不可见。 2、缓存被提交的时候，会提交一个新的段（一个新的倒排索引）和一个带有新段名字的提交点到磁盘。 3、被提交到磁盘的新段被读取打开，里面包含的文档可以被搜索。 4、内存缓存被清空，准备接受新的文档。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:2","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#索引更新流程"},{"categories":["notes"],"content":"实时搜索的保证因为按段搜索（多个倒排索引）的存在，一个新的文档从索引到可被搜索（按段写入磁盘）的延迟降低了，但是可能还需要几分钟，因为按段搜索需要调用 fsync 创建一个提交点。但是 fsync 操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。更加轻量的方式是走 refresh API。 refresh 是一种轻量级的刷新，通过 refresh 可以不通过 fsync 就让文档被索引到，因为 refresh 通过 write 的系统调用，将内存中的数据转换成文件系统的页缓存，数据能够被很快的写入（还是在内存中），并且能被 read 系统调用作为文件打开。 下面的API，可以通过设置刷新时间把内存刷新的间隔拉长，默认是1s，如果设置成 -1 那么就是不刷新。 POST /_refresh # 所有索引都刷新 POST /blogs/_refresh # 单个索引刷新 PUT my_logs { \"settings\": { \"refresh_interval\": \"60s\" } } 在被刷入磁盘前,内存中新数据是不能被刷新的，例如： POST my_logs/_doc { \"abc\" : 1 } GET my_logs/_search 在search API中是60s内看不到新post的数据的。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:3","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#实时搜索的保证"},{"categories":["notes"],"content":"文件系统页缓存页缓存（Page Cache）是位于内存和文件之间的缓冲区，它实际上也是一块内存区域。页缓存对应文件中的一块区域，如果页缓存和对应的文件区域内容不一致，则该页缓存叫做脏页（Dirty Page）。 页缓存查看： SZKSGD00582 : ~ -\u003e free -h total used free shared buff/cache available Mem: 23G 538M 22G 401M 897M 22G Swap: 0B 0B 0B 或者： SZKSGD00582 : ~ -\u003e cat /proc/meminfo MemTotal: 24629088 kB MemFree: 23157836 kB MemAvailable: 23353692 kB Buffers: 20724 kB -\u003e Cached: 875168 kB SwapCached: 0 kB Active: 538556 kB Inactive: 807752 kB Active(anon): 464264 kB Inactive(anon): 393480 kB Active(file): 74292 kB Inactive(file): 414272 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 0 kB SwapFree: 0 kB -\u003e Dirty: 0 kB Writeback: 0 kB AnonPages: 407528 kB Mapped: 185108 kB Shmem: 411116 kB Slab: 58664 kB SReclaimable: 23568 kB SUnreclaim: 35096 kB KernelStack: 7648 kB PageTables: 3396 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 12314544 kB Committed_AS: 3829504 kB VmallocTotal: 34359738367 kB VmallocUsed: 0 kB VmallocChunk: 0 kB Percpu: 1776 kB AnonHugePages: 190464 kB ShmemHugePages: 0 kB ShmemPmdMapped: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB Hugetlb: 0 kB DirectMap4k: 15360 kB DirectMap2M: 3129344 kB DirectMap1G: 23068672 kB write 系统调用： 用户发起write操作 操作系统查找页缓存 若未命中，则产生缺页异常，然后创建页缓存，将用户传入的内容写入页缓存 若命中，则直接将用户传入的内容写入页缓存 用户write调用完成 页被修改后成为脏页，操作系统有两种机制将脏页写回磁盘 用户手动调用fsync() 由pdflush进程定时将脏页写回磁盘（脏页数据比例过高，脏页缓存占用的内存太多，长时间未刷新） read 系统调用： 用户发起read操作 操作系统查找页缓存 若未命中，则产生缺页异常，然后创建页缓存，并从磁盘读取相应页填充页缓存 若命中，则直接从页缓存返回要读取的内容 用户read调用完成 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:4","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#文件系统页缓存"},{"categories":["notes"],"content":"实时删除删除操作：每个提交点会包含一个.del文件，包含被删除的文档，被删除的任然可以被搜索到。 更新操作: 旧文档被标记为删除，新版本文档被索引到一个新的段中 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:5","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#实时删除"},{"categories":["notes"],"content":"持久化虽然通过每秒刷新（refresh）实现了近实时搜索，但是refresh只是写入页缓存，并没有真正写入到磁盘中，我们仍然需要经常进行完整提交来确保能从失败中恢复。es提供了translog（事务日志）机制用于记录操作。类似于redis的aof。 1、一篇文档被索引后会被写入内存缓冲区，并追加到translog。（数据内存中） 2、内存缓冲区的数据被写入到一个新段，但是没有fsync，但是可以被用于搜索。（文件系统缓存，仍旧在内存中） 3、数据不断积累，执行索引刷新（flush），新的 translog 创建，执行全量提交，内存中的数据写入新段，缓冲区清空，通过fsync将提交点写入硬盘，删除老的translog。 translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。 translog 也被用来提供实时 CRUD 。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。 flush API 可以用于手动刷新数据，将页缓存刷入磁盘中去。 POST /blogs/_flush # 刷新（flush）blogs 索引 POST /_flush?wait_for_ongoing # 刷新（flush）所有的索引并且并且等待所有刷新在返回前完成。 持久化也能通过索引的配置来刷新： PUT /my_index/_settings { \"index.translog.durability\": \"async\", # 异步刷入磁盘，同步为 \"request\" \"index.translog.sync_interval\": \"5s\" # 同步磁盘的间隔 } translog 默认5s刷一次，或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)，因为数据结构简单+顺序写速度较快。整个请求被 fsync 到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。当然如果希望获得更高的吞吐，并且在同步间隔丢失的数据无所谓，那么可以设置为 async，当请求。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:6","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#持久化"},{"categories":["notes"],"content":"段合并每次refesh都会产生一个段，但每秒刷新很快就会导致段数量太多的问题，从而消耗很多cpu、内存、文件句柄，而搜索请求会查询每一个段，所以段数量越多，搜索数量越多。（就像一个哈希表被拆分成多个哈希表，时间复杂度从O(1)转变成O(n)） 段合并在进行索引和搜索时会自动进行： 索引文档时，refresh 创建新段用于搜索 合并进程选择大小相似的段在后台合并成大段，不影响索引和搜索 新大段被写入磁盘（flush），另外新的小段也被flush到磁盘，新的提交点被创建，translog也会被清空。 新段可以被打开搜索 老段被删除 强制合并API： POST /logstash-2014-10/_optimize?max_num_segments=1 合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:7","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#段合并"},{"categories":["notes"],"content":"总结es 的索引写入分成两个部分： 为了内存使得文档能够被快速被搜索，首先被缓存在内存中，再通过 refresh 使得文档可以被及时搜索到，再周期性地写入磁盘提交。 为了保证文档不丢失，translog能够在内存失效的情况下，从磁盘恢复数据。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:2:8","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#总结"},{"categories":["notes"],"content":"分布式检索","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:3:0","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#分布式检索"},{"categories":["notes"],"content":"单结点es集群在创建索引时，可以在setting字段中加入分片设置，下面的配置创建了3个主分片和一份副本，即每个主分片一个副本。 PUT /blogs { \"settings\" : { \"number_of_shards\" : 3, \"number_of_replicas\" : 1 } } 当集群中只有一个节点时，状态为： 但是可以看到，NODE1 上只有主分片，没有副本分片，因为在同一个节点上既保存原始数据又保存副本是没有意义的。 通过 _health 接口查询， GET /_cluster/health 其中 status 的值和对应的解释如： green：所有的主分片和副本分片都正常运行。 yellow：所有的主分片都正常运行，但不是所有的副本分片都正常运行。 red：有主分片没能正常运行。 可以发现此时的集群状态为 yellow ，是因为此时没有副本分片。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:0","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#单结点es集群"},{"categories":["notes"],"content":"多节点集群当加入新物理节点后，es集群就会在新节点上创建副本节点，此时集群状态就会转变为green，因为所有主副分片都正常运行了。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:1","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#多节点集群"},{"categories":["notes"],"content":"多节点负载当拥有三个节点后，es 会为了分散负载而对分片进行重新分配，分片数据，如： 每一个分片都是一个独立的功能完整的搜索引擎，拥有使用一个节点上的所有资源的能力。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:2","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#多节点负载"},{"categories":["notes"],"content":"继续扩容es 的主分片数量在创建索引的时候，主分片数量就确定了，之后不可以修改，能修改的只有副本节点。 主分片的数目定义了这个索引能够 存储 的最大数据量。 PUT /blogs/_settings { \"number_of_replicas\" : 2 } 原本3主3副个节点就会扩充到3主6副个节点，这样即使两个节点宕机，也不会丢失数据。其次，有多个副本节点能够获得更高的吞吐，因为在不同的节点上都能处理相同分片的请求了，当然副本节点的数量提升的吞吐取决于机器性能，分片越多，从机器获取的资源也就更少。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:3","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#继续扩容"},{"categories":["notes"],"content":"集群搜索流程我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 1、当请求到达一个节点，那么这个节点就会变成协调节点 2、协调节点把搜索请求发送到其他节点的索引分片上搜索数据 3、然后再汇总数据返回给客户端。 文档路由的规则比较常见，对文档ID进行hash得到具体分片，es 不能扩容，扩容就会存在节点对应不上的情况。 ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:4","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#集群搜索流程"},{"categories":["notes"],"content":"分页集群搜索流程请求如： GET /_search { \"from\": 90, \"size\": 10 } 的查询流程如下： 客户端发送一个 search 请求到 Node 3 ， Node 3 会创建一个大小为 from + size 的空优先队列。 Node 3 将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为 from + size 的本地有序优先队列中。 每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，也就是 Node 3 ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。 PS：搜索请求被发送到某个节点时，这个节点就变成了协调节点 并且：注意是 from + size，而不是 size，因为每个节点的数据不一定是排好序的，当from很大的时候会有深分页存在，多个节点需要返回很多数据，协调节点进行排序，所以会占用相当多的CPU/内存/带宽。“深分页” 很少符合人的行为，人的行为一般停留在前几页，深分页一般是爬虫。 获取集群状态： GET _cluster/stats?pretty 获取分片状态： GET /_cat/shards/\u003ctarget\u003e GET /_cat/shards ","date":"2021-07-24","objectID":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/:4:5","series":null,"tags":null,"title":"ElasticSearch 检索内部原理","uri":"/elasticsearch-%E6%A3%80%E7%B4%A2%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86/#分页集群搜索流程"},{"categories":["notes"],"content":"部署和启动","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:1:0","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#部署和启动"},{"categories":["notes"],"content":"docker-compose.ymlversion: '2.2' services: node01: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node01 environment: - node.name=node01 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \"ES_JAVA_OPTS=-Xms128m -Xmx128m\" ulimits: memlock: soft: -1 hard: -1 volumes: - es-data01:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 networks: - es-network node02: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node02 environment: - node.name=node02 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \"ES_JAVA_OPTS=-Xms128m -Xmx128m\" ulimits: memlock: soft: -1 hard: -1 volumes: - es-data02:/usr/share/elasticsearch/data ports: - 9201:9201 - 9301:9301 networks: - es-network node03: image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1 container_name: node03 environment: - node.name=node03 - cluster.name=es-cluster-7 - discovery.seed_hosts=node01,node02,node03 - cluster.initial_master_nodes=node01,node02,node03 - \"ES_JAVA_OPTS=-Xms128m -Xmx128m\" ulimits: memlock: soft: -1 hard: -1 volumes: - es-data03:/usr/share/elasticsearch/data ports: - 9202:9202 - 9302:9302 networks: - es-network kibana: image: docker.elastic.co/kibana/kibana:7.11.1 environment: ELASTICSEARCH_HOSTS: http://node01:9200 ports: - 5601:5601 networks: - es-network depends_on: - node01 volumes: es-data01: driver: local es-data02: driver: local es-data03: driver: local networks: es-network: driver: bridge 来https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-stack-docker.html ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:1:1","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#docker-composeyml"},{"categories":["notes"],"content":"启动和检查# 启动 sudo docker-compose up # 集群监控 curl localhost:9200/_cat/health =\u003e 1627449664 05:21:04 es-cluster-7 green 3 3 12 6 0 0 0 0 - 100.0% # 数据和索引文件挂载位置 /usr/share/elasticsearch/data title: “ElasticSearch（1）：基础查询” date: 2021-07-16T22:37:19+08:00 Summary: 包括 Elasticsearch 的CRUD和基础检索方式 draft: false categories: notes ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:1:2","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#启动和检查"},{"categories":["notes"],"content":"文档创建和删除","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:0","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#文档创建和删除"},{"categories":["notes"],"content":"创建文档ElasticSearch 提供创建一篇文档的接口如下，如果这是索引的第一篇文档，索引也会被同时创建。 PUT /\u003ctarget\u003e/_doc/\u003c_id\u003e POST /\u003ctarget\u003e/_doc/ PUT /\u003ctarget\u003e/_create/\u003c_id\u003e POST /\u003ctarget\u003e/_create/\u003c_id\u003e 下面的例子利用PUT方法创建一个 id 为1的文档： 其中，version字段为1，并且result的值为created。 另一种创建文档的方式是通过POST，又ES自动生成一个全局唯一的 _id 给新的文档： ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:1","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#创建文档"},{"categories":["notes"],"content":"更新的文档如果重复对这个文档执行PUT操作，那么ES就会转变为更新，并且自增version字段。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:2","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#更新的文档"},{"categories":["notes"],"content":"查询索引的信息因为创建文档的同时会自动创建索引以及和请求结构相关的mappings(类似数据库的表结构schema) 直接通过GET索引名就可以查询到索引的信息： GET /\u003cindex_name\u003e 例如： 通常会得到三个信息： aliases： 用于别名 mappings：索引的字段信息，如图中的索引 index-001 是根据 POST/PUT 请求的字段自动生成的，并且自动推导成对应的类型，但是对于字符串类型（text）在默认请求下，会新增一个子字段keyword，用于精准匹配查询。 settings：包含了 ElasticSearch 配置、分片等信息 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:3","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#查询索引的信息"},{"categories":["notes"],"content":"查看文档文档索引完成后，能够通过下面的查询查到新加入的文档： GET /\u003cindex_name\u003e/_doc/1 # 找到 _id 为 1 的文档 GET /\u003cindex_name\u003e/_search # 查找出该索引下的所有文档 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:4","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#查看文档"},{"categories":["notes"],"content":"删除文档DELETE /\u003cindex\u003e/_doc/\u003c_id\u003e 例如： 如果找到了，会返回200OK，并且 found 判断是否存在文档，_version 字段在删除成功后会自增 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:2:5","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#删除文档"},{"categories":["notes"],"content":"常见的查询方式","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:0","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#常见的查询方式"},{"categories":["notes"],"content":"准备查询数据PUT /megacorp/employee/1 { \"first_name\" : \"John\", \"last_name\" : \"Smith\", \"age\" : 25, \"about\" : \"I love to go rock climbing\", \"interests\": [ \"sports\", \"music\" ] } PUT /megacorp/employee/2 { \"first_name\" : \"Jane\", \"last_name\" : \"Smith\", \"age\" : 32, \"about\" : \"I like to collect rock albums\", \"interests\": [ \"music\" ] } PUT /megacorp/employee/3 { \"first_name\" : \"Douglas\", \"last_name\" : \"Fir\", \"age\" : 35, \"about\": \"I like to build cabinets\", \"interests\": [ \"forestry\" ] } PS: megacorp 是官方的例子，在下面的例子中，创建的方式和前面叙述的有些不同，官方的例子是在ElasticSearch 2.X出的， 在索引和文档之间，还存在类型这一概念，虽然在后续的版本中可能不再维护，但是在这里用做例子并无大碍。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:1","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#准备查询数据"},{"categories":["notes"],"content":"请求的方式 基于 URL 的搜索方式： GET /megacorp/employee/_search?q=last_name:Smith 基于 Request Body 的搜索方式 GET /megacorp/_search { \"query\": { \"query_string\": { \"fields\": [\"last_name\"], \"query\": \"Smith\" } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:2","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#请求的方式"},{"categories":["notes"],"content":"一个完整的请求GET /megacorp/_search { \"query\" : { \"match\" : { \"last_name\" : \"Smith\" } }, \"from\": 0, \"size\": 2, \"_source\": [\"first_name\", \"last_name\"], \"sort\": [{\"age\": \"desc\"}] } query：相当于SQL中的WHERE子句 from/size： 和SQL的 FROM/LIMIT 用法一致，用于分页 _source： 相当于 SELECT sort：对应 ORDER BY ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:3","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#一个完整的请求"},{"categories":["notes"],"content":"查询返回结构","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:4","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#查询返回结构"},{"categories":["notes"],"content":"查询字符串(query_string)GET /megacorp/_search { \"query\": { \"query_string\": { \"fields\": [\"about\"], \"query\": \"I AND cabinets\" } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:5","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#查询字符串query_string"},{"categories":["notes"],"content":"简单查询字串(simpile_query_string)simpile_query_string 是 query_string 的一种优化方式，能够将 AND/OR 关键词简化： GET /megacorp/_search { \"query\": { \"simple_query_string\": { \"fields\": [\"about\"], \"query\": \"I + cabinets\" } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:6","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#简单查询字串simpile_query_string"},{"categories":["notes"],"content":"全文搜索(match)GET /megacorp/employee/_search { \"query\" : { \"match\" : { \"about\" : \"rock climbing\" } } } 查询在 about 属性上喜欢 rock climbing 的人。rock albums和 rock climbing 都会被命中。如果字段是设置了 not_analyzed 或者是日期、数字、布尔，也会给定精确匹配的值。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:7","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#全文搜索match"},{"categories":["notes"],"content":"短语检索(match_phrase)GET /megacorp/employee/_search { \"query\" : { \"match_phrase\" : { \"about\" : \"rock climbing\" } } } 只有完全含有短语 rock climbing 的文档才被检索 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:8","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#短语检索match_phrase"},{"categories":["notes"],"content":"多字段查询(multi_match)允许在多个字段上执行相同的查询 GET /megacorp/_search { \"query\": { \"multi_match\": { \"query\": \"like music\", \"fields\": [\"about\", \"interests\"] } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:9","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#多字段查询multi_match"},{"categories":["notes"],"content":"范围查询(range)GET /megacorp/_search { \"query\": { \"range\": { \"age\": { \"gte\": 20, \"lt\": 33 } } } } gt: 大于 gte: 大于等于 lt: 小于 lte: 小于等于 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:10","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#范围查询range"},{"categories":["notes"],"content":"精确值查找(term/terms)term 查询被用于精确值匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串 GET /megacorp/_search { \"query\": { \"term\": { \"age\": { \"value\": \"25\"} } } } terms 查询是 term 的多值版本 GET /megacorp/_search { \"query\": { \"terms\": { \"age\": [\"25\", \"32\"] } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:11","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#精确值查找termterms"},{"categories":["notes"],"content":"存在性查找(exsists/missing)exsists 和 missing 是一个逻辑相反的关系，用于判断字段是否有值，类似于 SQL 的WHERE FieldA IS NOT null { \"exists\": { \"field\": \"title\" } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:12","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#存在性查找exsistsmissing"},{"categories":["notes"],"content":"前缀查询(match_prefix)因为目前只有三条记录，分别是： \"first_name\" : \"John\", \"first_name\" : \"Jane\", \"first_name\" : \"Douglas\", 当期待用 J 去匹配John和Jane在first_name字段匹配不会成功，而需要使用字段first_name.keyword ： GET /megacorp/_search { \"query\": { \"prefix\": { \"first_name.keyword\": { \"value\": \"J\" } } } } 或者使用小写的 j，因为 first_name 是一个被分词的字段(analyzed)，在经过一系列的分词器和转化后，存储在倒排索引是小写的单词，而 first_name.keyword 字段是 first_name 的不做分词版本，可以用大写的 J 匹配到。 GET /megacorp/_search { \"query\": { \"prefix\": { \"first_name\": { \"value\": \"j\" } } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:13","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#前缀查询match_prefix"},{"categories":["notes"],"content":"模糊查询和正则表达式(wildcard/regexp)因为语句会被es分解成词，match查询的最小模糊匹配是词，利用模糊查询就能将模糊粒度降低到字母，如： GET /megacorp/_search { \"query\": { \"wildcard\": { \"about\": { \"value\": \"c*\" } } } } 或者: GET /megacorp/_search { \"query\": { \"regexp\": { \"about\": { \"value\": \"c.*\" } } } } 数据在索引时的预处理有助于提高前缀匹配的效率，而通配符和正则表达式查询只能在查询时完成，尽管这些查询有其应用场景，但使用仍需谨慎。 prefix 、 wildcard 和 regexp 查询是基于词操作的，像语句“Quick brown fox”如果设置了analyzed 就会被分解成 quick 、 brown 和 fox。 { \"regexp\": { \"title\": \"br.*\" }} 语句能够检索到，但是下面这些组合了词语的查询不行 { \"regexp\": { \"title\": \"Qu.*\" }} { \"regexp\": { \"title\": \"quick br*\" }} ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:14","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#模糊查询和正则表达式wildcardregexp"},{"categories":["notes"],"content":"复合查询复合查询使用 bool 查询来实现逻辑的组合，接受以下四种参数： must： 文档必须匹配这些条件才能被包含进来。 must_not：文档必须不匹配这些条件才能被包含进来。 should: 如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter: 必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。 结构为： \"query\": { \"bool\": { \"must\": [ SUB_QUERY ], \"must_not\": [ SUB_QUERY ] } } 例如： GET /megacorp/_search { \"query\": { \"bool\": { \"must\": [ {\"range\": { \"age\": { \"gte\": 30 } }} ], \"must_not\": [ {\"match\": { \"about\": \"cabinets\" }} ] } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:15","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#复合查询"},{"categories":["notes"],"content":"过滤查询(filter)GET /megacorp/_search { \"query\": { \"bool\": { \"must\": {\"match\" : {\"about\" : \"like build\"}}, \"filter\": { \"bool\": { \"must\" : {\"range\": {\"age\": { \"gte\": 30 }}} } } } } } 将查询移到 bool 查询的 filter 的 bool 语句中，例如像年龄这样的字段，只需要进行过滤，不需要放在查询做，所以可以放到filter中来优化查询性能。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:16","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#过滤查询filter"},{"categories":["notes"],"content":"过滤查询(constant_score)constant_score 是filter的另外一种形式，通常用在只进行filter，而不用查询相关性分的情况。 如下： GET /megacorp/_search { \"query\": { \"constant_score\": { \"filter\": {\"range\": {\"age\": { \"gte\": 30 }}} } } } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:3:17","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#过滤查询constant_score"},{"categories":["notes"],"content":"分析文档：分词","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:4:0","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#分析文档分词"},{"categories":["notes"],"content":"请求分析POST _analyze { \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"asciifolding\" ], \"text\": \"Is this déja vu?\" } ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:4:1","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#请求分析"},{"categories":["notes"],"content":"为索引设置不同的分词器PUT my-index-000002 { \"settings\": { \"analysis\": { \"analyzer\": { \"std_english\": { \"type\": \"standard\", \"stopwords\": \"_english_\" } } } }, \"mappings\": { \"properties\": { \"my_text\": { \"type\": \"text\", \"analyzer\": \"standard\", \"fields\": { \"english\": { \"type\": \"text\", \"analyzer\": \"std_english\" } } } } } } POST my-index-000002/_analyze { \"field\": \"my_text\", \"text\": \"The old brown cow\" } POST my-index-000002/_analyze { \"field\": \"my_text.english\", \"text\": \"The old brown cow\" } 分析器也能在elastic search的启动配置中设置。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:4:2","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#为索引设置不同的分词器"},{"categories":["notes"],"content":"分词过程文档加入索引前，都会经过系列处理： 字符过滤 （char_filter） 文本切分 （tokenizer） 分词过滤 （filter） 分词索引 POST _analyze { \"char_filter\": [\"html_strip\"], \"tokenizer\" : \"whitespace\", \"filter\": [\"stop\"], \"text\": \"\u003cbody\u003e share your experiece with NoSql and big data technologies \u003c/body\u003e\" } 给定一个语句 text ：\u003cbody\u003e share your experiece with NoSql and big data technologies \u003c/body\u003e 并且设置相应的分词配置。 ","date":"2021-07-08","objectID":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:4:3","series":null,"tags":null,"title":"ElasticSearch 基础使用和理解","uri":"/elasticsearch-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/#分词过程"},{"categories":null,"content":"全排列class Solution { public: vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; void dfs(int k, int n, int idx, int sum) { for (int i = idx; i \u003c= 9; ++i) { state.push_back(i); sum += i; if (state.size() == k \u0026\u0026 sum == n) { res.push_back(state); } else if (sum \u003c n) { dfs(k, n, i+1, sum); } sum -= i; state.pop_back(); } } vector\u003cvector\u003cint\u003e\u003e combinationSum3(int k, int n) { dfs(k, n, 1, 0); return res; } }; 简单回溯。 ","date":"2021-05-18","objectID":"/leetcode_backtrace/:1:0","series":null,"tags":null,"title":"Leetcode: backtrace 专题","uri":"/leetcode_backtrace/#全排列"},{"categories":["sys"],"content":"前言准确的度量系统的开销是很重要的, 系统级别比较出名的是 Latency Numbers Every Programmer Should Know, 而在各种变成语言中, 需要依赖基准测试来判断程序实际的耗时。 Latency Comparison Numbers (~2012) ---------------------------------- L1 cache reference 0.5 ns Branch mispredict 5 ns L2 cache reference 7 ns 14x L1 cache Mutex lock/unlock 25 ns Main memory reference 100 ns 20x L2 cache, 200x L1 cache Compress 1K bytes with Zippy 3,000 ns 3 us Send 1K bytes over 1 Gbps network 10,000 ns 10 us Read 4K randomly from SSD* 150,000 ns 150 us ~1GB/sec SSD Read 1 MB sequentially from memory 250,000 ns 250 us Round trip within same datacenter 500,000 ns 500 us Read 1 MB sequentially from SSD* 1,000,000 ns 1,000 us 1 ms ~1GB/sec SSD, 4X memory Disk seek 10,000,000 ns 10,000 us 10 ms 20x datacenter roundtrip Read 1 MB sequentially from disk 20,000,000 ns 20,000 us 20 ms 80x memory, 20X SSD Send packet CA-\u003eNetherlands-\u003eCA 150,000,000 ns 150,000 us 150 ms Notes ----- 1 ns = 10^-9 seconds 1 us = 10^-6 seconds = 1,000 ns 1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns Credit ------ By Jeff Dean: http://research.google.com/people/jeff/ Originally by Peter Norvig: http://norvig.com/21-days.html#answers Contributions ------------- 'Humanized' comparison: https://gist.github.com/hellerbarde/2843375 Visual comparison chart: http://i.imgur.com/k0t1e.png ","date":"2021-04-30","objectID":"/google-benchmark/:0:0","series":null,"tags":null,"title":"google benchmark 的初体验","uri":"/google-benchmark/#前言"},{"categories":["sys"],"content":"基准测试在CPP中可以依赖 goolge benchmark 来完成这样的事情，安装和编译非常简单，按照文档给出的命令可以很快部署并且开始使用。 $ git clone https://github.com/google/benchmark.git # Benchmark requires Google Test as a dependency. Add the source tree as a subdirectory. $ git clone https://github.com/google/googletest.git benchmark/googletest # Go to the library root directory $ cd benchmark # Make a build directory to place the build output. $ cmake -E make_directory \"build\" # Generate build system files with cmake. $ cmake -E chdir \"build\" cmake -DCMAKE_BUILD_TYPE=Release ../ # or, starting with CMake 3.13, use a simpler form: # cmake -DCMAKE_BUILD_TYPE=Release -S . -B \"build\" # Build the library. $ cmake --build \"build\" --config Release 然后进行安装 sudo cmake --build \"build\" --config Release --target install ","date":"2021-04-30","objectID":"/google-benchmark/:0:0","series":null,"tags":null,"title":"google benchmark 的初体验","uri":"/google-benchmark/#基准测试"},{"categories":["sys"],"content":"开始一个简单的测试// bench.cc #include \u003cbenchmark/benchmark.h\u003e#include \u003cvector\u003e static void BM_create(benchmark::State\u0026 state) { // Perform setup here for (auto _ : state) { // This code gets timed std::vector\u003cint\u003e vec; (void)vec; } } static void BM_push_back(benchmark::State\u0026 state) { // Perform setup here for (auto _ : state) { // This code gets timed std::vector\u003cint\u003e vec; vec.push_back(1); } } static void BM_reserve(benchmark::State\u0026 state) { // Perform setup here for (auto _ : state) { // This code gets timed std::vector\u003cint\u003e vec; vec.reserve(1); vec.push_back(1); } } // Register the function as a benchmark BENCHMARK(BM_create); BENCHMARK(BM_push_back); BENCHMARK(BM_reserve); // Run the benchmark BENCHMARK_MAIN(); 编译、链接并且运行： g++ bench.cc -std=c++11 -g -lbenchmark -lpthread -o bench \u0026\u0026 ./bench 可以看到一个清晰的耗时测试结果： ","date":"2021-04-30","objectID":"/google-benchmark/:1:0","series":null,"tags":null,"title":"google benchmark 的初体验","uri":"/google-benchmark/#开始一个简单的测试"},{"categories":["sys"],"content":"内存不符预期的不断上涨，可能的原因是内存泄漏，例如new出来的对象未进行delete就重新进行复制，使得之前分配的内存块被悬空，应用程序没办法访问到那部分内存，并且也没有办法释放；在C++中，STL容器都会有clear()方法并且伴随RAII原则对容器里元素进行清理，但除了STL还有可能是字符串不断地在进行累加，不断的分配出新的内存块存放增长的字符串。 在cppzh 群 内看到讨论利用jemalloc对内存占用的调试，能够清楚的 dump 出内存的使用情况，便尝试了下。 ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:0:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#"},{"categories":["sys"],"content":"安装# 用于生成 pdf yum -y install graphviz ghostscript wget https://github.com/jemalloc/jemalloc/archive/5.1.0.tar.gz tar zxvf 5.1.0.tar.gz cd jemalloc-5.1.0/ ./autogen.sh ./configure --prefix=/usr/local/jemalloc-5.1.0 --enable-prof make -j make install ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:1:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#安装"},{"categories":["sys"],"content":"程序退出时的用例和检查# run MALLOC_CONF=prof_leak:true,lg_prof_sample:0,prof_final:true LD_PRELOAD=/usr/local/jemalloc-5.1.0/lib/libjemalloc.so.2 ./a.out # 查看内存占用情况 /usr/local/jemalloc-5.1.0/bin/jeprof a.out jeprof.34447.0.f.heap \u003e top ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:2:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#程序退出时的用例和检查"},{"categories":["sys"],"content":"长时间运行-测试用例对于长时间运行的程序，例如服务端程序通常不能够退出，jemalloc提供每增长指定大小进行一次内存dump。 下面这个例子mock长时间运行的程序，分别测试顺序容器(vector)和关联容器(map)，string 和最基本的new，并且每100ms执行1000次，代表服务端的运行情况。 #include \u003ciostream\u003e#include \u003cstring\u003e#include \u003cvector\u003e#include \u003cmap\u003e#include \u003cchrono\u003e#include \u003cthread\u003e int main() { std::vector\u003cint\u003e vec; std::map\u003cint, int\u003e mp; std::string s; for (;;) { for (int i = 0; i \u003c 1000; ++i) { vec.push_back(i); mp[rand()] = i; s += \"xxxx\"; new char[4]; } std::this_thread::sleep_for(std::chrono::microseconds(100)); } return 0; } 编译运行: g++ test.cc -o a.out 将环境变量MALLOC_CONF设置为prof:true,lg_prof_interval:26使jemalloc开启prof并且每2^26字节(64M)大小进行一次dump，并且利用LD_PRELOAD 环境变量代替。 export MALLOC_CONF=\"prof:true,lg_prof_interval:26\" LD_PRELOAD=/usr/local/jemalloc-5.1.0/lib/libjemalloc.so.2 ./a.out [root@pwh c++]# ls -l -t total 212 -rw-r--r-- 1 root root 5208 Dec 19 14:31 jeprof.17988.17.i17.heap -rw-r--r-- 1 root root 5206 Dec 19 14:31 jeprof.17988.16.i16.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.15.i15.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.14.i14.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.13.i13.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.12.i12.heap -rw-r--r-- 1 root root 5204 Dec 19 14:31 jeprof.17988.11.i11.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.10.i10.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.9.i9.heap -rw-r--r-- 1 root root 5200 Dec 19 14:31 jeprof.17988.8.i8.heap -rw-r--r-- 1 root root 5198 Dec 19 14:31 jeprof.17988.7.i7.heap -rw-r--r-- 1 root root 5198 Dec 19 14:31 jeprof.17988.6.i6.heap ... ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:3:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#长时间运行-测试用例"},{"categories":["sys"],"content":"结果分析由于是每隔一段内存大小进行的dump，每个文件都是内存的片段信息，利用--base指定从哪一份heap文件开始分析。 $ /usr/local/jemalloc-5.1.0/bin/jeprof a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap $ /usr/local/jemalloc-5.1.0/bin/jeprof a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap Using local file a.out. Argument \"MSWin32\" isn't numeric in numeric eq (==) at /usr/local/jemalloc-5.1.0/bin/jeprof line 5123. Argument \"linux\" isn't numeric in numeric eq (==) at /usr/local/jemalloc-5.1.0/bin/jeprof line 5123. Using local file jeprof.17988.17.i17.heap. Welcome to jeprof! For help, type 'help'. (jeprof) top Total: 1002.5 MB 754.5 75.3% 75.3% 754.5 75.3% __gnu_cxx::new_allocator::allocate@4031fc 124.0 12.4% 87.6% 124.0 12.4% __gnu_cxx::new_allocator::allocate@402fac 124.0 12.4% 100.0% 124.0 12.4% std::__cxx11::basic_string::_M_mutate 0.0 0.0% 100.0% 1002.5 100.0% __libc_start_main 0.0 0.0% 100.0% 1002.5 100.0% _start 0.0 0.0% 100.0% 1002.5 100.0% main 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_create_node 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_emplace_hint_unique 0.0 0.0% 100.0% 754.5 75.3% std::_Rb_tree::_M_get_node 0.0 0.0% 100.0% 124.0 12.4% std::_Vector_base::_M_allocate # 导出为 pdf /usr/local/jemalloc-5.1.0/bin/jeprof --pdf a.out --base=jeprof.17988.0.i0.heap jeprof.17988.17.i17.heap \u003e a.pdf ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:4:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#结果分析"},{"categories":["sys"],"content":"统计内存使用情况取了新的一段内存区间将其导出为pdf后，总共分配使用718MB内存，其中在map的[]的操作符重载函数中占用了514.5MB，为string分配了60MB，为vector分配了60MB，而最基础的new char[4]的调用栈是停留在main()中，所以main()也占用了84MB，得到的数据和Total MB(718.5MB)吻合。 ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:5:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#统计内存使用情况"},{"categories":["sys"],"content":"ref https://www.yuanguohuo.com/2019/01/02/jemalloc-heap-profiling/ http://jemalloc.net/ ","date":"2020-12-18","objectID":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/:0:0","series":null,"tags":null,"title":"利用Jemalloc进行内存泄漏的调试","uri":"/%E5%88%A9%E7%94%A8jemalloc%E8%BF%9B%E8%A1%8C%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E8%B0%83%E8%AF%95/#ref"},{"categories":null,"content":"leetcode top100题中的数组tag：https://leetcode-cn.com/problem-list/2cktkvj/ ","date":"2020-11-18","objectID":"/leetcode_top100/:0:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#"},{"categories":null,"content":"15. 三数之和class Solution { public: vector\u003cvector\u003cint\u003e\u003e threeSum(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; std::sort(nums.begin(), nums.end()); for (int i = 0; i \u003c nums.size(); ++i) { int first = nums[i]; if (first \u003e 0) { continue; } if (i \u003e 0 \u0026\u0026 nums[i-1] == first) { continue; } int target = -1 * first; int j = i + 1; int k = nums.size() - 1; while (j \u003c k) { int second = nums[j]; int third = nums[k]; if (second + third \u003e target) { k--; continue; } else if (second + third \u003c target) { j++; continue; } else { res.emplace_back(std::vector\u003cint\u003e({first, second, third})); ++j; --k; while (j \u003c k \u0026\u0026 nums[j] == nums[j-1]) ++j; while (j \u003c k \u0026\u0026 nums[k] == nums[k+1]) --k; } } } return res; } }; 题目的注意事项是：不包含重复的三元组，暴力去解决还需要set来去重，特别麻烦。 解法应该是将三数和转化为两数和的问题，排序+双指针。 注意： 因为是递增序列，如果第一个不是负数，那后面相加肯定不可能等于0 找到target后，用双指针移动不断找到两个合适的值，并且要用移动指针去重。 ","date":"2020-11-18","objectID":"/leetcode_top100/:1:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#15-三数之和"},{"categories":null,"content":"39. 组合总和class Solution { public: void search(vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 candidates, int target, int idx, std::vector\u003cint\u003e\u0026 combine) { if (target == 0) { res.emplace_back(std::vector\u003cint\u003e(combine.cbegin(), combine.cend())); return; } if (idx \u003e= candidates.size() || target \u003c 0) { return; } // 选择自己 combine.push_back(candidates[idx]); search(res, candidates, target - candidates[idx], idx, combine); combine.pop_back(); // 选择下一个 if (idx + 1 \u003c candidates.size()) { search(res, candidates, target, idx+1, combine); } } vector\u003cvector\u003cint\u003e\u003e combinationSum(vector\u003cint\u003e\u0026 candidates, int target) { // std::list\u003cint\u003e combine; std::vector\u003cint\u003e combine; vector\u003cvector\u003cint\u003e\u003e res; search(res, candidates, target, 0, combine); return res; } }; 搜索问题可以先画一颗树来解决问题。（vector比list快） 保存当前的状态再进去求子问题，并且保证能够恢复到递归前的状态。 比如跳过了当前数字，就不要保存状态了。 ","date":"2020-11-18","objectID":"/leetcode_top100/:2:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#39-组合总和"},{"categories":null,"content":"40. 组合总和IIclass Solution { public: void search(vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 candidates, int target, int idx, std::vector\u003cint\u003e\u0026 combine) { if (target == 0) { res.emplace_back(std::vector\u003cint\u003e(combine.cbegin(), combine.cend())); return; } if (idx \u003e= candidates.size() || target \u003c 0) { return; } // 选择自己 if (target - candidates[idx] \u003e= 0) { combine.push_back(candidates[idx]); search(res, candidates, target - candidates[idx], idx+1, combine); combine.pop_back(); } // 选择下一个 ++idx; while(idx \u003c candidates.size()) { if (candidates[idx] != candidates[idx-1]) { search(res, candidates, target, idx, combine); break; } ++idx; } } vector\u003cvector\u003cint\u003e\u003e combinationSum2(vector\u003cint\u003e\u0026 candidates, int target) { std::vector\u003cint\u003e combine; std::sort(candidates.begin(), candidates.end()); vector\u003cvector\u003cint\u003e\u003e res; search(res, candidates, target, 0, combine); return res; } }; 39题的变种题，40题因为数字只能选一次，而且有重复数字，所以会出现重复结果集。 去重和3sum问题类似，先排序，排序解决的问题是当选中当前数字搜索完后，就能跳到下个不重复的数字（剪枝）。 ","date":"2020-11-18","objectID":"/leetcode_top100/:3:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#40-组合总和ii"},{"categories":null,"content":"46. 全排列class Solution { public: void search(vector\u003cint\u003e\u0026 nums, vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 state, int idx) { for (int i = idx; i \u003c nums.size(); ++i) { std::swap(nums[idx], nums[i]); state.push_back(nums[idx]); if (idx+1 == nums.size()) { res.push_back(state); } else { search(nums, res, state, idx+1); } state.pop_back(); std::swap(nums[idx], nums[i]); } } vector\u003cvector\u003cint\u003e\u003e permute(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; state.reserve(nums.size()); search(nums, res, state, 0); return res; } }; 全排列也是一道回溯的题目，回溯就可以理解为是不断地从集合里面挑选东西，然后不断试错找到结果，但是要能在继续找结果前保存状态，找完后恢复状态。 全排列这里保存状态有一个小技巧就是用swap交换来切换要选的数字，省去了一些繁琐的保存可选集合的复杂度。 ","date":"2020-11-18","objectID":"/leetcode_top100/:4:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#46-全排列"},{"categories":null,"content":"46. 全排列 IIclass Solution { public: void print(std::vector\u003cint\u003e\u0026 state) { for (auto v : state) { std::cout \u003c\u003c v \u003c\u003c \" \"; } } void search(vector\u003cint\u003e\u0026 nums, vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 state, int idx, vector\u003cbool\u003e\u0026 visited) { for (int i = 0; i \u003c nums.size(); ++i) { if (visited[i] || (i \u003e 0 \u0026\u0026 nums[i-1] == nums[i] \u0026\u0026 !visited[i-1])) { continue; } state.push_back(nums[i]); visited[i] = true; if (idx+1 == nums.size()) { res.emplace_back(std::vector\u003cint\u003e(state)); } else { search(nums, res, state, idx+1, visited); } visited[i] = false; state.pop_back(); } } vector\u003cvector\u003cint\u003e\u003e permuteUnique(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; vector\u003cbool\u003e visited(nums.size()); std::sort(nums.begin(), nums.end()); state.reserve(nums.size()); search(nums, res, state, 0, visited); return res; } }; 因为 swap 发生了变化，会导致排序剪枝不可用，相同元素在一块这个条件被打破了。 所以需要一个 visited 的记忆数组来判断选过没有，并且确定每次要选的条件，每层的 search 的循环都是在选一个合适的数字。 这个数字在其他选择的时候没有被选择过 同一层 跳过相同的选择 i \u003e 0 \u0026\u0026 nums[i-1] == nums[i]\u0026\u0026 !visited[i-1] 这个追加的条件就是让同层在循环的时候指选择一次相同的数字。（假如序列是 1a,1b,1c,2b; 当同一层的1a用过了之后，会回溯状态到未使用的状态，也就是未visted。1b想挑选只能在1a已经被挑选的情况下使用） 另外，在回溯的问题中，idx 变量可以理解为选择第 k 个数字。 ","date":"2020-11-18","objectID":"/leetcode_top100/:5:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#46-全排列-ii"},{"categories":null,"content":"31. 下一个排列class Solution { public: void nextPermutation(vector\u003cint\u003e\u0026 nums) { int left_idx = nums.size()-2; while (left_idx \u003e= 0 \u0026\u0026 nums[left_idx] \u003e= nums[left_idx+1]) left_idx--; if (left_idx \u003e= 0) { int left = nums[left_idx]; for (int i = nums.size()-1; i \u003e= left_idx; --i) { if (nums[i] \u003e left) { std::swap(nums[left_idx], nums[i]); break; } } } std::reverse(nums.begin() + left_idx + 1, nums.end()); } }; 这题的思路和全排列不是一种类型，全排列是回溯类型的题目，而这题是数字找规律。 要找到最右的最小数，和右边的大于最小数的值交换，然后反转原最小数右边的序列。 找最小数的过程是要从左往右找到 nums[left_idx] \u003c nums[left_idx+1]，是因为我们需要找到一个最靠右边的小数能够交换就好了。只要小于一个值的原因是从右边往左搜保证了单调性。比如1 2 5 4 3，5 \u003e 4 那么 5 肯定大于 3，而只需要 2 小于 5 就能保证 2 能够和后面的数字发生交换。 交换完 reverse 的原因其实是相当于从小到大 sort 了一下。但是因为具有单调性，所以reverse一下就能达到效果。 算法的实现有些 trick，利用 i 在搜不到的情况下等于 -1，就能处理入参为最后一个排列的情况（回到完全升序排列的情况）。 ","date":"2020-11-18","objectID":"/leetcode_top100/:6:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#31-下一个排列"},{"categories":null,"content":"77. 组合class Solution { public: void dfs(vector\u003cvector\u003cint\u003e\u003e\u0026 res, int n, int idx, int k, vector\u003cint\u003e\u0026 state) { // for (int i = idx; i \u003c= n; ++i) { for (int i = idx; i \u003c= n - k + 1 + state.size() ; ++i) { state.push_back(i); if (state.size() == k) { res.push_back(state); } else { dfs(res, n, i+1, k, state); } state.pop_back(); } } vector\u003cvector\u003cint\u003e\u003e combine(int n, int k) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; dfs(res, n, 1, k, state); return res; } }; 不断选择所有结果即可，但是存在剪枝的条件。n - k + 1 是没有一个数字的情况可以减去的枝，比如1 2 3 4 5 6 7, k = 4， i 就不能等于5了。 再补上当前持有的数字，就是剪枝条件。 ","date":"2020-11-18","objectID":"/leetcode_top100/:7:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#77-组合"},{"categories":null,"content":"78. 子集合class Solution { public: void dfs(vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 state, vector\u003cint\u003e\u0026 nums, int idx) { if (idx == nums.size()) { res.push_back(state); return; } state.push_back(nums[idx]); dfs(res, state, nums, idx+1); state.pop_back(); dfs(res, state, nums, idx+1); } vector\u003cvector\u003cint\u003e\u003e subsets(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; dfs(res, state, nums, 0); return res; } }; 简单回溯。 ","date":"2020-11-18","objectID":"/leetcode_top100/:8:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#78-子集合"},{"categories":null,"content":"90. 子集 IIclass Solution { public: void dfs(vector\u003cvector\u003cint\u003e\u003e\u0026 res, vector\u003cint\u003e\u0026 state, vector\u003cint\u003e\u0026 nums, int idx) { // for (auto v : state) { // cout \u003c\u003c v \u003c\u003c \",\"; // } // cout \u003c\u003c endl; if (idx == nums.size()) { res.push_back(state); return; } state.push_back(nums[idx]); dfs(res, state, nums, idx+1); state.pop_back(); int next_idx = idx+1; while (next_idx \u003c nums.size() \u0026\u0026 nums[next_idx] == nums[next_idx-1]) { ++next_idx; } dfs(res, state, nums, next_idx); } vector\u003cvector\u003cint\u003e\u003e subsetsWithDup(vector\u003cint\u003e\u0026 nums) { vector\u003cvector\u003cint\u003e\u003e res; vector\u003cint\u003e state; sort(nums.begin(), nums.end()); dfs(res, state, nums, 0); return res; } }; 对于 idx 的数值，选还是不选的问题，把递归树画出来后，比如1,2,2，发生重复的原因是当第一个2选了后并且第二个2没有选择，与第一个2没选但是选了第二个2发生了重复。 ","date":"2020-11-18","objectID":"/leetcode_top100/:9:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#90-子集-ii"},{"categories":null,"content":"搜素旋转数组class Solution { public: int search(vector\u003cint\u003e\u0026 nums, int target) { int left = 0, right = nums.size() - 1; while (left \u003c= right) { int mid = (left + right) / 2; if (nums[mid] == target) { return mid; } if (nums[left] \u003c= nums[mid]) { if (nums[left] \u003c= target \u0026\u0026 target \u003c nums[mid]) { right = mid - 1; } else { left = mid + 1; } } else { if (nums[mid] \u003c target \u0026\u0026 target \u003c= nums[right]) { left = mid + 1; } else { right = mid - 1; } } } return -1; } }; 二分的问题见：https://www.youtube.com/watch?v=U3U9XMtSxQc ⚠️ 注意等号的处理 ","date":"2020-11-18","objectID":"/leetcode_top100/:10:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#搜素旋转数组"},{"categories":null,"content":"题目链接39. 组合总和 40. 组合总和 II 46. 全排列 47. 全排列 II 77.组合 78. 子集 90. 子集 II ","date":"2020-11-18","objectID":"/leetcode_top100/:12:0","series":null,"tags":null,"title":"Leetcode: top100","uri":"/leetcode_top100/#题目链接"},{"categories":["sys"],"content":"异步请求过程在利用异步gRPC实现请求的时候，通常使用gRPC example中的greeter_async_client2.cc作为模板发起异步请求，并通过CompletionQueue中的Next()阻塞机制等待请求的完成。 异步请求流程应该如下： 在greeter_async_client2.cc中，每一个请求都会创建一个AsyncClientCall，并且根据这个new出来的对象地址，作为唯一标识，存储在CompletionQueue中， // struct for keeping state and data information struct AsyncClientCall { // Container for the data we expect from the server. HelloReply reply; // Context for the client. It could be used to convey extra information to // the server and/or tweak certain RPC behaviors. ClientContext context; // Storage for the status of the RPC upon completion. Status status; std::unique_ptr\u003cClientAsyncResponseReader\u003cHelloReply\u003e\u003e response_reader; }; void SayHello(const std::string\u0026 user) { // Data we are sending to the server. HelloRequest request; request.set_name(user); // Call object to store rpc data AsyncClientCall* call = new AsyncClientCall; // stub_-\u003ePrepareAsyncSayHello() creates an RPC object, returning // an instance to store in \"call\" but does not actually start the RPC // Because we are using the asynchronous API, we need to hold on to // the \"call\" instance in order to get updates on the ongoing RPC. call-\u003eresponse_reader = stub_-\u003ePrepareAsyncSayHello(\u0026call-\u003econtext, request, \u0026cq_); // StartCall initiates the RPC call call-\u003eresponse_reader-\u003eStartCall(); // Request that, upon completion of the RPC, \"reply\" be updated with the // server's response; \"status\" with the indication of whether the operation // was successful. Tag the request with the memory address of the call object. call-\u003eresponse_reader-\u003eFinish(\u0026call-\u003ereply, \u0026call-\u003estatus, (void*)call); } 在官方的例子中，客户端启动了一个线程专门去处理数据异步的接收，但是能同步完成，即在发送完后 直接利用cq.Next()等待请求的完成。 ","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:1:0","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#异步请求过程"},{"categories":["sys"],"content":"为什么需要复用一个CompletionQueue假设目前有个线程正在执行一个操作，并且需要调用多个不同的gRPC服务获取数据，如果使用同步的调用， 那么就需要经过多次调用的时间才能完成数据的获取。 ... ↓ call A --\u003et1--\u003e gRPC Server A ↓ call B --\u003et2--\u003e gRPC Server B ↓ call C --\u003et3--\u003e gRPC Server C ↓ ... 完成三次数据取的时间就是 t1 + t2 + t3，换成官方的example中的aync_client中的异步调用，收到请求需要CompletetionQueue的Next()调用来同步，处理收到的请求。因为要发起不同的RPC请求，容易惯性地开启多个CompletetionQueue来发起请求，最终等待的时候就会需要多个Next()进行同步，从而不得不开启另一个线程检查 多个CompletetionQueue是否完成，或者单线调用多次Next()导致使用的时间和同步调用没有差别。 如果使用同一个CompletetionQueue发送请求，那么就可以使用一个Next()等待多个请求同步，所使用的时间就是 Max(t1, t2, t3)。使用同一个CompletetionQueue会产生一个问题，Next()等待收到响应后，如何分发到不同的 响应处理中去就成了一个新的问题，最简单的方法之一就是在CompletetionQueue的tag值上想方法，类似于greeter_async_client2.cc中的AsyncClientCall，将结构体的地址写入CQ中，然后在Next()返回得到tag值时 转型成AsyncClientCall类型。在这个结构体中，加入一个类似于type的字段，用于判断请求的类型，就能区分收到的响应是哪个gRPC请求对应的响应。 ","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:2:0","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#为什么需要复用一个completionqueue"},{"categories":["sys"],"content":"简单例子","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:3:0","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#简单例子"},{"categories":["sys"],"content":"Protobuffer 协议文件grpc/examples/protos/helloworld.proto syntax = \"proto3\";option java_multiple_files = true;option java_package = \"io.grpc.examples.helloworld\";option java_outer_classname = \"HelloWorldProto\";option objc_class_prefix = \"HLW\";package helloworld;// The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {}}// The request message containing the user's name. message HelloRequest { string name = 1;}// The response message containing the greetings message HelloReply { string message = 1;}service PingPongService { rpc PingPong (PingRequest) returns (PongReply) {}}message PingRequest { string seq = 1;}message PongReply { string seq = 1;}","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:3:1","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#protobuffer-协议文件"},{"categories":["sys"],"content":"server.cc#include \u003ciostream\u003e#include \u003cmemory\u003e#include \u003cstring\u003e#include \u003cthread\u003e #include \u003cgrpcpp/grpcpp.h\u003e#include \u003cgrpcpp/health_check_service_interface.h\u003e#include \u003cgrpcpp/ext/proto_server_reflection_plugin.h\u003e #ifdef BAZEL_BUILD #include \"examples/protos/helloworld.grpc.pb.h\"#else #include \"helloworld.grpc.pb.h\"#endif using grpc::Server; using grpc::ServerBuilder; using grpc::ServerContext; using grpc::Status; using helloworld::HelloRequest; using helloworld::HelloReply; using helloworld::Greeter; using helloworld::PingPongService; using helloworld::PingRequest; using helloworld::PongReply; // Logic and data behind the server's behavior. class GreeterServiceImpl final : public Greeter::Service { Status SayHello(ServerContext* context, const HelloRequest* request, HelloReply* reply) override { std::cout \u003c\u003c request-\u003ename() \u003c\u003c std::endl; reply-\u003eset_message(\"world\"); return Status::OK; } }; class PingPongServiceImpl final : public PingPongService::Service { Status PingPong(ServerContext* context, const PingRequest* request, PongReply* reply) override { std::cout \u003c\u003c request-\u003eseq() \u003c\u003c std::endl; reply-\u003eset_seq(\"pong\"); return Status::OK; } }; void RunServer() { std::string server_address(\"0.0.0.0:50051\"); GreeterServiceImpl service; grpc::EnableDefaultHealthCheckService(true); grpc::reflection::InitProtoReflectionServerBuilderPlugin(); ServerBuilder builder; // Listen on the given address without any authentication mechanism. builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); // Register \"service\" as the instance through which we'll communicate with // clients. In this case it corresponds to an *synchronous* service. builder.RegisterService(\u0026service); // Finally assemble the server. std::unique_ptr\u003cServer\u003e server(builder.BuildAndStart()); std::cout \u003c\u003c \"Server listening on \" \u003c\u003c server_address \u003c\u003c std::endl; // Wait for the server to shutdown. Note that some other thread must be // responsible for shutting down the server for this call to ever return. server-\u003eWait(); } void RunPingPongServer() { std::string server_address(\"0.0.0.0:50052\"); PingPongServiceImpl service; grpc::EnableDefaultHealthCheckService(true); grpc::reflection::InitProtoReflectionServerBuilderPlugin(); ServerBuilder builder; // Listen on the given address without any authentication mechanism. builder.AddListeningPort(server_address, grpc::InsecureServerCredentials()); // Register \"service\" as the instance through which we'll communicate with // clients. In this case it corresponds to an *synchronous* service. builder.RegisterService(\u0026service); // Finally assemble the server. std::unique_ptr\u003cServer\u003e server(builder.BuildAndStart()); std::cout \u003c\u003c \"Server listening on \" \u003c\u003c server_address \u003c\u003c std::endl; // Wait for the server to shutdown. Note that some other thread must be // responsible for shutting down the server for this call to ever return. server-\u003eWait(); } int main(int argc, char** argv) { std::thread t1 = std::thread(RunServer); std::thread t2 = std::thread(RunPingPongServer); t1.join(); t2.join(); return 0; } ","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:3:2","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#servercc"},{"categories":["sys"],"content":"async_client.cc#include \u003ciostream\u003e#include \u003cmemory\u003e#include \u003cstring\u003e #include \u003cgrpcpp/grpcpp.h\u003e#include \u003cgrpc/support/log.h\u003e#include \u003cthread\u003e #ifdef BAZEL_BUILD #include \"examples/protos/helloworld.grpc.pb.h\"#else #include \"helloworld.grpc.pb.h\"#endif using grpc::Channel; using grpc::ClientAsyncResponseReader; using grpc::ClientContext; using grpc::CompletionQueue; using grpc::Status; using helloworld::PingRequest; using helloworld::PongReply; using helloworld::PingPongService; using helloworld::HelloRequest; using helloworld::HelloReply; using helloworld::Greeter; struct AsyncClientCall { int type; PongReply pong_reply; HelloReply hello_reply; ClientContext context; Status status; std::unique_ptr\u003cClientAsyncResponseReader\u003cPongReply\u003e\u003e pingpong_reader; std::unique_ptr\u003cClientAsyncResponseReader\u003cHelloReply\u003e\u003e greeter_reader; }; class PingPongClient { public: explicit PingPongClient(std::shared_ptr\u003cChannel\u003e channel, CompletionQueue *cq) : stub_(PingPongService::NewStub(channel)), cq_(cq) {} void PingPong(const std::string\u0026 seq) { PingRequest request; request.set_seq(seq); AsyncClientCall* call = new AsyncClientCall; call-\u003etype = 1; call-\u003epingpong_reader = stub_-\u003ePrepareAsyncPingPong(\u0026call-\u003econtext, request, cq_); call-\u003epingpong_reader-\u003eStartCall(); call-\u003epingpong_reader-\u003eFinish(\u0026call-\u003epong_reply, \u0026call-\u003estatus, (void*)call); std::cout \u003c\u003c \"pingpong call struct address:\" \u003c\u003c call \u003c\u003c std::endl; } private: std::unique_ptr\u003cPingPongService::Stub\u003e stub_; CompletionQueue *cq_; }; class GreeterClient { public: explicit GreeterClient(std::shared_ptr\u003cChannel\u003e channel, CompletionQueue *cq) : stub_(Greeter::NewStub(channel)), cq_(cq) {} void SayHello(const std::string\u0026 user) { HelloRequest request; request.set_name(user); AsyncClientCall* call = new AsyncClientCall; call-\u003etype = 0; call-\u003egreeter_reader = stub_-\u003ePrepareAsyncSayHello(\u0026call-\u003econtext, request, cq_); call-\u003egreeter_reader-\u003eStartCall(); call-\u003egreeter_reader-\u003eFinish(\u0026call-\u003ehello_reply, \u0026call-\u003estatus, (void*)call); std::cout \u003c\u003c \"greeter call struct address:\" \u003c\u003c call \u003c\u003c std::endl; } private: std::unique_ptr\u003cGreeter::Stub\u003e stub_; CompletionQueue *cq_; }; void AsyncCompleteRpc(CompletionQueue\u0026 cq_) { void* got_tag; bool ok = false; while (cq_.Next(\u0026got_tag, \u0026ok)) { AsyncClientCall* call = static_cast\u003cAsyncClientCall*\u003e(got_tag); if (call-\u003estatus.ok()) if (call-\u003etype == 0) { std::cout \u003c\u003c \"address=\" \u003c\u003c call \u003c\u003c \" received: \" \u003c\u003c call-\u003ehello_reply.message() \u003c\u003c std::endl; } else { std::cout \u003c\u003c \"address=\" \u003c\u003c call \u003c\u003c \" received: \" \u003c\u003c call-\u003epong_reply.seq() \u003c\u003c std::endl; } else std::cout \u003c\u003c \"RPC failed\" \u003c\u003c std::endl; delete call; } } int main(int argc, char** argv) { CompletionQueue cq; GreeterClient greeter(grpc::CreateChannel( \"localhost:50051\", grpc::InsecureChannelCredentials()), \u0026cq); PingPongClient client(grpc::CreateChannel( \"localhost:50052\", grpc::InsecureChannelCredentials()), \u0026cq); greeter.SayHello(\"hello\"); client.PingPong(\"ping\"); AsyncCompleteRpc(cq); return 0; } ","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:3:3","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#async_clientcc"},{"categories":["sys"],"content":"运行结果\u003e\u003e ./server Server listening on 0.0.0.0:50052 Server listening on 0.0.0.0:50051 ---- \u003e\u003e ./async_client greeter call struct address:0x1748eb0 pingpong call struct address:0x174e410 address=0x1748eb0 received: world address=0x174e410 received: pong ","date":"2020-10-19","objectID":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/:3:4","series":null,"tags":null,"title":"gRPC：复用CompletionQueue","uri":"/%E5%8D%95%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%A6%82%E4%BD%95%E5%8F%91%E8%B5%B7%E5%A4%9A%E4%B8%AArpc%E8%AF%B7%E6%B1%82/#运行结果"},{"categories":["notes"],"content":"前言如果一次性总结，文章太过于冗长，上部分更加是一种在编程中会碰到的技术细节，而这一部分是一些编程中需要记住的良好习惯。 ","date":"2020-04-15","objectID":"/programatic2/:1:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#前言"},{"categories":["notes"],"content":"1. 养成估算的习惯1000字节数据通过路由器需要多少时间？类似这样的问题需要有个大致的答案，通过学习估算，能将估算发展到对事物的数量级有直觉的程度，就可以确定方案的可能性。 无论什么时候有人需要你进行估算，你都可以给出答案。 如果没有经验，估算通常可以去问问已经做过该事情的人。 追踪自己的估算能力，如果估算错了，找出什么事情与自己的预期不同。 ","date":"2020-04-15","objectID":"/programatic2/:2:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#1-养成估算的习惯"},{"categories":["notes"],"content":"2. 调试的过程这里不讲技术上怎么调试，而是另外一种途径进行调试：向别人一行一行解释代码的作用，并且详细描述假定的情况，可能在解释的过程中就可以知道哪里处理问题。 花很长时间找到bug后，想想可以做点什么使找到这个bug更加容易，例如内建更加好的测试。 ","date":"2020-04-15","objectID":"/programatic2/:3:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#2-调试的过程"},{"categories":["notes"],"content":"3. 重构不要害怕重构，老旧的代码如果不适用，所有代码都可以被替换。重构往往在非正交设计，违反DRY原则、过时的知识、性能缺陷存在时发生。 那么如何合理地进行重构？ 不要在重构同时新增功能 开始重构前要有良好的测试，确保重构后能通过 采用小改动的模式，利用局部改动慢慢扩大到更大规模的改动，避免长时间的调试 ","date":"2020-04-15","objectID":"/programatic2/:4:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#3-重构"},{"categories":["notes"],"content":"4. 测试的一些建议根据合约(契约式编程)进行单元测试，先测试子模块，再测试模块自身子模块，再测试模块自身。 单元测试应该在模块目录，使测试代码容易找到，既可以说明怎么使用模块的功能，又可以用于构建回归测试，验证未来对代码的改动是否正确。 另外测试都应该具有以下功能： setup和cleanup的标准途径 可选择地选择可用测试方法 分析输出结果的手段 标准化故障报告的形式 ","date":"2020-04-15","objectID":"/programatic2/:5:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#4-测试的一些建议"},{"categories":["notes"],"content":"5. 曳光弹与原型开发曳光弹原本是指在机枪子弹中间接出现的用于显示子弹射击目标的子弹，比起精确计算风向、射速、角度再射击，曳光弹的方式更加实际。曳光弹的原理就是指，尝试制作一个项目，慢慢地靠近客户需求的一种构建方式，可以有效的展现工作进度，并且这种构建方式的每一段代码都需要有完整的错误检查，结构，文档，以及自查。 而原型开发这种方式通常是一种实验性的探索，为取得某种功能，不必关注太多细节情况，通常没有太多文档和注释。 ","date":"2020-04-15","objectID":"/programatic2/:6:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#5-曳光弹与原型开发"},{"categories":["notes"],"content":"6. 做变化的催化剂这一点对自己的要求比较高，在团队合作中，写出很好的代码，让团队的其他人大吃一惊，渐渐影响他们，从而提高项目质量。 ","date":"2020-04-15","objectID":"/programatic2/:7:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#6-做变化的催化剂"},{"categories":["notes"],"content":"7. 不要过度修饰和求精程序这和过早优化的概念同理，但概念更加偏向于用户，今日了不起的软件往往被明天更加完美的软件更加可取，让用户先使用，用他们的反馈引领软件走向最终解决方案。但是并不是说就可以用不整洁的代码，或者制作糟糕的代码。 ","date":"2020-04-15","objectID":"/programatic2/:8:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#7-不要过度修饰和求精程序"},{"categories":["notes"],"content":"8. 管理知识资产对于金融资产的管理： 定期投资，形成习惯 多元化是长期成功的关键 在保守的投资和高风险，高回报的投资之间平衡资产 设法低买高卖获取最大回报 周期性的评估和平衡财产 而程序员管理自己的知识资产可以类比： 定投，周期性的学习 多元化，广度学习，底线是需要知道目前所使用技术的各种特性，优劣 管理风险，不要把所学的技术都放在一个篮子里 低买高卖：新兴技术可能就是被低估的股票，提前学习可能可以更好的找到工作 重新评估：热门技术可能很快就冷门了，甚至过一段时间有需要重新温习忘记的数据库技术等，需要对自己的知识体系重新评估。 所以可以给自己设立一些周期性的目标，防止自己的脱节： 定期投资可以是每年至少学习一种新的语言，每月阅读一本技术书籍，阅读非技术书籍。 偶尔学习一些公开课 参与一些组织，打听公司以外的人都在做什么 试验不同的环境，技术或者非技术都是如此，逃离舒适区 持续投入！ ","date":"2020-04-15","objectID":"/programatic2/:9:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#8-管理知识资产"},{"categories":["notes"],"content":"9. 交流交流很重要，即使是“自闭”人群，该说话的时候还是得好好说话。 书中提到的最关键的几点： ","date":"2020-04-15","objectID":"/programatic2/:10:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#9-交流"},{"categories":["notes"],"content":"了解听众 你想让他们学到什么 他们对你讲的什么感兴趣 他们有多丰富的经验 他们要多少细节 你想要谁拥有这些信息 你如何促使他们听你说话 ","date":"2020-04-15","objectID":"/programatic2/:10:1","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#了解听众"},{"categories":["notes"],"content":"认真倾听和及时回复对于前者，你不听别人讲话，别人也懒得听你的 ：）；及时回复这一点，在现代社会中其实很容易遗忘，但是即使简单回复，”我稍后回复你“，也会显得礼貌。 ","date":"2020-04-15","objectID":"/programatic2/:10:2","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#认真倾听和及时回复"},{"categories":["notes"],"content":"参考资料 《The Programatic Programmer》 https://en.wikipedia.org/wiki/Law_of_Demeter ","date":"2020-04-15","objectID":"/programatic2/:11:0","series":null,"tags":null,"title":"实效性软件构建的途径-下","uri":"/programatic2/#参考资料"},{"categories":["notes"],"content":"前言无意中看到了这本书，译名是程序员修炼之道，想尝试在这本书中找到一些跟软件构建相关问题的答案。这本书虽然是上个世纪出版的，要注意时代的局限性和过期的经验，进行自我验证，但一遍看下来，对我来说，干货还是有很多的。 ","date":"2020-04-12","objectID":"/programatic1/:1:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#前言"},{"categories":["notes"],"content":"1. 需求挖掘这一点我认为是最重要的一点，于是放在最前面。 找出用户为何要做特定事情的原因，而不是目前要做这件事情的方式，开发最终是需要解决商业问题。 比如，“只有员工和上级和人事部门才能查看员工的档案”和“只有指定人员能查看员工档案”，后者更加容易编写出适用于元数据编程的程序，也更加的灵活。 这个用户不仅仅指实际使用的人，也可以是交给你这个工作的人。 ","date":"2020-04-12","objectID":"/programatic1/:2:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#1-需求挖掘"},{"categories":["notes"],"content":"2. 做好退路和保险书中是用代码所存储的机器因为崩溃而引发的问题，虽然在git的时代，这种问题不容易发生了，但是这种想法得印在脑子里，如果真发生类似的问题，损失将是非常大的。 这一点和可撤销性想类似，要考虑架构部署的改动和灵活性，假设某次会议决定使用MySQL进行存储数据，但是在快完成时，需要换成其他DB进行存储，如果要改动很大，那么就是错误建立在了假定的决策上面。假定项目以后只会用到MySQL，很多代码都被写死了。 再比如开发Unix软件，是否考虑所有平台的可以执行问题，例如epoll可以在linux上使用，那么如果在只有Kqueue的FreeBSD上面会怎么样，所以需要保证代码在一些决策上可以变通。 ","date":"2020-04-12","objectID":"/programatic1/:3:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#2-做好退路和保险"},{"categories":["notes"],"content":"3. 不要破窗户这也就是常说的破窗效应，一扇破窗户，只要一段时间不修理，就会逐渐带来废弃感，逐渐变为破败的废弃物。软件中的破窗户就是指，低劣的设计，错误的决策，糟糕的代码。应该发现一个就修一个，如果没时间就加入注释，并且可以深究窗户什么时候破的，原因是什么，如何修理。 并且要注意变化，随着软件补丁的添加，会慢慢偏离其规范，周期性地审视环境的变化，以免量变引发的雪崩。 ","date":"2020-04-12","objectID":"/programatic1/:4:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#3-不要破窗户"},{"categories":["notes"],"content":"4. 重复的工作(Don’t Repeat Yourself)这种重复不单单指代码的复制粘贴，还有可能是一些不容易发现的错误。 ","date":"2020-04-12","objectID":"/programatic1/:5:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#4-重复的工作dont-repeat-yourself"},{"categories":["notes"],"content":"强加的重复 例如客户端和服务端使用不同的语言，那么两端都会有类似的数据结构，可以用schema的元数据自动生成相关的类定义。 文档：注释会随代码更新而过时，注释应该用于更加高级的说明，我的理解是注释应该写下这段代码应该干什么，而不是干了什么 语言：例如C/C++应该在头文件的函数声明前说明接口问题，实现文件中记载实现细节 文档和代码：如果边写代码边写文档，就会造成代码和文档的重复问题，比如代码改动了，文档也会随即发生变。如果最开始就根据用户的需求写成文档来生成测试，所有的代码只需要在提交时通过所有的测试即可。 ","date":"2020-04-12","objectID":"/programatic1/:5:1","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#强加的重复"},{"categories":["notes"],"content":"无意的重复通常是设计问题引起的，注意数据之间的关联性，书中的例子是一个数据集合中同时出现了两个点和一段距离，如果点发生了变化，那么需要同时更改距离，比较好的做法是通过点来计算距离，而不是通过赋值。 ","date":"2020-04-12","objectID":"/programatic1/:5:2","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#无意的重复"},{"categories":["notes"],"content":"耐性的重复这就是在项目中放着好好的代码不用，自己重写写个轮子来浪费时间。 ","date":"2020-04-12","objectID":"/programatic1/:5:3","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#耐性的重复"},{"categories":["notes"],"content":"开发者之间的重复分工不明确导致工作职责重复，这个往往需要清晰的设计和强有力的技术项目领导进行责任划分。 ","date":"2020-04-12","objectID":"/programatic1/:5:4","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#开发者之间的重复"},{"categories":["notes"],"content":"5. 解耦接口设计时，应该考虑到传入的类型，比如某个函数需要B类型中的时间成员变量，下面这种耦合度更低。 void foo(B \u0026b) { theTime = b.t; } void foo(time \u0026t) { theTime = t; } ","date":"2020-04-12","objectID":"/programatic1/:6:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#5-解耦"},{"categories":["notes"],"content":"较小响应集根据统计结果，较大响应集更加容易出错，响应集的定义是：类的各个方法直接调用的函数的数目。 ","date":"2020-04-12","objectID":"/programatic1/:6:1","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#较小响应集"},{"categories":["notes"],"content":"Demeter法则wiki：https://en.wikipedia.org/wiki/Law_of_Demeter 每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元； 每个单元只能和它的朋友交谈：不能和陌生单元交谈； 只和自己直接的朋友交谈。 在OOP中，这个法则的规定为某个对象的任何方法都应该只调用属于一下情形中的方法： 它自身的方法 传入该方法的任何参数的方法 该类所属的成员对象所含有的方法 所持有的任何对象的方法 class Demeter { private: A *a; int func(); public: // ... void example(B\u0026 b); } void Demeter::example(B\u0026 b) { C c; int f = func(); // 1. 它自身的方法 b.invert(); // 2. 传入该方法的任何参数的方法 a = new A(); a-\u003esetActive(); // 3. 该类所属的成员对象所含有的方法 c.print() // 4. 所持有的任何对象的方法 } ","date":"2020-04-12","objectID":"/programatic1/:6:2","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#demeter法则"},{"categories":["notes"],"content":"元数据驱动应用用配置来定义程序行为，比如使用什么数据库，单机还是多机等，给予程序退路，可撤销性。 ","date":"2020-04-12","objectID":"/programatic1/:6:3","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#元数据驱动应用"},{"categories":["notes"],"content":"时间耦合这个名词头一次听到，概念比较简单，这种耦合发生于假定了事件发生的顺序，要考虑事件可能的发生顺序和并发性。 ","date":"2020-04-12","objectID":"/programatic1/:6:4","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#时间耦合"},{"categories":["notes"],"content":"发布和订阅这里的意思是将事情/业务拆分成多个例程进行处理，如果用单个例程处理所有的情况，其实就是大量的if、else的组合。如果我们对某个publisher生成的特定事件感兴趣，要做的事情就是登记自己，然后由publisher通知subscriber。 ","date":"2020-04-12","objectID":"/programatic1/:6:5","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#发布和订阅"},{"categories":["notes"],"content":"6. 正交性正交换个词可以是不相依赖性，解耦性，消除无关事物之间的相互影响。在设计正交组件的时候，可以问自己“如果我显式的改变了某个特定功能背后的需求，有多少模块会受到影响”。 不要依赖无法控制的事物属性，比如把电话号码作为顾客标识符，如果电话公司重新分配了区号会怎么样。 在编码时：代码解耦，减少向外暴露的接口和数据，避免全局数据，避免相似的函数。 构建单元测试的时候，也是对正交性的一种验证，如果只是为了某个测试，需要拉扯到系统中其他一大部分，那么解耦性就没有做的很好。 修正bug的时候也是，修正一个bug如果要牵扯到系统的很多地方，那么也需要警惕解耦问题。 etc: 可以尝试月报自己的bug所影响文件数目的趋势。 ","date":"2020-04-12","objectID":"/programatic1/:7:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#6-正交性"},{"categories":["notes"],"content":"7. 契约式编程在项目合作过程中，可能需要不断地和他人的代码进行接合，别人的代码可能不符合高标准代码，所以需要防御性编码。用断言检查坏数据，数据库的列加上约束。更进一步，连自己的代码也不信任，防御性的编程。 前条件：调用例程前的需求 后条件：例程保证会做的事情 不变项：在计算机科学中，不变条件是指，在程序执行过程或部分过程中，可始终被假定成立的条件。程序员往往使用断言来现式定义不变条件。 通常前条件是由调用者来保证的，也就是说，如果被调用者需要一个正整数，而调用者传递一个负数，那行为应该是未定义的。 当调用者确保了例程的前条件后，后条件和不变项都应该为真。 ","date":"2020-04-12","objectID":"/programatic1/:8:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#7-契约式编程"},{"categories":["notes"],"content":"8. 断言式编程判断绝不可能发生的事情，而不是进行代替错误处理。并且断言失败会退出进程，最好的是用断言产生异常，跳到某个退出点，执行清理。另外，进行断言的代码，不要再有其他的副作用。 ","date":"2020-04-12","objectID":"/programatic1/:9:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#8-断言式编程"},{"categories":["notes"],"content":"9. 尽早崩溃一般来说，尽早的崩溃比隐藏着错误继续运行的结果可能更坏，所以当出现问题的时候及早对程序结束运行。 有时候直接退出不合适，全局资源可能没有释放，比如一些全局锁等，所以可能需要在崩溃前进行清理，打日志等。 ","date":"2020-04-12","objectID":"/programatic1/:10:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#9-尽早崩溃"},{"categories":["notes"],"content":"10. 使用异常很有可能在 C 中看到下面这样的代码 retcode = OK; if (socket.read(name) != OK) { retcode = BAD_READ; } if (socket.read(age) != OK) { retcode = BAD_READ; } if (socket.read(address) != OK) { retcode = BAD_READ; } return retcode; 过多的判断而导致的丑陋代码，甚至忘记代码原本要做什么就有异常进行专门处理。 retcode = OK; try { socket.read(name); socket.read(age); socket.read(address); } catch (IOException e) { retcode = BAD_READ; LOG.ERROR(\"Error reading from . . .\"); } return retcode; 由于C++没有Java那样在try..catch后面有finally子句，所以常常会有重复的情况，违反了DRY((Don’t Repeat Yourself)原则，比如： void doSomething(void) { Node *n = new Node; try { /* do something */ } catch (exception e) { delete n; throw; } delete n; } 碰到这样的情况，这种情况下，通常需要把 n 转变为栈上对象，如果非得需要使用指针，可以利用智能指针进行自动销毁。 ","date":"2020-04-12","objectID":"/programatic1/:11:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#10-使用异常"},{"categories":["notes"],"content":"参考资料 《The Programatic Programmer》 https://en.wikipedia.org/wiki/Law_of_Demeter ","date":"2020-04-12","objectID":"/programatic1/:12:0","series":null,"tags":null,"title":"实效性软件构建的途径-上","uri":"/programatic1/#参考资料"},{"categories":["sys"],"content":" “The most effective debugging tool is still careful thought, coupled with judiciously placed print statements” — Brian Kernighan, Unix for Beginners. 最朴素的debug方法还是使用print，并且在合适的地方插入print语句，过多的日志信息反而会引起混乱，使debug效率降低。 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:0:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#"},{"categories":["sys"],"content":"日志分级根据事情的验证程度，可以将事件的严重情况分为： INFO WARNING ERROR CRITICAL 每当输出日志的时候，在响应事件前面加上前缀，相关的语言应该都有现成的库，根据需求进行选取即可。 对于一个事件运行的程序，比如daemon进程，日志输出在响应文件夹，利用grep就能很好的查询不同严重程度的事件的发生情况。 日志的位置通常在/var/log目录下，例如nginx的日志文件就在/var/log/nginx目录下，系统服务systemd的地址文件就在/var/log/journal目录下。 日志除了写入文件外，还能通过相关配置写入到套接字/远程服务器上，对日志进行集中处理或存储。 其他： - 交互式日志查看工具: lnav ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:1:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#日志分级"},{"categories":["sys"],"content":"debug 工具除了GNU项目中的gdb和python自带的pdb，还有一些能在debug过程中自动显示相关变量以及寄存器值的debug工具： pwndb lldb ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:2:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#debug-工具"},{"categories":["sys"],"content":"backtrace利用strace可以查询一些系统调用的次数，例如 store : ~/go \u003e\u003e ls bin pkg src store : ~/go \u003e\u003e sudo strace -e lstat ls -l \u003e /dev/null lstat(\"pkg\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 lstat(\"src\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 lstat(\"bin\", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 +++ exited with 0 +++ 通过strace获得ls程序调用了多少次lstat。 扩展阅读： - https://blogs.oracle.com/linux/strace-the-sysadmins-microscope-v2 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:3:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#backtrace"},{"categories":["sys"],"content":"静态分析静态分析(wiki)就像是对一个文本直接检查，推断相应的语法错误和可能的语法错误。 例如python有pyflakes，shell脚本有shellcheck，在github上也有相关的静态分析工具集合。 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:4:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#静态分析"},{"categories":["sys"],"content":"性能剖析 Premature optimization is the root of all evil 通常认为过早优化是不好的，有时间可以读下**Premature Optimization**。 最简单的性能测试可以通过程序结束的时间减去程序开始运行的时间获得。比如： $ time ls \u003e /dev/null real 0m0.002s user 0m0.001s sys 0m0.000s 可以获得三个时间: real: 从程序开始到程序结束的时间，包括了I/O，网络的时间 user：运行用户级别代码的时间 sys: 运行内核的时间 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#性能剖析"},{"categories":["sys"],"content":"CPU在python中，可以利用cProfile模组进行测试每个函数所使用的时间，line profile测试每一行执行时间。 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:1","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#cpu"},{"categories":["sys"],"content":"内存占用 c/c++: Valgrind https://valgrind.org/ python: mem-profiler https://pypi.org/project/memory-profiler/ ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:2","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#内存占用"},{"categories":["sys"],"content":"事件采样perf 简介perf工具是Linux下用于性能剖析的工具，执行相应的程序，由内核或者硬件来计数程序所触发的事件。 事件分为几类： software events: 完全由内核计数的事件，比如：上下文切换，fault等 PMU hardware events: 由处理器自己或者性能监控单元PMU(Performance Monitoring Unit)提供，比如这些事件：运行CPU时钟的数量，失效指令，L1级cache未命中次数等。由CPU的种类和模型决定。 tracepoint events：由内核的ftrace实现，并且只能用在2.6.3x等更新的内核。 失效指令这个术语是intel中的instructions retired，意思是所执行的指令数目，并不包括由于分支预测失败的那一部分指令。 Instructions Retired: This event indicates the number of instructions that retired or executed completely. This does not include partially processed instructions executed due to branch mispredictions. 回到perf工具，机器所支持的事件列表可以通过list查询: $ perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] context-switches OR cs [Software event] cpu-clock [Software event] ... 开始监控一个程序运行$ perf stat -B dd if=/dev/zero of=/dev/null count=1000000 1000000+0 records in 1000000+0 records out 512000000 bytes (512 MB) copied, 0.461866 s, 1.1 GB/s Performance counter stats for 'dd if=/dev/zero of=/dev/null count=1000000': 453.12 msec task-clock # 0.979 CPUs utilized 43 context-switches # 0.095 K/sec 0 cpu-migrations # 0.000 K/sec 216 page-faults # 0.477 K/sec \u003cnot supported\u003e cycles \u003cnot supported\u003e instructions \u003cnot supported\u003e branches \u003cnot supported\u003e branch-misses 0.462827938 seconds time elapsed 0.087344000 seconds user 0.366061000 seconds sys ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:3","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#事件采样"},{"categories":["sys"],"content":"事件采样perf 简介perf工具是Linux下用于性能剖析的工具，执行相应的程序，由内核或者硬件来计数程序所触发的事件。 事件分为几类： software events: 完全由内核计数的事件，比如：上下文切换，fault等 PMU hardware events: 由处理器自己或者性能监控单元PMU(Performance Monitoring Unit)提供，比如这些事件：运行CPU时钟的数量，失效指令，L1级cache未命中次数等。由CPU的种类和模型决定。 tracepoint events：由内核的ftrace实现，并且只能用在2.6.3x等更新的内核。 失效指令这个术语是intel中的instructions retired，意思是所执行的指令数目，并不包括由于分支预测失败的那一部分指令。 Instructions Retired: This event indicates the number of instructions that retired or executed completely. This does not include partially processed instructions executed due to branch mispredictions. 回到perf工具，机器所支持的事件列表可以通过list查询: $ perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] context-switches OR cs [Software event] cpu-clock [Software event] ... 开始监控一个程序运行$ perf stat -B dd if=/dev/zero of=/dev/null count=1000000 1000000+0 records in 1000000+0 records out 512000000 bytes (512 MB) copied, 0.461866 s, 1.1 GB/s Performance counter stats for 'dd if=/dev/zero of=/dev/null count=1000000': 453.12 msec task-clock # 0.979 CPUs utilized 43 context-switches # 0.095 K/sec 0 cpu-migrations # 0.000 K/sec 216 page-faults # 0.477 K/sec cycles instructions branches branch-misses 0.462827938 seconds time elapsed 0.087344000 seconds user 0.366061000 seconds sys ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:3","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#perf-简介"},{"categories":["sys"],"content":"事件采样perf 简介perf工具是Linux下用于性能剖析的工具，执行相应的程序，由内核或者硬件来计数程序所触发的事件。 事件分为几类： software events: 完全由内核计数的事件，比如：上下文切换，fault等 PMU hardware events: 由处理器自己或者性能监控单元PMU(Performance Monitoring Unit)提供，比如这些事件：运行CPU时钟的数量，失效指令，L1级cache未命中次数等。由CPU的种类和模型决定。 tracepoint events：由内核的ftrace实现，并且只能用在2.6.3x等更新的内核。 失效指令这个术语是intel中的instructions retired，意思是所执行的指令数目，并不包括由于分支预测失败的那一部分指令。 Instructions Retired: This event indicates the number of instructions that retired or executed completely. This does not include partially processed instructions executed due to branch mispredictions. 回到perf工具，机器所支持的事件列表可以通过list查询: $ perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] context-switches OR cs [Software event] cpu-clock [Software event] ... 开始监控一个程序运行$ perf stat -B dd if=/dev/zero of=/dev/null count=1000000 1000000+0 records in 1000000+0 records out 512000000 bytes (512 MB) copied, 0.461866 s, 1.1 GB/s Performance counter stats for 'dd if=/dev/zero of=/dev/null count=1000000': 453.12 msec task-clock # 0.979 CPUs utilized 43 context-switches # 0.095 K/sec 0 cpu-migrations # 0.000 K/sec 216 page-faults # 0.477 K/sec cycles instructions branches branch-misses 0.462827938 seconds time elapsed 0.087344000 seconds user 0.366061000 seconds sys ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:3","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#开始监控一个程序运行"},{"categories":["sys"],"content":"火焰图利用perf工具还有一个比较方便的功能就是生成火焰图。 例如，以上面的例子制作一个火焰图: $ git clone git@github.com:brendangregg/FlameGraph.git $ perf record -F 99 -g dd if=/dev/zero of=/dev/null count=1000000 $ perf script \u003e out.perf $ FlameGraph/stackcollapse-perf.pl out.perf \u003e out.folded $ FlameGraph/flamegraph.pl out.folded \u003e myflame.svg 就能得到一个dd命令执行的调用过程的*.svg： 另外python有pycallgraph，golang也有go tool pprof工具进行性能剖析。 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:5:4","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#火焰图"},{"categories":["sys"],"content":"性能监控","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#性能监控"},{"categories":["sys"],"content":"资源概览除了经常使用的top，还有许多开源的可视化的工具也比较方便。 htopglances","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:1","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#资源概览"},{"categories":["sys"],"content":"资源概览除了经常使用的top，还有许多开源的可视化的工具也比较方便。 htopglances","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:1","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#htop"},{"categories":["sys"],"content":"资源概览除了经常使用的top，还有许多开源的可视化的工具也比较方便。 htopglances","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:1","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#glances"},{"categories":["sys"],"content":"磁盘与I/O# io监控 $ iotop # 全局系统磁盘空间使用 df -h # 指定目录占用情况 $ du -sh * # 交互式磁盘占用工具 $ ncdu ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:2","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#磁盘与io"},{"categories":["sys"],"content":"内存$ free -h ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:3","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#内存"},{"categories":["sys"],"content":"打开的文件$ lsof ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:4","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#打开的文件"},{"categories":["sys"],"content":"网络常用命令： $ ss $ ip $ netstat $ ifconfig ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:5","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#网络"},{"categories":["sys"],"content":"网络使用情况iftopnethogs","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:6","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#网络使用情况"},{"categories":["sys"],"content":"网络使用情况iftopnethogs","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:6","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#iftop"},{"categories":["sys"],"content":"网络使用情况iftopnethogs","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:6:6","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#nethogs"},{"categories":["sys"],"content":"MISC除了这些基本的命令外，还有一些杂项，比如比较两个命令哪个执行得比较快的工具hyperfine: 还有 cgroup/taskset 等工具，其中cgroup需要单独拿出讲，cgroup在Docker中的资源隔离起着重要作用，先挖个坑。 ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:7:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#misc"},{"categories":["sys"],"content":"参考 https://missing.csail.mit.edu/2020/debugging-profiling/ perf相关: http://perf.wiki.kernel.org/index.php/Tutorial https://github.com/brendangregg/FlameGraph hyperfine: https://github.com/sharkdp/hyperfine ","date":"2020-03-20","objectID":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/:8:0","series":null,"tags":["shell","debug","profiling"],"title":"如何进行调试以及性能剖析","uri":"/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/#参考"},{"categories":["algorithm"],"content":"最初的数据库LSM-tree得从最简单的数据库的shell实现说起，如： #! /bin/bash db_set() { echo \"$1,$2\" \u003e\u003e database } db_get() { grep \"^$1,\" database | sed -e \"s/^$1,//\" | tail -n 1 } db_set将两个参数简单追加database文件，而db_get利用匹配出来的结果去掉key和逗号得到value，再利用tail获取到最set到database中去。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:1:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#最初的数据库"},{"categories":["algorithm"],"content":"读取优化很明显，由于是追加写也是最简单的写操作，这种set方式通常足够高效，但是对于get，事件复杂度就需要上升到O(n)，所以最常见的想法是对数据追加索引，比如利用哈希表在内存中设置一个key，而key对应的value设置为该key/value在文件中的偏移。 key byte offset abc 0 b 64 … … aacb 3613 就有类似于这样一个哈希表存储在内存中，这也就是Bitcask的核心做法，只需要一次磁盘寻址就可以加载到这个value，适合每个键的值频繁更新的场景。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:1:1","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#读取优化"},{"categories":["algorithm"],"content":"存储优化因为都会往同一个文件追加文件，所以设置键的写入，会造成磁盘空间用尽。解决办法是将日志分解成一定大小的段，文件到达一定大小就关闭，后续的写入写到新的段文件中，读请求仍旧使用旧段文件，当后台线程将后台文件合并/压缩后，读请求就能切换到新的合并段上，旧段文件安全删除。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:1:2","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#存储优化"},{"categories":["algorithm"],"content":"其他 文件格式：替换类似于CSV的字符格式为二进制格式。 删除记录：追加删除标记，当合并时检测到这个标记丢弃响应的key 崩溃恢复：这个主要针对存储在内存中的哈希表，当机器宕机后，哈希表将会丢失，重启恢复需要重新读取所有的段文件才能恢复，Bitcask的做法时将相应段的哈希表快照存储磁盘中。 记录写入：写入操作的过程中如果发送了崩溃，那么最新的值将是不完整的，可以在一条记录前追加校验，如果损毁就需要丢弃。 并发控制：写入需要按先后顺序写入，所以写线程通常只有一个，而读取是可以多个同时进行的。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:1:3","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#其他"},{"categories":["algorithm"],"content":"SSTablesSSTables全名为排序字符串表(Sort String Tables)，写入的记录会被排序。对key进行排序会有如下的有点： 合并段更加高效：方法类似于归并排序，同时读取多个段文件，比较每一个文件的第一个键，将最小的键拷贝到输出文件，重复这个过程，就可以得到一个按键排序的合并段文件。另外就是文件大于可用内存也可以进行，像前面的方法，需要将所有kv都保存在内存中，合并完成才能写入磁盘，而归并的方法只需要维护输入端的数量个kv，即使出现相同的kv，也可以保证他们是相邻的，覆盖即可。 压缩内存：查找特定键时，不需要保存所有键的索引，而是建立稀疏索引，比如1个几KB大小的文件，只需要1个key即可。根据这个key的字典序找到稀疏索引中提供的偏移，读取该部分，找到相应的key即可。 范围查询：请求某个范围内的多个key/value更加方便。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:2:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#sstables"},{"categories":["algorithm"],"content":"构建和维护SSTables 写入Key写写入内存表(类似于红黑树的平衡树) 内存表大小大于某个阈值，根据二叉排序树的特点，顺序写入磁盘，此时在内存中新生成一个内存表 查表时，先查询内存表找到偏移，如果没找到，那么查找以前的段文件 后台周期性合并，压缩，丢弃不需要的key 写入key需要追加日志(用于恢复内存表)，但是超出阈值并写完当前内存表后，可以删除该日志。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:2:1","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#构建和维护sstables"},{"categories":["algorithm"],"content":"优化SSTables 读取SSTables中不存在的key会回溯到最旧的段文件，所以开销很大，对于这种存在问题，可以使用布隆过滤器。 其他是一些压缩/合并的方式，例如LevelDB/RocksDB使用的分层压缩，HBase使用大小分级，而Cassandra两种都支持。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:2:2","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#优化sstables"},{"categories":["algorithm"],"content":"LSM-tree和SSTablesSSTables的算法本质就是LevelDB和RocksDB所使用，并且最初这种索引结构是被称为以日志结构的合并树(Log-Structured Merge-Tree)，因此，基于合并和压缩排序文件原理的存储引擎，通常被称为LSM存储引擎。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:3:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#lsm-tree和sstables"},{"categories":["algorithm"],"content":"B-treeB树其实已经非常熟悉了，常见于各大关系型数据的索引。Btree也是按键排序的key-value对，以及高效的区间查询。但是在存储方面，是以4KB甚至更大作为存储单元，这样更加借鉴底层硬件。 由于B树也保持平衡，具有n个key的B树深度也是O(log n)，其中一个页中包含子页的引用数量称为分页因子，当分页因子为500的4KB页的四级树可存储256TB数据。 崩溃问题：和日志合并树一样，也要考虑写时发生崩溃的问题，因为在重写页时，如果发生崩溃直接导致的结果是索引破坏，所以需要预写日志WAL(WriteAhead Log)在写入前，追加写入日志文件，用于恢复B树到最近一致状态。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:4:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#b-tree"},{"categories":["algorithm"],"content":"优化B-tree 写时复制：修改的页被写入不同位置，创建完成后修改父页中的引用。这样就不用覆盖和维护WAL 保存键的缩略信息，减少key在页内占用，增加分页因子，降低层数 尝试让页的磁盘位置更加接近，减少寻道时间 另外一点就是常见的添加一个额外的指针到相邻的页，这样就不需要跳回父页，减少不必要的I/O 最后就是分型树等等 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:4:1","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#优化b-tree"},{"categories":["algorithm"],"content":"LSM-tree和B-tree的优劣通常认为B树读取更快，而LSM树写入更快。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:5:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#lsm-tree和b-tree的优劣"},{"categories":["algorithm"],"content":"LSM-tree的优点对于B树来说，一次写操作需要写两次磁盘： 写入日志(WAL) 写入到实际的B树中，另外还有页分裂的可能，导致多次I/O 而对于LSM树来说： 追加写一次 但是又反复的后台压缩和SSTables合并 所以要注意一次写入请求会导致多次磁盘写(写放大)，SSD由于其物理性质所决定，只能承受住比机械硬盘更低覆盖重写次数，所以需要加入考量，另外，如果写入磁盘占用的带块越多，可用的磁盘带宽也就越少。而LSM时拥有较低的写放大。 另外，回到SSTables的构建，LSM的写入时是从内存一次性写入到磁盘的，也就是其磁盘块更加连续，顺序写比随机写要快得多，相比于分散的磁盘块，拥有更低的寻道时间。相关联的还有碎片化问题，由于B树是面向页的，也可能被分裂成多个页时，页中空间无法使用，导致碎片化。而SSTables的定期合并可以消除碎片话，拥有更加紧凑的数据表达方式。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:5:1","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#lsm-tree的优点"},{"categories":["algorithm"],"content":"LSM-tree的缺点 压缩过程(I/O)中会干扰当前读写操作(I/O)，造成读写等待。 另外B-tree的key在磁盘中，只有一个副本，而LSM-tree有多个。所以在关系型数据库中，B树可以直接定义锁在页中，完成键范围上的事务隔离。 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:5:2","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#lsm-tree的缺点"},{"categories":["algorithm"],"content":"参考 《数据密集型应用系统设计》 ","date":"2020-03-18","objectID":"/b-tree-and-lsm-tree/:6:0","series":null,"tags":["LSM-tree","B-tree"],"title":"B-tree和LSM-tree","uri":"/b-tree-and-lsm-tree/#参考"},{"categories":["sys"],"content":"前言因为前段时间把6.824的lab3做完了，但是lab内部是用channel mock了一个简单的网络来测试网络丢包，网络分区等问题，也就是说跑在单机上面，其rpc也是通过channel和反射实现。目前比较有名的RPC框架就是gRPC，golang也自带了rpc库，这篇文章主要讲述这两者的简单使用，以及谈论一些关于rpc的观点。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:1:0","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#前言"},{"categories":["sys"],"content":"RPC历史RPC也称远程过程调用，自从上世纪70年代就存在的思想，RPC模型是尝试使远程服务看起来像在统一进程空间的函数一样。但是，一种基于HTTP原则的设计理念REST可以扮演RPC的角色，利用url表示资源，利用HTTP的其他功能提供身份验证等，并且RPC虽然看上去非常简洁，实际上是存在缺陷的，比如rpc的时间根据网络情况可能大不相同，网络不可信时，超时重传会使RPC函数被调用多次，这就又需要这个函数能保证幂等性等。 虽然有以上问题，RPC没有消失肯定有其独特存在的原因，首先是使用二进制编码的RPC协议能实现比REST上基于JSON的数据流协议获得更好的性能(但是JSON数据流可以提供良好的调试功能，这是二进制编码不可比拟的)。所以REST一般用于公共API，而RPC框架侧重于同一组织内多项服务之间的请求，也通常发生在同一个数据中心。 RPC的目标是让客户端和服务端易于交互(编程意义上)，隐藏底层的网络协议。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:2:0","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#rpc历史"},{"categories":["sys"],"content":"原生RPC这里直接尝试写一个简单的KV服务，提供Put，Get的接口。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:3:0","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#原生rpc"},{"categories":["sys"],"content":"客户端代码package main import ( \"fmt\" \"log\" \"net/rpc\" ) // // Common RPC request/reply definitions // const ( OK = \"OK\" ErrNoKey = \"ErrNoKey\" ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Client // func connect() *rpc.Client { client, err := rpc.Dial(\"tcp\", \"fatwaer.store:1234\") if err != nil { log.Fatal(\"dialing:\", err) } return client } func get(key string) string { client := connect() args := GetArgs{\"subject\"} reply := GetReply{} err := client.Call(\"KV.Get\", \u0026args, \u0026reply) if err != nil { log.Fatal(\"error:\", err) } client.Close() return reply.Value } func put(key string, val string) { client := connect() args := PutArgs{\"subject\", \"6.824\"} reply := PutReply{} err := client.Call(\"KV.Put\", \u0026args, \u0026reply) if err != nil { log.Fatal(\"error:\", err) } client.Close() } // // main // func main() { put(\"subject\", \"6.824\") fmt.Printf(\"Put(subject, 6.824) done\\n\") fmt.Printf(\"get(subject) -\u003e %s\\n\", get(\"subject\")) } ","date":"2020-02-26","objectID":"/rpc-and-grpc/:3:1","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#客户端代码"},{"categories":["sys"],"content":"服务端代码package main import ( \"fmt\" \"log\" \"net\" \"net/rpc\" \"sync\" ) // // Common RPC request/reply definitions // const ( OK = \"OK\" ErrNoKey = \"ErrNoKey\" ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Server // type KV struct { mu sync.Mutex data map[string]string } func server() { kv := new(KV) kv.data = map[string]string{} rpcs := rpc.NewServer() rpcs.Register(kv) l, e := net.Listen(\"tcp\", \":1234\") if e != nil { log.Fatal(\"listen error:\", e) } fmt.Println(\"server Listen \") for { conn, err := l.Accept() if err == nil { go rpcs.ServeConn(conn) } else { break } } l.Close() } func (kv *KV) Get(args *GetArgs, reply *GetReply) error { fmt.Printf(\"server recive get %s\\n\", args.Key) kv.mu.Lock() defer kv.mu.Unlock() val, ok := kv.data[args.Key] if ok { reply.Err = OK reply.Value = val } else { reply.Err = ErrNoKey reply.Value = \"\" } return nil } func (kv *KV) Put(args *PutArgs, reply *PutReply) error { fmt.Printf(\"server recive put %s-\u003e%s\\n\", args.Key, args.Value) kv.mu.Lock() defer kv.mu.Unlock() kv.data[args.Key] = args.Value reply.Err = OK return nil } // // main // func main() { server() } ","date":"2020-02-26","objectID":"/rpc-and-grpc/:3:2","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#服务端代码"},{"categories":["sys"],"content":"运行结果分别在两台云服务器上运行，确保可以通过网络传递消息： ","date":"2020-02-26","objectID":"/rpc-and-grpc/:3:3","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#运行结果"},{"categories":["sys"],"content":"代码结构Software structure client app handler fns stub fns dispatcher RPC lib RPC lib net ------------ net 客户端/服务端需要先建立相应的TCP连接，即服务端先在相应端口绑定监听，然后客户端与该端口三次握手后，服务端accept返回得到建立好的TCP连接，注册到RPC中，然后将数据写入到连接内，服务端收到调用，执行相应的程序返回。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:3:4","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#代码结构"},{"categories":["sys"],"content":"gRPCgRPC的使用分为三部: 将需要在网络中传递的数据/服务定义在.proto里 利用protocol buffer compiler基于上面的.proto生成代码 使用gRPC的API ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:0","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#grpc"},{"categories":["sys"],"content":"安装依赖 grpc go get google.golang.org/grpc go get -u github.com/golang/protobuf/protoc-gen-go export PATH=$PATH:$GOPATH/bin protocol buffer compiler(protoc) PROTOC_ZIP=protoc-3.7.1-linux-x86_64.zip curl -OL https://github.com/protocolbuffers/protobuf/releases/download/v3.7.1/$PROTOC_ZIP sudo unzip -o $PROTOC_ZIP -d /usr/local bin/protoc sudo unzip -o $PROTOC_ZIP -d /usr/local 'include/*' rm -f $PROTOC_ZIP ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:1","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#安装依赖"},{"categories":["sys"],"content":"定义自己的proto kv.proto syntax = \"proto3\"; package kv; service kv { rpc Put (PutArgs) returns (PutReply) {} rpc Get (GetArgs) returns (GetReply) {} } message PutArgs { string key = 1; string value = 2; } message PutReply { string ok = 1; } message GetArgs { string key = 1; } message GetReply { string ok = 1; string value = 2; } syntax为protobuf编码版本，message类似于类型定义关键字，而每一个message内都需要有一个单独的值来指定某个变量。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:2","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#定义自己的proto"},{"categories":["sys"],"content":"生成 .pb.go例如如下的代码结构： store : ~/gokv/grpc/src \u003e tree . . ├── kv │ ├── kv.proto store : ~/gokv/grpc/src \u003e echo $GOPATH /root/go:/root/gokv/grpc 执行 protoc -I kv/ kv/kv.proto --go_out=plugins=grpc:kv 在kv目录下生成kv.pb.go，然后在外部利用import kv即可使用kv.pb.go中生成的代码。 kv.pb.go包含了如下内容： 生成的服务端和客户端的代码 对调用参数进行序列化、反序列化的代码 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:3","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#生成-pbgo"},{"categories":["sys"],"content":"写自己的KV服务和上面原生RPC的类似： 服务端代码 package main import ( \"context\" \"log\" \"net\" \"sync\" \"google.golang.org/grpc\" pb \"kv\" ) const ( port = \":1234\" ) // server is used to implement kv.Kvserver. type server struct { data map[string] string mu sync.Mutex pb.UnimplementedKvServer } // Put implements implement kv.Kvserver func (s *server) Put(ctx context.Context, in *pb.PutArgs) (*pb.PutReply, error) { log.Printf(\"Received Put: %v\", in) s.mu.Lock() defer s.mu.Unlock() s.data[in.Key] = in.Value return \u0026pb.PutReply{Ok: \"Ok\"}, nil } func (s *server) Get(ctx context.Context, in *pb.GetArgs) (*pb.GetReply, error) { log.Printf(\"Received Get: %v\", in) s.mu.Lock() defer s.mu.Unlock() value := s.data[in.Key] return \u0026pb.GetReply{Ok: \"Ok\", Value:value}, nil } func main() { log.Printf(\"server start\\n\") lis, err := net.Listen(\"tcp\", port) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } rpcs := grpc.NewServer() srv := new(server) srv.data = map[string]string{} pb.RegisterKvServer(rpcs, srv) log.Printf(\"Listen at %s\\n\", port) if err := rpcs.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } 客户端代码 package main import ( \"context\" \"log\" \"time\" \"google.golang.org/grpc\" pb \"kv\" ) const ( address = \"fatwaer.store:1234\" ) func main() { // set-up connection. conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(\"didn't connect: %v\", err) } defer conn.Close() c := pb.NewKvClient(conn) log.Printf(\"connect ok\") ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.Put(ctx, \u0026pb.PutArgs{Key: \"Hello\", Value: \"World\"}) if err != nil { log.Fatalf(\"put err %v\", err) } log.Printf(\"put %s\", r.GetOk()) nr, err := c.Get(ctx, \u0026pb.GetArgs{Key: \"Hello\"}) if err != nil { log.Fatalf(\"put err %v\", err) } log.Printf(\"get %s, get value %s\", nr.GetOk(), nr.GetValue()) } ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:4","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#写自己的kv服务"},{"categories":["sys"],"content":"运行结果和原生RPC使用很类似，但是中间加了一层protobuf的使用问题，而protobuf的存在却可以解决在多语言之间进行通信的问题，而原生不行。 ","date":"2020-02-26","objectID":"/rpc-and-grpc/:4:5","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#运行结果-1"},{"categories":["sys"],"content":"参考资料 《数据密集型应用系统设计》 https://pdos.csail.mit.edu/6.824/notes/kv.go https://pdos.csail.mit.edu/6.824/notes/l-rpc.txt https://developers.google.com/protocol-buffers/docs/overview https://developers.google.com/protocol-buffers/docs/proto https://grpc.io/docs/tutorials/basic/go/ http://google.github.io/proto-lens/installing-protoc.html ","date":"2020-02-26","objectID":"/rpc-and-grpc/:5:0","series":null,"tags":["distributed system"],"title":"Golang原生RPC与gPRC","uri":"/rpc-and-grpc/#参考资料"},{"categories":["language"],"content":"前言这篇笔记主要是说明一些bash scripts中要注意的问题，比如变量的赋值，函数，Shebang，特殊变量，通配符等；以及介绍一些提高在shell环境下提高工作效率的工具，例如查看使用方法的时候，可以快速翻阅 TLDR 获取命令的用法，而不用使用 man 手册慢慢地找相关的参数等。 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:0","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#前言"},{"categories":["language"],"content":"基本变量赋值变量通过 foo=bar 来完成，并且带空格的 foo = bar 不会成功，因为相当于直接连续调用 foo 、 = 、 bar 三个命令，另外双引号 \" 会展开变量而单引号不会 ' 。 foo=bar echo \"$foo\" # prints bar echo '$foo' # prints $foo ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:1","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#基本变量"},{"categories":["language"],"content":"函数mcd.sh mcd () { mkdir -p \"$1\" cd \"$1\" } Here $1 is the first argument to the script/function $0 - Name of the script $1 to $9 - Arguments to the script. $1 is the first argument and so on. $@ - All the arguments $# - Number of arguments $? - Return code of the previous command $$ - Process Identification number for the current script !! - Entire last command, including arguments. A common pattern is to 更多参数相关 Special Characters ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:2","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#函数"},{"categories":["language"],"content":"加载函数source mcd.sh mcd test 利用source读取函数后可以把.sh中的函数加载到shell环境中，于是可以直接使用函数名作为命令来执行，这里产生一个test文件并且进入到test目录中。 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:3","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#加载函数"},{"categories":["language"],"content":"条件截断类似于其他编程语言的函数截断，一般用于测试上一条命令的执行结果。 false || echo \"Oops, fail\" # Oops, fail true || echo \"Will not be printed\" # true \u0026\u0026 echo \"Things went well\" # Things went well false \u0026\u0026 echo \"Will not be printed\" # false ; echo \"This will always run\" # This will always run ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:4","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#条件截断"},{"categories":["language"],"content":"命令替代当在shell使用 $(CMD) 后，CMD命令将会被执行，并且会将这条命令的输出给替换掉。例如 for file in $(ls)先会调用ls，然后变量所有ls所输出的文件名。 另外一个很少被人知道的特性叫做 过程替代(process substitution), \u003c( CMD ) 将会执行CMD指令，并且把输出放到一个临时文件内，然后把\u003c()替换为这个临时文件的名字。例如 diff \u003c(ls foo) \u003c(ls bar) 将会显示 foo 和 bar 两个目录内的不同 #!/bin/bash echo \"Starting program at $(date)\" # Date will be substituted echo \"Running program $0with $#arguments with pid $$\" for file in $@; do grep foobar $file \u003e /dev/null 2\u003e /dev/null # When pattern is not found, grep has exit status 1 # We redirect STDOUT and STDERR to a null register since we do not care about them if [[ $? -ne 0 ]]; then echo \"File $filedoes not have any foobar, adding one\" echo \"# foobar\" \u003e\u003e \"$file\" fi done 这个脚本所完成的事情是：在所有参数文件中，如果没有文件内没有grep到foobar这个字符串，那么就会输出 File $file does not have any foobar, adding one 输出到标准输出，然后追加 # foobar\" \u003e\u003e \"$file 到 $file 的结尾。 其中： $# 代表该脚本执行使用的PID， $@ 所有参数，不包括$0。 $? 代表grep指令的运行结果，如果没有匹配到会输出不等于0的值。 \u003e /dev/null 即 1 \u003e /dev/null将标准输出指向null， 2 \u003e /dev/null 将标准错误输出指向null。 if 判断中的逻辑词和其他编程语言有些区别，具体可以看 http://man7.org/linux/man-pages/man1/test.1.html []和[[]] 的区别: http://mywiki.wooledge.org/BashFAQ/031 [ (“test” command) and [[ (“new test” command) are used to evaluate expressions. [[ works only in Bash, Zsh and the Korn shell, and is more powerful; [ and test are available in POSIX shells. 一般来说使用 [[]] 这种形式犯错的机会更少。 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:5","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#命令替代"},{"categories":["language"],"content":"shell globbing一共分为两类： 通配符(Wildcards)： ? 和 * 给定文件 foo, foo1, foo2, foo10, bar， rm foo? 会删除foo1和foo2， rm foo* 将会删除除了bar的所有文件。 Curly braces {} convert image.{png,jpg} # Will expand to convert image.png image.jpg cp /path/to/project/{foo,bar,baz}.sh /newpath # Will expand to cp /path/to/project/foo.sh /path/to/project/bar.sh /path/to/project/baz.sh /newpath # Globbing techniques can also be combined mv *{.py,.sh} folder # Will move all *.py and *.sh files mkdir foo bar # This creates files foo/a, foo/b, ... foo/h, bar/a, bar/b, ... bar/h touch {foo,bar}/{a..j} touch foo/x bar/y # Show differences between files in foo and bar diff \u003c(ls foo) \u003c(ls bar) # Outputs # \u003c x # --- # \u003e y ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:6","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#shell-globbing"},{"categories":["language"],"content":"Shebang#!/usr/local/bin/python import sys for arg in reversed(sys.argv[1:]): print(arg) shell 知道使用python解释器而不是shell是因为写了一行叫做shebang的在脚本顶部。 但是由于不同机器的安装不一样，所以可以通过env来定位 #!/usr/bin/env python ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:7","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#shebang"},{"categories":["language"],"content":"函数与shell脚本的区别 函数的语言需要和shell的语言相同，需要写shebang，所以前面mcd在不同的系统上不能使用，脚本倒是可以使用任意语言（废话 函数会在定义式被读取的时候加载，脚本每次都会重新加载，函数比脚本稍微快点，但是每次修改都需要重新加载。 函数是在shell环境下执行，能修改环境变量，而脚本在其进程中执行，所以执行脚本并不能改变文件路径，可以通过 export 来设置脚本的环境变量 modularity, code reuse and clarity of shell code，shell 脚本里也会有自己的函数 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:1:8","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#函数与shell脚本的区别"},{"categories":["language"],"content":"命令行工具","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:0","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#命令行工具"},{"categories":["language"],"content":"shellcheck 安装 koalaman/shellcheck yum -y install epel-release yum install ShellCheck 使用 iZbp1237a4x521y1gkpax4Z : /tmp/missing \u003e shellcheck random.sh n=$(( RANDOM % 100 )) ^-- SC2034: n appears unused. Verify it or export it. In random.sh line 5: if [[ n -eq 42 ]]; then ^-- SC2130: -eq is for integer comparisons. Use = instead. ^-- SC2050: This expression is constant. Did you forget the $ on a variable?d 相当于shell脚本编译器，然后根据产生的错误到 shellcheck wiki找原因。 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:1","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#shellcheck"},{"categories":["language"],"content":"TLDR出去敲 -help 或者 man cmd 的方式查询使用，当仅仅只想知道某个命令怎么使用的时候，可以使用TLDR查询用法。 直接访问：https://tldr.ostera.io/xargs 或者去github下载相关客户端显示在命令行上：https://tldr.sh/ ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:2","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#tldr"},{"categories":["language"],"content":"文件搜索: find使用# Find all directories named src find . -name src -type d # Find all python files that have a folder named test in their path find . -path '**/test/**/*.py' -type f # Find all files modified in the last day find . -mtime -1 # Find all zip files with size in range 500k to 10M find . -size +500k -size -10M -name '*.tar.gz' ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:3","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#文件搜索-find使用"},{"categories":["language"],"content":"find后批量执行# Delete all files with .tmp extension find . -name '*.tmp' -exec rm {} \\; # Find all PNG files and convert them to JPG find . -name '*.png' -exec convert {} {.}.jpg \\; ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:4","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#find后批量执行"},{"categories":["language"],"content":"文件搜索: fdfd 是 find 的简化版本，人性化许多。 How to install fd on CentOS sharkdp/fd ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:5","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#文件搜索-fd"},{"categories":["language"],"content":"文件搜索: locatelocate也是一个用来找文件的命令，使用也比较简单。 iZbp1237a4x521y1gkpax4Z : ~ \u003e locate run.sh /run.sh /root/run.sh /root/.vim/plugged/YouCompleteMe/third_party/requests_deps/urllib3/_travis/run.sh /root/.vim/plugged/YouCompleteMe/third_party/ycmd/third_party/requests_deps/urllib3/_travis/run.sh /root/mc/run.sh /root/minecraft/run.sh /root/openssl/openssl-OpenSSL_1_1_1-stable/demos/certs/ocsprun.sh /root/ssr/shadowsocksr/logrun.sh iZbp1237a4x521y1gkpax4Z : ~ \u003e 但是locate有一些容易犯错的点，locate是通过unpdatedb来查询的，而updatedb通过crond进行更新，一般一天更新一次，所以有时候新下载下来的文件会出现找不到的情况，这时可以手动updatedb，即: $ updatedb $ locate file 像我的centos上并没有自带locate，安装为： $ yum -y install mlocate ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:6","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#文件搜索-locate"},{"categories":["language"],"content":"找代码: grep常用的例子还是得看 TLDR：https://tldr.ostera.io/grep，而自己最常用的还是 grep -rn 'content' * ， -r 用于递归， -n 用于打印行数。 另外还有ack, ag, rg等就不一一列举了。 ack: https://beyondgrep.com/ ag: https://github.com/ggreer/the_silver_searcher rg: https://github.com/BurntSushi/ripgrep ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:7","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#找代码-grep"},{"categories":["language"],"content":"找指令这里倒是很简单，利用 ctrl+r 可以在历史里反向搜索，以及简单的利用管道进行grep： history | grep cmd 。另外 fzf 在这里推荐使用一下，在必要的时候可能比较有用。 fzf：https://github.com/junegunn/fzf/wiki/Configuring-shell-key-bindings#ctrl-r 一些其他的shell，和bash不同，提供了基于历史的自动建议型shell，像 zsh 和 fish 内都提供有。如果在命令中敲入了一些以明文显示的敏感性文字的话，可以在.bash_history或者.zhistory中删除。 Tips: 自己的机器可以使用一些便捷的的工具，但如果需要管理多台服务器甚至是集群，linux提供的最基础的find等命令还是记清楚的好。 ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:8","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#找指令"},{"categories":["language"],"content":"目录导航命令行下查看目录确实没有那么直观，可以利用 ln -s 创建一个软连接快速选择，当然也有一些命令行下的工具： Fasd ranks files and directories by frecency fasd :https://github.com/clvv/fasd get an overview of a directory structure: tree: https://linux.die.net/man/1/tree broot: https://github.com/jarun/nnn full fledged file managers: nnn: https://github.com/jarun/nnn ranger: https://github.com/ranger/ranger ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:2:9","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#目录导航"},{"categories":["language"],"content":"练习 Read [man ls](http://man7.org/linux/man-pages/man1/ls.1.html) and write an ls command that lists files in the following manner Includes all files, including hidden files Sizes are listed in human readable format (e.g. 454M instead of 454279954) Files are ordered by recency Output is colorized ls -alth --color=auto Write bash functions marco and polo that do the following. Whenever you execute marco the current working directory should be saved in some manner, then when you execute polo, no matter what directory you are in, polo should cd you back to the directory where you executed marco. For ease of debugging you can write the code in a file marco.sh and (re)load the definitions to your shell by executing source marco.sh #!/bin/bash # marco.sh path=$(pwd) export MARCOPATH=$path } #!/bin/bash # polo.sh cd \"$MARCOPATH\" \u0026\u0026 echo \"cd error\" } Marco Polo →（马可·波罗) :) Say you have a command that fails rarely. In order to debug it you need to capture its output but it can be time consuming to get a failure run. Write a bash script that runs the following script until it fails and captures its standard output and error streams to files and prints everything at the end. Bonus points if you can also report how many runs it took for the script to fail. #!/bin/bash return_code=0 while [[ $return_code -eq 0 ]] do output=$(sh \"$1\" 2\u003e\u00261) return_code=$? cnt=$((cnt+1)) done cnt=$((cnt-1)) echo \"failed after ${cnt}th.\" echo \"output:\" echo \"$output\" As we covered in lecture find’s -exec can be very powerful for performing operations over the files we are searching for. However, what if we want to do something with all the files, like creating a zip file? As you have seen so far commands will take input from both arguments and STDIN. When piping commands, we are connecting STDOUT to STDIN, but some commands like tar take inputs from arguments. To bridge this disconnect there’s the [xargs](http://man7.org/linux/man-pages/man1/xargs.1.html) command which will execute a command using STDIN as arguments. For example ls | xargs rm will delete the files in the current directory. Your task is to write a command that recursively finds all HTML files in the folder and makes a zip with them. Note that your command should work even if the files have spaces (hint: check -d flag for xargs) find . -name *.html -type f | xargs tar cf target.tar ","date":"2020-02-13","objectID":"/shell-tools-and-scripting/:3:0","series":null,"tags":["shell","globbing"],"title":"Shell Tools and Scripting","uri":"/shell-tools-and-scripting/#练习"},{"categories":["sys"],"content":"强一致性Key/Value服务其实在写完Raft后，K/V的接口已经比较明显了，只需要将操作写入Raft entry的Command内，然后等待Raft的同步，再应用到状态机（例如map[string]string）即可，但是实际上在跑3A测试的时候还是出现了很多问题。 ","date":"2020-02-12","objectID":"/kv-server/:1:0","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#强一致性keyvalue服务"},{"categories":["sys"],"content":"并发(Concurrency)虽然保证同一个客户端同时只会发送一个Put或者Get请求，但是在面对多个客户端时，如何处理这些请求，并且将这些请求写入到Raft的log entry中。老生常谈的问题，但是在这里处理比较简单，在Raft开始协调一个新的共识(Agreement)的时候,也就是start()，已经使用了mutex来附加新的entry到log中。 ","date":"2020-02-12","objectID":"/kv-server/:1:1","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#并发concurrency"},{"categories":["sys"],"content":"网络不可靠(Unreliable)这里是在3A碰到的第一个要认真考虑的点，如果一个RPC请求（比如append “1”-\u003e“2”）经过了慢速网络而触发了重传，导致这个RPC被调用了两次，所以在Hint中有提醒，让client的每一个请求都有一个独一无二的ID来保证每个操作只能被执行一次。而如何使得每个操作只会被执行一次，并保证幂等性，还需要考虑到接下来的几个情况。 ","date":"2020-02-12","objectID":"/kv-server/:1:2","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#网络不可靠unreliable"},{"categories":["sys"],"content":"服务器主机崩溃(Crash)服务器主机崩溃的情景里要考虑的不是网络问题，而是当发生了主机崩溃，往往代表着新的一轮选举和新的leader诞生。所以当真正发生leader切换的时候，客户端需要做的事情是将当前的RPC重新发往新的leader。另外一点是持久化问题，这个会在快照机制中遇到一些需要思考的点。 ","date":"2020-02-12","objectID":"/kv-server/:1:3","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#服务器主机崩溃crash"},{"categories":["sys"],"content":"网络分区(Partition)由于是实现一个强一致性的KV服务，在并发条件下，每一个Get/Put/Append操作都会被按顺序执行一次，而每次调用都需要监控之前的操作序列所做的操作所带来的影响，就好像在调用前，前面的所有的调用已经完成，通常称其为线性化。 最先碰到网络分区和检查一致性是TestOnePartition3A，这个测试中做了如下几件事情： 创建一个5个server的kv服务器集群 客户端请求: Put:1 -\u003e 13 建立网络分区，3台主机处于大多数(majority)，另外两台主机(保证有一台是leader)处于少数(minority)。 往majority中提交Put:1-\u003e14 检查majority 往minority中提交操作Put:1 -\u003e 15和Get:1 检测6中两个操作是否会成功 往majority提交Put:1-\u003e16并检查 合并两个分区，检查最后Key 1的值。 最后的值应该为15，在这里碰到的一致性检查是关于第六步Get操作，从Raft可以知道在minority中提交的操作是不会被commit的，更不会被应用到状态机，此时minority中的key 1的值是13，相比于majority中的14，是一个过期的值，所以6步中的Get RPC在分区合并前不应该返回。 当分区合并后，minority的leader会被majority中的新leader的心跳设置为follower，所以旧leader的kv服务应该检测到自己不再是leader而返回现存的RPC：Put:1 -\u003e 15和Get:1，使客户端重定向到新的leader。 而Get什么时候返回？这个在Hint中也提到了，最方便的做法就是将Get也塞入raft的log entry内，在这种情境下，处于minority分区的Get操作就会被读取到过期的数据。 ","date":"2020-02-12","objectID":"/kv-server/:1:4","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#网络分区partition"},{"categories":["sys"],"content":"标识操作(UniqueID)如何为每一个操作定独一无二ID？我的做法是每个操作维护三个变量以及新加一个RPC用于客户端注册： seriesN：每个客户端初始化为-1，每执行一次Get/Put/Append调用前自增1。 Client ID：初始化为-1，用于辨识客户端，由kv服务端来分配，客户端进行维护。 Server ID：代表分配Client ID的服务端，用于解决同一个操作因为leader切换而造成ID冲突。 每当启用一个新的客户端并且提交操作时，先自增seriesN，如果Client ID为-1，就会向服务端注册自己，即请求一个可用的Client ID，并设置Server ID。每当一个操作在raft中达成共识时，应用到状态机后，应该记录Cid和Sid的最大值，用于防止重复的操作被提交到状态机。 当出现小于当前seriesN的操作出现时，需要返回一个duplicate的错误告知客户端。 考虑下面这种情景： s1 | x = 0 | x += 1 同步到其他server s2 | x = 0 | x += 1 s3 | x = 0 | x += 1 s4 | x = 0 | x += 1 s5 | x = 0 | nil leader s1 提交了一个 x += 1 的操作后，并同步到了s2, s3, s4，然后发生分区。 s2 当选新一轮的leader，并同步完成 s1 恢复到该分区中，被s2的心跳转变为follower client对s1的rpc被返回，重定向到s2，重复的op被提交。 这里也可以通过比较相同clinetID的seriesN来决定是否应用到状态机，但是如果第一步中，x += 1 并没有提交到s1以外的服务器，s2服务器当选leader后先为另一个client分配了相同的client ID，在分区合并前提交过几次操作，那么 x += 1的操作将会被驳回，所以这里需要server ID处理命名空间的冲突。 既然服务端要分配client ID，那么如何记住这些id以应对服务器崩溃，比较简单的办法是分配一个client ID后就做一次持久化，因为真正进行提交操作的client并不是很多也并不频繁。另外一种方法是根据raft的applyMsg会带有Sid，Cid，SeriesN三者，所以当服务crash后重启时，会随着一致性检查恢复之前自己已经分配过的Cid。 Part A内容的大致就是这些，还剩一些优化的细节，比如client在找到server后就记住server的索引，没必要每次都向集群所有服务器发送请求。关于RPC，配置到服务器上时，没必要为每次RPC都新建一次连接，应该维护住这个连接直到主动断开或者发生错误。 ","date":"2020-02-12","objectID":"/kv-server/:1:5","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#标识操作uniqueid"},{"categories":["sys"],"content":"快照(Snapshot)快照机制主要作用是两点: 一是压缩日志，实际系统中，日志不能在内存中无限增长，如果没有相关机制清理陈旧的信息，那么会产生可用性的问题。日志压缩除了利用快照机制外，在Raft论文中还有提到了利用LSM-Tree对Raft的日志进行增量压缩的方法，由于保证日志的增长是顺序的，在这里利用日志结构树能承受住更高的I/O吞吐量。 第二点是在写Lab中发现的，拥有快照机制的Raft能够更快地使落后的(发生了崩溃或者网络分区)follower恢复到同步水平。 ","date":"2020-02-12","objectID":"/kv-server/:2:0","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#快照snapshot"},{"categories":["sys"],"content":"Snapshot要做什么快照所做的事情也比较简单，主要针对的是那些已经提交过的条目(即在大多是中达成共识)进行压缩，让这些条目所应用后的状态有一个备份，然后再将这些进行截断即可。因为没有必要每应用一个条目就执行一次快照，所以在应用到状态机后，可以设置一个阈值与当前在内存中的raft log进行比较，当超过这个阈值后执行日志压缩，这也就是3b主要需要做的事情。 3B部分最难处理也就是如何进行日志截断、什么时候进行日志截断、截断后需要重新设置哪些值，在想好这三个问题后动手会减少大量的debug工作。 ","date":"2020-02-12","objectID":"/kv-server/:2:1","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#snapshot要做什么"},{"categories":["sys"],"content":"什么时候进行截断截断的时间是发生在应用到状态机后检测到raft log的大小已经增长超过了阈值，于是kv服务将自己的状态map[string]string进行保存，随着logIndex一起递交给自己的raft，raft根据index获取到最后条目的term，进行持久化，然后截断自己的日志。 ","date":"2020-02-12","objectID":"/kv-server/:2:2","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#什么时候进行截断"},{"categories":["sys"],"content":"如何进行日志截断截断首先要考虑到截断后对其他操作的影响： raft负责发送appendEntry的操作，对于落后的机器可能会读取到陈旧的条目 raft收到appendEntry，常常发生于旧leader对最新的服务器(leader和follower)发送的心跳 raft收到InstallSnapshot后，会有log的截断操作 InstallSnapshot RPC: 6. If existing log entry has same index and term as snapshot’s last included entry, retain log entries following it and reply 这些操作本质上都是数组下标界限的问题，需要根据实际逻辑进行判断。 另外一点就是关于Golang的切片内存模型，因为在这里raft log是以切片进行保存，所以类似于arr[beg:end]的操作只是移动指向底层的指针和长度，所以这里得需要新分配一个切片给rf.log。 ","date":"2020-02-12","objectID":"/kv-server/:2:3","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#如何进行日志截断"},{"categories":["sys"],"content":"截断后需要重新设置哪些值首先是在论文里的LastIncludeIndex和LastIncludeTerm，这两个变量可以维护在raft的状态里，以免每次都需要进行一次I/O读取这两个变量。因为需要维护这两个变量，所以每当要读取和写入快照时都需要更新。 另外一对重要的值是commitIndex和applyIndex，根据raft论文: If commitIndex \u003e lastApplied: increment lastApplied, apply log[lastApplied] to state machine 这种情况在InstallSnapshot内要着重考虑，因为InstallSnapshot的LastIncludeIndex会大于当前的commitIndex，当某台follower还在apply到状态机的时候，收到了快照，需要做的事情是，应用完上一个快照后，检查自己的applyIndex和commitIndex。而在InstallSnapshot内需要做的事情除了设置LastIncludeIndex和LastIncludeTerm，还同时提高applyIndex和commitIndex。 中断的之前的apply过程并不会导致不一致，在安装完快照后，需要重置kv的状态机，所以不用担心同步问题。 ","date":"2020-02-12","objectID":"/kv-server/:2:4","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#截断后需要重新设置哪些值"},{"categories":["sys"],"content":"快照与K/V服务3A部分中的kv服务是通过一致性检查后，一个一个地从0开始恢复状态，把以前的操作重新做一遍来恢复自己已分配掉的client ID，因为这个ID是会保存在raft的log中，对日志压缩也就会造成这些信息丢失，所以将当前已经分配掉的client ID写入到快照是有必要的。 ","date":"2020-02-12","objectID":"/kv-server/:2:5","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#快照与kv服务"},{"categories":["sys"],"content":"部署后的 K/V 服务 Server 1: state: http://fatwaer.store/kv/state.html log : http://fatwaer.store/kv/log.html Server 2: state: http://106.13.211.207/kv/state.html log : http://106.13.211.207/kv/log.html Server 3: state: http://18.162.39.157/kv/state.html log : http://18.162.39.157/kv/log.html ","date":"2020-02-12","objectID":"/kv-server/:3:0","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#部署后的-kv-服务"},{"categories":["sys"],"content":"参考资料 《数据密集型应用系统设计》 《Unix网络编程：卷1》 https://blog.golang.org/go-slices-usage-and-internals https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf ","date":"2020-02-12","objectID":"/kv-server/:4:0","series":null,"tags":null,"title":"6.824 Lab3 Fault-tolerant Key/Value Service","uri":"/kv-server/#参考资料"},{"categories":["sys"],"content":"80386 下的保护模式划为5个部分： 类型检查 界限检查 可寻址域的限制 过程调用的限制 指令集的限制 事实上按照段页机制又需要分为段机制下的保护和页机制下的保护。 ","date":"2019-11-11","objectID":"/protection/:0:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#"},{"categories":["sys"],"content":"段级别的保护段描述符中存储了保护参数，当段描述符到段寄存器中和访问相应的段时，CPU 会自动启用保护机制进行检测。 段描述符格式 上图中一共有三种段，除了常被应用程序使用的数据段和可执行段外，还有一种用作门（gate）的描述符。 当段寄存器加载一个段的时候，不仅仅只是加载了段的基地址，还会加载其他的保护机制所需要用到的信息。在段寄存器的不可见部分存储了段基地址，界限，特权等级，所以在保护机制在检查合法性时没有额外的时钟周期损耗。 ","date":"2019-11-11","objectID":"/protection/:0:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#段级别的保护"},{"categories":["sys"],"content":"段机制的类型检查描述符中的 TYPE 域用来区分不同描述符的格式和描述符的作用。 在数据段的 writable bit 代表正在执行的指令可否写入到该段。 代码段中的 readable bit 代表正在执行的指令能否读取该段中的数据，例如操作数为常量的情况。 一个可读可执行的段可以被两种形式加载： 通过 CS 寄存器，例如 ljmp cs:addr 加载到通用段寄存器中 类型检查会在两种情况下进行： 当描述符被加载到到段寄存器时，相应的段寄存器只能加载对应的描述符种类，例如： CS 寄存器只能加载可执行的段 不可读但是可执行的段不能被加载到数据段寄存器中 只有科协的数据段能被加载到SS寄存器 当指令显式或者隐式地引用段寄存器，相应的段只能被预先定义好的方式来使用，例如： 不能尝试往可执行的段中写入 不能往w位未置位的数据段中写入 不能读取r位未置位的可执行段（数据段默认可读） ","date":"2019-11-11","objectID":"/protection/:1:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#段机制的类型检查"},{"categories":["sys"],"content":"段机制的界限检查故名思意，界限（limit）域在描述符中被处理器阻止程序寻址到超出段界限外的地方，与段界限相关的还有 G (granularity) bit，对于数据段，还有 E-bit (expansion-direction bit) 和 the B-bit (big bit)。 bit 组合 除去 expand-down 类型的数据段，下列这些情况会产生一般保护错误（general-protection exception）： 尝试访问1字节的地址，地址大于界限 尝试访问1字的地址，地址大于等于界限 尝试访问2字的地址，地址大于等于界限值-2 界限的检查能捕获一些程序的运行错误例如非法的指针计算。这些错误会在刚刚发生时被检测到，所以检测这些错误更加简单，如果没有这个机制，这些错误可能会影响到其他的部件，到那时候再去追踪就难多了。 ","date":"2019-11-11","objectID":"/protection/:2:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#段机制的界限检查"},{"categories":["sys"],"content":"特权等级特权等级分为四级，但是基本只会用到两级，最高特权级别 ring 0和最低的特权级别 ring 3。 特权等级在以下这些地方展现： CPL(Current privilege level): CPL 代表当前正在运行的程序或者任务的权限等级，存储在CS或者SS段寄存器的第0和1位。通常CPL和当前运行的代码段的等级相同，当CPL发生改变时，代表程序在不同特权等级之间的控制转移。 但是当代码段描述符的 conforming 位置位时，情况有所不同，conforming 置位的代码段能被特权等级与其相等或者更低权限的任务所访问，并且，在执行 conforming 置位的代码时，CPL不会发生改变，所以通常 conforming 代码段用于低权限任务需要执行数学函数或者异常处理函数等情况。 DPL(descriptor privilege level): 在段描述符或者门描述符中存在一个域用于表明这个描述符的特权等级，当正在执行的代码段尝试去访问一个段或者门时，CPL和RPL就会与DPL进行比较，DPL根据段或门的类型不同会有不同的解释方法： 数据段：DPL代表可以访问该段的最低权限，比如数据段的DPL位1，仅只有程序运行在CPL为0或1时才能访问该段。 非 conforming 的代码段（不使用 call gate）：DPL代表程序必须运行在的特权等级（即使特权等级大于DPL也不行） Call gate：DPL代表可以访问该段的最低权限，同数据段 使用call gate 访问代码段：DPL代表可以访问该段的最高权限，比如某个代码段的DPL为2，运行在特权等级 0 或者 1 的程序无法访问。 TSS：DPL代表可以访问该段的最低权限，同数据段 RPL(Requested privilege level): RPL 是存储在段选择子第0 和 1 位，处理器在检查特权等级时会同时检查 CPL 和 RPL。即使程序运行的特权等级 (CPL) 已经满足了相应段的特权等级 (DPL)，如果 RPL 不能满足 DPL 的话，访问段的操作仍然会被拒绝。这意味着，如果 RPL 树枝上大于 CPL，那么RPL将会作为尝试去访问相应段的特权等级，反之亦然。RPL 可以被保证 特权代码不会代表应用程序去访问一个该应用程序并没有权限的段。 关于 RPL 的作用在 Intel® 64 Developer’s Manual : 4.10.4 Checking Caller Access Privileges (ARPL Instruction) 里面有几个例子进行说明。 当一个应用程序过程(the calling procedure)调用操作系统 的一个过程(the called procedure)时，在执行操作系统过程中会将特权等级设置为应用程序的段选择子的 RPL。当操作系统尝试去访问相关的段时，处理器会对 RPL 而不是特权等级值更低的 CPL（此时为0）进行特权等级检查。 在上图中，应用程序正运行在代码段A中，处理数据段D1中的数据，此时在数据段D1中指向了一个特权数据结构（在数据段D中的操作系统数据结构，数据段的 DPL 为0）。因为 CPL 的值大于特权等级值，权限不足以访问。 为了访问到数据段 D，应用程序执行了一个调用，并且通过栈传递了段选择子 D1（存在RPL） 到操作系统。在传递段选择子前，应用程序会将段选择子设置为当前的 CPL （SS或者CS中）。当通过门 C （运行在特权等级0）利用段选择子 D1 （栈上的值）访问数据段 D时，由于D1的RPL要大于DPL，访问数据段 D 的操作被拒绝。 该部分后面还有一种情况，通过门调用时，由于应用程序可以修改栈上的段选择器中的 RPL 值（对应图中数据段D2），这会导致保护机制被破坏，于是有了 ARPL 指令对栈上的 RPL 和调用此操作系统过程的程序的 CPL 进行比较。 ","date":"2019-11-11","objectID":"/protection/:2:1","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#特权等级"},{"categories":["sys"],"content":"段机制的数据的访问限制为了访问到在内存中的操作数，程序必须将数据段加载到数据段(DS, ES, FS, GS, SS)寄存器中。处理器会在访问数据段时自动比较特权等级。 数据段寄存器能加载一个数据段的前提是DPL大于RPL和CPL。 ","date":"2019-11-11","objectID":"/protection/:3:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#段机制的数据的访问限制"},{"categories":["sys"],"content":"段机制的控制转移限制控制转移往往伴随着JMP, CALL, RET, INT, IRET指令以及中断和异常机制。在同一个代码段的JMP, CALL, RET仅仅只有段界限检查。远距离的调用或者跳转会引用到其他段，因此，处理器会进行特权检查。 例如：ljmp $0x8,$0x7c32，$0x8为段寄存器值。 JMP 或者 CALL 会通过两种方式引用另外一个段： 操作数中存在另一个可执行的代码段描述符 操作数中有一个调用门描述符 一般情况下，处理器正在运行的代码段的 DPL 和 CPL 相等，但是如果代码段的 conforming 位置位时，CPL 可能大于 DPL。所以只有当 DPL 和 CPL 相等时或者代码段的conforming 位置位并且 DPL 小于等于 CPL 时，JMP和CALL能够直接从原先的代码段跳转到另一个代码段。 代码段的检查 ","date":"2019-11-11","objectID":"/protection/:4:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#段机制的控制转移限制"},{"categories":["sys"],"content":"门限描述符对过程调用的保护一共有4中描述符用于在不同特权等级间进行跳转： call gate Trap gates Interrupt gates Task gates call gate 和普通描述符一样，定义在GDT或者LDT中，它定义了一个过程调用的入口和调用该过程所需要的特权等级。call gate描述符对于jmp和call指令来说和代码段的处理方式一样。 call gate selector 和 offset 域能形成一个到调用过程入口的指针，call gate 保证能跳转到另一个段的合法地址，而不是跳转到一个过程调用的中间或者….一条指令的中间。一条指令的控制转移的偏移地址不会在call gate跳转中使用（前面那种跳转到中途的情况）。 执行指令时，首先通过操作数中的段选择器得到门限描述符的偏移，在门限描述符中的 selector 字段获得目标调用过程的代码段描述符，执行过程调用，在这过程中，一共涉及到4个特权等级，CPL，RPL，门限的 DPL 和目标代码段的 DPL。 通过 gate 可以实现不同特权等级的转移，但是只有通过 call 指令能切换到更低的特权等级上，而 jmp 指令只能在同特权等级之间跳转（不考虑comforming 代码段）。 对于 jmp 指令，要求： MAX (CPL,RPL) \u003c= gate DPL target segment DPL = CPL 对于 call 指令或者 jmp 目的代码段为 comforming： MAX (CPL,RPL) \u003c= gate DPL target segment DPL \u003c= CPL ","date":"2019-11-11","objectID":"/protection/:4:1","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#门限描述符对过程调用的保护"},{"categories":["sys"],"content":"栈切换为了维护系统的整体性，任意特权等级拥有各自独立的栈，处理器通过TSS（task state segment）定位这些不同特权等级的栈。比如通过call gate切换特权等级时，新的栈指针将会从tss中读取出来。 TSS 处理器会利用目标代码段的DPL找到对应特权等级（PL 0，1，2）的栈，并且 DPL 必须与 CPL 相等。TSS 中没有对应特权等级为3的栈，因为特权等级3的过程不能被其他任意低于其特权等级的过程调用。每个栈都必须有足够的空间去存储 ss:esp，返回地址，参数等。 为了在不同特权等级之间调用过程，处理器必须将调用者的参数从旧的栈帧中拷贝到新特权等级的栈帧中去。call gate 描述符中的 count 字段代表多少双字（doublewords）需要拷贝，如果count为0，拷贝就不会发生。 切换特权等级的栈切换： 新栈检查是否有足够的空间容纳参数等，否则产生一个栈错误，错误代码设置为0. 将旧栈SS:ESP压入新栈（占用两个双字） 复制剩下的参数 调用者的call的下一条指令地址以 CS:EIP 压入新栈 将新的 SS:ESP 指向新栈栈顶 ","date":"2019-11-11","objectID":"/protection/:4:2","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#栈切换"},{"categories":["sys"],"content":"从过程调用中返回（ret）和 call 指令类似，同一个代码段之间的 ret 只有界限检查。对于段间的 ret，首先会弹出由 call 压入的返回地址，通常情况下时合法的，但是也有可能由于调用过程替换掉了这个地址或者没有很好地维护栈，这个返回地址也是不可信的，所以权限检查还是会有的。 段之间的 ret 只能返回到与其相等或者更高特权值的等级去，当栈上保存的 CS 中的 RPL 大于当前的 CPL 时，特权等级间的控制转移就会发生： 检查下表中的内容，加载栈上的 CS:EIP 和 SS:ESP 到相应寄存器。 原先的栈指针会被 ret 指令做相应的调整，此时 esp 的值不会进行界限检查，如果 esp 实在超出了界限，那么下次对栈的操作将会产生错误。 基础段寄存器的特权值将会被检查，如果这些段寄存器引用了那些 DPL 大于新 CPL（栈上保存的CS得到） 的段，那么段寄存器就会加载 null selector，即 GDT 中的一个 null 描述符（INDEX = 0, TI = 0）。并且，此时不会产生异常，直到下次操作相应段内存时产生一般保护异常。 SF = Stack Fault GP = General Protection Exception NP = Segment-Not-Present Exception Type of Check Exception Error Code ESP is within current SS segment SF 0 ESP + 7 is within current SS segment SF 0 RPL of return CS is greater than CPL GP Return CS Return CS selector is not null GP Return CS Return CS segment is within descriptor table limit GP Return CS Return CS descriptor is a code segment GP Return CS Return CS segment is present NP Return CS DPL of return nonconforming code segment = RPL of return CS, or DPL of return conforming code segment \u003c= RPL of return CS GP Return CS ESP + N + 15 is within SS segment N Immediate Operand of RET N Instruction SF Return SS SS selector at ESP + N + 12 is not null GP Return SS SS selector at ESP + N + 12 is within descriptor table limit GP Return SS SS descriptor is writable data segment GP Return SS SS segment is present SF Return SS Saved SS segment DPL = RPL of saved CS GP Return SS Saved SS selector RPL = Saved SS segment DPL GP Return SS ","date":"2019-11-11","objectID":"/protection/:4:3","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#从过程调用中返回ret"},{"categories":["sys"],"content":"指令集的限制影响到保护机制的指令分为两类，特权指令，通常被用于系统控制；敏感指令，通常被用作 IO或者 IO相关的操作。 特权指令如下： CLTS -- Clear Task-Switched Flag HLT -- Halt Processor LGDT -- Load GDL Register LIDT -- Load IDT Register LLDT -- Load LDT Register LMSW -- Load Machine Status Word LTR -- Load Task Register MOV to/from CRn -- Move to Control Register n MOV to /from DRn -- Move to Debug Register n MOV to/from TRn -- Move to Test Register n ","date":"2019-11-11","objectID":"/protection/:5:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#指令集的限制"},{"categories":["sys"],"content":"页级别保护页级别的保护较为简单，分成有两种： 对可寻址的内存进行限制 类型检查 ","date":"2019-11-11","objectID":"/protection/:0:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#页级别保护"},{"categories":["sys"],"content":"页机制中的寻址限制 PDE/PTE 在页机制中，特权等级被分为了两级： Supervisor level (U/S=0) ：对应操作系统的软件和相关数据 User level (U/S=1)：对于应用程序级别的过程和数据 页机制中的特权等级和段机制中的 CPL 相关联，CPL 处于 ring 0,1,2 代表处理器执行在 supervisor level， CPL 处于 ring 3 代表执行在 user level。 当处理器执行在 user level ，只能寻址那些属于用户级别的页，如果处于 supervisor level ，那么处理器能够寻址所有的页。 ","date":"2019-11-11","objectID":"/protection/:1:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#页机制中的寻址限制"},{"categories":["sys"],"content":"页机制中的类型检查对于所有的页，定义了两种类型页，分别为只读的和可读可写类型的。当处于supervisor并且CR0寄存器中的WP位没有置位，所有的页都是可读可写的。而处于 user 级别，就需要对应读写位分情况讨论。处于 user 级别时，对于supervisor 的所有的页都是不可读写的。 参考资料： Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1 6.828 readings, Protection ","date":"2019-11-11","objectID":"/protection/:2:0","series":null,"tags":null,"title":"Protection Mechanism on 80386","uri":"/protection/#页机制中的类型检查"},{"categories":["env"],"content":" 将博客从 hexo 迁到了 hugo，主要原因是文章越来越多，hexo build速度就显得力不从心了，hexo 很多主题都不再维护，甚至很少有新的主题发布出来，而 hugo 相反，随着golang热度的上涨，社区也很活跃，其主题的更新在官网可以看出来相对频繁。我目前使用的主题是由zzossig 提供的Zzo主题。 ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:0:0","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#"},{"categories":["env"],"content":"Hugo 总览看到比较合适的主题，有需要自己定制的话，可以简单过一遍Hugo的一个官方教程(大概3-4小时)： https://www.youtube.com/watch?v=qtIqKaDlqXo\u0026list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3 ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:1:0","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#hugo-总览"},{"categories":["env"],"content":"Hugo 的安装和环境配置Hugo 提供了较为详细的官方教程，安装过程非常详细，如果是在windows上安装，可以下载二进制文件到任意目录下，并且将改目录添加到PATH环境变量即可。 ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:1:1","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#hugo-的安装和环境配置"},{"categories":["env"],"content":"Hugo 的基本使用将hugo的环境搭建完成后博客根目录进行初始化： hugo version mkdir Sites cd Sites hugo new site sitename 然后需要去主题页找一个合适的主题，并且下载到Sites/sitename/themes目录，或者在Sites/sitename目录下执行： git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 然后将配置文件中的主题设置为下载到themes目录中的主题文件夹名字： echo 'theme = \"ananke\"' \u003e\u003e config.toml 像hexo一样，hugo提供了本地预览的功能，在 Sites/sitename目录下运行，然后就可以访问localhost:1313来访问博客了： $ hugo server Building sites … | EN | KO -------------------+-----+------ Pages | 54 | 10 Paginator pages | 3 | 0 Non-page files | 0 | 0 Static files | 209 | 209 Processed images | 0 | 0 Aliases | 11 | 1 Sitemaps | 2 | 1 Cleaned | 0 | 0 Built in 5641 ms Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at //localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:1:2","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#hugo-的基本使用"},{"categories":["env"],"content":"Hugo 与 Github如果单单运行hugo并且不添加仍和参数，hugo就会将博客的静态文件全部生成到sitename/public内，然后与githubname.github.io仓库进行关联，然后将代码推上去，就可以正常访问了。 ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:1:3","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#hugo-与-github"},{"categories":["env"],"content":"其他Hugo 静态生成主要由两个部分组成，一个是list template，用于生成类似于目录页的页面，另一个是single template，类似于每一篇博客展现内容的页面。这两个页面一般是被嵌入在一个叫baseof.html的模板中。 ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:1:4","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#其他"},{"categories":["env"],"content":"Markdown 图床最开始用微博+chrome插件， 后来微博开启了防盗链， 转移到了七牛+picGo https://www.cnblogs.com/Dozeer/p/10965508.html ","date":"2019-09-18","objectID":"/hugo%E9%85%8D%E7%BD%AE/:2:0","series":null,"tags":["config"],"title":"Hugo is comming !","uri":"/hugo%E9%85%8D%E7%BD%AE/#markdown-图床"},{"categories":["themes","syntax"],"content":"Sample article showcasing basic Markdown syntax and formatting for HTML elements.","date":"2019-03-11","objectID":"/markdown-syntax-guide/","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["themes","syntax"],"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme. ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:0:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#"},{"categories":["themes","syntax"],"content":"HeadingsThe following HTML \u003ch1\u003e—\u003ch6\u003e elements represent six levels of section headings. \u003ch1\u003e is the highest section level while \u003ch6\u003e is the lowest. ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#headings"},{"categories":["themes","syntax"],"content":"H1","date":"2019-03-11","objectID":"/markdown-syntax-guide/:0:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h1"},{"categories":["themes","syntax"],"content":"H2","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h2"},{"categories":["themes","syntax"],"content":"H3H4H5H6","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:1","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h3"},{"categories":["themes","syntax"],"content":"H3H4H5H6","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:1","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h4"},{"categories":["themes","syntax"],"content":"H3H4H5H6","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:1","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h5"},{"categories":["themes","syntax"],"content":"H3H4H5H6","date":"2019-03-11","objectID":"/markdown-syntax-guide/:1:1","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#h6"},{"categories":["themes","syntax"],"content":"ParagraphXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat. Itatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat. ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:2:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#paragraph"},{"categories":["themes","syntax"],"content":"BlockquotesThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations. Blockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote. Blockquote with attribution Don’t communicate by sharing memory, share memory by communicating. — Rob Pike1 ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:3:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#blockquotes"},{"categories":["themes","syntax"],"content":"BlockquotesThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations. Blockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote. Blockquote with attribution Don’t communicate by sharing memory, share memory by communicating. — Rob Pike1 ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:3:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#blockquote-without-attribution"},{"categories":["themes","syntax"],"content":"BlockquotesThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations. Blockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote. Blockquote with attribution Don’t communicate by sharing memory, share memory by communicating. — Rob Pike1 ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:3:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#blockquote-with-attribution"},{"categories":["themes","syntax"],"content":"TablesTables aren’t part of the core Markdown spec, but Hugo supports them out-of-the-box. Name Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:4:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#tables"},{"categories":["themes","syntax"],"content":"TablesTables aren’t part of the core Markdown spec, but Hugo supports them out-of-the-box. Name Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:4:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#inline-markdown-within-tables"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks\u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\" /\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block with backticks and language specified \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\" /\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003cmeta name=\"description\" content=\"Sample article showcasing basic Markdown syntax and formatting for HTML elements.\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block indented with four spaces\u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block with Hugo’s internal highlight shortcode\u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#code-blocks"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#inline-code"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#only-pre"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#code-block-with-backticks"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#code-block-with-backticks-and-language-specified"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#code-block-indented-with-four-spaces"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#code-block-with-hugos-internal-highlight-shortcode"},{"categories":["themes","syntax"],"content":"Code BlocksInline CodeThis is Inline Code Only pre This is pre text Code block with backticks Example HTML5 Document Test Code block with backticks and language specified Example HTML5 Document Test Code block indented with four spaces Example HTML5 Document Test Code block with Hugo’s internal highlight shortcode Example HTML5 Document Test Gist ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:5:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#gist"},{"categories":["themes","syntax"],"content":"List TypesOrdered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:6:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#list-types"},{"categories":["themes","syntax"],"content":"List TypesOrdered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:6:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#ordered-list"},{"categories":["themes","syntax"],"content":"List TypesOrdered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:6:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#unordered-list"},{"categories":["themes","syntax"],"content":"List TypesOrdered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:6:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#nested-list"},{"categories":["themes","syntax"],"content":"Other Elements — abbr, sub, sup, kbd, markGIF is a bitmap image format. H2O Xn + Yn = Zn Press CTRL+ALT+Delete to end the session. Most salamanders are nocturnal, and hunt for insects, worms, and other small creatures. The above quote is excerpted from Rob Pike’s talk during Gopherfest, November 18, 2015. ↩︎ ","date":"2019-03-11","objectID":"/markdown-syntax-guide/:7:0","series":["Themes Guide"],"tags":["markdown","css","html","themes"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/#other-elements--abbr-sub-sup-kbd-mark"},{"categories":["sys"],"content":"最近这段时间有一些空闲时间，可以开始做下6.824，目前是Spring 2018，最新的2019也快出了，提前刷下notes和paper。 分布式系统是关于多个计算机系统共同合作并且进行存储大量的网站数据，执行mapreduce，端对端共享的一种系统，大量的关键基础设施都是分布式的。 分布式系统的优点是能够组织物理上分离的实体，通过isolation取得系统安全，通过replication获取容错机制，通过并行CPUs/mem/disk/net来比例提升系统速度。 当然也有些缺点，这些过程中必须需要处理大量的并发部件，必须应对部分组件失效，以及很难获取一些潜在的性能。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:0:0","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#"},{"categories":["sys"],"content":"MapReduce(2004)input is divided into M files [diagram: maps generate rows of K-V pairs, reduces consume columns] Input1 -\u003e Map -\u003e a,1 b,1 c,1 Input2 -\u003e Map -\u003e b,1 Input3 -\u003e Map -\u003e a,1 c,1 | | | | | -\u003e Reduce -\u003e c,2 | -----\u003e Reduce -\u003e b,2 ---------\u003e Reduce -\u003e a,2 对于输入的文件，首先将其分为 M 个文件，对于每一个文件调用一个 Map()作为一次作业，每一个Map()调用产生一组 \u003ck2, v2\u003e键值对(图中的一行)作为中间数据。 MapReduce聚集键为 k2 的所有中间值，将其传输给Reduce()调用，并且以 \u003ck2, v3\u003e 的集合作为最终输出存入到Reduce的输出文件中。也就形成了最后的形式API形式： map(k1, v1) -\u003e list(k2, v2) reduce(k2, list(v2) -\u003e list(k2, v3)] MapReduce 隐藏了很多关键的细节，l如启动处于服务器上的软件，跟踪任务是否完成，数据的移动，从错误中恢复等。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:1:0","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#mapreduce2004"},{"categories":["sys"],"content":"MapReduce 过程Paper中共分为7个步骤： MapReduce将输入文件分成M份，并且开始在集群的机器上运行该程序的拷贝。 其中有该程序拷贝的Master节点会为集群中剩下的workers分配任务，其中有M份map任务和R份reduce工作，并且master将会为处于闲置状态的worker分配map或者reduce任务 worker被赋予了map任务将会从对应的input分片中读取内容，并且将从中解析出的k/v键值对传递到user-defined函数中。(这些由map()产生的k/v对被缓冲在内存中) 这些中间值将会被周期性的写到worker的本地磁盘，并且被partitioning function分成R份区域。这些被写到磁盘的键值对的位置将会被传回给master，并且可靠地将这些定位推进到reduce worker 当reduce worker被Master告知了这些键值对的定位，使用RPC读取这些在map worker本地磁盘缓冲的数据，当reduce worker读取到了所有的中间值，接下来会根据key值进行分组。 reduce worker将会遍历这些排序好的中间值，并且将遇到的每一个独一无二的key值，传递到user的Reduce function中，该函数的输出最后会附加到最终输出中去。 当所有map和reduce的任务完成后，master将会唤醒user program，此时 MapReduce调用已经返回到用户代码中。 其中 没有reduce worker会在map任务完成之前被调用。 中间值将只会在网络中出现一次，map从分布式文件系统中进行本地复制，执行Map然后写本地磁盘，通知Master通知reduce worker从该位置远程读取数据，然后写到reduce worker的本地磁盘。 根据以上的条件，有一种非常坏的情况就是N-1台服务器等待最后一台服务器完成任务，整个系统都在等待其完成任务。解决办法是使得任务数目要多余主机数，master需要递送新的任务给已经完成任务的workers,最后的结果是较快的servers会比较慢的servers完成更多的工作,但是绝对时间是相同的。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:1:1","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#mapreduce-过程"},{"categories":["sys"],"content":"容错处理 Map worker 崩溃 master多次ping崩溃的主机仍没有回应，并且Map的输出已经丢失了，但是后面的每一个reduce任务都需要该结果。如果reduce worker已经完全拉取了中间值，并且在reduce的过程中又发生了crash，则会强制执行失效map。 Reduce worker 崩溃 如果在worker上的任务已经完成则没有关系，因为已经存储到了分布式文件系统中了，如果是在执行过程中发生了崩溃，则在新的worker上启动未完成的工作。 Reduce 在输出结果集发生了崩溃 在reduce工作完成前是不可见的，整个reduce到输出文件都是保持原子性的，这保证master重新在其他地方执行任务。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:1:2","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#容错处理"},{"categories":["sys"],"content":"RPCClient: z = fn(x, y) Server: fn(x, y) { compute return z } RPC简单来说就是客户端通过tcp连接调用远程服务器中的函数并且获取值的一个过程，GoLang中自带了rpc库。如果rpc库调用失败，可能有几种情况，比如服务器根本没有收到这个请求，可能收到了请求并且执行了相关调用，但是崩溃在发送之前，或者在发送后该数据包迷失在了网络中。 最简单的方法模式的“尽最大努力交付”： 客户端调用rpc，并且等待 如果没有响应，则重传 重传多次无果，返回错误值 尽最大努力交付这种模式只适合一些多次操作不会进行写操作的调用，比如读操作，检查db记录是否被插入等等。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:2:0","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#rpc"},{"categories":["sys"],"content":"GFS(2003)GFS支持一些常见的文件操作，例如create, delete, open, close, read, write等，另外还有snapshot和record append的操作。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:3:0","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#gfs2003"},{"categories":["sys"],"content":"GFS的结构一个GFS集群由一个master节点和多个能被clients访问的chunkservers组成。通常是是一些商业linux机器运行着用户级别的服务器进程，并且可以让clients和chunkserver的进程运行在同一个机器上面。 文件被分成固定大小的chunksize(一般为64MB), 并且每一个chunk都在创建期间被master一个全局不可变的chunk handle，并且默认情况下，每一个chunk都有三份备份。 master负责维护整个系统的metadata，其中包括了命名空间，访问控制信息，文件到文件系统的映射信息，以及当前状态chunk服务器的位置，并且使用周期性的HeartBeat消息来给予指令或者收集chunk的状态。 client不会从master节点读写数据，取而代之的是获取chunkserver的信息，并且缓冲这些信息在一段时间内，并且进行接下来的系列操作。 GFS的读取操作: 首先，client将文件名和字节偏移转化为chunk索引，然后发送给master一个包含文件名和该索引的请求。master回复对应的chunk handle和各个备份的位置。client缓冲这些信息，以文件名和chunk index作为key值 然后，client发送请求到其中的一个备份去，一般选择最近的，这个请求中包含了chunk内偏移，然后chunk将数据回复给clients。 GFS的写操作： 客户端请求master获取一份持有lease的chunk server master回复主备份的节点id和其他备份的位置，client缓冲这些数据。并且在这些备份地址不可达的时候，重新请求master节点。 client推送数据到到所有的拷贝，并且chunkserver将会缓冲这些数据到基于LRU的缓冲区直到数据被使用或者超时。 一旦所欲的拷贝都回复确认收到了该数据，client将会发送写请求到主拷贝节点，主拷贝将会复制一串连续的数字给所接收到的数据变动，并且将这连续的数据变动应用到本地。 主拷贝将会向前推送写请求到所有的第二级拷贝，并且所有的拷贝对数据的变动与拷贝相同 第二级拷贝将会回复主拷贝已经完成了这个操作 主拷贝将会回复client，在变动过程中发生了任何错误都会回复给client。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:3:1","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#gfs的结构"},{"categories":["sys"],"content":"Raft(2014)推荐下这个视频，结合那篇paper一起看比较容易理解 https://www.youtube.com/watch?v=YbZ3zDzDnrw raft 协议主要是可理解性，相对于paxos来说简单了很多，raft也是提供了在非拜占庭错误(non-Byzantine fault)下一种新的并发模型。 当clients向其中一个sever提交一个操作的时候，该操作首先会被放入log中，然后使其他的servers也记录该操作，当大多数的机器正确回复了请求后，那么该操作就会被提交到该服务器的状态机，从而完成一个完整的操作，当多个操作开始执行的时候，都会以相同的顺序进行执行。 raft中所有的server在某一时刻会扮演三种角色中的一种： Leader：　处理client的交互，日志复制，并且同一时刻，只会有一个leader Follower：　完全处于被动状态，不会产生RPC，但是会回应即将到来的RPC Candidate：　将会被选举成一个新的leader 在raft协议中，时间被分为以term为单位的时间片段，term有如下的性质： 每一期被分为选举时间和普通操作时间。 每一期最多有一个leader 有些时期可能没有leader，之后提到的一些选举失败的情况中会出现。 每一个server中都会维护一个当前期数的值，用于server发生crash或者unreachable的时候 期数在raft中是个非常重要的概念，用于指示server中哪些数据已经过时了 Raft　大体上可以分成６个部分 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:0","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#raft2014"},{"categories":["sys"],"content":"1.Leader election 最开始的时候，所有的服务器在raft中以follower的角色启动 follower期待来自leader或者candidates的rpc leader必须发送心跳包(空的AppendEntries　RPC)来维护自己的权威性 如果electionTimeout到了并且没有接收到rpc，那么 follower将会假定leader崩溃了 follower开始新的选举 timeout的时长通常为100-500ms 选举的过程： 自增当前的期数 从follower改变至candidate状态 为自己投票 发送RequestVote RPC到其他服务器，如果没有收到回复，那么一直重传至： 接受到大多数的服务器的投票，那么该服务器变成leader并且发送心跳包到其他服务器 接收到来自合法leader的RPC，那么该服务器回到follower的状态 没有任何一个服务器赢得该轮选举，那么自增期数，开始新的一轮选举(splite vote　term的产生)，新开始的一轮的时期通常选为electionTimeout T~2T之间 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:1","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#1leader-election"},{"categories":["sys"],"content":"2.Normal operation每一个日志条目(log entry)由三个部分组成：index, term和command，并且都会存储在稳定的存储介质中，例如磁盘。 log的并发处理:　1. 如果在不同的服务器上面日志条目有相同的index和term，那么表示这些条目存储了相同的命令并且之前的条目也是准确的。2.　如果一个条目是被committed的，那么之前的所有条目也是被committed的 一个条目被称之为committed则说明这个条目已经被存储在了大多数的服务器上面，并且最终会在集群每个服务器的状态机上执行。 正常运行过程： client发送一个命令到leader leader将会把这个命令附加到其log上 leader发送AppendEntries RPC到follower 一旦一个新的entry是committed，那么代表: leader把这个命令应用到状态机上并且返回结果给client leader将会给已经提交该条目发送接下来的AppendEntries RPC follower把该命令提交到自己的状态机上面 每一个AppendEntries RPC会包含需要附加位置之前一个的index, term，如果不相符合，follower将会拒绝这个请求。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:2","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#2normal-operation"},{"categories":["sys"],"content":"3.leader changesleader发生改变最重要的一点是，leader的log总是对的，在follower中发生冲突的条目将会被删除。 在选举期间，candidate最有可能是包含了的最多已经committed条目的服务器，在RequestVote RPC中，包含了candidate最后一个条目的index和term，收到该请求的服务器将会与自己的最后期数进行对比，如果自己的期数等于candidate的期数或者期数相等但是自己的最后的索引大于candidate的索引，那么将会否决投票，这样就保证leader拥有最完整的log。 修复follower的log，新的leader必须使follower的log与自己的一致，删除那些不想管的条目并且填充缺少的条目，leader会为每一个follower保持一个nextIndex，初始值为(1 + leader’s last index)，当一个一个AppendEntries RPC失败了，对应的nextIndex将会进行递减并且重新尝试。如果follower覆盖了不一致的条目，那么follower将会删除接下来所有的条目。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:3","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#3leader-changes"},{"categories":["sys"],"content":"4.Neutralizing old leader假设出现这种情况，需要使得旧的leader无效： 暂时性地从网络中断开 剩下的其他服务器选举出一个新的leader 旧的leader重新连接到集群网络并且尝试去提交日志条目 terms用来检测过时的leader或者candidate，每个rpc中都包含有sender的期数，如果发送者的期数更低，那么rpc将会被接受者拒绝，并且发送方将会转变为follower并且更新其自己的期数。相反，如果接受者的期数更低，那么接收者变成follower，并且更新自己的期数然后正常处理rpc ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:4","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#4neutralizing-old-leader"},{"categories":["sys"],"content":"5.clients interaction client发送命令到leader，如果不知道leader的位置，联系任何一个已知的服务器，最终将会重定向到leader处。 除非命令已经被状态机logged，committed，并且exectued，leader不会进行回复该请求。 如果一个请求超时了，client需要重新发送命令到其他的服务器。 但是多次重新发送同一个命令会引起多次执行，所以client必须嵌入一个独一无二的id到每一个指令中去，服务器也将会接受该id到日志条目中去，在接收新来的指令之前，leader会检查其日志的该id，如果找到了，将会无视新的指令，但是会返回原来执行过的结果。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:5","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#5clients-interaction"},{"categories":["sys"],"content":"6.configuration changes配置发生改变是指，该集群中某些机器失效了或者需要新的机器来代替原来的机器等等更改集群物理配置的一些改变。集群配置变更不能直接发生变化，例如决策的处理等等。 raft使用2-phase的途径来处理这种情况： C(old)表示需要在旧配置上的大多数服务器进行决策，而C(old)+C(new)代表需要在旧配置的大多数服务器上通过并且同时需要在新配置的大多数服务器上通过决策。 ","date":"2019-01-15","objectID":"/6.824-notesmapreducegfsraft/:4:6","series":null,"tags":["distributed system"],"title":"6.824 Notes：MapReduce、GFS、Raft","uri":"/6.824-notesmapreducegfsraft/#6configuration-changes"},{"categories":["sys"],"content":"goroutine部分goroutine的一些tricks，比如 func Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // 注意括号 - 必须调用该函数。 } 直接在go关键字后面接一个lambada表达式作为例程。 goroutine通常和channal一起使用，Unix的管道是基于生产-消费者模型，而channal则使用CSP(Communicating Sequential Process)进行构建。信道没有数据的时候会进行阻塞，利用这种条件可以实现一些信号量机制。 var sem = make(chan int, MaxOutstanding) func handle(r *Request) { sem \u003c- 1 // 等待活动队列清空。 process(r) // 可能需要很长时间。 \u003c-sem // 完成；使下一个请求可以运行。 } func Serve(queue chan *Request) { for { req := \u003c-queue go handle(req) // 无需等待 handle 结束。 } } 例如这样一段代码可以实现最大接受请求数量为MaxOutstanding,当新的请求到达时，req := \u003c-queue从阻塞中恢复并且执行goroutine处理请求，再往sem里面写入内容时，会因为队列满了而阻塞，当然这样也有局限性，当有大量请求到达的时候，会不停地新生成新的goroutine，占用系统资源。 func Serve(queue chan *Request) { for req := range queue { req := req // 为该Go程创建 req 的新实例。 sem \u003c- 1 go func() { process(req) \u003c-sem }() } } 解决方案是在循环的routine中尝试往信道中写入内容，这样可以正确实现队列的大小限制。考虑去掉req := req这一行，req变量在每个循环中都被赋予不同的值，但是实际上底层使用的同样的内存，相应的goroutine后的函数闭包可以引用该作用域的变量并且保持和修改，所以每个新生成的goroutine都会使用同一个变量，造成比较严重的错误。 Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once. 另外，并发(concurrency)和并行(parallelism)是两种单独的意思，并发是多个独立地执行程序的组合，即一次性解决大量的事情，而并行是同时执行某些相关连的计算。 ","date":"2019-01-10","objectID":"/effective-go/:1:0","series":null,"tags":["distributed system"],"title":"Effective Go","uri":"/effective-go/#goroutine部分"},{"categories":["sys"],"content":"反射相关变量的最基本信息就是类型和值：反射包的 Type 用来表示一个 Go 类型，反射包的 Value 为 Go 值提供了反射接口。这对于没有源代码的包尤其有用。这是一个强大的工具，除非真得有必要，否则应当避免使用或小心使用。 实际上，反射是通过检查一个接口的值，变量首先被转换成空接口。这从下面两个函数签名能够很明显的看出来： func TypeOf(i interface{}) Type func ValueOf(i interface{}) Value 接口的值包含一个 type 和 value。 ","date":"2019-01-10","objectID":"/effective-go/:2:0","series":null,"tags":["distributed system"],"title":"Effective Go","uri":"/effective-go/#反射相关"},{"categories":["sys"],"content":"结构体，集合设计https://go.fdos.me/11.14.html (golang中一些关于结构体的设计技巧) ","date":"2019-01-10","objectID":"/effective-go/:3:0","series":null,"tags":["distributed system"],"title":"Effective Go","uri":"/effective-go/#结构体集合设计"},{"categories":["sys"],"content":"常见错误50种常见错误 (在awesome-go仓库里面翻到的，有空可以看看) 翻译版本 ","date":"2019-01-10","objectID":"/effective-go/:4:0","series":null,"tags":["distributed system"],"title":"Effective Go","uri":"/effective-go/#常见错误"},{"categories":["sys"],"content":"并发控制库Context库 (该作者其他的帖子也可以看看，干货较多) ","date":"2019-01-10","objectID":"/effective-go/:5:0","series":null,"tags":["distributed system"],"title":"Effective Go","uri":"/effective-go/#并发控制库"},{"categories":null,"content":"前言最近想深入下数据库原理，在知乎和Google发现有几门开源的好课值得去学习。我选择的是6.830，首先是之前有刷过6.828，相对来说比较熟悉，不过实现是选择的是java，这也就是我为什么写博客的理由。另外也被人推荐的CMU15445,这门课程稍微浏览了下主页，是使用C++来实现的，并且课件PPT和视频都非常良心。 这是头一次认真接触JAVA，我使用的是《JAVA核心技术　卷１》,是一本相对来说比较方便C/C++程序员入坑的书，这篇博客也会根据这本书的目录作为大纲进行梳理。 ","date":"2018-11-18","objectID":"/core-java/:0:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#前言"},{"categories":null,"content":"基本结构基本类型大多数语言其实差不了太多，不做太多废话，但是字符串的操作更加接近与python那一类的语言，自动拼接、垃圾回收之类的。 ","date":"2018-11-18","objectID":"/core-java/:0:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#基本结构"},{"categories":null,"content":"字符串字符串判断为空： if (str.length() == 0) or if (str.equals(\"\")) 虽然可以进行字符串拼接，但是效率比较低，可以使用StringBuilder类: StringBuilder builder = new StringBuilder(); builder.append(ch); builder.append(str); builder.toString(); ","date":"2018-11-18","objectID":"/core-java/:1:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#字符串"},{"categories":null,"content":"作用域JAVA的作用域和C/C++不同，内部块中的同名变量名不会覆盖外部块的变量名，甚至无法通过编译。所以在内部块中需要取不同的变量名，但在class中，可以使用this指针来指定变量。 ","date":"2018-11-18","objectID":"/core-java/:2:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#作用域"},{"categories":null,"content":"数组JAVA的数组都是分配在堆上，这又是和C/C++不同的一点： JAVA中的: int[] a = new int[100]; 等同于C/C++中的: int* a = new int[100]; 不同于: int a[100]; 并且数组的完整拷贝通过方法Arrays.copyOf(): newArr = Arrays.copyOf(oldArr, oldArr.lenght()); 也可以通过这个方法来扩展数组： Arr = Arrays.copyOf(Arr, 2 * Arr.lenght()); ","date":"2018-11-18","objectID":"/core-java/:3:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#数组"},{"categories":null,"content":"对象与类OO应该是JAVA的重点，OOP三个特性： 封装：用一个类将实现和使用分开，只保留接口与外部进行联系。 继承：子类自动继承其父类的属性和方法，并且可以添加新的方法和属性。 多态：虽然多个子类都有同一个方法，但是子类的子类实例化之后都可以获得完全不同的结果。 通过下面的方法实例化一个类： new Date(); 如果想使用类中的一个方法： System.out.println(new Date().toString()); ","date":"2018-11-18","objectID":"/core-java/:0:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#对象与类"},{"categories":null,"content":"final 关键字const关键字相当于const关键字即不可变的意思，并且在构造一个类的时候必须要被初始化。 ","date":"2018-11-18","objectID":"/core-java/:1:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#final-关键字"},{"categories":null,"content":"static 关键字static关键字其实也很类似，将static理解为类的方法和域即可而不是对象的方法和域。 例如: class Employee { ... public static currentId; public static int getId() { return currentId; } ... } 调用使用 int id = Employee.curremtID; int id = Employee.getId(); ","date":"2018-11-18","objectID":"/core-java/:2:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#static-关键字"},{"categories":null,"content":"main方法有意思的是java的每一个类里面都可以有main函数，这方便了java为每一个类做单元测试，自己在coding的时候也确实经常用到类的main函数进行测试。 ","date":"2018-11-18","objectID":"/core-java/:3:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#main方法"},{"categories":null,"content":"初始化块初始化块也非常有意思，直接在类域里面输入大括号就能在调用构造器的时候执行。例如： class Employee { private int id; // initializeation block { id = 1; } } ","date":"2018-11-18","objectID":"/core-java/:4:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#初始化块"},{"categories":null,"content":"类继承java中继承的关键字是extends,并且注意子类中的方法不能直接访问超类中的private域，所以需要通过在超类中准备访问器，利用super关键字来获取private域，构造函数也是如此。 class Manager extends Employee{ public Manager(String name) { super(name); ... // other initialization } } ","date":"2018-11-18","objectID":"/core-java/:0:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#类继承"},{"categories":null,"content":"强制转化强制转化可以发生在类的子类和超类转化中，进行类型转化的唯一原因是：在暂时忽视对象的实际类型后，使用对象的全部功能。并且，将一个子类的引用赋值给超类的时候，编译器是允许的，但是将一个超类赋值给一个子类变量，必须进行类型转化。 对于测试强制类型转化，可以使用下面的tricks: if (staff instanceof Manager) { boss = (Manager) staff; ... } 意思是，如果staff是Manager的一个实例，那么可以发生强制转化，当然必须是一个继承链才能成立。 ","date":"2018-11-18","objectID":"/core-java/:1:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#强制转化"},{"categories":null,"content":"抽象类抽象类的意义是提供一个较高层次的抽象，作为基类的存在，关键词是abstract。抽象类中的方法只是充当占位的角色，真正对方法的实现发生在子类中，并且抽象类不能被实例化。 如果子类实现了全部的抽象方法，那么子类就不是抽象的。但若子类只定义了部分抽象类或不定义抽象类的方法，子类也必须标记为抽象类。 ","date":"2018-11-18","objectID":"/core-java/:2:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#抽象类"},{"categories":null,"content":"受保护访问protected关键词可以使得子类能够访问该域，但是外部代码不行，不过通常都是谨慎使用protected类，因为违背了OOP提倡的数据封装原则。 ","date":"2018-11-18","objectID":"/core-java/:3:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#受保护访问"},{"categories":null,"content":"继承的设计技巧 将公共操作和域放在超类中 不使用protected 使用继承实现\"is-a\"关系 除非所有的继承方法都有意义，否则不使用继承 覆盖方法时，不要改变预期行为 使用多态，而非类型信息 ","date":"2018-11-18","objectID":"/core-java/:4:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#继承的设计技巧"},{"categories":null,"content":"接口、lambda、内部类java提供的这三种机制是用来弥补类和类继承一些地方的不灵活性而创立的高级技术。 ","date":"2018-11-18","objectID":"/core-java/:0:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#接口lambda内部类"},{"categories":null,"content":"接口书上给了一个很好的理解接口的解释：”如果类遵从某个特定的接口，那么就履行这项服务“。即如果要调用数组的排序服务，那么这个数组中的类需要提供一个不同对象之间进行比较的接口。 比如，用Employee类提供接口,关键词是implements，之后跟随的是要提供的接口: class Employee implements Compareble\u003cEmployee\u003e { public int compareTo(Employee other) { ... // implements } ... } 当然，在某一处提供了接口的代码，类似于声明的作用： public interface Comparable { int compareTo\u003cObject other\u003e } 其中Object类是所有类的超类。 接口不是类，所以不能被实例化，但是可以声明接口的变量： Comparable x; 然后引用实现了接口的类对象： x = new Employee(...); 接口不能包含实例域和静态方法，但是可以包含常量。 接口概念对于抽象类来说是不同的，抽象类只能用在继承链之中，每个子类只能继承一个超类，但是接口可以实现多个，提高了代码复用。 ","date":"2018-11-18","objectID":"/core-java/:1:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#接口"},{"categories":null,"content":"深拷贝和浅拷贝java每个变量其实可以理解为一个指针或者引用，它们引用一个内存空间作为对象实例的存储位置，但是对象实例中也可能引用了其他的对象。 浅拷贝就是单单拷贝该变量引用的内存部分，但是深拷贝会将该对象内部所引用的对象也拷一份。 比如： class Employee implements Cloneable { ... public Employee clone() { Employee cloned = (Employee) super.clone(); cloned.hireDay = (Date) hireDay.clone(); } } 这样就是深拷贝，在拷贝完本身的内容后还会递归拷贝所引用对象的内存。 ","date":"2018-11-18","objectID":"/core-java/:1:1","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#深拷贝和浅拷贝"},{"categories":null,"content":"lambda表达式lambda就是一个代码块，表达形式为 (参数) -\u003e 表达式。 例如: Comparator\u003cString\u003e comp = (first, second) -\u003e first.length() - second.length(); 如果出现如下类似的lambda表达式: x-\u003eSystem.out.println(x) 那么可以简写为: System.out::println lambda表达式中的一些限制： 只能引用不会改变的变量 表达式捕获的变量必须是实际上的最终变量 lambda中的局部变量不能与外部变量重名 可以使用Runable来保存一个lambda,类似于回调： Runable an = (int a, int b)-\u003eSystem.out.println(a+b); ... ... an.run(); ","date":"2018-11-18","objectID":"/core-java/:2:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#lambda表达式"},{"categories":null,"content":"内部类顾名思义，内部类就是定义在一个class内部的类，使用原因： 内部类方法可以访问该类定义所在作用域中的数据，包括私有数据 内部类可以对同一类中的其他类隐藏起来 若想定义一个回调函数，使用匿名内部类会比较便捷 内部类其实是相对于所在类的一个独立的类，当new操作符新建一个实体的时候，并不会实体化内部类，内部类需要独立进行实例化。不过，内部类和所在类建立了一定的联系使得内部类可以访问外围类的数据。 内部类的初始化语法稍微有点复杂： outerObject.new InnerClass(construction parmeter) 例如： TalkingClock jabberer = new TalkingClock(1000, true); TalkingClock.TimePrinter listener = jabberer.new TimerPrinter(); 内部类的一些限制： 内部类声明所有的静态域必须要final，对于每一个外围类只需要有一个静态域的实例，若不是final，则分别会有单独的内部类实例。 类似于lambda，访问外围局部变量也需要保证被引用的局部变量是事实上的final,内部类引用的时候，实际上创建了一份备份，防止外围类被垃圾回收的时候，引用出错，并且声明为final使得内部类和外围类引用的同一个实体。 有一种方法来绕过这个限制，使用长度为1的数组： int[] conuter new int[1]; for (int i = 0; i \u003c dates.length; i++) dates[i] = new Date() { public int compareTo(Date other); return super.compareTo(other); }; ","date":"2018-11-18","objectID":"/core-java/:3:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#内部类"},{"categories":null,"content":"匿名内部类匿名内部类是一种很方便的工具来扩充某个接口，它的语法如下： new SuperType(construction parameters) { inner class methods and data } 常用的使用方式为 Person queen = new Person(\"Mary\"); // normal object Person count = new Person(\"Dracula\") { ... }; // a object extending Person ","date":"2018-11-18","objectID":"/core-java/:4:0","series":null,"tags":["Java"],"title":"Java 核心技术卷1 笔记","uri":"/core-java/#匿名内部类"},{"categories":["sys"],"content":"这篇文章是针对APUE习题11-2的writeup，进程在开启线程后，不同线程需要完成不同的工作，然后在运行中可能引用同一个元素，举一个例子，当多个线程创建后，需要从消息队列中获取一个作业信息的结构体来部署作业工作，但是可能出现第一个线程获取到一个作业之后，在将此作业从作业队列中删除之前，另外一个线程获取了这个作业，然后同样从队列中删除这个作业的操作，那么这个作业就会被删除两次，在C中通常是用链表实现，往往这样做的结果就是指针访问不存在的对象，引发段错误，从而发生非同步性的修改。 在完成这道题目之前，先对结构体做一些简单的修改，新增两个元素，作业函数指针和要进行累加的数字。 struct job { struct job *j_next; struct job *j_prev; pthread_t j_id; /** job */ int (*j_add)(int); int j_num; }; 然后写一个简单的作业函数，完成j_num的累加工作，已经初始化结构体job的作业分配函数，并且将这个作业加入到作业队列中去： 累加函数 int add(int i) { int sum; sum = 0; while (i) sum += i--; return sum; } 作业分配 struct job * job_alloc(struct queue *qp, int num) { struct job *jp; if ((jp = (struct job *)malloc(sizeof(struct job))) == NULL) return (NULL); jp-\u003ej_add = add; jp-\u003ej_num = num; jp-\u003ej_id = pthread_self(); job_insert(qp, jp); return (jp); } 然后可以创建一个线程去完成作业分配工作，生成一个待执行的作业队列，虽然在这里使用主线程来创建会更好。 开启线程以及队列初始化 struct queue qn; int err; pthread_t tid1, tid2; queue_init(\u0026qn); setbuf(stdout, NULL); err = pthread_create(\u0026tid1, NULL, th_func1, \u0026qn); if (err != 0) err_exit(err, \"thread create error\"); pthread_join(tid1, NULL); 线程例程 void * th_func1(void *arg) { job_alloc((struct queue *)arg, 10); job_alloc((struct queue *)arg, 9); job_alloc((struct queue *)arg, 8); job_alloc((struct queue *)arg, 7); return ((void *)0); } 题目中有提到，需要将线程挂起然后修改作业对应的线程ID，之后要继续执行进行验证，在这里先排除信号量，因为信号量是用在多进程同步，异常的一种机制；所以选择条件变量实现线程的唤醒操作，然后定义一个枚举量来判断多线程处于挂起还是运行状态，如果线程发现这个全局枚举量是处于运行状态，从作业队列中用job_find找到一个作业，并且使用job_remove从作业队列中移除。 条件变量和枚举量 /** thread suspend mutex*/ pthread_cond_t jready = PTHREAD_COND_INITIALIZER; pthread_mutex_t statmtx = PTHREAD_MUTEX_INITIALIZER; pthread_barrier_t b; enum status { STOP = 0, RUNNING = 1 }; static enum status t1st = STOP; 作业线程例程 void * th_func2(void *arg) { struct job *jp; int sum; pthread_mutex_lock(\u0026statmtx); while (t1st == STOP) { printf(\"thread %lu is waiting resource..\\n\", (unsigned long)pthread_self()); pthread_cond_wait(\u0026jready, \u0026statmtx); /** when the pthread recived the signal, it will test the while loop confidion fisrt*/ } printf(\"thread %lu is going to run\\n\", (unsigned long)pthread_self()); pthread_mutex_unlock(\u0026statmtx); jp = job_find((struct queue *)arg, pthread_self()); job_remove((struct queue *)arg, jp); /** processing job */ sum = jp-\u003ej_add(jp-\u003ej_num); printf(\"thread %lu caculate %d\\n\", (unsigned long)pthread_self(), sum); printf(\"return = %d, tid = %lu\\n\", pthread_barrier_wait(\u0026b), (unsigned long)pthread_self()); 全局枚举量已经将状态设置为了暂停状态，所以线程一进入例程，就将挂起等待条件变量发生改变，恢复函数应该将枚举量提前设置为运行状态，因为当pthread_cond_wait()函数在接收到条件变量发生变化时，只是唤醒线程，不能跳出while循环。 修改线程ID int modify_tid(struct queue *qp, pthread_t tid1, pthread_t tid2) { struct job *jp; pthread_rwlock_wrlock(\u0026qp-\u003eq_lock); for (jp = qp-\u003eq_head; jp != NULL; jp = jp-\u003ej_next) if (pthread_equal(jp-\u003ej_id, tid1)) break; jp-\u003ej_id = tid2; pthread_rwlock_unlock(\u0026qp-\u003eq_lock); return 0; } 在线程唤醒之前，将ID修改为tid2指定的数值，让新创建的线程能在工作队列中找到设置好的对应作业。 线程恢复 void th_resume(void) { if (t1st == STOP) { pthread_mutex_lock(\u0026statmtx); t1st = RUNNING; pthread_cond_broadcast(\u0026jready); printf(\"thread resume signal send..\\n\"); pthread_mutex_unlock(\u0026statmtx); } } 简单地把状态设置为运行，并且广播条件变量已经发生了改变。 多线程创建和恢复运行线程 pthread_barrier_init(\u0026b, NULL, 4+1); for (int i = 0; i \u003c 4; i++) { err = pthread_create(\u0026tid2, NULL, th_func2, \u0026qn); if (err != 0) err_exit(err, \"thread create error\"); modify_tid(\u0026qn, tid1, tid2); } th_resume(); pthread_barrier_wait(\u0026b); 11-2-preposition.c 多个线程按照想象中的情况从作业队列中取出不同的作业，然后从队列中删去通过job_find()找到的作业，并且调用登记在结构体中的函数进行累加，最后在pthread_barrier_wait()处进行同步。值得注意的是，虽然在这里一共开了4个线程，但是调用pthread_barrier_init()进行初始化的时候，将屏障需要等待的线程数设置为5，因为是把主线程也算了进去。还有一个有意思的地方是，总有一个线程在到达屏障的时候返回-1，是因为这个值实际上代表的是PTHREAD_BARRIER_SERIAL_THREAD宏，说明这个线程来执行多个线程的归并操作。 通过书上给的代码，已经实现了一个多线程处理作业队列的操作，并且修改了暂停线程的ID，使得对应线程能从工作队列中得到作业。那么回到题目问到的问题上，这样会对job_remove产生什么影响？试想这样一种情况，当一个线程已经被唤醒了，然后去调用job_find函数寻找相应ID的作业，使得线程的工作指针jp指向改结构体，但是此时发生了调度或者系统拥塞事件，这时调用了修改之前修改线程id的函数modify_tid，使得描述该作业的结构体的线程ID被填写为另外一个线程的线程ID，现在的情况就变成两个线程的工作指针jp都指向了同一个结构体，并且准备执行job_remove，这时候任意一个线程先执行，后者都会产生段错误（一般是对NULL指针解引用）。现在修改之前代码来模拟这种情况: 11-2-exception.c ","date":"2018-10-15","objectID":"/thread-synchronization/:0:0","series":null,"tags":null,"title":"线程同步","uri":"/thread-synchronization/#"},{"categories":["algorithm"],"content":"CLRS快撸完一半了，所以趁开学前做下小总结，CLRS研究问题的方式和平时的感觉有那么些不太一样，但是接触久了就会慢慢习惯，主要注重算法的运行时间和算法可行性。初阶学习目标是掌握几种重要的排序算法和课堂中没有学到的数据结构。 首先还要推荐一下usfca的这个算法可视化的网站：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#"},{"categories":["algorithm"],"content":"排序算法排序算法在系统学习之前，只会冒泡排序，非常简单但是时间复杂度为O(n^2)的算法，是一种没有怎么优化过的想法。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#排序算法"},{"categories":["algorithm"],"content":"插入排序插入排序(insert sort)是学习CLRS最先接触的算法，可以理解为将序列中的元素插入到一个已经排序好的队列中去。提供一个序列的起始位置(be)和长度(len)，循环从起始位置的下一个元素开始迭代，作为需要插入的数值(key)，将所有大于关键字元素后移一位，最后在放入对应的位置。期望运行时间(n^2)。 for (int i = be + 1; i \u003c len; i++) { int key = a[i]; int j = i - 1; while (j \u003e= 0 \u0026\u0026 a[j] \u003e key) { a[j+1] = a[j]; j--; } a[j+1] = key; } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#插入排序"},{"categories":["algorithm"],"content":"归并排序归并排序(merge sort)是接触分治法接触到的算法，这种方法是将需要解决的问题细分为细小的问题，然后递归求解这些子问题，直接求解，最后将这些子问题的解合并成原问题的解。应用到排序算法中的话就是将待排序的元素分成n/2两个子序列，然后递归解决子序列的顺序问题，最后合并两个已排序的子序列，形成排序好的队列。期望运行时间(nlgn)。 首先是归并过程的辅助函数: void SortAlgorithm::mergeArray(int p, int q, int r) { int n1 = q - p + 1; int n2 = r - q; int L[n1], R[n2]; int i1, i2; for (int i = 0; i \u003c n1; i++) L[i] = a[p+i]; for (int i = 0; i \u003c n2; i++) R[i] = a[q+i+1]; i1 = 0; i2 = 0; for (int k = p; k \u003c= r; k++) { if ((L[i1] \u003c= R[i2] \u0026\u0026 i1 \u003c n1 )|| i2 == n2) { a[k] = L[i1]; i1++; } else { a[k] = R[i2]; i2++; } } } 前面两个for循环是赋值递归过程已经排好的两个子数组left和right，然后根据i1和i2所指向的数组元素大小放入到原来的数组中去，完成两个子数组的归并。 然后是一个将问题分解的递归过程: void SortAlgorithm::mergeSort(int p, int r) { int q; if (p \u003c r) { q = (r + p) / 2; mergeSort(p, q); mergeSort(q+1, r); mergeArray(p, q, r); } } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:2:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#归并排序"},{"categories":["algorithm"],"content":"主定理//todo ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:3:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#主定理"},{"categories":["algorithm"],"content":"堆排序堆的性质比较简单，以最大堆为例，父节点必须大于等于子节点的值。另外还有个重要的推论：叶子节点的下标分别是n/2+1，　n/2+2, ｎ/2+3, …, n。其中，堆排序的最坏运行时间期望是(nlgn)。 实现堆的过程首先是: 位置关系和辅助函数 inline int PARENT(int i) { return i / 2; } inline int LEFT(int i) { return i * 2; } inline int RIGHT(int i) { return i * 2 + 1; } inline void pSwap(int \u0026x, int \u0026y) { int temp = x; x = y; y = temp; } 堆的维护过程 将指定节点与左右节点相互比较，让三个节点中最大的节点成为父节点。 void SortAlgorithm::maxHeapify(int i) { int l = LEFT(i); int r = RIGHT(i); int lagest; if (l \u003c arrayLength() \u0026\u0026 a[i-1] \u003c a[l-1]) lagest = l; else lagest = i; if (r \u003c arrayLength() \u0026\u0026 a[lagest-1] \u003c a[r-1]) lagest = r; if (lagest != i) { pSwap(a[i-1], a[lagest -1]); maxHeapify(lagest); } } 建立堆 将一个已有的序列形成堆，利用由下往上的方法建立。 void SortAlgorithm::bulidMaxHeap() { for (int i = arrayLength()/2; i \u003e= 1; i--) maxHeapify(i); } 堆排序 建成好的堆的根节点是这个序列的最大值，所以，将这个节点先排除出来，然后再进行堆化，可以找出次最大值，依次类推得到一个排好序的队列。 void SortAlgorithm::heapSort() { for (int i = arrayLength(); i \u003e= 2; i--) { pSwap(a[0], a[i-1]); maxHeapify(1); len--; } } 先将最大值根节点与数组的端节点交换，然后将长度减少1，对根节点堆化，重新形成最大堆。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:4:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#堆排序"},{"categories":["algorithm"],"content":"快速排序快排是一种使用广泛的排序，虽然最坏运行情况是时间复杂度是(n^2)，但是在元素不用的情况下，期望时间复杂度是(nlgn)，并且，快速排序的过程中不用不会用到临时数组作为存储，也就是说，快速排序是原址排序的。快排的思想和归并一样，先将问题进行分解再归并。 快排的代码不长，代码比想象中要神奇。 首先是原址重排： int SortAlgorithm::partitionArray(int p, int r) { int key = a[r-1]; int i = p - 1; for (int k = p; k \u003c= r; k++) { if (a[k-1] \u003c key) { i++; pSwap(a[i-1], a[k-1]); } } pSwap(a[i+1-1], a[r-1]); return i+1; } 这个函数的作用就是将(p-\u003er)的数组进行划分，把数组端点的值作为划分界限，也叫主元。然后递归下去，将每一个小区域进行排序，完成排序。 然后是分治的过程： void SortAlgorithm::quickSort(int p, int r) { if (p \u003c r) { int q = partitionArray(p, r); quickSort(p, q-1); quickSort(q+1, r); } } ps:是先进行分治然后再细分的。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:5:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#快速排序"},{"categories":["algorithm"],"content":"计数排序基数排序(count sort)也是一种比较神奇的算法，要用到三个数组。时间复杂度为(k+n)。 void SortAlgorithm::countSort() { // the size fo array c must // bigger than the maximum number // in the array a. int length = arrayLength(); int b[length], c[length]; for (int i = 0; i \u003c length; i++) { c[i] = 0; b[i] = 0; } for (int i = 1; i \u003c= length; i++) c[a[i-1]]++; for (int i = 1; i \u003c length; i++) c[i] = c[i-1] + c[i]; for (int i = length; i \u003e= 1; i--) { b[c[a[i-1]]-1] = a[i-1]; c[a[i-1]]--; } for (int i = 0; i \u003c length; i++) a[i] = b[i]; } 计数排序的主要用第2，3，4个循环进行排序，其中a[i]对应着序列的值，C[i]对应在数组B中最后填充的位置。每当填充一个，C[i]就会进行减1操作，实际上就是对应在数组B中的位置往前面移动一位。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:6:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#计数排序"},{"categories":["algorithm"],"content":"基数排序基数排序(radix)在针对数值不大的情况是一种很好的排序算法，其中会用到一种稳定的排序算法作为子算法排序，虽然用到了其他的算法，但是更加重要的其想法。针对数值的相应位进行比较排序。 用到了三个辅助函数: int getBase(int n) { int d = 0; while (n/10 != 0) n /= 10, d++; return d; } int power(int base,int p) { if (p == 0) return 1; if (p == 1) return base; int result = power(10, p/2); if (p % 2 == 1) return base * result * result; else return result * result; } int getNumber(int n, int d) { if (d == 0) return n % 10; return (n % power(10, d+1)) / power(10, d); } getBase()获得元素的基数, power获取以base为底,p为幂值的数值, getNumber()获取对应位数的值。 然后进行对应数位的排序移位: void SortAlgorithm::radixSort() { int maxBase = 0; int d; int b[arrayLength()]; for (int i = 0; i \u003c arrayLength(); i++) { d = getBase(radixArr[i]); maxBase = maxBase \u003e d ? maxBase : d; } for (int i = 0; i \u003c maxBase+1; i++) { for (int j = 0; j \u003c arrayLength(); j++) b[j] = getNumber(radixArr[j], i); dependInsertSort(b, 0, arrayLength()); } } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:7:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#基数排序"},{"categories":["algorithm"],"content":"数据结构","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#数据结构"},{"categories":["algorithm"],"content":"散列表","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#散列表"},{"categories":["algorithm"],"content":"二叉搜索树二叉搜索树建立好后就已经是一个排序好的序列了，只要执行中序遍历，就是顺序序列。首先声明这样一个结构体来代表叶节点。 typedef struct treenode { treenode(int value); int key; struct treenode *left; struct treenode *right; struct treenode *p; //parent }node; 以及用来整合二叉树操作的类，其中包含一个数据来存放树的根节点。 class BinarySearchTree { public: BinarySearchTree(); void treeInsert(node *z); void inorderTreeWalk(node *x); node* getRoot(); node* searchNode(int value); node* treeMin(node *x); node* treeMAX(node *x); node* successor(node *x); void treeDelete(node *z); void transplant(node* u, node* v); private: node *root; }; 二叉搜索树中的删除操作要分情况讨论: 如果节点没有孩子节点，那么直接替换该节点为null即可。 如果只有一个孩子，那么用孩子节点进行替换。 如果有两个孩子，那么寻找该节点的后继（顺序序列的下一个值）来代替该节点，并且后继节点一定在该节点的右子树中。 首先是要一个辅助过程tansplant来帮助删除，即用u的双亲来代替v的双亲。 void BinarySearchTree::transplant(node *u, node *v) { // v -\u003e u if (u-\u003ep == NULL) root = v; else if (u == u-\u003ep-\u003eleft) u-\u003ep-\u003eleft = v; else u-\u003ep-\u003eright = v; if (v != NULL) v-\u003ep = u-\u003ep; } 然后就是根据三种情况来删除节点: void BinarySearchTree::treeDelete(node *z) { if (z-\u003eleft == NULL) transplant(z, z-\u003eright); else if (z-\u003eright == NULL) transplant(z, z-\u003eleft); else { node *y = treeMin(z-\u003eright); if (y-\u003ep != z) { transplant(y, y-\u003eright); y-\u003eright = z-\u003eright; y-\u003eright-\u003ep = y; } transplant(z, y); y-\u003eleft = z-\u003eleft; y-\u003eleft-\u003ep = y; } } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:2:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#二叉搜索树"},{"categories":["algorithm"],"content":"红黑树红黑树是一种平衡树，大致意思就是树的节点会分散得比较平均。相比二叉搜索树来说，执行一些动态集合操作比如插入删除，搜索的时候执行会比较快，可以保证最差情况下，动态集合操作的时间复杂度为nlgn。 红黑树的性质： 每个节点都是红色或者黑色的。 根节点是黑色的。 每个叶节点都是黑色的(nil)。 如果一个节点是红色的，那么两个子节点都是黑色的。 从某个节点出发，到其叶子节点的简单路径上，所包含的黑色节点相同。 所以引申出一颗有n个及诶单的红黑树的高度最高为2lg(n+1)。 实现红黑树的插入操作之前，需要用到一个旋转操作来保持二叉搜索树性质: 左旋操作： void rbtree::LeftRotate(rbnode *x) { rbnode *y = x-\u003eright; x-\u003eright = y-\u003eleft; if (y-\u003eleft != NULL) y-\u003eleft-\u003ep = x; y-\u003ep = x-\u003ep; if (x-\u003ep == NULL) root = y; else if (x == x-\u003ep-\u003eleft) x-\u003ep-\u003eleft = y; else x-\u003ep-\u003eright = x; y-\u003eleft = x; x-\u003ep = y; } 右旋操作： void rbtree::RightRotate(rbnode *y) { rbnode *x = y-\u003eleft; y-\u003eleft = x-\u003eright; if (x-\u003eright != NULL) x-\u003eright-\u003ep = y; x-\u003ep = y-\u003ep; if (y-\u003ep == NULL) root = x; else if (y == y-\u003ep-\u003eleft) x = y-\u003ep-\u003eleft; else x = y-\u003ep-\u003eright; x-\u003eright = y; y-\u003ep = x; } 然后是插入操作，和二叉搜索树一样，通过和节点比对大小确定插入的位置，但是多出一个把新的节点涂色的过程，新的节点会被涂成红色，方便进行平衡二叉树，插入操作完成后，要对红黑树的性质进行检查，并且修复RBT。 插入操作实现： void rbtree::RBInsert(rbnode* z) { rbnode *x, *y; y = NULL; x = root; while (x != NULL) { y = x; if (z-\u003ekey \u003c x-\u003ekey) x = x-\u003eleft; else x = x-\u003eright; } z-\u003ep = y; if (y == NULL) root = z; else if (z-\u003ekey \u003c y-\u003ekey) y-\u003eleft = z; else y-\u003eright = z; z-\u003ec = RED; z-\u003eleft = NULL; z-\u003eright = NULL; RBinsertFixup(z); } 新插入的节点是红色，如果此时其父节点也是红色，那么就违反了性质4，因此要进行红黑树的修复操作，红黑树的插入修复有三种情况： （假定新插入的节点为z，父节点为z.p,叔节点为y） a. z节点的叔节点y是红色的，那么将z.p和y都着为黑色，z.p.p着为红色，并且将z指向z.p.p b. z的叔节点y是黑色，并且z是一个右孩子，那么对z的父节点z.p进行左旋操作。 c. z的叔节点y是黑色，并且z是一个左孩子，那么就将z.p着为黑色，z.p.p着为红色，对z.p执行右旋操作。 以上只是针对一边的情况，另外一侧镜像对称操作，下面是修复操作的实现： void rbtree::RBinsertFixup(rbnode* z) { rbnode *y; printf(\"node : %d %s\\n\", z-\u003ekey, z-\u003ec ? \"RED\":\"BLACK\"); while (z-\u003ep != NULL \u0026\u0026 z-\u003ep-\u003ep != NULL \u0026\u0026 z-\u003ep-\u003ec == RED) { if (z-\u003ep == z-\u003ep-\u003ep-\u003eleft) { y = z-\u003ep-\u003ep-\u003eright; /*case 1*/ if (y != NULL \u0026\u0026 y-\u003ec == RED) { //uncle node is red z-\u003ep-\u003ec = BLACK; y-\u003ec = BLACK; z-\u003ep-\u003ep-\u003ec = RED; z = z-\u003ep-\u003ep; } else { if (z == z-\u003ep-\u003eright) { /*case 2*/ z = z-\u003ep; LeftRotate(z); } /*case 3*/ z-\u003ep-\u003ec = BLACK; z-\u003ep-\u003ep-\u003ec =RED; RightRotate(z-\u003ep-\u003ep); } }else { y = z-\u003ep-\u003ep-\u003eleft; if (y != NULL \u0026\u0026 y-\u003ec == RED) { z-\u003ep-\u003ec = BLACK; y-\u003ec = BLACK; z-\u003ep-\u003ep-\u003ec = RED; z = z-\u003ep-\u003ep; } else { if (z == z-\u003ep-\u003eleft) { z = z-\u003ep; RightRotate(z); } z-\u003ep-\u003ec = BLACK; z-\u003ep-\u003ep-\u003ec = RED; LeftRotate(z-\u003ep-\u003ep); } } } root-\u003ec = BLACK; } 实现删除操作之前，要准备两个辅助函数，一个用来更换父节点，一个用来寻找节点的后继。 首先是transplant将u的父节点的子节点更换为v的操作： void rbtree::rbTransplant(rbnode *u, rbnode *v) { if (u-\u003ep == NULL) root = v; else if (u == u-\u003ep-\u003eleft) u-\u003ep-\u003eleft = v; else u-\u003ep-\u003eright = v; if (v != NULL) v-\u003ep = u-\u003ep; } 寻找某个节点后继即寻找左孩子的右子树： rbnode * rbtree::minimum(rbnode *x) { while (x-\u003eleft != NULL) x = x-\u003eleft; return x; } 删除操作也和二叉搜索树想类似，如果只有一个节点就简单删除；否则，寻找后继节点来替代被删除的节点，但是红黑树需要对颜色进行跟踪，如果被替换的节点y原来是黑色，那么就引起了黑高变化，因此会进行红黑树修复操作。 void rbtree::rbDelete(rbnode *z) { rbnode *x, *y = z; color origin = y-\u003ec; if (z-\u003eleft == NULL) { x = z-\u003eright; rbTransplant(z, z-\u003eright); } else if (z-\u003eright == NULL) { x = z-\u003eleft; rbTransplant(z, z-\u003eleft); } else { y = minimum(z-\u003eright); origin = y-\u003ec; x = y-\u003eright; if (y-\u003ep == z) { if (x != NULL) x-\u003ep = y; } else { rbTransplant(y, y-\u003eright); y-\u003eright = z-\u003eright; y-\u003eright-\u003ep = y; } rbTransplant(z, y); y-\u003eleft = z-\u003eleft; if (y-\u003eleft != NULL) y-\u003eleft-\u003ep = y; y-\u003ec = z-\u003ec; free(z); } if (origin == BLACK) rbDeleteFixup(x); } 删除修复工作有些复杂，这里没有理解为什么这么做，先记下来： x的兄弟节点w是红色，那么改变w和x.p的颜色，然后对x.p做一次左旋。 x的兄弟节点w是黑色，且w的两个子节点都是黑色，那么将w着为黑色并且将x指向x.p。 x的兄弟节点w是黑色，且w的左孩子是红色的，w的右孩子是黑色的，那么交换w和w.left的颜色，并且对w执行右旋。 x的兄弟节点w是黑色，且w的右孩子是红色的，那么将w的颜色着为x.p的颜色，w.right和x.p都着为黑色，并且对x.p执行左旋。 同样的，以上情况只针对左子树，右子树的处理镜像对称。 删除操作的实现： void rbtree::rbDeleteFixup(rbnode *x) { rbnode *w; while (x != root \u0026\u0026 x-\u003ec == BLACK) { if (x == x-\u003ep-\u003eleft) { w = x-\u003ep-\u003eright; if (w-\u003ec == RED) { //case 1 w-\u003ec = BLACK; x-\u003ep-\u003ec = RED; LeftRotate(x-\u003ep); w = x-\u003ep-\u003eright; } if (w-\u003eleft-\u003ec == BLACK \u0026\u0026 w-\u003eright-\u003ec == RED) { // case 2 w-\u003ec = RED; x = x-\u003ep; } else { if (w-\u003eright-\u003ec == BLACK) { // case 3 w-\u003eleft-\u003ec = BLACK; w-\u003ec = RED; RightRotate(w); w = x-\u003ep-\u003eright; } // case 4 w-\u003ec = x-\u003ep-\u003ec; x-\u003ep-\u003ec = BLACK; w-\u003eright-\u003ec = BLACK; LeftRotate(x-\u003ep); x = root; } } else { w = ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:3:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#红黑树"},{"categories":["algorithm"],"content":"扩展数据结构","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#扩展数据结构"},{"categories":["algorithm"],"content":"区间树","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#区间树"},{"categories":["algorithm"],"content":"动态统计树","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:2:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#动态统计树"},{"categories":["algorithm"],"content":"动态规划","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#动态规划"},{"categories":["algorithm"],"content":"最长公共子序列问题这个问题为了求出两个字符序列xy中最长的公共子序列(LCS)，用i和j分别代表xy的长度，解决这个问题的方法是分别从字符序列的一段开始比较，分成两种情况： 如果x[i] == y[j]，那么说明这个字符是公共字符，属于LCS。那么，接下来只要将这个字符加入到LCS中，并且将序列xy的长度进行减１，继续求出剩下序列的LCS。 如果x[i] != y[j]，那么说明x[i-1]和y[j] 或者 x[i]和y[j-1]存在LCS。 这样可以得到递归式： 当x[i] == y[j]时，C[i][j] = C[i-1][j-1]+1 当x[i] != y[j]时，C[i][j] = max{C[i-1][j], C[i][j-1]} 首先定义了一个方向的枚举类型： enum direction { LEFT = 0, UP, UpperLeft }; LCS问题用递归的方法更加容易理解和操作： int DynamicProgramming::LCSlengthRecursive(int i, int j) { if (i == 0 || j == 0) return 0; if (strA[i-1] == strB[j-1]) c[j][i] = LCSlengthRecursive(i-1, j-1) + 1; else { int x, y; x = LCSlengthRecursive(i-1, j); y = LCSlengthRecursive(i, j-1); c[j][i] = x \u003e y ? x : y; } return c[j][i]; } 然后发现决策树里多次重复出现求同样的子问题的情况，那么可以去掉这些重复的操作，进行一下优化。 int DynamicProgramming::LCSlengthRecursive(int i, int j) { if (c[j][i] == 0){ if (i == 0 || j == 0) return 0; if (strA[i-1] == strB[j-1]) c[j][i] = LCSlengthRecursive(i-1, j-1) + 1; else { int x, y; x = LCSlengthRecursive(i-1, j); y = LCSlengthRecursive(i, j-1); c[j][i] = x \u003e y ? x : y; } } return c[j][i]; } 但是迭代的速度更快： void DynamicProgramming::LCSlengthIterate() { int i = 0, j = 0; for (i = 1; i \u003c m; i++) c[0][i] = 0; for (i = 0; i \u003c n; i++) c[i][0] = 0; /*CASE DILIVER*/ for (i = 1; i \u003c n; i++) for (j = 1; j \u003c m; j++) if (strA[j-1] == strB[i-1]) { c[i][j] = c[i-1][j-1] + 1; b[i][j] = UpperLeft; } else if (c[i][j-1] \u003e= c[i-1][j]) { c[i][j] = c[i][j-1]; b[i][j] = LEFT; } else { c[i][j] = c[i-1][j]; b[i][j] = UP; } } PrintLCS(b, c, m, n); } 这个函数后半部分是做LCS各种情况的派发的，两层for循环，内层代表这个表格的x轴，外层代表表格的y轴，将i和j所指的元素进行比较，如果相同根据第一种情况从子问题中获取最优解，也就是长度分别为i-1和长度为j-1的子序列获取LCS，并且由于ij所指定位置相等，该位置进行自增。数组C用来记录LCS的长度，数组B用来LCS的路径。 在准备输出LCS的时候，想起来要传递两个二维数组，才能递归输出，然后踩到了一个关于二维数组与二级指针转换问题的坑，一种更好的解决办法是把这一部分准备二维数组的操作放入到构造函数内去，并且在析构函数中释放掉： /*constructor*/ DynamicProgramming::DynamicProgramming(string s1, string s2) : strA(s1), strB(s2), lcs(\"\") , m(strA.length()+1), n(strB.length()+1) { c = (int **) malloc (sizeof(int *[m]) * n); *b = (direction *)malloc(sizeof(direction) * m * n); *c = (int *)malloc(sizeof(int) * m * n); for (int y = 1; y \u003c n; y++ ) { b[y] = b[y-1] + m; c[y] = c[y-1] + m; } } /*destructor*/ DynamicProgramming::~DynamicProgramming() { //dtor free(*c); free(*b); free(c); free(b); } 。输出递归函数根据数组B所记录的方向进行输出，得到LCS： void DynamicProgramming::PrintLCS(direction **b, int **c, int x, int y) { if (x == 0 || y == 0) return ; if (b[y-1][x-1] == UpperLeft) { PrintLCS(b, c, x-1, y-1); cout \u003c\u003c strB[y-2] \u003c\u003cendl; } else if (b[y-1][x-1] == LEFT) PrintLCS(b, c, x-1, y); else PrintLCS(b, c, x, y-1); } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#最长公共子序列问题"},{"categories":["algorithm"],"content":"贪心算法贪心问题是每一步都选择最优解,从而达到最有解的情况，相比于动态规划，其编程复杂性比较低。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#贪心算法"},{"categories":["algorithm"],"content":"活动选择问题该问题是从起始时间和结束时间不同的多个活动中，选取尽量多的活动，那么贪心的运用就是，先将该活动序列以结束时间进行排序，然后依次选择合适的结束时间早的活动，得到最优解。 递归实现： void ActivitySelect::recursive_selector(int k, int n) { int m = k + 1; while (m \u003c n \u0026\u0026 f[k] \u003e s[m]) m++; if (m \u003c= n) { greedy_sequence.push_back(m); recursive_selector(m, n); } } 迭代版本： void ActivitySelect::iterative_selector(int n) { int k = 1; greedy_sequence.push_back(k); for (int m = 2; m \u003c= n; m++) if (s[m] \u003e= f[k]) { greedy_sequence.push_back(m); k = m; } } 为了方便实现并集操作，这里选择将结果的集合用vector来处理。 ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#活动选择问题"},{"categories":["algorithm"],"content":"霍夫曼编码霍夫曼编码常用于压缩数据，是在给定字符频率的情况下，获取最优的压缩率，霍夫曼树向左下降就是编码添加0，向右即为1，为了取得较好的压缩率，所以，频率高的关键字应该在接近树根的位置，相应地，频率低的节点应该在叶子节点附近。 其结构体定义也比较简单，二叉树节点中加入键值和频率即可： typedef struct huffmantree{ huffmantree() = default; huffmantree(char c, int f) : freq(f), character(c){} int freq; char character; struct huffmantree *left; struct huffmantree *right; }hfnode; 因为霍夫曼树每次建立一个新节点都要从需要编码的队列中找出最小的元素，所以，需要完成一个最小堆来减少时间消耗。只需要几个简单的集合操作即可: 堆的维护 void minHeapify(hfnode* a, int len, int i) { int r = _Right(i); int l = _Left(i) ; int minimum; if (l \u003c len \u0026\u0026 a[l-1].freq \u003c a[i-1].freq) minimum = l; else minimum = i; if (r \u003c len \u0026\u0026 a[r-1].freq \u003c a[minimum-1].freq) minimum = r; if (minimum != i) { myswap(a[minimum-1], a[i-1]); minHeapify(a, len, minimum); } } 建立堆 void buildHeap(hfnode* a, int len) { for (int i = len/2; i \u003e= 1; i--) minHeapify(a, len, i); } 抽取最小值 hfnode\u0026 extractmin(hfnode* heap, int \u0026len) { myswap(heap[0], heap[len-1]); len--; minHeapify(heap, len, 1); return heap[len]; } 插入 void heapInsert(hfnode* heap, int \u0026len, hfnode\u0026 z) { heap[len++] = z; buildHeap(heap, len+1); } 建立霍夫曼树的过程就是，首先尽量选频率小的元素作为叶子，然后分配一个新的节点作为它们的父节点，该父节点的频率值为子节点频率和，最后将该父节点重新放回最小堆，循环再次从堆中抽取两个最小值，形成下一个节点，依次类推知道得到最后的根节点，其频率应该为1。 实现如下： hfnode * Huffmantranslations::buildHuffmanTree(hfnode arr[], int len) { int n = len; for (int i = 1; i \u003c n; i++) { hfnode x = extractmin(arr, len); hfnode y = extractmin(arr, len); hfnode *z = new hfnode; z-\u003eleft = \u0026x; z-\u003eright = \u0026y; z-\u003efreq = x.freq + y.freq; heapInsert(arr, len, *z); printf(\"%d %d\\n\", x.freq, y.freq); } return \u0026arr[0]; } ","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:2:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#霍夫曼编码"},{"categories":["algorithm"],"content":"高级数据结构","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:0:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#高级数据结构"},{"categories":["algorithm"],"content":"B树B树主要的用途是用来进行优化磁盘操作，减少慢速设备和快速设备之间的速度差是很有必要的，所以在该算法中会有出现磁盘操作，虽然没有进行对应的操作，但是有必要知道什么时候进行读写，磁盘页只会在内存中留着极少数量。 性质： 节点属性 x.n代表存储在节点x中的节点个数 x.key[i]以非降序排放 x.leaf判断是否为叶子节点 有x.n+1个指针(x.c)指向该节点的孩子节点 节点x.key[i]分割孩子节点的关键字 每个节点的最大和最小关键字又最小度数(minumum degree)决定，最小度数为２时是最简单的Ｂ树，即２－３－４树。 除了根节点，每个节点必须有t-1个关键字 除了根节点，每个节点必须有t个孩子节点 树非空，根节点必须要有关键字 每个节点最多2t-1个关键字，即有2t个孩子节点 在实现过程中，自己有用到算法可视化进行辅助编写，但是里面的概念和书上有点不同，比如t=2时，应该选中max.degree=4，并且选中Preemtive Split优先分离选项。 首先是树的节点定义： typedef struct btreenode { int n; // the number of key bool leaf; /* both key and child pointer need to be allocated according to the value __n__ */ struct btreenode **cp; // point to the child pointer void ** diskpage; char *key; // point to the key area }bnode; 刚开始定义的时候，以为关键字大小是变化的，需要进行动态分配，实际上使用数组会方便很多，但是要提前知道度数。 然后是创建B树的根节点，二叉树是向下进行增长的，新的节点加入到叶子节点然后再进行其他的操作，而Ｂ树是向上进行增长的，所以，除了前面几个节点是叶子节点，并且所有的树高都是同样的。 bnode* Btree::BTree_Create() { bnode* x = new bnode; x-\u003eleaf = true; x-\u003en = 0; x-\u003ekey = new char[2 * t - 1 + 1]; x-\u003ecp = new bnode*[2 * t + 1]; // abort the first element of the array; DiskRead(x); root = x; return x; } 然后是进行插入操作，但是在这之前需要完成一个分类节点的辅助函数，当一个节点的最大元素数量大于2t-1的时候，那么就需要进行分裂操作，将该节点变为两个各含t-1个元素的节点，并且将中间关键字提升到父节点去。 分列函数的实现: void Btree::BTree_SplitChild(bnode *x, int i) { bnode* z = Allocate_Node(); bnode* y = (x-\u003ecp)[i]; z-\u003eleaf = y-\u003eleaf; z-\u003en = t-1; for (int j = 1; j \u003c= t-1; j++) (z-\u003ekey)[j] = (y-\u003ekey)[j+t]; // j+t = j + (t-1) + 1 if (y-\u003eleaf == false) for (int j = 1; j \u003c= t; j++) (z-\u003ecp)[j] = (y-\u003ecp)[j+t]; y-\u003en = t-1; for (int j = x-\u003en + 1; j \u003e= i+1; j--) (x-\u003ecp)[j+1] = (x-\u003ecp)[j]; (x-\u003ecp)[i+1] = z; for (int j = x-\u003en; j \u003e= i; j--) (x-\u003ekey)[j+1] = (x-\u003ekey)[j]; (x-\u003ekey)[i] = (y-\u003ekey)[t]; printf(\"split-\u003e[%c]\\n\", (x-\u003ekey)[i]); x-\u003en++; DiskWrite(x); DiskWrite(y); DiskWrite(z); } 参数i的作用是定位孩子节点，(x-\u003ekey)[i]是提升子节点关键字的位置，(y-\u003ekey)[t]用t进行定位，得到需要被提升的关键字。除此之外，如果不是叶子情况，那么孩子节点都需要进行对应赋值。 然后开始插入过程： void Btree::BTree_Insert(char key) { bnode* r = root; if (r-\u003en == 2 * t - 1) { bnode *s = Allocate_Node(); root = s; s-\u003eleaf = false; s-\u003en = 0; (s-\u003ecp)[1] = r; BTree_SplitChild(s,1); BTree_Insert_NONFULL(s, key); } else BTree_Insert_NONFULL(r, key); } 因为Ｂ树是向上进行增长的，所以，分裂一般是在根节点发生的。比如，最小度数t=２的情况，根节点当插入了３个值准备进行第４个值的插入操作的时候，就会分配一个新的节点作为新的根节点，分裂，并且提升子关键字。 保证x.leaf正确性的理由是，从Insert函数分配的新根节点都是false值，但是在split函数中的是通过兄弟节点进行赋值才获取的值，也就是说，只有叶子节点的兄弟节点才是叶子节点。 完成这些准备后，才开始真正的插入操作过程： void Btree::BTree_Insert_NONFULL(bnode *x, char k) { int i = x-\u003en; if (x-\u003eleaf == true) { while (i \u003e= 1 \u0026\u0026 k \u003c (x-\u003ekey)[i]) { (x-\u003ekey)[i+1] = (x-\u003ekey)[i]; i--; } printf(\"insert : %c\\n\", k); (x-\u003ekey)[i+1] = k; x-\u003en++; DiskWrite(x); } else { while (i \u003e= 1 \u0026\u0026 k \u003c (x-\u003ekey)[i]) i--; i += 1; DiskRead((x-\u003ecp)[i]); if ((x-\u003ecp)[i]-\u003en == 2 * t - 1) { BTree_SplitChild(x, i); if (k \u003e (x-\u003ekey)[i]) // the new key comes from child node i += 1; } BTree_Insert_NONFULL((x-\u003ecp)[i], k); } } 由此可见，插入函数是不断地把关键字插入到叶子节点去，如果某个叶子节点满了的话，那么就会分裂该节点并且，提升一个关键字到父节点，如果该父节点也满了，那么递归进行分裂。在执行分裂后有一个小细节，如果从子节点提升的关键字比ｉ小，那么就要把这个节点插入到这个节点的右孩子中去，所以ｉ执行了加１的操作。 然后是删除操作了： 书上没有给出删除操作的伪代码，但是给出了不同情况的解决办法，我以我的理解对这些情况进行了扩充： 如果关键字ｋ在叶子节点ｘ中，并且该节点的元素不少于t-1，那么简单从ｘ中删除该关键字。 如果关键字ｋ在内部节点ｘ中，那么分三种情况: a.　如果该节点的左子节点包含大于等于t个关键字，那么可以从左子节点中找出前驱k'（最后一个元素）代替ｘ节点中的ｋ，然后递归删除左子节点中的k'。 b.　如果左子节点只含有t-1个关键字，那么从右子节点中找出后继k'（第一个元素），然后递归删除k'。 c.　如果左右子节点的关键字都是t-1个关键字，那么将k和右子节点都合并到左子节点，左子节点中的元素变为 2t-1　，然后释放右子节点并且递归删除k。 如果不在内部节点ｘ（叶子节点）中，那么需要在子节点中去删除,又可以分成两种情况： a.　如果孩子节点只有ｔ-1个关键字，但是前一个或者后一个子节点拥有至少t个关键字，那么就需要借一个关键字，也就是ｘ中的关键字k1下降到孩子节点中，然后从其他子节点中去偷取一个关键字k2，并且删除原来的k2关键字。 b.　如果相邻的子节点也都是只含有t-1关键字，那就要进行合并存在k的节点和任意一个节点，并且从x中下降一个关键字到新节点去，然后再简单删除关键字k。 下面是删除操作的实现： int Btree::BTree_Delete(bnode* x, char k) { int j = 1; // find k; while (j \u003c= x-\u003en \u0026\u0026 k \u003e (x-\u003ekey)[j]) j++; /** case 1: key 'k' is in the node x, and node x is a leaf node*/ if (x-\u003eleaf \u0026\u0026 x-\u003en \u003e t-1) { printf(\"case 1\\n\"); j += 1; // left shift while (j \u003c= x-\u003en) { (x-\u003ekey)[j-1] = (x-\u003ekey)[j]; j++; } x-\u003en--; // set nil while ((j-1) \u003c 2 * t ) { (x-\u003ekey)[j-1] = 0; j++; } printf(\"remove [%c]\\n\", k); DiskWrite(x); return 0; } else if (k == (x-\u003ekey)[j] \u0026\u0026 !(x-\u003eleaf)) { /** case 2:","date":"2018-09-09","objectID":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/:1:0","series":null,"tags":["algorithm"],"title":"算法与数据结构总结","uri":"/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/#b树"},{"categories":["sys"],"content":"文件类型stat函数簇(fstat,lstat, lstat, fstatat)是用来获取文件状态的函数，需要提前定义一个结构体struct stat来获取这些文件的特殊信息。 文件类型包括普通文件，目录文件，块特殊文件,字符特殊文件，ＦＩＦＯ，套接字，符号链接。可以向函数(S_ISREG(), S_ISDIR()…)传入结构体中的st_stat获取文件类型。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:1:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#文件类型"},{"categories":["sys"],"content":"文件访问权限 读权限允许我们读取目录，获得在该目录下的文件名列表，但是当某个目录是　路径名　的一部分的时候，必须有该目录的可执行权限。 在目录下创建一个文件，是需要对该目录有写权限和执行权限，删除一个文件也是一样，但是不需要对该文件有读写权限。 书上有一个关于access的实例，虽然有些文件可以不能通过可读权限，但是open()函数仍然能打开但是不能用read()等方法进行读操作。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:2:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#文件访问权限"},{"categories":["sys"],"content":"文件系统现代unix和以前学的有些不同，其中JOS不支持inode，但是还是有相似的地方。重新翻了下前面的文章。文件系统都有一个boot块用来自启，紧接着的是叫做super块来描述文件系统的性质，例如目录地址，上次检错时间等。现代unix在之后的磁盘块中以超级块副本，配置信息，Ｉ节点图，bitmap，ｉ节点，数据块依次排开构成文件系统。JOS就要简化了一些，因为不存在ｉnode，所以数据和目录都是放在bitmap后的数据块中。 硬链接是指inode的引用计数，当计数为０时才是真正从磁盘中擦去该目录项，保存在结构体stat的st_nlink中。 inode节点包含了文件所有信息，文件类型，文件访问权限位，文件长度，指向文件数据块的指针（JOS中的FILE结构体）。 $ mkdir test 该命令执行后，会创建一个新的文件目录，任何新目录创建后的引用数都为２．该test目录在创建后，父目录中的test指向该目录，以及test目录中的 .　也指向该目录，所以引用计数为２。 以此类推，其父目录的引用计数应该为３，１是该目录的父目录的指向，２是该目录下.文件的指向，３是test文件中..的指向。所以没创建一个文件目录，该目录的引用计数都会增加１。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:3:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#文件系统"},{"categories":["sys"],"content":"unlink当文件的引用计数为０时，就会从磁盘中擦去，像vim打开一个文件，填入内容保存后，就会在该目录下引用了这个普通文件，引用计数为１，使用unlink可以解除即删去该文件。 当一个程序用open()打开一个文件后，马上调用unlink()，那么只有当进程关闭改文件或者进程终止的时候，文件内容才被删除。 if (open(\"tempfile\", O_RDWR) \u003c 0) err_sys(\"open error\"); if (unlink(\"tempfile\") \u003c 0) err_sys(\"unlink errorr\"); ","date":"2018-08-14","objectID":"/apue-file-and-directory/:4:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#unlink"},{"categories":["sys"],"content":"符号链接符号链接是一种与硬链接相比较限制宽松的链接方式，不用接触到文件系统底层。 使用命令ln来创建一个符号链接 $ln -s ~/file file 然后使用 ls -l 查看文件 lrwxrwxrwx 1 moonlight users 26 Aug 14 16:07 sp -\u003e /home/moonlight/hotspot.py 可以看到对一个文件的链接，但是使用cat命令确并不存在。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:5:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#符号链接"},{"categories":["sys"],"content":"文件的时间最后访问时间(st_atim) ： 文件数据最后被read操作的最后一次时间。 最后修改时间(st_mtim) ： 文件数据内容最后被write操作修改的最后一次时间。 状态修改时间(st_ctim) ： 文件inode中信息(权限等)被修改的最后一次时间。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:6:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#文件的时间"},{"categories":["sys"],"content":"读目录这个两百多行的代码是当给定一个目录是，递归获取其目录下的所有文件，首先放在最前面的: typedef int Myfunc(const char *, const struct stat *, int); 是定义了一个返回类型为int，参数是const char*,const struct stat和int的函数指针类型。 然后声明: static Myfunc myfunc; 声明了一个类型为Myfunc，变量名为myfunc的函数指针，其中static关键词的作用是用于限定函数作用域。 接下来函数myftw为路径分配一段内存空间来存取路径大小，其中path_alloc是一个第二章的一个实例程序，用于兼容性地分配路径长度。 fullpath = path_alloc(\u0026pathlen); 此语句的作用是分配一段路径名长度加1的内存空间，最后一个字节存取/目录符号，然后进行赋值等操作后执行这个程序的主体dopath()。 这个函数的主要作用应该是分类文件，首先lstat获取文件信息，然后判断是否为目录文件，如果不是目录文件，直接跳转到myfunc进行更加细分的文件类型判断（如普通文件，符号文件，块文件，FIFO，字符文件，套接字等）。 func()是一种回调函数，当调用者将函数指针在调用的时候填入实参的位置时，那么函数就已经被登记，等func()进行调用的时候就相当于调用被登记的函数。 如果是目录文件，那么进行递归的准备工作，例如重新分配长度等。 fullpath[n++] = `/`; fullpath[n] = 0; 该语句的作用是将目录符号进行填充，然后用null截断文件路径。 while ((dirp = readdir(dp)) != NULL) { if (strcmp(dirp-\u003ed_name, \".\") == 0 || strcmp(dirp-\u003ed_name, \"..\") == 0) continue; strcpy(\u0026fullpath[n], dirp-\u003ed_name); if ((ret = dopath(func)) != 0) break; } 循环体用于遍历整个文件目录，然后将文件名复制到准备好的目录路径上，在递归查询这个新的文件路径。 fullpath[n-1] = 0; 这个语句的作用就是截断文件目录符号，返回查询上级目录的文件。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:7:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#读目录"},{"categories":["sys"],"content":"设备特殊文件每个文件系统所在的存储设备由主次设备号表示，主设备号表示设备驱动程序，次设备号表示特定的子设备，数据类型是dev_t。通常使用major,minor两个宏来访问主次设备号。st_dev存储了文件系统的设备号，st_rdev是只有块设备和字符设备才拥有的属性。 × minor和major宏是包含在文件/usr/include/sys/sysmacros.h中所以需要inlude \u003csys/sysmacros.h\u003e。 d ","date":"2018-08-14","objectID":"/apue-file-and-directory/:8:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#设备特殊文件"},{"categories":["sys"],"content":"writeup","date":"2018-08-14","objectID":"/apue-file-and-directory/:9:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#writeup"},{"categories":["sys"],"content":"4.1stat会跟随符号链接所指向的文件 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:9:1","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#41"},{"categories":["sys"],"content":"4.６首先用下面的程序创建一个空洞文件： #include \"apue.h\"#include \u003cfcntl.h\u003e int main(int argc, char *argv[]) { int fd = 0; char buf1[] = \"abcdefg\"; char buf2[] = \"ABCDEFG\"; off_t off = 65536; size_t memsz = off + strlen(buf1) + strlen(buf2); char* buf3 =(char*) malloc(memsz); memset(buf3, 32, memsz); /*hole file*/ if ((fd = open(\"file.hole\", O_CREAT | O_RDWR, S_IRUSR | S_IWUSR)) \u003c 0) err_sys(\"error open\"); int n = strlen(buf1); if (write(fd, buf1, n) != n) err_sys(\"error write buf1\"); if (lseek(fd, off, SEEK_CUR) \u003c 0) err_sys(\"error seek\"); n = strlen(buf2); if (write(fd, buf2, n) != n) err_sys(\"error write buf2\"); close(fd); /*nohole file*/ if ((fd = open(\"file.nohole\", O_CREAT | O_RDWR, S_IRUSR | S_IWUSR)) \u003c 0) err_sys(\"error open\"); if (write(fd, buf3, memsz) != memsz) err_sys(\"error write buf3\"); free(buf3); close(fd); exit(0); } 会创建一个file.hole和file.nohole的文件，使用du命令(disk usage)和ls来分别查看实际磁盘使用数，和在文件系统中使用的数量。 [moonlight@ArchLinux c4]$ ll file.* -rw------- 1 moonlight users 65550 Aug 23 16:46 file.hole -rw------- 1 moonlight users 65550 Aug 23 16:46 file.nohole [moonlight@ArchLinux c4]$ du file.* 8 file.hole 68 file.nohole 现在可以做下前面那一章的实验，分别使用cp和cat重定向到一个文件。 [moonlight@ArchLinux c4]$ cp file.hole hole.cp [moonlight@ArchLinux c4]$ cat file.hole \u003e hole.cat [moonlight@ArchLinux c4]$ ll hole* -rw-r--r-- 1 moonlight users 65550 Aug 23 16:59 hole.cat -rw------- 1 moonlight users 65550 Aug 23 16:59 hole.cp [moonlight@ArchLinux c4]$ du hole.* 68 hole.cat 8 hole.cp cat遇到文件空洞会进行填０操作，而cp遇到文件空洞则是跳过，所以占用的实际磁盘块不同，文件系统的逻辑大小不会发生改变。Linux的read()遇见空洞也是跳过，所以可以完成一个类似程序。 #include \"apue.h\"#include \u003cfcntl.h\u003e#define BFSZ 4096 int main(int argc, char *argv[]) { int fd1, fd2; int n; char buf[BFSZ]; if (argc != 3) err_sys(\"usage: cp file1 file2\"); if ((fd1 = open(argv[1], O_RDONLY)) \u003c 0) err_sys(\"open file error :%s\", argv[1]); if ((fd2 = open(argv[2], O_RDWR|O_TRUNC|O_CREAT, S_IRUSR|S_IWUSR)) \u003c 0) err_sys(\"open file error :%s\", argv[2]); while ((n = read(fd1, buf, BFSZ)) != 0) { if (write(fd2, buf, n) != n) err_sys(\"write error\"); } exit(0); } ","date":"2018-08-14","objectID":"/apue-file-and-directory/:9:2","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#4６"},{"categories":["sys"],"content":"4.17注: 删除文件需要有该目录的可写权限和可执行权限。 ","date":"2018-08-14","objectID":"/apue-file-and-directory/:10:0","series":null,"tags":["unix","file","c/c++"],"title":"apue-file and directory","uri":"/apue-file-and-directory/#417"},{"categories":["sys"],"content":"写在前面的话暑期撸了一阵子算法导论，在红黑树的删除操作卡主了，暂时放下算法，稍微看看别的计算机知识，APUE是一本关于Linux下C语言API的书籍，中间穿插了关于UNIX操作系统的知识，趁这个机会，利用6.828的知识，来提高下在linux下的编程水平，比完赛回来后，换成了arch linux，这是一款非常轻量级的操作系统，比较适合用来做自己的开发环境，另一方面也减少了游戏对自己的干扰。 本书第一章节主要讲的标准输入输出的一些基本操作，第二章提到了一些POSIX的标准，快速浏览一遍就好。 ","date":"2018-08-11","objectID":"/apue-chapter3/:0:0","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#写在前面的话"},{"categories":["sys"],"content":"学习笔记 ","date":"2018-08-11","objectID":"/apue-chapter3/:0:0","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#学习笔记"},{"categories":["sys"],"content":"文件描述符文件描述符这个概念已经比较熟悉了，是一个 0~OPEN_MAX-1 的正整数，也是一个程序中方便操作的对象。一般来说，0代表的标准输入，1代表标准输出，2代表的是标准错误输出。 ","date":"2018-08-11","objectID":"/apue-chapter3/:1:0","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#文件描述符"},{"categories":["sys"],"content":"open()标志位O_RDONLY : 只读打开 O_WRONLY : 只写打开，后面会发现如果尝试读取只写的文件会出现乱码 O_RDWR : 读写打开 O_EXEC : 只执行打开 O_SEARCH : 用于搜索* 以上是打开文件必须选择的标志 O_APPEND : 附加 O_CLOEXEC: 这个以前做过验证: 链接 O_CREAT : 不存在就创建 O_EXCL : 在创建文件时，如果指定了该标志位，文件存在，那么open返回失败值 O_DIRECTORY: 目录判断 O_NOFOLLOW: 需要是非链接文件 O_NOBLOCK : 以非阻塞模式打开FIFO，块设备，字符特殊文件 O_SYNC : 每次write都需要写入磁盘(同步写)，然后等待磁盘返回 O_TRUNC: 打开已存在的文件，并且将长度截为0，也就是原来的文件内容不能再进行访问，文件变为新文件,需要有写权限。 *O_TTY_INIT/O_DSYNC/O_RSYNC 还不清楚 ","date":"2018-08-11","objectID":"/apue-chapter3/:2:0","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#open标志位"},{"categories":["sys"],"content":"习题 writeup","date":"2018-08-11","objectID":"/apue-chapter3/:3:0","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#习题-writeup"},{"categories":["sys"],"content":"3.3在该题目中，fd1和fd2当然都指向同一个文件表，因为执行了dup操作，所以相关的文件描述符标志等信息都会被复制，对于fd3，我理解为这是打开的同一个文件，在自己尝试写出的代码中，可以反复打开同一个文件多次，但是不会指向同一个文件表项。 首先打开两个相同的文件 fd1 = open(\"file\", O_RDONLY); fd2 = open(\"file\", O_RDONLY); 然后读取分别读取fd1，fd2几个字符，再用lseek()获取当前文件偏移。 read(fd1, buf, 3); off1 = lseek(fd1, 0, SEEK_CUR); read(fd2, buf, 5); off2 = lseek(fd2, 0, SEEK_CUR); 结果显示这两个文件偏移off1和off2并没有相互叠加。 read: abc read: abcde fd1 off: 3, fd2 off: 5 这就是说明，一个程序用open()打开文件多次的话，不同的fd会指向不同的文件表项，其中包含了“当前文件偏移量”，及时都是指向的同一个文件。 ","date":"2018-08-11","objectID":"/apue-chapter3/:3:1","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#33"},{"categories":["sys"],"content":"3.6我自己测试的程序实际上是可以任意位置读写的，和书上的答案有所不同。首先是打开文件，然后用lseek()定位到一个任意位置开始读取一定长度的字符: lseek(fd, 1, SEEK_SET); read(fd, buf, 32); printf(\"read file(seek (1)):%s\\n\", buf); 然后再一次使用lseek()继续定位一个位置，再进行写操作。 lseek(fd, 1, SEEK_SET); write(fd, buf2, sizeof(buf2)/sizeof(*buf2)); 实际上，lseek可以定位到任意位置，也就是可以大于文件字符大小，造成文件空洞的现象。 ","date":"2018-08-11","objectID":"/apue-chapter3/:3:2","series":null,"tags":["file","c/c++","I/O"],"title":"apue-file I/O","uri":"/apue-chapter3/#36"},{"categories":["sys"],"content":"这章节是完成一个网络驱动程序，现在系统中已经存在了文件系统里，所以可以添加一个网络栈，是基于82540EM芯片(E1000)。这章节内容比我想象中难，虽然之前概览了一下，但是实际做起来的时候涉及到的概念和知识超出我现在所掌握的。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#"},{"categories":["sys"],"content":"准备git $ git add . $ git commit -am \"lab 5 done\" $ make handin $ git pull $ git checkout -b lab6 origin/lab6 $ git merge lab5 Auto-merging lib/fd.c Auto-merging kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c Auto-merging inc/lib.h Auto-merging fs/serv.c Merge made by the 'recursive' strategy. boot/main.c | 1 - fs/bc.c | 22 +- fs/fs.c | 73 +- .... user/faultio.c | 2 +- user/forktree.c | 1 + user/sh.c | 9 +- user/testfile.c | 5 + 33 files changed, 14503 insertions(+), 111 deletions(-) 除了完成网卡驱动，还需要 1.创建一个系统调用接口来访问驱动。 2.实现服务器和驱动网络栈传输数据包的代码。 3.完成一个web服务器 数据包调试 tcpdump -XXnr qemu.pcap 或者使用wireshark也行。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#准备"},{"categories":["sys"],"content":"网络服务从零开始实现一个网络栈(协议栈)是一件非常困难的事情。所以会用到一个轻量级的开源的TCP/IP协议簇LwIP(lightweight IP)来实现接下来的工作。在这里需要把LwIP看成一个黑箱，它是实现了BSD的套接字接口到了输出端口和输入端口。\\ 所以网络服务实际上就是4个环境(进程)的结合： 核心网络服务器环境(套接字分发和LwIP) 套接字调用调度工作方式很像文件服务，用户环境使用存根stubs(lib/nsipc.c)发送IPC信息到核心网络环境。i386_init创建一个NS_TYPE_NS类型的NS环境，然后扫描envs这个全局变量可以找到特殊的环境。对于任何一个用户环境，网络服务中的调度器调用合适的由LwIP提供的BSD套接字接口函数。 普通的用户环境使用lib/sockets中的函数发送sokets，这是基于文件描述符的套接字API。就像之前使用磁盘中的文件一样，用户环境使用套接字也是通过文件描述符。像connect，accept操作指定接收类型为套接字，而read，write等操作是通过接收普通的文件描述符，所以可通过LwIP为开启的套接字生成的独一无二的ID映射到对应的文件描述符上。 文件服务和网络服务中的IPC分发工作即使相同，但有一点关键不同的在于BSD套接字调用accept和recv能够无尽的阻塞。如果分发器让LwIP执行一个阻塞操作，这整个系统都会被阻塞，所以网络服务使用用户级别的线程去避免阻塞整个服务。对于到来的IPC消息，分发器创建一个线程并且处理这个请求。如果线程阻塞了，那么只有该线程被置为睡眠状态而其他线程仍在运行。 输出环境 当用户环境的套接字服务函数被调用，IwIP将会生成一个被网卡传输的数据包。核心网络环境将通过IPC信息并把要发送的包作为共享页给输出环境，那么接下来输出环境将会接收这些信息并且将这些包通过网卡驱动发送出去。 输入环境 网卡收到包之后需要注入到LwIP中去，对于每一个通过设备驱动接收到的包，输入环境将会把这些包调出内核空间并且用IPC将包发送到核心服务环境中去。 计时器环境 计时器环境周期性的发送NSREQ_TIMER到核心网络服务提醒计时器已经过期了，这个环境被用作多种网络的超时报告。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#网络服务"},{"categories":["sys"],"content":"初始化并且发送包现在内核还没有时间的概念，现在需要加上这个，时钟中断是每10ms发送一次，所以当时钟中断发生的时候，自增一个变量让时间前进。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#初始化并且发送包"},{"categories":["sys"],"content":"练习 1当时钟中断发生的时候，调用time_tick来自增时间 实现sys_time_msec使得用户环境能获取当前时间 trap.c # trap_dispatch() if (tf-\u003etf_trapno == IRQ_OFFSET + 0) { time_tick(); lapic_eoi(); //cprintf(\"clock interrput: \"); sched_yield(); } sys_time_msec static int sys_time_msec(void) { // LAB 6: Your code here. //panic(\"sys_time_msec not implemented\"); return time_msec(); } ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习-1"},{"categories":["sys"],"content":"网卡接口接下来就是准备写网卡驱动，但是需要知道硬件和接口怎么在软件中表示。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#网卡接口"},{"categories":["sys"],"content":"练习 2练习2的任务阅读Intel手册关于E1000的部分，章节2概览，章节3和14细节。 E1000是一种非常复杂的设备并且拥有很多优越的特性，只需要利用很少的一部分E1000的特性和接口就能完成工作。 这里不得不重新审视下驱动，驱动程序是计算机操作和控制特殊类型的被附加到计算机的设备，为硬件提供软件的接口，使得操作系统或者其他程序能访问硬件功能(hardware function)但是不需要直到使用硬件的细节。绝大多数驱动都是运行在内核态，操作硬件资源，访问底层资源。 第二章节我关注了几个点 DMA Engine and Data FIFO DMA 寻址 网络数据都是字节流，所以确认处理器处理的方式和网卡控制器需要以相同的方式处理字节流，PCI是使用的little-endian，低位字节排放在内存的低地址端。 以太网控制器中有几个存放以太网物理地址的寄存器，两个32位的寄存器组成地址，RAH(Receive Address High)和RAL(Receive Address Low)。 // todo： 为什么mac地址是6个字节？并不方便两个寄存器处理。 以太网帧从外部发来后，字节流从左往右对应，处理数据。比如地址00_AA_00_11_22_33h，除去帧的其他部分，首先出现在总线上的是最低有效位的0bit位。这里涉及到了一个组播比特位，详情可看这里，组播的话该最先出现的位会被置为1。最后处理完后在缓冲区的情况如下: 顺便复习下mac帧的结构和作用 中断 也就是外部中断发送到I/O APIC，接收到外部中断后，cpu开始执行相应的外部中断处理程序，在这，就是处理网络包。 卸载检验和 以太网控制器会将IP分组,TCP/UDP数据报中的检验和卸载下来，硬件会自动计算，插入并且检测检验和，但是检验和的值是由软件提供的。 缓冲和描述符结构 驱动会分配传输和接收缓冲，并且会形成一个描述符指向缓冲的地址和状态。驱动为硬件准备一个队列缓冲用来接收，一旦合法的数据包到达后，接收了数据的缓冲将为驱动所有。为了传输数据包，驱动自身会维护一个队列缓冲，当这个缓冲中数据已经可以准备发送时，驱动将会把这个缓冲提交给硬件，然后硬件接下来就会读取缓冲中的数据并且以FIFO的方式发送数据包。 描述符指定了1. 缓冲物理地址 2. 缓冲长度 3. 缓冲状态和命令信息 4. 指向数据包尾部的指针 5. 数据包的类型 6. 硬件需要对数据包的操作(VLAN或者卸载检验和) ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习-2"},{"categories":["sys"],"content":"PCI 接口E1000网卡是PCI(Peripheral Component Interconnect)设备，这意味着网卡是插在主板PCI总线上的，PCI总线包含了地址数据中断线，允许CPU和PCI设备进行交互，并且PCI设备能读写内存。PCI设备需要在使用前被发现并且初始化。 发现过程就是通过遍历PCI总线寻找附加的设备，初始化过程就是分配I/O和内存空间并且商榷IRQ线的使用权。当找到设备的时候，可以读到设备的vendor ID和device ID。JOS中使用这两个键在pci_attach_vendor中找寻值。并且将这两个键组合成一个结构体，并包含一个回调函数执行设备初始化。 struct pci_func { struct pci_bus *bus; uint32_t dev; uint32_t func; uint32_t dev_id; uint32_t dev_class; uint32_t reg_base[6]; uint32_t reg_size[6]; uint8_t irq_line; }; 反映了初始化的寄存器，其中reg_base基地址寄存器BARs（Base Address Registers），reg_size应该类似于基地址偏移确认IO端口。 当pci_device结构体中的函数被调用的时候，设备已经被发现了，但是仍没被启用。这意味着PCI仍然没有为设备分配资源，例如内存空间，IRQ线，基地址寄存器等在结构体中的信息也没有被填入，所以需要调用pci_func_enable来完成这些工作。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#pci-接口"},{"categories":["sys"],"content":"练习 3实现一个附加函数去初始化E1000 如果在pci_attach_vendor数组找到了PCI设备，提供一个入口来触发初始化函数(确定该PCI键是放在{0, 0, 0}结束标志前的)。 vendor ID和device ID信息: 然后通过pci_func_enable函数来启动pci设备，完成kern/e1000.c和kern/e1000.h 启动时先从i386_init开始执行到pci_init，再紧接着调用pci_bus_scan将总线中的设备扫描出来，并且把这些信息存到一个临时的pci_func结构体中，最后调用pci_attach函数在pci_attach_class或者pci_attach_vendor用vendorID和DeviceID找寻相应的attach function并且调用这个回调函数。 pci_attach_match if (list[i].key1 == key1 \u0026\u0026 list[i].key2 == key2) { int r = list[i].attachfn(pcif); 这里就是在list(class或者vendor数组)用键索引，然后调用attachfn来完成启动。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习-3"},{"categories":["sys"],"content":"e1000.c#include \u003ckern/e1000.h\u003e // LAB 6: Your driver code here //extern struct pci_func; int e1000_attach(struct pci_func *pcif) { pci_func_enable(pcif); return 1; } ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:1:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#e1000c"},{"categories":["sys"],"content":"pci.cstruct pci_driver pci_attach_vendor[] = { { 0x8086, 0x100e, \u0026e1000_attach }, { 0, 0, 0 }, }; ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:2:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#pcic"},{"categories":["sys"],"content":"内存映射IO软件与E1000芯片通过MMIO(memory-mapped I/O)，之前已经接触过两次，CGA控制台和LAPIC，控制和请求都是通过读写这些内存。但是实际上这些读写操作不会通过DRAM，而是直接操作到设备上去。init过程中，JOS先执行的内存映射，也就是说之前映射这些IO内存的读写是通过bus(?)直接进行的，往LAPIC映射的内容写入值，就是发送IPC信息。 pci_func_enable选定一个合适的MMIO区域为E1000使用，并且存储基地址和偏移到BAR 0(reg_base[0]和reg_size[0])中，然后这部分物理内存地址将会赋值给设备，和之前一样，MMIO区域通常是一个很高的物理地址，所以需要将其映射到MMIOBASE中，虽然LAB4中已经使用了这部分区域，但是设置了一个静态变量static uintptr_t base在映射之后会自增映射后的大小，保证不会被重写覆盖。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#内存映射io"},{"categories":["sys"],"content":"练习4在attach function中，通过调用为E1000的BAR 0创建一个虚拟内存的映射 struct pci_func; extern void *mmio_map_region(physaddr_t, size_t); int e1000_attach(struct pci_func *pcif) { volatile uint32_t *mmio_e1000; //negotiates an MMIO region pci_func_enable(pcif); //map to MMIOBASE mmio_e1000 = mmio_map_region(pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"base: %x size: %x \\n\", pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"E1000 STATUS REGISTER VALUE: %x\\n\", *(mmio_e1000+2)); return 1; } pci_func_enable已经填入了合适的地址到了BAR0中去了，简单调用mmio_e1000就好。文件kern/pcireg.h中的状态寄存器偏移为0x04但是Hint提供的偏移是0x08,验证后是后者正确。 映射的地址指针应该声明为volatile，防止编译器优化让缓存记录访问改地址的值。 文档Table 13-5指出了该寄存器的6,7位的值表达了最大传输速度，1000MB/s对应的位设置应该10与0x80080783转换为二进制后6，7位的值相同。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习4"},{"categories":["sys"],"content":"DMA传输数据包通过读写上个练习中被映射的内存块是一种办法，但是这样太慢了，因为E1000自身需要缓冲包数据。所以E1000使用直接内存访问DMA(Direct Memory Access)来进行内存读写而不需要唤醒CPU。 CPU首先初始化数据传输，然后CPU去执行其他操作，当数据接收完后从DMA控制器发送一个中断告诉CPU已经传输完成了，这样就可以达到异步传输，从而提高处理速度。 驱动为传输和接收队列分配内存，设置DMA描述符，并让E1000定位这些队列，所以接下来的任务将会是异步执行。 为了发送数据包，驱动程序将会复制数据包到在传输队列的下一个DMA描述符中去并且告诉E1000有数据包可以进行发送了，E1000会在空闲状态的时候将数据从描述符中复制出来。相同地，当E1000接收到了数据包，E1000将数据复制到接收队列的下一个DMA描述符去，驱动有机会便会读取这个数据包对应的描述符。 接收和传输队列是非常相似的，都是由描述符序列组成，虽然这些描述符的确切结构各不相同，但每个描述符都包含一些标志和包含分组数据的缓冲区的物理地址。队列由环形数组组成，实现着队列用到的head pointer 和 tail pointer以及数据包缓冲的地址都必须是物理地址，因为硬件直接使用DMA访问内存而不会通过MMU。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#dma"},{"categories":["sys"],"content":"发送数据包E1000的接收功能和发送功能是相互独立的，首先必须为发送数据包初始化网卡，接下来的步骤在手册section 14.5。 设置传输队列 精确的结构体设置在章节section 3.4，描述符的结构体的设置在section 3.3.3 暂时不关系TCP的卸载特性，只需要关注遗留传输描述符格式(legacy transmit descriptor format) ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#发送数据包"},{"categories":["sys"],"content":"C 结构体使用C结构体描述E1000结构是很方便的，像之前的Trapframe结构体能够精确的安置数据在内存中，并且能在不同数据域填充空字节，虽然e1000没有这样的问题。如果遭遇了域对齐的问题，查看GCC的packed attribute。 合法传输描述符应该如下: 63 48 47 40 39 32 31 24 23 16 15 0 +---------------------------------------------------------------+ | Buffer address | +---------------+-------+-------+-------+-------+---------------+ | Special | CSS | Status| Cmd | CSO | Length | +---------------+-------+-------+-------+-------+---------------+ 驱动应该为传输描述符数组和描述符所指的数据包缓冲保留内存空间，例如将描述符结构体声明为一个全局变量。 最简单的办法去处理数据包缓冲区是在驱动初始化的时候为数据包缓冲保留空间，将复制的数据包复制到这个预先分配的缓冲区中。以太网包最大大小为1518字节，缓冲区应该分配这么多。很多复杂先进的驱动能够动态分配缓冲区缓冲(能够在网络利用率很低的时候减少内存消耗)，甚至直接在用户态下提供缓冲。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#c-结构体"},{"categories":["sys"],"content":"练习5实现14.5中的初始化步骤，13节提供了初始化步骤中的寄存器信息。 3.3.3和3.4提供传输描述符和传输描述符数组。 初始化传输 为传输描述符链分配一个内存区域，并且需要保证这部分内存是16byte内存对齐。 设置传输描述符基地址寄存器TDBAL/TDBAH(Transmit Descriptor Base Address)，32位只使用TDBAL。 设置传输描述符长度寄存器TDLENR保存描述符环的大小，值必须是128字节对齐的 传输描述符头尾寄存器TDH/TDT在加电后被硬件或者以太网控制器初始化为0B，驱动需要确认写入了0B到这两个寄存器。 初始化传输控制寄存器TCTL TCTL.EN(enable)置为1b TCTL.PSP(Pad Short Packet)置为1b 配置碰撞阈值TCTL.CT(Collision Threshold)为以太网标准值10h，半双工模式(half duplex mode) 配置碰撞距离TCTL.COLD，全双工设置为40h，1000Mb/s半双工的值应该为200h，10/100Mb/s的值应该设置为40h 配置Transmit IPG寄存器，设置为最小合法数据包间隔legal Inter Packet Gap。 struct TD transmit_desc_list[32] __attribute__ ((aligned (PGSIZE))) = { 0 }; struct packet buffer[32] __attribute__ ((aligned (PGSIZE))) = { 0 }; #define PBUFSZ 2048 volatile uint32_t *mmio_e1000; int e1000_attach(struct pci_func *pcif) { //negotiates an MMIO region pci_func_enable(pcif); desc_init(); //map to MMIOBASE mmio_e1000 = mmio_map_region(pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"base: %x size: %x \\n\", pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"E1000 STATUS REGISTER VALUE: %x\\n\", *(mmio_e1000+2)); //ex5: transmition initilizes transmit_init(); return 1; } static void desc_init() { int i; for(i = 0; i \u003c 32; ++i) { memset(\u0026transmit_desc_list[i], 0, sizeof(struct TD)); transmit_desc_list[i].addr = PADDR(\u0026buffer[i]); transmit_desc_list[i].status = TXD_STAT_DD; // transmit_desc_list[i].cmd = TXD_CMD_RS | TXD_CMD_EOP; } } int transmit_init() { //TD Base Address register pciw(E1000_TDBAL, PADDR(transmit_desc_list)); pciw(E1000_TDBAH, 0); //TD Descriptor Length register pciw(E1000_TDLEN, 32 * sizeof(struct TD)); //TD head and tail register pciw(E1000_TDH, 0x0); pciw(E1000_TDT, 0x0); //TD control register pciw(E1000_TCTL, TCTL_EN | TCTL_PSP | (TCTL_CT \u0026 (0x10 \u003c\u003c 4)) | (TCTL_COLD \u0026 (0x40 \u003c\u003c 12))); //Transmit Inter Packets Gap register pciw(E1000_TIPG, 10 | (8 \u003c\u003c 10) | (12 \u003c\u003c 20)); return 0; } 现在传输已经被初始化了，需要完成一部分代码使得用户空间能通过系统调用发送数据包。为了传输数据包，必须将数据包放在传输队列的尾部，即复制数据包的数据到下一个数据包的缓冲并且更新TDT寄存器告知网卡已经有另外一个数据包在传输队列中了。(TDT是传输描述符数组的索引，不是字节偏移) 然而，传输队列只有这么大，传输队列可能会完全被塞满。为了检测这种情况，需要从E1000芯片中获取一些反馈。文档说明TDH寄存器是不知道信任的，但是如果设置了在传输描述符CMD域RS bit位，接下来，当网卡已经发送了这个描述符的数据包后，网卡将会设置文件描述符状态域的DD比特位，那么这很安全去回收这个描述符，并且使用这个描述符去传输另一个包。 如果用户调用传输系统调用，但是下个描述符没有设置DD比特位，接下来的代码需要解决这种情况，可以仅仅通过丢弃这个包来实现。网络协议能够恢复部分(重传)，但是如果一瞬间丢掉了大量的包，网络协议将可能不能恢复。取而代之的方法是需要告诉用户环境需要重新尝试，就像之前完成的sys_ipc_try_send。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习5"},{"categories":["sys"],"content":"练习6完成一个函数传输数据包通过检测下一个描述符是否被释放，复制数据包数据到下一个描述符，更新TDT。保证你解决了当传输队列还是满的情况。 int transmit(void *addr, size_t len) { uint32_t tail = mmio_e1000[E1000_TDT]; struct TD *next_desc = \u0026transmit_desc_list[tail]; if ((next_desc-\u003estatus \u0026 TXD_STAT_DD) != TXD_STAT_DD) return -1; if (len \u003e PBUFSZ) len = PBUFSZ; memmove(\u0026buffer[tail], addr, len); next_desc-\u003elength = len; next_desc-\u003estatus \u0026= !TXD_STAT_DD; mmio_e1000[E1000_TDT] = (tail+1) % 32; cprintf(\"status register value: %x\\n\", *(mmio_e1000+2)); cprintf(\"send : %s\\n\", addr); return 0; } 现在可以检测传输代码。发送少量包直接通过内核调用传输函数。使用make E1000_DEBUG=TXERR,TX qemu去测试，能够看到 e1000: index 0: 0x271f00 : 9000002a 0作为传输包。每一行都会给出传输数组的索引，传输描述符的缓冲地址，cmd/cso/length和special/css/status域。 当QEMU允许的时候，执行tcpdump -XXnr qemu.pcap查看发送出去的数据包内的数据。 可以在monitor.c中添加一个测试函数，执行发送函数。执行完后，E1000的DEBUG命令回自动保存这个流量包到qemu.pcap文件中。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习6"},{"categories":["sys"],"content":"练习7为数据包的传输创建一个系统调用，并且检查传输过去的指针。 lib/syscall.c int sys_transmit(void *addr, size_t len) { return syscall(SYS_transmit, 1, (uint32_t)addr, len, 0, 0, 0); } kern/syscall.c // transmit packets // return -1 if the transmition failed. static int sys_transmit(void *addr, size_t len) { user_mem_assert(curenv, addr, len, PTE_U); return transmit(addr, len); } sudo apt-get remove –auto-remove qemu-system-x86 git clone http://web.mit.edu/ccutler/www/qemu.git -b 6.828-2.3.0 网络服务器 现在拥有了一个系统调用的接口从设备驱动这端传输数据，现在可以用来发送数据包了。这个输出帮助环境的目标是做接下来这个循环：接收NSREQ_OUTPUT 来自网络服务器内核的IPC消息和利用前面写的系统调用来发送IPC消息。 NSREQ_OUTPUT IPC消息由low_level_output函数来发送，依附于LwIP栈。每一个IPC都会包含一个由union Nsipc和struct jif_pkt组成。 结构体jif_pkt中的jp_len表示了数据包的长度。所有接下来的字节是数据包的内容。这个长度为0的数组一C语言的一个小技巧，就好像jp_data就是指向结构体的末尾，因为缓冲区是没有提前声名长度的。因为C语言不会做数组边界检查，只要保证在这个结构体后面有足够的未使用的内存，就能使用jp_data来指定任意数组大小。 注意当传输队列中没有足够的空间的时候，设备驱动，输出环境和网络服务内核的交互。网络服务内核利用IPC发送数据包到输出环境。如果输出环境环境因为设备驱动没有足够的缓冲而被暂停，那么网络服务将会被阻塞直到输出环境接收了IPC调用。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习7"},{"categories":["sys"],"content":"练习8实现net/output.c中的功能 void output(envid_t ns_envid) { binaryname = \"ns_output\"; union Nsipc output; int perm; envid_t envid; // LAB 6: Your code here: // - read a packet from the network server // - send the packet to the device driver while (1) { if (ipc_recv(\u0026envid, \u0026nsipcbuf, \u0026perm) != NSREQ_OUTPUT) continue; while (sys_transmit(nsipcbuf.pkt.jp_data, nsipcbuf.pkt.jp_len) \u003c 0); } } 使用tcpdump打开pcap.qemu，这样就能看到发出ARP数据包。 Q1:How did you structure your transmit implementation? In particular, what do you do if the transmit ring is full? 在循环队列中不断检测下一个描述符的位置是否合法，通过while循环多次访问直到空闲。 PartB: 接收数据包 就像发送数据包，现在将配置E1000芯片来接收数据包并且提供接收描述符队列和接收描述符。手册3.2章节描述了数据包如何工作，包括接收队列结构体和接收描述符，以及初始化进程的细节(章节14.4)。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习8"},{"categories":["sys"],"content":"练习9阅读手册3.2章节 通常数据的接收需要识别在线缆上的数据包，过滤地址，以FIFO方式存储数据，从接收缓存传输到主存中去，并且更i新年接收描述符。 包地址过滤 硬件存储即将到来的包到主存中通过过滤规则管理。如果没有足够的空间，硬件将会选择丢弃数据包，并且指出这个数据包丢失了。一般来说，只有号的数据包被接收，比如数据包没有CRC错误，符号错误，队列错误，长度错误，对齐错误等等。当然，如果设置了相关控制寄存器(RCTL.SBP)，那么这些坏包能被接收到(RDESC.ERRORS)接收描述符中。 接收描述符 一旦数据包被以太网控制器接收了，硬件将会存储数据包到指定的缓冲并且填写长度，包的检验和，状态，错误等状态域。长度是整个被写入缓冲区的长度包括CRC校验位。软件必须读取多个描述符确认数据包是完整的。 接受描述符状态域 状态信息指出描述符是否被使用了和相关的缓冲是否是数据包的最后一个。 捕捉接收描述符 描述符捕捉策略是被设计去支持通过PCI总线的大量数据包的。捕捉算法尝试去最大利用PCI带宽通过缓冲线。 当一个芯片缓冲区是空的，一旦任意描述符可以使用，一次捕捉将会发送，软件将会写入到tail指针。当缓冲区几乎要空的时候，只要有足够的有效描述符就会执行一次预先捕捉并且没有其他更高优先级的PCI活动。 回写接收描述符的避免 关于回写: 一种称为“穿透”(Write-Through)模式，在这种模式中高速缓存对于写操作就好像不存在一样，每次写时都直接写到内存中，所以实际上只是对读操作使用高速缓存，因而效率相对较低。 另一种称为“回写”(Write-Back)模式，写的时候先写入高速缓存，然后由高速缓存的硬件在周转使用缓冲线时自动写入内存，或者由软件主动地“冲刷”有关的缓冲线。 接收描述符队列结构 软件通过写到队尾指针来添加有效的描述符，当一个数据包到达的时候，硬件将会存储这个数据包，并且自增头指针。当头指针域尾指针相等的时候，队列环就处于空的状态。硬件停止存储数据包到系统内存中直到然间前进了尾指针，让更多接收缓冲可用。 头尾指针分别引用一个16Bytes的内存块。 图中阴影部分表示描述符已经存储了到来的数据包但是未被软件识别。 地址过滤器 MAC：mac地址过滤器检测MAC目的地址来保证该地址是否有效，接收配置的设置决定了哪一个物理地址被接收。 IPv4：检测有效的IPv4头，域值应该为4. UDP/TCP:检测合法的UDP/TCP头，原型值分别为11h和06h。 SNAP/VLAN/IPv6 接收队列与传输队列非常相似，除了接收队列需要等待被即将到来的数据包填满。因此，当网络是空闲状态的时候，传输队列应该是空的，而接收队列的缓冲区应该是满的(尾指针和头指针相等)。 当E1000芯片就收到了数据包，首先检测器是否满足网卡配置的过滤规则。否则，E1000会尝试从接受队列中取回下一个接收描述符。如果头指针已经等于了尾指针，那么说明接收兑率已经没有空闲的描述符，所以会丢弃数据包。如果有空闲的描述符，将会复制数据包数据到描述符所指到的缓冲区，并且设置描述符DD域和EOP域的状态比特位，并且自增头指针。 E1000如果接收到了一个数据包大于一个接受描述符的数据包缓冲，那么将会尽可能多的从接收队列中获取描述符并且存储完整的数据包内容。为了指出这种情况发生了，那么这个数据包所用的描述符都会标记DD比特位，但是EOP状态为只有最后一个描述符标记了。你能处理这种可能发生的可能性，也可以简单地不接受这种大数据包来保证所接收到缓冲区的数据包不会大于标准的以太网数据包1518字节。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习9"},{"categories":["sys"],"content":"练习10设置好接受队列并且根据手册14.4章节配置E1000(跳过中断和CRC) 默认情况下，网卡会过滤所有的数据包，所以必须去配置接收地址寄存器拥有一个MAC地址为了让数据包能够寻址到该网卡。可以使用QEMU默认的MAC地址52:54:00:12:34:56，MAC地址的字节序是从低序写到高序的，所以52:54:00:12在低32比特，而34:56在高16位。 E1000只支持一个特定的接收缓冲区大小，如果数据包缓冲区足够大并且禁用了长数据包的接收，你不用担心数据包旋转在多个接收缓存。就像传输队列，数据缓冲必须是连续的物理内存。 这里必须使用至少128接收描述符。 设置地址接收寄存器为QEMU的MAC地址，从左往右代表从低到高字节序，并且需要设置RAH寄存器的‘Address valid’标志位。 设置接收循环队列的基地址寄存器RDBAH/RDBAL 设置描述符长度寄存器RDLEN 设置队列头尾指针，与传输队列不同，接收队列的头指针与尾指针相等代表没有描述符可用，会发生丢包的情况 设置一些相关的控制寄存器。 接收描述符 struct RD { uint64_t addr; uint16_t length; uint16_t checksum; uint8_t status; uint8_t errors; uint16_t special; }__attribute__((packed)); //same as lapicw(), read after write. int e1000_attach(struct pci_func *pcif) { //negotiates an MMIO region pci_func_enable(pcif); desc_init(); //map to MMIOBASE mmio_e1000 = mmio_map_region(pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"base: %x size: %x \\n\", pcif-\u003ereg_base[0], pcif-\u003ereg_size[0]); cprintf(\"E1000 STATUS REGISTER VALUE: %x\\n\", *(mmio_e1000+2)); //ex5: transmition initilizes transmit_init(); //ex10: reception inistiizes recv_init(); return 1; } static void desc_init() { int i; // transmit for(i = 0; i \u003c 32; ++i) { memset(\u0026transmit_desc_list[i], 0, sizeof(struct TD)); transmit_desc_list[i].addr = PADDR(\u0026buffer[i]); transmit_desc_list[i].status = TXD_STAT_DD; transmit_desc_list[i].cmd = TXD_CMD_RS | TXD_CMD_EOP; } // receive for (i = 0; i \u003c RECVNUM; ++i) { memset(\u0026recv_desc[0], 0, sizeof(struct RD)); recv_desc[i].addr = PADDR(\u0026rbuf[i]); recv_desc[i].status = RXD_STAT_DD | RXD_STAT_EOP; } } int recv_init() { //Receive Address Register //pciw(E1000_RA, 0x52540012); pciw(E1000_RA, 0x12005452); pciw(E1000_RA+1, 0x5634 | E1000_RAV); //Multicast Table Array for (int i = 0; i \u003c 128; i++) pciw(E1000_MTA+i, 0); //Base Address register pciw(E1000_RDBAL, PADDR(recv_desc)); pciw(E1000_RDBAH, 0); // Descriptor Length pciw(E1000_RDLEN, sizeof(struct RD) * RECVNUM); // head and tail register pciw(E1000_RDH, 0); pciw(E1000_RDT, RECVNUM-1); pciw(E1000_RCTL, RCTL_EN | RCTL_LPE | RCTL_LBM_NO | RCTL_SZ_2048 | RCTL_SECRC); return 0; } 完成这部分驱动后，即使没有完成接收数据包的代码，运行make E1000_DEBUG=TX,TXERR,RX,RXERR,RXFILTER run-net_testinput将会发送一个ARP数据包可以看到如下的内容。 现在已经准备好了来接收数据包，为了能够接收到一个数据包，你的驱动将会跟踪下一个已经接收到了数据包的下一个描述符。和传输一样，文档所陈述的RDH寄存器不可以信赖，所以为了知道一个数据包已经被分发，必须读取描述符的DD状态位。如果DD位被被设置了，那么就能复制数据包的数据到描述符缓冲区，并且告诉E1000描述符已经空闲通过自增队列的尾指针。 如果DD比特位没有被设置，那么就没有数据包被接收了，这等于当传输队列是满的情况。面对这种情况，可以返回一个重试的错误信息，要求调用者重新尝试。虽然这种方法适合全满的传输队列，因为这是一个瞬时情况，但是不太适合空的接收队列，因为接收队列可能长时间出去一个空队列状态。第二种途径就是暂停调用的环境知道有数据包在接受队列中需要处理。这种策略与sys_ipc_recv非常相似，就像IPC的情况，因为每个CPU只会拥有一个内核栈，一旦离开内核，那么这个内核栈将会丢失。所以需要设置一个FLAG指出这个环境已经被接收队列暂停了并且记录系统调用的参数。这种方法的确定是很复杂的，E1000必须只是去省常接收中断并且驱动必须恢复被阻塞而等待的环境。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习10"},{"categories":["sys"],"content":"练习11完成一个函数从E1000接收数据包并且添加一个用户环境能使用的系统调用。 int recv(void *addr,size_t len) { uint32_t tail = (mmio_e1000[E1000_RDT] + 1) % RECVNUM; struct RD *next_desc = \u0026recv_desc[tail]; //cprintf(\"tail value :%d\\n\", tail) ; if ((next_desc-\u003estatus \u0026 RXD_STAT_DD) != RXD_STAT_DD) return -1; if (next_desc-\u003elength \u003c len) len = next_desc-\u003elength; memcpy(addr, \u0026rbuf[tail], len); next_desc-\u003estatus \u0026= !RXD_STAT_DD; mmio_e1000[E1000_RDT] = tail; return next_desc-\u003elength; } ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习11"},{"categories":["sys"],"content":"网络服务的接收数据包再网络服务的输入环境中，需要使用新的接收心痛调用来接收数据包并且传递到网络服务的核心环境通过使用NSREQ_INPUT IPC消息，这些IPC消息需要有一个页面附加一个union Nsipc，数据包来填充其struct jif_pkt域。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#网络服务的接收数据包"},{"categories":["sys"],"content":"练习12完成 net/input.c #define RDBUF 10 void input(envid_t ns_envid) { binaryname = \"ns_input\"; // LAB 6: Your code here: // - read a packet from the device driver // - send it to the network server // Hint: When you IPC a page to the network server, it will be // reading from it for a while, so don't immediately receive // another packet in to the same physical page. int i, r; struct jif_pkt *head, *pkt = (struct jif_pkt*)\u0026nsipcbuf; // 10 buffers for (i = 0; i \u003c RDBUF; ++i) if ((r = sys_page_alloc(0, (void *)((uint32_t)pkt + i * PGSIZE), PTE_U | PTE_P | PTE_W)) \u003c 0) panic(\"alloc error\"); i = 0; head = pkt; while (1) { while((r = sys_recv((void *)((uint32_t)pkt + sizeof(pkt-\u003ejp_len)), PGSIZE - sizeof(pkt-\u003ejp_len))) \u003c 0) { sys_yield(); // cprintf(\"return value: %d\\n\", r); } //cprintf(\"pkt : %x | [i] : %d \\n\", pkt, i); pkt-\u003ejp_len = r; ipc_send(ns_envid, NSREQ_INPUT, pkt, PTE_P | PTE_U); pkt = (struct jif_pkt *)((uint32_t)pkt + PGSIZE); if (i++ == RDBUF-1) { pkt = head; i = 0; } } } 运行make E1000_DEBUG=TX,TXERR,RX,RXERR,RXFILTER run-net_testinput能够收到下面这个消息 Sending ARP announcement... Waiting for packets... e1000: index 0: 0x26dea0 : 900002a 0 e1000: unicast match[0]: 52:54:00:12:34:56 input: 0000 5254 0012 3456 5255 0a00 0202 0806 0001 input: 0010 0800 0604 0002 5255 0a00 0202 0a00 0202 input: 0020 5254 0012 3456 0a00 020f 0000 0000 0000 input: 0030 0000 0000 0000 0000 0000 0000 0000 0000 testinput只会发送一个数据包，但是评分脚本会有5个数据包 为了更加深入测试网络代码，JOS提供了一个叫做echosrv的守护进程来设置回显服务通过TCP服务的端口7。 Q2: How did you structure your receive implementation? In particular, what do you do if the receive queue is empty and a user environment requests the next incoming packet? 结构体的的定义根据手册来定义就行，如果接收队列是空的，那么该环境自己放弃时间片，调用调度算法，等下一个时间片周期再来检测是否有数据包。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习12"},{"categories":["sys"],"content":"网页服务网页服务以其最简单的形式发送内容给请求的客户端。JOS已经一共了非常简单的网络服务在user/httpd.c中。这个代码框架解决了即将到来的连接并且解析HTTP头。 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#网页服务"},{"categories":["sys"],"content":"练习13网络服务缺失了发送内容到客户端的代码，完成send_file和send_data。 static int send_data(struct http_request *req, int fd) { // LAB 6: Your code here. //panic(\"send_data not implemented\"); int r; char buf[512]; while ((r = read(fd, buf, 512)) \u003e 0) if (write(req-\u003esock, buf, r) != r) return -1; return 0; } static int send_file(struct http_request *req) { int r; off_t file_size = -1; int fd; struct Stat fst; // open the requested url for reading // if the file does not exist, send a 404 error using send_error // if the file is a directory, send a 404 error using send_error // set file_size to the size of the file // LAB 6: Your code here. //cprintf(\"url: %s \\n\", req-\u003eurl); //panic(\"send_file not implemented\"); if ((fd = open(req-\u003eurl, O_RDONLY)) \u003c 0) return send_error(req, 404); if ((r = fstat(fd, \u0026fst)) \u003c 0) return send_error(req, 404); file_size = fst.st_size; if (fst.st_isdir) return send_error(req, 404); if ((r = send_header(req, 200)) \u003c 0) goto end; if ((r = send_size(req, file_size)) \u003c 0) goto end; if ((r = send_content_type(req)) \u003c 0) goto end; if ((r = send_header_fin(req)) \u003c 0) goto end; r = send_data(req, fd); end: close(fd); return r; } 从最开始的概览图可以知道，这里是属于用户环境的程序，struct http_request中的socket相当于一个文件描述符，当把内容写到这个文件缓冲区，并且调用文件系统的回调函数，网络服务核心发送IPC消息到输出辅助环境。最开始接收到数据包的适合，利用http_request_parse函数获取文件路径，然后这个程序尝试去打开文件看能否打开，来判断文件的存在。然后发送HTTP头，HTTP头大小，类型以及\\r\\n的http头结束符。最后再将HTTP包主体传过去，也就是通过URL所指定的文件。 最后可以通过浏览器访问这个网站 ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#练习13"},{"categories":["sys"],"content":"make grademake[1]: Leaving directory '/home/moonlight/lab' testtime: OK (9.9s) pci attach: OK (1.7s) testoutput [5 packets]: OK (3.1s) testoutput [100 packets]: OK (2.8s) Part A score: 35/35 testinput [5 packets]: OK (3.1s) testinput [100 packets]: OK (2.2s) tcp echo server [echosrv]: OK (2.6s) web server [httpd]: http://localhost:26002/: OK (1.8s) http://localhost:26002/index.html: OK (1.8s) http://localhost:26002/random_file.txt: OK (2.8s) Part B score: 70/70 Score: 105/105 you have a file system, no self respecting OS should go without a network stack. ","date":"2018-05-28","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab6-Network Driver(Final)","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/#make-grade"},{"categories":["sys"],"content":"这个实验主要是实现spawn库函数用来读取并运行可执行文件，然后扩充操作系统的内核和库 ，使得足以在控制台上运行shell。实现这些特性需要一个文件系统，而接下来就会介绍一个简单的可读写的文件系统。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#"},{"categories":["sys"],"content":"准备git $ find . -name \"*.swp\" | xargs rm $ git add . $ git commit -m \"lab4 done\" $ git pull $ git merge lab4 Auto-merging kern/trap.c CONFLICT (content): Merge conflict in kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c CONFLICT (content): Merge conflict in kern/init.c Auto-merging kern/env.c CONFLICT (content): Merge conflict in kern/env.c Auto-merging inc/lib.h Automatic merge failed; fix conflicts and then commit the result. 解决conflict，并且确认pingpong, primes, 和forktree这三个用户程序可以正常运行。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#准备"},{"categories":["sys"],"content":"文件系统这里将使用一个比实际更简单的文件系统，但这足以提供一些基本的特点：创建，读取，写入和删在除文件在一个具有层级结构的文件结构。 到目前为止已经完成了单用户操作系统，能够提供足够的保护去捕获bug但是不会阻止来自其他可疑用户的操作。新的文件系统暂时不支持硬链接(hard link),符号链接(symbolic links),时间戳(time stamps)或者特殊设备文件(device files). 磁盘文件系统的结构：大多数UNIX文件系统将磁盘空间分成两类，inode区域和data区域。UNIX文件系统给每一个文件都赋予一个inode值，文件的inode保持这个文件的临界元数据(critical meta-data)例如文件的stat属性和指向数据块的指针。数据区域被分成了更大的data block，文件系统将文件数据和目录元数据存储在其中。目录的入口包含了文件名和指向inode的指针。一个文件能被硬链接只有多个文件目录入口引用了这个文件的inode。因为这里不支持硬链接，所以可以做一个方便的转化：完全不使用inode而简单地存储所有的文件的元数据在目录入口来描述每个文件。 文件和目录逻辑上组成了一连串的数据块(data block)，可能被散布在磁盘也有可能在一个环境的虚拟地址空间所映射的物理内存上。文件系统隐藏了这些数据块的存放细节，为在一个绝对的文件偏移提供了接口方便读写字节流。文件系统对目录的修改表现为创建文件或者删除文件。这里的文件系统云溪用户环境读取目录的元数据，这意味着用户环境能自己扫描文件目录而不是依赖于一个二外的调用。这样做也有缺点，现代大多是UNIX的变体都不推荐使用它，这使得应用程序依赖于文件目录的格式，这让在没有改变或者编译应用程序的情况下很难改变文件系统内部存放。 扇区和块 大多数磁盘不支持字节粒度的读写而是通过读写一个扇区单元。JOS中，每个区块都是512字节。文件系统实际上在块的单元分配和使用磁盘存储。注意：sector取决于磁盘硬件，然而block的大小是操作系统使用磁盘的一个大小。所以文件系统的块大小必须是块的整数倍。 superblock 文件系统通常保留一个确定位置(最前面或者最末尾)的磁盘块来保存描述文件系统特性的元数据。任何元数据被要求找到根目录，文件系统上次被增减的时间，上次检查错误的时间等等。在这里的文件系统中将会有一个确定的superblock，它将总是在block1的位置，被定义在stuct Super。Block0通常被用来保存boot loaders和分区表(partition tables)。大多是实际的文件系统维护多个superblock，散布在disk中，所以其中的一个块发生了损毁或者介质错误，其他的superbloock仍能被找到。 文件元数据 在这个文件系统中，meta-data的存放在stuct File中定义了。其中包含了文件名，文件大小，文件类型(普通文件或者目录)，以及一个指针指向下一个包含文件的块，因为不支持inode，所以这些元数据被存储在了目录入口，为了简化，将会直用File这一个结构体去表示即在磁盘和内存的元数据。 结构体中f_direct数据包含了文件空间的前十个块，称之为文件的直接块。从小到大共40KB，这意味着这10个块号可以被这个File结构体直接引用。对于更大的文件，分配一个额外的磁盘块，被称作文件的间接块(indirect block)，能够保存1024个额外的块号。所以，文件系统因此能允许文件最大到1034个块已经大于了4M，当然实际的文件系统通常支持多个double-和triple indrect block。 目录 vs. 普通文件 文件系统中的File结构体既能表示一个普通文件也能表示一个目录。它们的区别在于结构体的。type，两者的管理方法基本相同，除了目录文件不会解析普通文件的数据块，但是他会解析文件对目录文件的描述和子目录。 superblock包含了一个File结构体，Super结构体中的root域保存了系统根目录的元数据。目录文件的内容是一系列File结构体，所有在根目录下的子目录也许会有多个File结构体用来表示次次级目录。 x86使用EFLAGS寄存器中的IOPL位来决定在保护模式下的代码是否被允许执行例如in或者out这样的指令。因为所有的在x86 IO空间的IDE(Integrated Drive Electronics)磁盘寄存器都需要访问，而不是被映射到内存。给予文件系统的IO权限是为了能偶个访问所有的寄存器，同时是一种办法来控制其他用户环境的代码是否有权限来访问I/O空间。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#文件系统"},{"categories":["sys"],"content":"练习1 if (type == ENV_TYPE_FS) env-\u003eenv_tf.tf_eflags |= FL_IOPL_3; 一开始的想法是使用privilige 0，也就是FL_IOPL_0，但是出错了。 Indicates the I/O privilege level (IOPL) of the currently running program or task. The CPL of the currently running program or task must be less than or equal to the IOPL to access the I/O address space. This field can only be modified by the POPF and IRET instructions when operating at a CPL of 0. 解释是当前用户环境的CPL(current privilege level)必须小于或等于IOPL等级才行。普通用户环境默认被初始化为0，而CPL是3，所以正常的进程是不能直接执行IO操作的。在后面的测试spawnfaultio测试中有测试。如果需要文件系统能进行IO，则将IOPL值置为3即可。 Q1:Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why? 前面的实验中有想过，每当一个环境开始运行的时候，也就是调用env_run函数的适合都会执行iret以恢复寄存器状态。 块高速缓存 在这个文件系统中，将会在处理器的虚拟内存系统中实现一个简单的缓冲区，代码在fs/bc.c 文件系统将会限制可操作的磁盘大小是3G或者更少，保留一个够大的3GB区域在文件系统的内存空间，从0x10000000 (DISKMAP) 到 0xD0000000 (DISKMAP+DISKMAX)，作为一个映射在内存的磁盘版本。例如，block0被映射在0x1000000，block1映射在0x10001000等等。diskaddr函数实现了从块号到虚拟内存的转换，并且做了一些正常的检测。 文件系统拥有其自己的虚拟内存空间独立于其他所有的用户环境，并且文件系统的仅需要做的一件事就是实现文件访问，有理由去保留大多数文件系统的内存空间。 当然，读取整个磁盘到内存中将会花费相当长的时间，所以实现一种demand paging仅仅分配那些需要相应块号对应的页，以可信的方式引发一个页错误，再分配。通过这种方式，能假定整个磁盘是在内存中。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习1"},{"categories":["sys"],"content":"练习2 实现fs/bc.c中的bc_pgfault函数和flush_block函数 bc_pgfault是一个页错误处理handler，就像之前的cow fork，希望从磁盘读取页会产生页错误。 1.addr 也许不是与block边界对齐的。 2.ide_read 是在扇区操作不是块。 flush_block 函数如果有必要的话需要写一个块到磁盘中，如果没有block cache或者不是\"dirty\"状态(5.2.4.3),fluash_block什么也不会做。 ide_write int ide_write(uint32_t secno, const void *src, size_t nsecs) { int r; assert(nsecs \u003c= 256); ide_wait_ready(0); outb(0x1F2, nsecs); //sector count outb(0x1F3, secno \u0026 0xFF); //sector number outb(0x1F4, (secno \u003e\u003e 8) \u0026 0xFF); //clinder low outb(0x1F5, (secno \u003e\u003e 16) \u0026 0xFF); //clinder high outb(0x1F6, 0xE0 | ((diskno\u00261)\u003c\u003c4) | ((secno\u003e\u003e24)\u00260x0F)); //select driver 1 outb(0x1F7, 0x30); // CMD 0x30 means write sector for (; nsecs \u003e 0; nsecs--, src += SECTSIZE) { if ((r = ide_wait_ready(1)) \u003c 0) return r; outsl(0x1F0, src, SECTSIZE/4);//data register } return 0; } 这个函数和ide_read基本相同，往磁盘寄存器内读写数据，设置读写计数器，读写的扇区号，柱面等等，然后通过一个for循环读取写入数据。CPU之前已经将相应的内存页在UVPT中标记为了dirty状态，也就是页重写标志位，当把内容读到内存中去的适合发生页错误，引发陷入从而分配一个新的物理页，并且写入数据。JOS用bc_pgfault作为handler处理这种页错误，代码如下。 # bc_pgfault // Allocate a page in the disk map region, read the contents // of the block from the disk into that page. // Hint: first round addr to page boundary. fs/ide.c has code to read // the disk. // // LAB 5: you code here: addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); if ((r = sys_page_alloc(0, addr, PTE_P|PTE_U|PTE_W)) \u003c 0) panic(\"in sys_page_alloc, %e\", r); if ((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS) \u003c 0)) panic(\"in ide_read , %e\", r); flush_content的主要作用就是把数据写回到磁盘中去，然后清楚PTE_D页面重写标记为，代码如下： void flush_block(void *addr) { uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if (addr \u003c (void*)DISKMAP || addr \u003e= (void*)(DISKMAP + DISKSIZE)) panic(\"flush_block of bad va %08x\", addr); // LAB 5: Your code here. addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); if (!va_is_mapped(addr)) return; if (!va_is_dirty(addr)) return; if ((r = ide_write(blockno*BLKSECTS, addr, BLKSECTS)) \u003c 0) panic(\"ide_write fault : %e\", r); if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] \u0026 PTE_SYSCALL)) \u003c 0) panic(\"map fault : %e\", r); //panic(\"flush_block not implemented\"); } fs_init函数是一个范例使用block cache，初始化后super存储指向磁盘映射范围的指针。在此之后，就能从super结构体读取数据就好像是从磁盘读取一样。 Challenge:淘汰机制. 块位图(Block Bitmap) 在fs_init设置好了bitmap指针后，可以将bitmap看作一个比特数组，其中一位对应着在磁盘中的一个块。例如，block_is_free就是检测一个跟定的块是否在bitmap中被标记。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习2"},{"categories":["sys"],"content":"练习3 使用free_block作为一个范例去实现alloc_block函数，如果能在位图里找到空闲的磁盘块，标记其已经被使用，并且返回块号。当分配好了块，需要马上改变磁盘中的的位图块，使用flush_block函数，使得文件系统在内存的内容和在硬盘中内容一致。 int alloc_block(void) { // The bitmap consists of one or more blocks. A single bitmap block // contains the in-use bits for BLKBITSIZE blocks. There are // super-\u003es_nblocks blocks in the disk altogether. // LAB 5: Your code here. //panic(\"alloc_block not implemented\"); int i; for (i = 2; i \u003c super-\u003es_nblocks; i++) if (block_is_free(i)) { bitmap[i/32] ^= 1\u003c\u003c(i%32); flush_block(bitmap); return i; } return -E_NO_DISK; } 块的位图将每一个整形的bit最为一个块的使用标志，3G区域共3GB/4KB个块，所对应的位图共96KB。PS：位图中置0表示已经使用。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习3"},{"categories":["sys"],"content":"文件操作在文件fs/fs.c中提供了一些函数管理File结构体的函数，解释结构体，扫描管理目录文件的入口，从根目录遍历整个文件系统。 fs_init()：找到JOS的磁盘，全局变量super block指向第1号扇区在内存中的映射(第0号扇区是bootloader)，bitmap指向第2号扇区所对应在内存中的映射。 static int file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc) 找到文件结构体中的文件块号对应的全局文件块号，将块号存在*ppdiskbno中，如果没有根据alloc的值判断是否分配。 int file_get_block(struct File *f, uint32_t filebno, char **blk) 获得一个文件结构体文件块号所对应在内存中的映射，把结果存在*blk中。 static int dir_lookup(struct File *dir, const char *name, struct File **file) 通过file_get_block获得这个目录文件结构体所在的块，再用一个文件一个文件结构体的对照文件名，直到相等再把file指向这个找到的文件。 static int dir_alloc_file(struct File *dir, struct File **file) 首先现在目录本身的结构体中寻找可以用的空文件结构体，如果找不到则新分配一个块并且目录文件大小也会增加，file指向这个空闲的文件结构体。 walk_path()：和HOMEWORK中做的命令解释器很像，从根目录开始迭代，例如/usr/bin就会被一步一步地解析为 super-\u003eusr-\u003ebin，usr和bin分别作为目录和文件返回。 file_create(const char *path, struct File **pf) 在path目录下创建一个文件，通过指针返回一个文件，并且会把文件写回磁盘。 file_open() file_read() file_write() 都是基本的文件操作，不过要注意的是，文件的写操作只是写在了磁盘所映射的内存，没有存回磁盘，所以应该需要flush操作。 file_free_block()：在块的位图上释放文件块 file_truncate_blocks()：缩小文件大小，释放掉保持的磁盘块，但是不会修改结构体中的f-\u003ef_size的值。 file_set_size()：设置文件的大小，并且写回磁盘。 file_flush()把一个单独的文件写回磁盘而fs_sync()将整个内存映射都写回磁盘。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#文件操作"},{"categories":["sys"],"content":"练习4实现file_block_walk和file_get_block函数。 file_block_walk通过一个在文件内的偏移，映射结构体所直接指向的块或者间接指向的块。 file_get_block更及进一步地映射实际的磁盘块，如果有必要的话分配一个新磁盘块。 代码如下： ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习4"},{"categories":["sys"],"content":"file_block_walk()static int file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc) { // LAB 5: Your code here. //panic(\"file_block_walk not implemented\"); int r; // cprintf(\"filebno %d\\n\", filebno); if (filebno \u003e NDIRECT + NINDIRECT) return -E_INVAL; if (filebno \u003c NDIRECT) { if (ppdiskbno) *ppdiskbno = f-\u003ef_direct + filebno; return 0; } //cprintf(\"indirect: %08x logic: %d\\n\", f-\u003ef_indirect, !f-\u003ef_indirect); if (!f-\u003ef_indirect) { if (alloc) { if ((r = alloc_block()) \u003c 0) return r; memset(diskaddr(r), 0, BLKSIZE); f-\u003ef_indirect = r; flush_block(diskaddr(r)); } else return -E_NOT_FOUND; } *ppdiskbno = (uint32_t *)diskaddr(f-\u003ef_indirect) + filebno - NDIRECT; //cprintf(\"fileno : %d -\u003e diskno: %x -\u003e %x\\n\", filebno, *ppdiskbno, **ppdiskbno); return 0; } 做的后面踩了前面的坑，diskaddr的返回类型需要坐下强制类型转换，void *指针类型p与uint32_t的n相加等于p + n * 1，而这里需要的是整形指针相加的结果p + n * 4。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:1:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#file_block_walk"},{"categories":["sys"],"content":"file_get_block()int file_get_block(struct File *f, uint32_t filebno, char **blk) { // LAB 5: Your code here. //panic(\"file_get_block not implemented\"); uint32_t *bno; int r; if ((r = file_block_walk(f, filebno, \u0026bno, 1)) \u003c 0) return r; // allocate a block if the block number is zero // meaning that it hasn't refered to any block by now. if (*bno == 0) { if ((r = alloc_block()) \u003c 0) return r; *bno = r; memset(diskaddr(r), 0, BLKSIZE); flush_block(diskaddr(r)); } // *bno is the number of blocks *blk = diskaddr(*bno); return 0; } 做到这里可以发现，当往文件写内容的适合，实际是先写入内存的缓冲区的，只有最后执行了flush操作，才会真正把内容保存到磁盘中去。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:2:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#file_get_block"},{"categories":["sys"],"content":"文件系统接口现在有必要为文件系统自己提供一些功能/接口，必须文件系统能够被其他用户环境使用。因为其他环境不能直接调用文件系统环境中的函数，所以通过远程程序调用RPC(remote procedure call)能访问文件系统的接口。 Regular env FS env +---------------+ +---------------+ | read | | file_read | | (lib/fd.c) | | (fs/fs.c) | ...|.......|.......|...|.......^.......|............... | v | | | | RPC mechanism | devfile_read | | serve_read | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | fsipc | | serve | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | ipc_send | | ipc_recv | | | | | ^ | +-------|-------+ +-------|-------+ | | +-------------------+ 在点线之下是从普通用户环境发送到文件系统环境的一个读请求。开始的时候，read工作在任何文件描述符上，并且分发到合适的设备读函数，这里是使用的devfile_read函数，当然还有其他各种的设备类型比如管道。devfile_read实现了读对磁盘上文件的操作，这个函数和其他devfile_*函数是实现了客户端这边的文件系统的操作，并且所有的工作几乎相同，绑定参数到request结构体，并且调用fsipc发送IPC请求和解析返回的值。fsipc函数完成了发送请求到服务端和接收回复的细节。 文件系统服务端代码在fs/serv.c中，服务端循环serve函数，接收来自IPC的请求，分发请求到合适的handler函数，并且将访问的结果通过IPC返回。在读操作的例子中，serve分发请求到serve_read，这个函数将会关注IPC的读请求细节，例如解包request结构体后调用file_read去执行文件读操作。 回顾JOS的IPC机制，让一个环境发送一个32位的数字，并且有选择性的分享页。为了从客户端到服务端发送一个请求，这里使用32位的数字去指定request类型，并且存储request参数到union Fsipc所在的共享页上去。在客户端，总是将共享页放在fsipcbuf处；在服务端，将即将到来的请求页映射在fsreq(0x0ffff000)处。 服务端也会通过IPC发送回复消息，将ipc参数中的32位值设置为相关函数的返回值。大多数RPC都会有它们自己的返回类型，FSREQ_READ和FSREQ_STAT总是返回数据，这两个函数将数据写到客户端所发送的request页上。但是不需要通过IPC发送这个页，因为客户端已经分享了这个物理页。当然，例如FSREQ_OPEN分享给客户端一个新的Fd页,将会很快的返回文件描述符指定的页。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#文件系统接口"},{"categories":["sys"],"content":"练习5实现serve_read serve_read的艰苦工作已经被file_read实现了，它只需要位文件的读提供RPC的接口，可以参照serve_set_size函数。 int serve_read(envid_t envid, union Fsipc *ipc) { struct Fsreq_read *req = \u0026ipc-\u003eread; struct Fsret_read *ret = \u0026ipc-\u003ereadRet; struct OpenFile *o; int r; char buf[PGSIZE]; size_t read_count, remainder; if (debug) cprintf(\"serve_read %08x %08x %08x\\n\", envid, req-\u003ereq_fileid, req-\u003ereq_n); // Lab 5: Your code here: // same as before, find the file firstly. if ((r = openfile_lookup(envid, req-\u003ereq_fileid, \u0026o)) \u003c 0) return r; if ((r = file_read(o-\u003eo_file, ret-\u003eret_buf, req-\u003ereq_n, o-\u003eo_fd-\u003efd_offset)) \u003c 0) return r; o-\u003eo_fd-\u003efd_offset += r; //memcpy(ret, buf, PGSIZE); return r; } 关于偏移的到结束的大小，这里不用再做判断了，已经file_read函数中实现了。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习5"},{"categories":["sys"],"content":"练习6实现serve_write static ssize_t devfile_write(struct Fd *fd, const void *buf, size_t n) { // Make an FSREQ_WRITE request to the file system server. Be // careful: fsipcbuf.write.req_buf is only so large, but // remember that write is always allowed to write *fewer* // bytes than requested. // LAB 5: Your code here //panic(\"devfile_write not implemented\"); int r; fsipcbuf.write.req_fileid = fd-\u003efd_file.id; fsipcbuf.write.req_n = n; memmove(fsipcbuf.write.req_buf, buf, n); if ((r = fsipc(FSREQ_WRITE, NULL)) \u003c 0) return r; return r; } 这两个实现比较简单，跟着指导做就好，但不能仅仅满足于函数天空，这些函数都是一层一层包装上去的，省去了背后的原理和操作，例如设置页位\"dirty状态\"，引发页错误分配映射，避免磁盘全部映射而占据大量内存空间。文件的读写操作都被简化了，在testfile.c源码中都是使用的write,open,read等被抽象的操作，而实际的过程比如write操作会被分发到devfile_write通过IPC发送写信号并且共享传递的页，文件系统进程收到写信号并将传递过来的页映射在一个固定的位置，找到文件描述符所指定的文件，然后将共享页buf中的内容复制到磁盘映射页上面，最后在关闭文件的时候flush进行保存；文件系统服务端这边处理完文件后，会把文件写操作的字节数返回做为操作成功的信号通过IPC返回给客户端，并且取消映射共享页。给人的直接感受就是，操作者通过write操作直接写入了文件中。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习6"},{"categories":["sys"],"content":"产生子进程spawn操作创建一个新的环境，从文件系统中读取程序镜像运行此程序，父进程独立于子进程继续运行。spwan函数的操作就像UNIX中fork后立马在子进程执行exec。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#产生子进程"},{"categories":["sys"],"content":"练习7spwan依赖于新的系统调用sys_env_set_trapframe来初始化新被创建的环境状态，完成这个函数后，尝试运行user/spanhello程序。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习7"},{"categories":["sys"],"content":"通过fork和spawn分享库状态UNIX文件描述符是一个泛指的概念，其中包含了pipe,控制台I/O等。在JOS中，每一种设备类型都有一个对应的struct Dev，使用指针实现读写等操作。对于这些设备类型，lib/fd.c实现了像UNIX的文件描述符的接口，每一个Fd结构体指定它自己的设备类型，fd.c中的函数分发分发各自的操作到相应的Dev结构体中去。 fd.c为每一个应用程序维护文件描述符表在它们各自的内存空间，地址起始于FDTABLE。这片4KB的页很值得为最多32个文件描述符保留在内存空间，使得应用程序能立即打开。在任意时刻，一个指定的文件描述符表页当且仅当对应的文件描述符是在被使用的。每一个文件描述符在这片区域还拥有一个可选的data page在地址FILEDATA处，设备可以用来使用。 因为可能需要通过fork和spawn来分享文件描述符的状态，但是文件描述符的状态是保存在各自用户内存空间中的。现在，fork已经标记那些需要被复制的页为cow状态。这里需要不同的用户环境共享用户环境，与cow分配并复制不同，PTE_SHARE的标记意味着直接映射该物理帧，达到共享的效果。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#通过fork和spawn分享库状态"},{"categories":["sys"],"content":"练习8修改lib/fork.c中的duppage 实现lib/spawn.c中的copy_shared_pages函数 va = pn*PGSIZE; //cprintf(\"%x\\n\", va); if (uvpt[pn] \u0026 PTE_SHARE) { if ((r = sys_page_map(thisenv-\u003eenv_id, (void *)va, envid, (void *)va, uvpt[pn] \u0026 PTE_SYSCALL)) \u003c 0) return r; return 0; } static int copy_shared_pages(envid_t child) { // LAB 5: Your code here. int32_t va; int r; for (va = 0; va \u003c USTACKTOP; va += PGSIZE) if ((uvpd[PDX(va)] \u0026 PTE_P) \u0026\u0026 (uvpt[PGNUM(va)] \u0026 PTE_P) \u0026\u0026 (uvpt[PGNUM(va)] \u0026 PTE_SHARE)) { if ((r = sys_page_map(0, (void *)va, child, (void *)va, PTE_SYSCALL\u0026uvpt[PGNUM(va)])) \u003c 0) return r; } return 0; } 代码中的spawn已经实现了，并且加了很多注释，在这做下笔记。 打开程序文件 读取ELF文件头，检测它的魔数(magic number) 使用系统调用sys_exofork()创建一个新的环境 设置子进程的初始栈，例如传递的参数 调用init_stack()设置好栈页 映射程序的各个段到新环境的内存空间 如果ELF文件flag没有包含ELF_PROG_FLAG_WRITE，那么短包含了代码正文和只读的数据。 如果ELF文件flag包含了ELF_PROG_FLAG_WRITE，那么代表这个段包含了可读写的数据和bss段 调用sys_env_set_trapframe设置子程序的栈 调用sys_env_set_status表明程序可以确认运行了。 这里设置栈帧的时候，要压入像main(int argc, char **argv)中argc,argv两个参数，这里的操作给出了更加准确的答复(函数init_stack(envid_t child, const char **argv, uintptr_t *init_esp)。 string_size = 0; for (argc = 0; argv[argc] != 0; argc++) string_size += strlen(argv[argc]) + 1; 首先确定字符串总长度，并且包含每个字符串结尾的null字节。 string_store = (char*) UTEMP + PGSIZE - string_size; argv_store = (uintptr_t*) (ROUNDDOWN(string_store, 4) - 4 * (argc + 1)); string_store ~ UTEMP+PGSIZE用来存放参数中的字符串，argv_store ~ string_store存放argv[i]这个二维数组指向各自字符串的指针。 if ((r = sys_page_alloc(0, (void*) UTEMP, PTE_P|PTE_U|PTE_W)) \u003c 0) return r; for (i = 0; i \u003c argc; i++) { argv_store[i] = UTEMP2USTACK(string_store); strcpy(string_store, argv[i]); string_store += strlen(argv[i]) + 1; } 设置栈帧的时候先在UTEMP这分配一个页面，然后才进行存放。这里有一点引起了我注意，argv_storep[i]也就是二维数组中的字符串指针都是指向USTACK的，但是字符串的内容还是存放在UTEMP~UTEMP+PGSIZE的范围中，因为最后程序正式开始执行的时候，指针不可能指向UTEMP，所以这里可以看作是一个小tricks。 argv_store[-1] = UTEMP2USTACK(argv_store); argv_store[-2] = argc; *init_esp = UTEMP2USTACK(\u0026argv_store[-2]); if ((r = sys_page_map(0, UTEMP, child, (void*) (USTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W)) \u003c 0) goto error; if ((r = sys_page_unmap(0, UTEMP)) \u003c 0) goto error; 接下来就是把argv_store这个在USTACK中对应的位置压栈，它指向字符串指针数组的开头，其次再压入的argc参数的个数，并将esp栈顶指针设置好后映射到USTACK去，解开UTEMP的映射回收内存页，这里就完成了栈的初始化。 PS: 这里的数组角标为负数时头次在C中见到，虽然理解不难，但是看到在python中常用的语法在C中出现还挺意外的。 所以最后spawn出来的程序所拥有的栈结构如下： ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习8"},{"categories":["sys"],"content":"键盘接口为了shell能工作，现在需要一种方式来打字。QEMU已经显示了输入到CGA(Color Graphics Adapter)和串口，但是到目前为止只能在内核的显示器上获取输入。从键盘的输入显示在图形窗口上，然而串口的输入会被显示到控制台上。kern/console.c已经完成键盘和串口驱动被用作内核的监视器，但是现在需要附加剩下的功能。 在代码中必定会接触到大量串口操作，与其外围寄存器相关，现在看着还是挺懵的，所以暂时不去关注端口的实现。 Q: 串口中断和按键中断有什么区别 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#键盘接口"},{"categories":["sys"],"content":"练习9分发按键中断IRQ_OFFSET+IRQ_KBD和串口中断IRQ_OFFSET+IRQ_SERIAL。 // Handle keyboard and serial interrupts. // LAB 5: Your code here. if (tf-\u003etf_trapno == IRQ_OFFSET + IRQ_KBD) { kbd_intr(); return; } if (tf-\u003etf_trapno == IRQ_OFFSET + IRQ_SERIAL) { serial_intr(); return; } 当键盘键入或者有串口中断发生的时候，串口和键盘分别通过各自的例程获取字符，并且调用cons_intr将字符放入结构体cons的缓冲区中，自增写端wpos。 static struct { uint8_t buf[CONSBUFSIZE]; uint32_t rpos; uint32_t wpos; } cons; 在当程序需要进行获取输入的时候，会调用kern/console.c中的cons_getc()，这个函数首先会调用serial_intr()和kbd_intr()先获取串口或者键盘输入，然后通过将从缓冲区buf中获取一个字符，并且自增rpos读端。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习9"},{"categories":["sys"],"content":"练习10这个练习基本上就是高层的命令解释器的实现，hw2中已经实现过了。 // LAB 5: Your code here. //panic(\"\u003c redirection not implemented\"); if ((fd = open(t, O_RDONLY)) \u003c 0) { cprintf(\"open %s for read: %e\", t, fd); } if (fd != 0) { dup(fd, 0); close(fd); } break; 和\u003e操作一样，代码基本相似，但是可以顺便看一下pipe和dup的实现。 dup() int dup(int oldfdnum, int newfdnum) { int r; char *ova, *nva; pte_t pte; struct Fd *oldfd, *newfd; if ((r = fd_lookup(oldfdnum, \u0026oldfd)) \u003c 0) return r; close(newfdnum); newfd = INDEX2FD(newfdnum); ova = fd2data(oldfd); nva = fd2data(newfd); if ((uvpd[PDX(ova)] \u0026 PTE_P) \u0026\u0026 (uvpt[PGNUM(ova)] \u0026 PTE_P)) if ((r = sys_page_map(0, ova, 0, nva, uvpt[PGNUM(ova)] \u0026 PTE_SYSCALL)) \u003c 0) goto err; if ((r = sys_page_map(0, oldfd, 0, newfd, uvpt[PGNUM(oldfd)] \u0026 PTE_SYSCALL)) \u003c 0) goto err; return newfdnum; } dup首先将新的文件描述符关闭，例如dup(fd, 0)会先将0也就是标准输出关闭(写回磁盘，取消物理帧的映射)，然后将fd所指向的数据块和文件描述符所占的页映射到根据文件描述符号转换到的虚存地址去，所以写入标准输出的内容可以写到fd所指向的文件中去了。 dup后一般有一个close()操作，这一步只是取消对物理块的引用而已，多出来文件描述符既不安全又不美观。 pipe() int pipe(int pfd[2]) { int r; struct Fd *fd0, *fd1; void *va; // allocate the file descriptor table entries if ((r = fd_alloc(\u0026fd0)) \u003c 0 || (r = sys_page_alloc(0, fd0, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u003c 0) goto err; if ((r = fd_alloc(\u0026fd1)) \u003c 0 || (r = sys_page_alloc(0, fd1, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u003c 0) goto err1; // allocate the pipe structure as first data page in both va = fd2data(fd0); if ((r = sys_page_alloc(0, va, PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u003c 0) goto err2; if ((r = sys_page_map(0, va, 0, fd2data(fd1), PTE_P|PTE_W|PTE_U|PTE_SHARE)) \u003c 0) goto err3; // set up fd structures fd0-\u003efd_dev_id = devpipe.dev_id; fd0-\u003efd_omode = O_RDONLY; fd1-\u003efd_dev_id = devpipe.dev_id; fd1-\u003efd_omode = O_WRONLY; pfd[0] = fd2num(fd0); pfd[1] = fd2num(fd1); return 0; } pipe()首先引起注意的就是权限设置，这也是为什么一段只能读一段只能写。首先为每个描述符提供一个页存储文件结构体，再分配一个页给0一个数据页，将这个页映射到0和1文件描述符对应的数据页，并且将页标记为PTE_SHARE。在任意一段尝试读或者写的时候，触发页错误，使用bc_pgfault进行实际映射。最后进行权限设置，完成管道的创建。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#练习10"},{"categories":["sys"],"content":"make grademake[1]: Leaving directory '/home/moonlight/lab' internal FS tests [fs/test.c]: OK (1.9s) fs i/o: OK check_bc: OK check_super: OK check_bitmap: OK alloc_block: OK file_open: OK file_get_block: OK file_flush/file_truncate/file rewrite: OK testfile: OK (1.7s) serve_open/file_stat/file_close: OK file_read: OK file_write: OK file_read after file_write: OK open: OK large file: OK spawn via spawnhello: OK (1.2s) Protection I/O space: OK (1.3s) PTE_SHARE [testpteshare]: OK (2.0s) PTE_SHARE [testfdsharing]: OK (1.2s) start the shell [icode]: Timeout! OK (31.4s) testshell: OK (3.9s) primespipe: OK (11.1s) Score: 150/150 This completes the lab 这一节实验代码量较小，但是实现了很多日常接触到的概念，例如管道，dup，文件描述符等。在完成实验的时候踩了很多坑，比如虽然通过了阶段性的测试，但是前面留下的错误代码影响到了后面的整个系统，仔细观察程序可以观察到代码都是一层一层抽象上去的，所以越是底层越需要仔细，考虑清楚corner case。每发生一个BUG都花了大量时间去寻找问题所在，这是很不应该的。 ","date":"2018-05-20","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/:0:0","series":null,"tags":["OS"],"title":"6-828-操作系统工程-Lab5-File system, Spawn and Shell","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/#make-grade"},{"categories":["sys"],"content":"在这个实验中，将会在多个用户环境同时运行时实现抢占式多任务。 part A:为JOS添加多处理器的支持，实现round-robin scheduling和增加基础的用户环境管理的系统调用，例如创建和销毁用户环境，分配和映射内存中的内容。 part B: 实现fork()函数，允许用户环境去添加一份自己环境的拷贝。 part C: 添加进程间的通信IPC(inter-process communication)，允许不同的用户环境各自通信和同步；添加硬件时钟中断和抢占任务。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#"},{"categories":["sys"],"content":"准备开始git #git rest --hard FETCH_HEAD git add -u git commit -m \"\" git pull git checkout -b lab4 origin/lab4 git merge lab3 confilcts in file config/lab.mk ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#准备开始"},{"categories":["sys"],"content":"源文件描述kern/cpu.h Kernel-private definitions for multiprocessor support kern/mpconfig.c Code to read the multiprocessor configuration kern/lapic.c Kernel code driving the local APIC unit in each processor kern/mpentry.S Assembly-language entry code for non-boot CPUs kern/spinlock.h Kernel-private definitions for spin locks, including the big kernel lock kern/spinlock.c Kernel code implementing spin locks kern/sched.c Code skeleton of the scheduler that you are about to implement ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#源文件描述"},{"categories":["sys"],"content":"PART A: 多处理器支持(Multiprocessor Support )和协作式多任务(Cooperative Multitasking)首先，会扩展JOS，使其能在多处理器系统上运行。然后实现一些JOS内核的系统调用，使得用户环境能创建额外的环境。通过实现cooperative round-robin scheduling，允许内核能切换到不同的用户环境，使用户环境自身让出CPU资源。 然后再part C中，将会实现 preemptive scheduling，这种调度算法允许内核从一个超出分配时间片的用户环境重新获取CPU的控制权。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#part-a-多处理器支持multiprocessor-support-和协作式多任务cooperative-multitasking"},{"categories":["sys"],"content":"Multiprocessor SupportJOS将会支持对称多处理SMP(symmetric multiprocessing)，这种多处理模型使得CPU能有对例如内存和IO总线等系统资源拥有平等的访问权。虽然所有的CPU在SMP中都一样，但是在执行启动进程期间，处理器会被分成两种。 引导处理器BSP(bootstrap processor)在启动操作系统的时候，初始化系统的时候使用。 应用程序处理器APs(application processos)仅当在操作系统已经启动好后，被BSP激活。 BSP处理器的选择取决于硬件和BIOS，到目前为止，JOS的代码都是运行在BSP处理器上的。 在SMP系统中，每个CPU都有一个附随的LAPIC单元(local APIC unit)，这些单元通过系统分发中断，LAPIC为其相关的CPU提供一个独一无二的标识符。 在这个实验中，将会使用LAPIC的以下功能： 通过读取APIC ID(LAPICT identifier)获取当前正在运行的CPU(cpunum()) 发送处理器之间的__STARTUP__中断IPI(interprocessor interrupt)当BSP启动APs的时候。 在part C中，LAPIC内置计时器去触发时钟中断，来支持抢占式多任务。 APIC(Adavanced Programmable Interrupt Controller) chapter 8:https://pdos.csail.mit.edu/6.828/2017/readings/ia32/IA32-3A.pdf Local APIC主要的作用分成两部分: 接收来自其他LAPIC的中断和外部的I/O APIC中断，或者发送中断。 在MP(multiple processor)系统中，在system bus发送接收处理器间中断IPI。 处理器访问它自己的LAPIC通过MMIO(memory-mapped I/O)，在MMIO中，一部分物理内存直接与IO设备的寄存器相连接，所以类似于ld/store的指令通常被用作间接访问外围设备的寄存器。Lab2为IO hole在物理地址0xA0000留了一部分内存空间用作VAG显示缓冲。LAPIC位于内存地址0xFE000000(4GB - 32MB)处，这个地址很高，所以不能直接通过KERNBASE映射。JOS的虚拟内存为MMIOBASE保留了4MB的空间，所以可以用来映射设备的内存。 另外Lapic所使用的内存应该是被设计为strong uncacheable的，而在 kern/lapic.c预先定义的ID，Version等信息可以在IA-32 Table8.1中查到。 接下来的实验中将会介绍更多MMIO的区域，并且为外围设备实现一些基础的内存分配和映射。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#multiprocessor-support"},{"categories":["sys"],"content":"练习1 实现kern/pmap.c中的mmio_map_region() 研究kern/lapic.c中的lapic_init() void * mmio_map_region(physaddr_t pa, size_t size) { static uintptr_t base = MMIOBASE; if (base + size \u003e MMIOLIM) panic(\"mmio memory space is not enough .\"); uint32_t va = base; pa = ROUNDDOWN((uint32_t)pa, PGSIZE); size = ROUNDUP((uint32_t)size, PGSIZE); boot_map_region(kern_pgdir, base, size, pa, PTE_PCD|PTE_PWT|PTE_W); base += size; return (void *)va; //panic(\"mmio_map_region not implemented\"); } 可以发现这个函数的页权限的设计是使用了PTE_PCD|PTE_PWT，当CPU采用高速缓存时，它的写内存操作有两种模式，一种称为“穿透”(Write-Through)模式，在这种模式中高速缓存对于写操作就好像不存在一样，每次写时都直接写到内存中，所以实际上只是对读操作使用高速缓存，因而效率相对较低。另一种称为“回写”(Write-Back)模式，写的时候先写入高速缓存，然后由高速缓存的硬件在周转使用缓冲线时自动写入内存，或者由软件主动地“冲刷”有关的缓冲线。另外一点就是Cache Disable，防止这里的内存被CPU缓存，就是为了保证LAPIC被映射在内存上的寄存器值能够准确地被读取。 注意lapic_init()开头几步，需要返回一个MMIO的地址 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习1"},{"categories":["sys"],"content":"Application Processor Bootstrap在启动APs之前，BSP首先需要收集关于多处理器系统的信息，比如CPU的数量，它们的APIC ID以及这些LAPIC单元对应的MMIO地址。kern/mpconfig.c中mp_init()通过读取BIOS内存块的MP configuration table获取这些信息。 kern/init.c中的boot_aps()函数驱动AP的启动引导进程，APs在实模式下开始工作，就像之前的内核引导程序(boot/boot.S,)，boot_aps在实模式下复制一份AP entry code(kern/mpentry.S)到一个内存可以寻址的地方，所以一定程度上可以控制AP开始执行的内存地址；现在将把entry code复制到0x7000(MPENTRY_PADDR)，但实际上低于640KB未使用的页对齐的物理地址都可用。 之后，boot_aps()一个一个激活应用处理器，通过发送STARTUP中断信号到这些处理器对应的LAPIC单元，并且初始化CS:IP(指向MPENTRY_PADDR)。安装完后，使得AP开启保护模式，分页机制，并调用启动例程mp_main()。boot_aps()等待AP发送一个Cpuinfo结构体中的CPU_STARTEDflag，然后再启动接下来的处理器。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#application-processor-bootstrap"},{"categories":["sys"],"content":"练习2 将MPENTRY_PADDR从free_list中删除 boot_aps():将MPENTRY的代码安装到内核中去，为每一个cpu准备相应的栈区。然后通过一个for循环初始化所以cpu，在循环体内用while循环等待cpu被启动好的信号。 lapic_startup(id, addr)然后发送IPI到APIC bus上，让相应AP的LAPIC收到这个中断，开始执行mpentry.S中的内容，开启保护模式，分页；加载数据段，代码段等。 当mpentry执行到最后，调用mp_init()函数，初始化该AP的寄存器。 lapic_init():从处理器中获取lapic的相关信息 env_init_percpu():初始化每个处理器的段寄存器 trap_init_percpu():读取TSS和IDT 在最后，xchg()即发送CPU_STARTED信号给boot_aps()，完成一个cpu寄存器的初始化。 前面说过，部分设备的寄存器与内存是直接映射的，这里也是，lapic与内存直接相连，所以在lapic_startup函数中可以看到，向cpu发送命令都是通过在特定内存区域读写。 void page_init(void) { size_t i; size_t allocated_pages = ((uint32_t)boot_alloc(0) - KERNBASE) / PGSIZE; size_t IOhole_pages = (EXTPHYSMEM - IOPHYSMEM) /PGSIZE; for (i = 1; i \u003c npages; i++) { if(i == MPENTRY_PADDR/PGSIZE) continue; // BIOS else if (i \u003e= npages_basemem \u0026\u0026 i \u003c npages_basemem + allocated_pages + IOhole_pages){ continue; // see figure } else { pages[i].pp_ref = 0; pages[i].pp_link = page_free_list; // a linkedlist for page_free_list = \u0026pages[i]; // that the pages is free . } } } 练习就是把MPENTRY_PADDR从free_list中去除即可。 Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S? MPBOOTPHYS是用来计算传递进去参数的绝对地址，这段代码在boot_aps内就被复制到了内存高地址，AP读取gdt的命令ldgdt是在开启保护模式之前，所以，需要使用物理地址来读取全局表，否则不能读取到。但是在boot.S中，代码就是工作在实模式下，可以直接读取。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习2"},{"categories":["sys"],"content":"Per-cpu State and Initialization(manual 8.4.4) 在实现多处理系统的时候， 弄清每一个CPU所私有的部分和整个系统的共享是很重要的。kern/cpu.h中定义了cpu状态的结构体struct CpuInfo。cpunnum返回当前正在使用的ID，可以用作cpus数组的下标，当然也可以用宏thiscpu表示当前CPU结构体。 需要关注的CPU状态： 内核栈 由于CPU能同时陷入内核，所以需要分离每一个CPU所对应的内核栈，阻止处理器对其他处理器在执行任务时相互影响，数组percpu_kstacks[NCPU][KSTKSIZE]存储了多个处理器所对应的内核栈地址。 Lab2中，已经将bootstack映射到KSTACKTOP，在这个实验中，需要映射每一个CPU的内核栈到这个区域，并且使用一个guard pages作为缓冲。CPU0使用KSTACKTOP，CPU1将使用KSTACKTOP - KSTKGAP，等等。inc/memlayout.h中有内存排布情况。 TSS和TSS descriptor 每个CPU的任务状态段TSS(task state segement)也需要被确认，CPU的TSS存储在cpus[i].cpu_ts中，TSS descriptor存储在GDT entry gdt[(GD_TSS0 \u003e\u003e 3) + i]中。 当前环境指针 因为每个CPU都同时运行着不同的用户进程，所以使用重新定义的curenv。使用thiscpu-\u003ecpuenv来指向当前正在执行的环境。 系统寄存器 所有的寄存器，都是每一个CPU私有的，所都需要通过指令初始化，lcr3(),ltr(),lgdt(),lidt等都需要在每个CPU上执行一次。函数env_init_percpu和trap_init_percpu用来完成这项工作。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#per-cpu-state-and-initialization"},{"categories":["sys"],"content":"练习3 完成内核栈的内存映射 static void mem_init_mp(void) { size_t i; uint32_t kstacktop_i = KSTACKTOP; for (i = 0; i \u003c NCPU; i++) { /*stack*/ boot_map_region(kern_pgdir, kstacktop_i - KSTKSIZE, KSTKSIZE, PADDR(percpu_kstacks[i]), PTE_W | PTE_P); kstacktop_i -= KSTKSIZE; /*guard gap*/ kstacktop_i -= KSTKGAP; } } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习3"},{"categories":["sys"],"content":"练习4 修改trap_init_percpu()，使得每个CPU都能使用。 thiscpu-\u003ecpu_ts.ts_esp0 = (uint32_t)percpu_kstacks[thiscpu-\u003ecpu_id]; thiscpu-\u003ecpu_ts.ts_ss0 = GD_KD; thiscpu-\u003ecpu_ts.ts_iomb = sizeof(struct Taskstate); // Initialize the TSS slot of the gdt. gdt[(GD_TSS0 \u003e\u003e 3) + thiscpu-\u003ecpu_id] = SEG16(STS_T32A, (uint32_t) (\u0026(thiscpu-\u003ecpu_ts)), sizeof(struct Taskstate) - 1, 0); gdt[(GD_TSS0 \u003e\u003e 3) + thiscpu-\u003ecpu_id].sd_s = 0; // Load the TSS selector (like other segment selectors, the // bottom three bits are special; we leave them 0) ltr(GD_TSS0 + (thiscpu-\u003ecpu_id \u003c\u003c 3)); // Load the IDT lidt(\u0026idt_pd); 根据之前ts全局变量的过程，为每一个CPU都初始化任务状态。 位移运算3位是因为每个描述符的大小是8字节(struct Segdesc) 完成这里后，利用make qemu-nox CPUS=4可以发现其他cpu的成功启动 $ make qemu-nox CPUS=4 *** *** Use Ctrl-a x to exit qemu *** qemu-system-i386 -nographic -drive file=obj/kern/kernel.img,index=0,media=disk,format=raw -serial mon:stdio -gdb tcp::26000 -D qemu.log -smp 4 6828 decimal is 15254 octal! Physical memory: 131072K available, base = 640K, extended = 130432K check_page_free_list() succeeded! check_page_alloc() succeeded! check_page() succeeded! check_kern_pgdir() succeeded! check_page_free_list() succeeded! check_page_installed_pgdir() succeeded! SMP: CPU 0 found 4 CPU(s) enabled interrupts: 1 2 SMP: CPU 1 starting SMP: CPU 2 starting SMP: CPU 3 starting [00000000] new env 00001000 kernel panic on CPU 0 at kern/trap.c:295: kernel page fault Welcome to the JOS kernel monitor! Type 'help' for a list of commands. K\u003e ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习4"},{"categories":["sys"],"content":"自旋锁现在代码在执行mp_main()最后的for死循环，在AP继续运行之前，首先要解决多个CPU同时执行内核代码的条件竞争的问题。最简单的方法是使用big kernel lock，一种当一个环境进入了内核态开启的全局锁，当退回到用户态的时候解锁。在这个模式下，用户态都能同时正确地使用可用的CPU，但是只能有一个环境能运行在用户态，其他尝试进入内核态的环境都会被强制等待。 自旋锁(spinlock)是互斥(mutual exclusive)锁的一种实现形式，通过不断访问所需资源来判断临界资源资源是否被释放，优点是非常高效，临界资源一释放，等待的CPU将马上获得这份临界资源，所以适合那些保持锁时间短的情况，缺点是会持续占用CPU，浪费CPU时间。面对那些长时间占用临界资源的，应该使用信号量(semaphore)机制。 前段时间专业课上提到了Swap，就算一个基本的自旋锁。 代码实现如下: void Swap(boolean \u0026a, boolean \u0026b) { boolean temp = a; a = b; b = temp; } # entry do { Key = true; while (Key == ture) Swap(Lock, Key); critical Section; Lock = false; non critical Section } while(1) JOS自旋锁的实现是在kern/spinlock的spin_lock()中: while (xchg(\u0026lk-\u003elocked, 1) != 0) asm volatile (\"pause\"); 在xchg()中，这段代码的意思就是将数值“1”和lk-\u003elocked的值交换。 asm volatile(\"lock; xchgl %0, %1\" : \"+m\" (*addr), \"=a\" (result) : \"1\" (newval) : \"cc\"); return result; lock : 将下个访问内存指令所引用的内存空间上锁 xchgl %0, %1: \"+m\" (*addr), \"=a\" (result): \"1\" (newval) *addr替代占位符%0，限定符\"+m\"代表可read-modify-write的内存变量，限定符\"1\"代表其后面的操作数去描述占位符%1。所以这句指令是将 *addr的值与 1进行交换，并且把结果输出到 *addr和result中。 cc ：GNU文档解释，“As the condition codes will be changed, we are adding “cc” to clobberlist.” 在while循环体内，pause指令只是减少处理器执行太快引起的电力损耗，类似与一个延时语句。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#自旋锁"},{"categories":["sys"],"content":"练习5 给合适的地方上锁 # i386_init() // Acquire the big kernel lock before waking up APs // Your code here: lock_kernel(); // Starting non-boot CPUs boot_aps(); # mp_main() // Now that we have finished some basic setup, call sched_yield() // to start running processes on this CPU. But make sure that // only one CPU can enter the scheduler at a time! // // Your code here: lock_kernel(); sched_yield(); # trap() if ((tf-\u003etf_cs \u0026 3) == 3) { // Trapped from user mode. // Acquire the big kernel lock before doing any // serious kernel work. // LAB 4: Your code here. assert(curenv); lock_kernel(); ... } # env_run() //switch to user's address space. lcr3(PADDR(curenv-\u003eenv_pgdir)); //following operation will not implement the kernel //data, releasing the kernel resources here. unlock_kernel(); // pop trap frame , the environment return to the user mode. env_pop_tf(\u0026(curenv-\u003eenv_tf)); 完成这部分上锁的时候，可以看见在启动AP之前，内核是被BSP给锁定的，其他的CPU都还卡在自旋锁处进行循环。 Q2:It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock. 当一个CPU陷入内核还在进行保存状态信息的时候，另一个CPU刚好发生中断，此时内核还未被上锁，在只有一个栈的情况下，会发生混乱。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习5"},{"categories":["sys"],"content":"Challenge// fine-grained locking ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#challenge"},{"categories":["sys"],"content":"练习6 实现Round-Robin Scheduling调度算法 这个调度算法就是在envs全局变量中找到第一个可以运行的程序，观察user/yield.c的程序，代码每一次循环产生一次系统调用，让CPU执行下一个env。 实现这个调度算法就是利用循环队列来做。 void sched_yield(void) { // LAB 4: Your code here. int i, cur_id, nxt; if (curenv) cur_id = ENVX(curenv-\u003eenv_id); else cur_id = 0; #ifdef SELF_DEBUG_INFO cprintf(\"cpuid %d \\n\", thiscpu-\u003ecpu_id); #endif for (i = 0; i \u003c NENV; i++) { nxt = (i + cur_id) % NENV; if (envs[nxt].env_status == ENV_RUNNABLE) env_run(envs + nxt); } // there are no others environment to run. if (curenv \u0026\u0026 curenv-\u003eenv_status == ENV_RUNNING) env_run(curenv); // sched_halt never returns sched_halt(); } 添加新的系统调用和创建多个这样的用户环境 # syscall_dispatch() case SYS_yield: sys_yield(); return 0; # i386_init() #if defined(TEST) // Don't touch -- used by grading script! ENV_CREATE(TEST, ENV_TYPE_USER); #else // Touch all you want. ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); ENV_CREATE(user_yield, ENV_TYPE_USER); #endif // TEST* Q3:In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context–the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch? e在创建的时候会从kern_pgdir处复制一份，所以lcr3指令执行前后页表项是一样的。 Q4:Whenever the kernel switches from one environment to another, it must ensure the old environment’s registers are saved so they can be restored properly later. Why? Where does this happen? env_run()通过poptask frame，而在调用trap()的时候就已经保存了相关寄存器信息。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习6"},{"categories":["sys"],"content":"Challenge// stride scheduling 和 lottery scheduling ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#challenge-1"},{"categories":["sys"],"content":"System Calls for Environment Creation虽然代码能在不同的用户环境中切换了，但是是依靠的内核初始化创建的环境。现在要做的就是实现在用户环境下创建和开始另一个新的用户环境。 Unix中提供了最原始的fork()函数进行创建ixnd进程，fork复制整个父进程的内存空间去新建一个进程，唯一不同的就是它们的返回值，子进程返回0. 在这个练习中，将为JOS实现更为原始的方法去创建新用户空间。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#system-calls-for-environment-creation"},{"categories":["sys"],"content":"练习7 完成syscall.c ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习7"},{"categories":["sys"],"content":"sys_exoforkstatic envid_t sys_exofork(void) { // LAB 4: Your code here. int r; struct Env *new_env; if ((r = env_alloc(\u0026new_env, sys_getenvid())) \u003c 0) return r; new_env-\u003eenv_tf = curenv-\u003eenv_tf; new_env-\u003eenv_status = ENV_NOT_RUNNABLE; // child env return 0 new_env-\u003eenv_tf.tf_regs.reg_eax = 0; return new_env-\u003eenv_id; ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_exofork"},{"categories":["sys"],"content":"sys_env_set_statusstatic int sys_env_set_status(envid_t envid, int status) { // LAB 4: Your code here. //panic(\"sys_env_set_status not implemented\"); struct Env *e; int ret; /* must be ENV_RUNNABLE or ENV_NOT_RUNNABLE*/ if (status == ENV_RUNNABLE || status == ENV_NOT_RUNNABLE) ; else return -E_INVAL; /* check whether the caller env is env to be set*/ if ((ret = envid2env(envid, \u0026e, 1)) \u003c 0) return ret; e-\u003eenv_status = status; return 0; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_env_set_status"},{"categories":["sys"],"content":"sys_page_allocstatic int sys_page_alloc(envid_t envid, void *va, int perm) { // LAB 4: Your code here. //panic(\"sys_page_alloc not implemented\"); int ret; struct PageInfo *pg; struct Env *e; /* * regist the page in the page directory */ /*check envid*/ if (envid2env(envid, \u0026e, 1) \u003c 0) return -E_BAD_ENV; /*check va*/ if ((uint32_t)va \u003e= UTOP || (uint32_t)va % PGSIZE) return -E_INVAL; /* permission check */ if (perm \u0026 ~(PTE_U | PTE_P | PTE_AVAIL | PTE_W)) return -E_INVAL; /*allocating page and mapping*/ pg = page_alloc(ALLOC_ZERO); if (!pg) return -E_NO_MEM; if ((ret = page_insert(e-\u003eenv_pgdir, pg, va, perm ))) { page_free(pg); // failed, free page; return ret; } return 0; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_page_alloc"},{"categories":["sys"],"content":"sys_page_mapstatic int sys_page_map(envid_t srcenvid, void *srcva, envid_t dstenvid, void *dstva, int perm) { // LAB 4: Your code here. //panic(\"sys_page_map not implemented\"); /* * mapping */ pte_t *pte; // page table entry; struct Env *src, *dst; struct PageInfo *pp; /*check env*/ if (envid2env(srcenvid, \u0026src, 1) \u003c 0 || envid2env(dstenvid, \u0026dst, 1) \u003c 0) return -E_BAD_ENV; /* check va */ if ((uint32_t)srcva \u003e= UTOP || (uint32_t)srcva % PGSIZE || (uint32_t)dstva \u003e= UTOP || (uint32_t)dstva % PGSIZE) return -E_INVAL; /* check address space*/ if ((pp = page_lookup(src-\u003eenv_pgdir, srcva, \u0026pte)) == NULL) return -E_INVAL; /* check parameter permission */ if (perm \u0026 ~(PTE_P | PTE_U | PTE_AVAIL | PTE_W)) return -E_INVAL; /* pte permission check*/ if (!(*pte \u0026 PTE_W) \u0026\u0026 (perm \u0026 PTE_W)) return -E_INVAL; return page_insert(dst-\u003eenv_pgdir, pp, dstva, perm ); } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:4","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_page_map"},{"categories":["sys"],"content":"sys_page_unmapstatic int sys_page_unmap(envid_t envid, void *va) { struct Env *e; /*check env*/ if (envid2env(envid, \u0026e, 1)) return -E_BAD_ENV; if ((uint32_t)va \u003e= UTOP || (uint32_t)va % PGSIZE) return -E_INVAL; page_remove(e-\u003eenv_pgdir, va); return 0; // LAB 4: Your code here. //panic(\"sys_page_unmap not implemented\"); } int32_t syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5) { #define SELF_DEBUG_INFO #ifdef SELF_DEBUG_INFO cprintf(\"call number:%d \\n\", syscallno); #endif switch (syscallno) { case SYS_cputs: sys_cputs((char *)a1, a2); return 0; case SYS_cgetc: return sys_cgetc(); case SYS_getenvid: return sys_getenvid(); case SYS_env_destroy: return sys_env_destroy(a1); case SYS_yield: sys_yield(); return 0; case SYS_exofork: return sys_exofork(); case SYS_page_alloc: return sys_page_alloc(a1, (void *)a2, a3); case SYS_page_map: return sys_page_map(a1, (void *)a2, a3, (void *)a4, a5); case SYS_page_unmap: return sys_page_unmap(a1, (void *)a2); case SYS_env_set_status: return sys_env_set_status(a1 ,a2); default: return -E_INVAL; } } 两点问题: 注意在设置status的时候的逻辑短路问题。 exofork()中新的用户环境的eax应该置为0，以证明是子进程。 用户环境的代码执行完后，一个CPU会执行kernel monitor一直占用内核，而另外3个CPU都在卡在了trap中的那个自旋锁中。 PART A done. ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:5","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_page_unmap"},{"categories":["sys"],"content":"Part B: Copy-On-Write Fork最初Unix提供最基础的fork()系统调用去创建新的进程，forK()通过复制整个父进程的内存空间到子进程的内存中去，然而复制父进程到子进程是fork()操作开销最大的一个操作。通常情况下，fork()后子进程一般会马上调用exec()函数，用新的程序去替代子进程的内存空间。在这种情况下，复制父进程内存空间的时间开销很大程度上是不需要的，因为子进程仅有非常小的一部分被exec()所使用。 在之后的版本中，Unix采用虚拟内存硬件这一机制，允许父子进程共享分别被映射到它们各自内存空间的内存，直到其中一个进程确实修改了这部分共享的内存，被称之为__copy on write__。为了这个机制，fork()不是复制被实际映射的页，而是复制描述内存空间的映射情况的页，同时标记这个页为只读。一旦这两个进程之一尝试去修改这部分被共享的页，该进程将会产生页错误。此时，Unix内核意识到这个页是一个\"copy-on-write\"的页需要被拷贝，于是分配一个新的私有的可写的页拷贝给这个产生页错误的进程。通过这种方式，这些分开的页的内容实际不会复制除非这些页确实别尝试写入。这个优化使得fork()后在子进程中执行exec()的开销更小，子进程可能只需要复制一个页(stack page)在调用exec()前。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#part-b-copy-on-write-fork"},{"categories":["sys"],"content":"User-level page fault handling首先实现写时拷贝的fork()，需要知道被写保护的页。copy-on-write是多种可能处理页错误的方法之一。 一种通用做法就是建立起一个内存空间指出当发生页错误的时候确定一些操作。比如，大多数Unix内核只为新进程的栈区映射一个单页面，分配和映射额外的栈页仅在该新进程栈增长和在栈地址中发生了未映射的栈区域时处理。通常unix内核需要确定对应处理方法当页错误发生在进程的不同区域。页错误发生在栈区通常分配和映射一个新的页帧给这个进程；页错误发生在程序的BSS区域通常分配一个新的页，并且将页内容全部置为0，并且映射到页表中去；页错误发生在可执行文件的.text区域将会从磁盘中读取相应的二进制文件，并且映射。 这种处理办法虽然需要内核追踪一大堆信息，但是大大增加了程序的灵活性。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#user-level-page-fault-handling"},{"categories":["sys"],"content":"Normal and Exception Stacks in User Environments正常执行过程中，用户环境将会运行在正常用户栈中：即ESP寄存器最开始就指向了USTACKTOP，栈区数据被压入到USTACKTOP-PGSIZE和USTACKTOP-1这个范围中。当页错误发生在用户态下，内核将会重启这个用户环境，并且运行在一个被设计好的用户级别页错误解决办法(page fault handler)在一个不同的栈上，被称之为用户异常栈。大体上来说，JOS实现了在用户模式下的栈自动切换，同时，x86处理器已经实现了栈切换当发生从用户态到内核态发生转换的时候。 JOS的异常栈也是只有PGSIZE，但是定义在了虚拟内存地址的UXSTACKTOP，所以在栈区UXSTACKTOP到UXSTACKTOP-1都是合法的。当运行在异常栈，用户级页错误handler能用普通的系统调用去映射新的页，调节映射情况并且修复这个导致页错误的问题。然后，这个handler将会return，通过汇编语言stub返回到发生页错误的代码处。 任何一个用户程序需要支持用户级页错误将会需要去分配页给异常栈。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#normal-and-exception-stacks-in-user-environments"},{"categories":["sys"],"content":"Invoking the User Page Fault Handler为了解决来自用户态的页错误，现在需要调用用户态在发送页错误时的trap-time状态。 如果没有页错误的handler被登记，JOS内核将会销毁这个用户进程，不然的话，内核将要设置下面这样的trap frame在该用户环境的异常栈上。 \u003c-- UXSTACKTOP trap-time esp trap-time eflags trap-time eip trap-time eax start of struct PushRegs trap-time ecx trap-time edx trap-time ebx trap-time esp trap-time ebp trap-time esi trap-time edi end of struct PushRegs tf_err (error code) fault_va \u003c-- %esp when handler is run (_pgfault_handler argument) (eip pushed by call instruction) reserved 4-bytes \u003c-- to ret, reserved for eip trap-time esp \u003c-- we should adjust the esp(esp = esp-4) trap-time eflags trap-time eip ... new trap-time frame trap-time esi trap-time edi tf_err (error code) fault_va \u003c-- esp 系统内核需要准备用户在异常栈上面执行page fault handler的准备，fault_va是导致页错误的虚拟地址。 如果用户环境在执行异常处理的时候发生页错误，那么将要将trap-time frame压栈在tf-\u003etf_esp之下，而不是UXSTACKTOP。在这里，需要压入1个空的32-bit字，然后压入trap-time帧。 为了确定tf-\u003etf_esp是否已经在用户异常栈了，只需要检查它是否在范围UXSTACKTOP-PGSIZE和UXSTACKTOP-1这个范围内即可。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#invoking-the-user-page-fault-handler"},{"categories":["sys"],"content":"练习9 实现page_fault_handler中的代码 程序的执行流梳理下： 首先用户程序使用sys_set_env_pgfault_handler()系统调用设置好页错误处理方法。 当用户程序发生页错误的时候，此时trap进入内核，通过trapdispatch()的分发错误机制，单独处理页错误。 因为是在用户环境下发生的页错误，内核将该用户环境的运行栈改成异常栈， void page_fault_handler(struct Trapframe *tf) { ... // LAB 4: Your code here. struct UTrapframe *utf; uint32_t uesp; cprintf(\"user page fault\\n\"); if (tf-\u003etf_esp \u003c= UXSTACKTOP-1 \u0026\u0026 tf-\u003etf_esp \u003e= UXSTACKTOP-PGSIZE) uesp = tf-\u003etf_esp - sizeof(struct UTrapframe) - 4; else uesp = UXSTACKTOP - sizeof(struct UTrapframe); /* call upcall if current env has handler*/ if (curenv-\u003eenv_pgfault_upcall != NULL) { user_mem_assert(curenv, (void *)uesp, sizeof(struct UTrapframe), PTE_U|PTE_P|PTE_W); /*locates to the exception stack*/ utf = (struct UTrapframe *)uesp; /*construct User trap frame*/ utf-\u003eutf_fault_va = fault_va; utf-\u003eutf_err = tf-\u003etf_err; utf-\u003eutf_regs = tf-\u003etf_regs; utf-\u003eutf_eflags = tf-\u003etf_eflags; utf-\u003eutf_eip = tf-\u003etf_eip; utf-\u003eutf_esp = tf-\u003etf_esp; /*ready for handler paremeter*/ tf-\u003etf_esp = uesp; /*after trap , execute the handler routine*/ tf-\u003etf_eip = (uint32_t)curenv-\u003eenv_pgfault_upcall; env_run(curenv); } ... } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习9"},{"categories":["sys"],"content":"练习10 当发生页错误的时候，内核通过设置eip指向_pgfault_upcall来调用汇编代码，并且调用已经注册好的handler，该练习的任务就是当handler执行完后，用户如何返回到错误时的状态去。 .globl _pgfault_upcall _pgfault_upcall: // Call the C page fault handler. pushl %esp // function argument: pointer to UTF movl _pgfault_handler, %eax call *%eax addl $4, %esp // LAB 4: Your code here. subl $0x4, 0x30(%esp) # for push eip movl 0x30(%esp), %ebx #regular esp movl 0x28(%esp), %eax #eip movl %eax, (%ebx) // Restore the trap-time registers. After you do this, you // can no longer modify any general-purpose registers. // LAB 4: Your code here. addl $0x8, %esp popal #regular registers // Restore eflags from the stack. After you do this, you can // no longer use arithmetic operations or anything else that // modifies eflags. // LAB 4: Your code here. addl $0x4, %esp popfl // Switch back to the adjusted trap-time stack. // LAB 4: Your code here. popl %esp // Return to re-execute the instruction that faulted. // LAB 4: Your code here. ret ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习10"},{"categories":["sys"],"content":"练习11 完成set_pgfault_handler() void set_pgfault_handler(void (*handler)(struct UTrapframe *utf)) { int r; if (_pgfault_handler == 0) { // First time through! // LAB 4: Your code here. //panic(\"set_pgfault_handler not implemented\"); if (sys_page_alloc(0, (void *)UXSTACKTOP-PGSIZE, PTE_W|PTE_U|PTE_P) \u003c 0) panic(\"memory allocation failed: On UXSTACKTOP\"); } // Save handler pointer for assembly to call. _pgfault_handler = handler; if (sys_env_set_pgfault_upcall(0, _pgfault_upcall) \u003c 0) panic(\"bad env\"); } 通过一个callback function登记需要运行的handler，实现对不同情况的异常分发。 #Implementing Copy-on-Write Fork 与之前练习中的dumbfork()不同的是，dumbfork()复制了整个父环境中的所有的页，但是fork()仅仅只会复制一个关于页映射的页，其他的页会在用户环境往这些被标记的页写入内容的时候，发生页错误，并且分配新页，复制页内容。 fork()的控制流如下： 父环境安装pgfault()作为page fault handler，利用set_pgfault_handler()可以做到。 父环境调用sys_exofork()来创建子环境。 将每一个地址低于UTOP的状态为可写或者copy-on-write的页，使用duppage函数，映射到子环境的内存空间去，并且把自己的和子内存空间的页状态都标记COW状态。 异常栈不需要被映射，取而代之的是，父环境需要为子环境异常栈分配一个新的页。 为子环境设置页错误入口 将子环境标记为可运行状态。 每当父环境或者子环境尝试写入状态为cow的页时，将会引发页错误，页错误处理程序的控制流如下： 内核传递也错给_pgfault_，然后调用pgfault()来处理 pgfault()检查页错误的错误代码(FEC_WR)，并且页是否被标记为PTE_COW，如果不是，panic。 pgfault()分配一个新的页映射到一个临时位置，然后复制发生错误的页到临时页位置，然后再将这个临时位置映射到一个合适的位置，并且标记为可读可写，代替之前只读的映射。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习11"},{"categories":["sys"],"content":"练习12 实现fork,duppage,pgfault ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习12"},{"categories":["sys"],"content":"fork()envid_t fork(void) { // LAB 4: Your code here. //panic(\"fork not implemented\"); set_pgfault_handler(pgfault); int r; envid_t envid; int32_t va; envid = sys_exofork(); if (envid \u003c 0) panic(\"sys_exofork error\"); if (envid == 0) { // panic(\"child\"); thisenv = \u0026envs[ENVX(sys_getenvid())]; cprintf(\"child: %d\\n\", thisenv-\u003eenv_id); return 0; } cprintf(\"parent fork:%d -\u003e %d\\n\", thisenv-\u003eenv_id, envid); for (va = 0; va \u003c USTACKTOP; va += PGSIZE) if ((uvpd[PDX(va)] \u0026 PTE_P) \u0026\u0026 (uvpt[PGNUM(va)] \u0026 (PTE_P|PTE_U)) ) duppage(envid, (uint32_t)PGNUM(va)); //panic(\"1\"); if ((r = sys_page_alloc(envid, (void *)UXSTACKTOP-PGSIZE, PTE_P|PTE_U|PTE_W)) \u003c 0) return r; extern void _pgfault_upcall(void); sys_env_set_pgfault_upcall(envid, _pgfault_upcall); if ((r = sys_env_set_status(envid, ENV_RUNNABLE)) \u003c 0) return r; return envid; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:4:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#fork"},{"categories":["sys"],"content":"duppage()static int duppage(envid_t envid, unsigned pn) { int r; uint32_t va; // LAB 4: Your code here. //panic(\"duppage not implemented\"); va = pn*PGSIZE; //cprintf(\"%x\\n\", va); if (uvpt[pn] \u0026 PTE_COW || uvpt[pn] \u0026 PTE_W) { if ((r = sys_page_map(thisenv-\u003eenv_id, (void *)va, envid, (void *)va, PTE_P|PTE_U|PTE_COW)) \u003c 0) panic(\"2\"); if ((r = sys_page_map(thisenv-\u003eenv_id, (void *)va, thisenv-\u003eenv_id, (void *)va, PTE_P|PTE_U|PTE_COW)) \u003c 0) panic(\"3\"); } else if ((r = sys_page_map(thisenv-\u003eenv_id, (void *)va, envid, (void *)va, PTE_U|PTE_P)) \u003c 0) panic(\"4\"); return 0; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:4:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#duppage"},{"categories":["sys"],"content":"pgfault()static void pgfault(struct UTrapframe *utf) { void *addr = (void *) utf-\u003eutf_fault_va; uint32_t err = utf-\u003eutf_err; int r; //cprintf(\"%d\\n\", err); if (!(err \u0026 FEC_WR) || !(uvpt[PGNUM(addr)] \u0026 PTE_COW)) panic(\"user page fault: write to non-copy-on-write page\"); // LAB 4: Your code here. //panic(\"pgfault not implemented\"); addr = (void *)ROUNDDOWN((uint32_t)addr, PGSIZE); //cprintf(\"thisenv-\u003eenvid : %d\\n\", thisenv-\u003eenv_id); if ((r = sys_page_alloc(0, (void *)PFTEMP, PTE_P|PTE_U|PTE_W)) \u003c 0) panic(\"handler fault :haven't memory \"); memmove((void *)PFTEMP, addr, PGSIZE); if ((r = sys_page_map(0, (void *)PFTEMP, 0, addr, PTE_P|PTE_U|PTE_W)) \u003c 0) panic(\"handler fault: sys_page_map\"); if ((r = sys_page_unmap(0, PFTEMP)) \u003c 0) panic(\"handler fault: sys_page_unmap\"); } 两个问题： 1.在这，fork()是设置好子环境的相关上下文才调度到子环境中去的。 thisenv-\u003eenv在duppage()中使用正常，但是在pgfault()会panic，于是观察系统调用信息：这个fork二叉树的根节点会在设置完子进程的信息后销毁，然后cpu调度新的任务。fork()函数中Hint告诉我注意修改子进程中的thienv的值。 thisenv = \u0026envs[ENVX(sys_getenvid())]; thisenv是一个全局(静态)变量，被放在程序的.data域，父环境已经标记这个页为cow状态，所以这个赋值写操作会引发页错误。然后页错误处理程序来为这个页做一个拷贝到该子环境内存空间中。所以当我使用三个系统调用sys_page_alloc,sys_page_map,sys_page_unmap并且传递thisenv-\u003eenv_id的时候，是被标记为cow的页发送读请求，结果读到的是父环境的内存内容。父环境已经被销毁了，所以程序在这儿被panic。 PS:父环境销毁的时候并不会回收实际页帧，每个页帧都要一个引用计数器，引用计数器的值在fork()的情境下，应该为2，所以不会被会受到free_list中去 PART B done ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:4:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#pgfault"},{"categories":["sys"],"content":"Part C: Preemptive Multitasking and Inter-Process communication (IPC)","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#part-c-preemptive-multitasking-and-inter-process-communication-ipc"},{"categories":["sys"],"content":"Clock Interrupts and Preemption运行user/spin测试程序，这个程序fork出一个子进程，子进程一旦接手CPU后只是简单地永久循环。父进程和内核都不能再获得CPU，这对保护操作系统防范恶意代码和bug的影响当然不是个好情况，因为任何用户态的进程都能接管整个系统去执行一个死循环。为了允许内核去抢占一个正在执行的环境，强制地重新获取CPU，必须为JOS提供来自时钟硬件的外部硬件中断。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#clock-interrupts-and-preemption"},{"categories":["sys"],"content":"Interrput discipline外部中断又被称作IRQ(Interrupt Request Line)，有16种可能的IRQ，从0-15。picirq.c中的pic_init()映射IRQ 0-15映射到IDT的IRQ_OFFSET~IRQ_OFFSET+15。 inc/trap.h文件中，IRQ_OFFSET 被定义为十进制的23，用IDT表的32-47对应IRQ的0~15中断。例如，时钟中断是IRQ的0号，IDT[IRQ_OFFSET+0]包含了再内核中的时钟的历程。IRQ_OFFSET，选用IRQ_OFFSET这个值是为了不覆盖处理器异常。 JOS做了一个相对于xv6来说关键性的简化，外部中断_总是_在内核态的时候总是被关闭的。外部中断被eflags寄存器的IF位所控制。当这个bit位被置1时，外部中断被打开。当然这个flag值能被多种方法修改，但是由于JOS的简化，保存和恢复eflags寄存器只有一种单独的方式进入和离开用户态。 在外部中断来临之前，必须保证FL_IF的标志位被设置，中断号通过处理器获得。否则，中断会被屏蔽，或者会被忽略直到中断位被重新开启。在bootloader的时候，就已经屏蔽了中断，并且到现在都没有重新开启它们。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#interrput-discipline"},{"categories":["sys"],"content":"练习13 修改kern/trapentry.S和kern/trap.c，在IDT中去初始化合适的入口，并且为IRQ提供合适的handler。 然后修改env_alloc()保证用户环境总是开启了中断响应。 去掉sti(set interrupt-enable flag)指令的注释，使得这个闲置CPU取消屏蔽中断。 处理器对于硬件中断不会push错误代码(通过CPU针脚和lapic的都不会) for example, it is possible to invoke the page-fault handler through the INTR pin (by means of vector 14); however, this is not a true page-fault exception. It is an interrupt. 也就是说，之前的异常是通过中断产生的，在这个练习中，需要为每一个env都开启IF标志位，所以需要修改之前的handler，使得用户环境发生中断的时候，将IF清0，屏蔽中断。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习13"},{"categories":["sys"],"content":"trap.c//irq void irq_handler0(); void irq_handler1(); void irq_handler2(); void irq_handler3(); void irq_handler4(); void irq_handler5(); void irq_handler6(); void irq_handler7(); void irq_handler8(); void irq_handler9(); void irq_handler10(); void irq_handler11(); void irq_handler12(); void irq_handler13(); void irq_handler14(); void irq_handler15(); SETGATE(idt[T_DIVIDE], 0, GD_KT, divid_entry, 0); SETGATE(idt[T_DEBUG], 0, GD_KT, debug_entry, 3); SETGATE(idt[T_NMI], 0, GD_KT, nmi_entry, 0); SETGATE(idt[T_BRKPT], 0, GD_KT, brkpt_entry, 3); SETGATE(idt[T_OFLOW], 0, GD_KT, oflow_entry, 0); SETGATE(idt[T_BOUND], 0, GD_KT, bound_entry, 0); SETGATE(idt[T_ILLOP], 0, GD_KT, illop_entry, 0); SETGATE(idt[T_DEVICE], 0, GD_KT, device_entry, 0); SETGATE(idt[T_DBLFLT], 0, GD_KT, dblflt_entry, 0); SETGATE(idt[T_TSS], 0, GD_KT, tss_entry, 0); SETGATE(idt[T_SEGNP], 0, GD_KT, segnp_entry, 0); SETGATE(idt[T_STACK], 0, GD_KT, stack_entry, 0); SETGATE(idt[T_GPFLT], 0, GD_KT, gpflt_entry, 0); SETGATE(idt[T_PGFLT], 0, GD_KT, pgflt_entry, 0); SETGATE(idt[T_FPERR], 0, GD_KT, fperr_entry, 0); SETGATE(idt[T_SYSCALL], 0, GD_KT, syscall_entry, 3); //irq handler mapping SETGATE(idt[IRQ_OFFSET+0], 0, GD_KT, irq_handler0, 3); SETGATE(idt[IRQ_OFFSET+1], 0, GD_KT, irq_handler1, 3); SETGATE(idt[IRQ_OFFSET+2], 0, GD_KT, irq_handler2, 3); SETGATE(idt[IRQ_OFFSET+3], 0, GD_KT, irq_handler3, 3); SETGATE(idt[IRQ_OFFSET+4], 0, GD_KT, irq_handler4, 3); SETGATE(idt[IRQ_OFFSET+5], 0, GD_KT, irq_handler5, 3); SETGATE(idt[IRQ_OFFSET+6], 0, GD_KT, irq_handler6, 3); SETGATE(idt[IRQ_OFFSET+7], 0, GD_KT, irq_handler7, 3); SETGATE(idt[IRQ_OFFSET+8], 0, GD_KT, irq_handler8, 3); SETGATE(idt[IRQ_OFFSET+9], 0, GD_KT, irq_handler9, 3); SETGATE(idt[IRQ_OFFSET+10], 0, GD_KT, irq_handler10, 3); SETGATE(idt[IRQ_OFFSET+11], 0, GD_KT, irq_handler11, 3); SETGATE(idt[IRQ_OFFSET+12], 0, GD_KT, irq_handler12, 3); SETGATE(idt[IRQ_OFFSET+13], 0, GD_KT, irq_handler13, 3); SETGATE(idt[IRQ_OFFSET+14], 0, GD_KT, irq_handler14, 3); SETGATE(idt[IRQ_OFFSET+15], 0, GD_KT, irq_handler15, 3); ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#trapc"},{"categories":["sys"],"content":"trapentry.STRAPHANDLER_NOEC(irq_handler0, 32); TRAPHANDLER_NOEC(irq_handler1, 33); TRAPHANDLER_NOEC(irq_handler2, 34); TRAPHANDLER_NOEC(irq_handler3, 35); TRAPHANDLER_NOEC(irq_handler4, 36); TRAPHANDLER_NOEC(irq_handler5, 37); TRAPHANDLER_NOEC(irq_handler6, 38); TRAPHANDLER_NOEC(irq_handler7, 39); TRAPHANDLER_NOEC(irq_handler8, 40); TRAPHANDLER_NOEC(irq_handler9, 41); TRAPHANDLER_NOEC(irq_handler10, 42); TRAPHANDLER_NOEC(irq_handler11, 43); TRAPHANDLER_NOEC(irq_handler12, 44); TRAPHANDLER_NOEC(irq_handler13, 45); TRAPHANDLER_NOEC(irq_handler14, 46); TRAPHANDLER_NOEC(irq_handler15, 47); ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#trapentrys"},{"categories":["sys"],"content":"env.c// Enable interrupts while in user mode. // LAB 4: Your code here. e-\u003eenv_tf.tf_eflags |= FL_IF; 此时为每一个用户进程响应外部中断。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#envc"},{"categories":["sys"],"content":"Handing Clock Interrupts在user/spin程序中，在子程序一开始运行时就仅仅是一直循环，内核不能取回控制权，所以现在需要生成周期性的时钟中断，强制性地取回内核的控制权，并且切换到不同的用户环境。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#handing-clock-interrupts"},{"categories":["sys"],"content":"练习14 修改trap_dispatch()，使得当发生时钟中断的时候，调用不同的用户环境。 // Handle clock interrupts. Don't forget to acknowledge the // interrupt using lapic_eoi() before calling the scheduler! // LAB 4: Your code here. if (tf-\u003etf_trapno == IRQ_OFFSET + 0) { lapic_eoi(); sched_yield(); } eoi(end of interrupt):置为0表示该中断例程已经结束了。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习14"},{"categories":["sys"],"content":"Inter-Process communication (IPC)之前都是关注的操作系统的独立性，这种方式使得每个程序看似独占一台机器。另外一个重要的操作系统服务就是允许程序与其他的程序进行交互。Unix中的pipe模型就是一个很典型的例子。 还有很多模型提供了IPC，关于这些模型哪个最好仍在争议中，取而代之的实现一个简单的IPC机制。 首先为JOS kernel提供几个的系统调用(sys_ipc_recv和sys_ipc_try_send)提供一个简单的IPC机制，然后实现两个库函数包装系统调用。 用户环境能发送给其他环境的“消息”由两部分组成：一个32-bit的值和一个可选的单页映射。相比单个32位整形，提供了一种更高效的通过传递页映射信息的方式，允许环境更方便设置共享内存。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#inter-process-communication-ipc"},{"categories":["sys"],"content":"Sending and Receiving Messages为了接收信息，一个用户环境调用sys_ipc_recv。系统调用放弃CPU当前执行的用户环境，并且直到接收到信息之前不会再运行。当一个用户环境正在等待一个消息，任何其他的环境能给它发送消息(不需要特定的用户环境，不需要父子进程等)。换句话说，PART A中的检查对IPC不适用，因为IPC系统调用被设计得很安全：一个用户进程不会因为被接收消息而发生失灵。 为了尝试发送一个值，用户环境调用sys_ipc_try_send发送接收者的环境id和需要发送的值。如果该id所指的环境确实在接收状态，那么发送方发送消息并且返回0。否则发送方返回-E_IPC_NOT_RECV指出目标环境现在不期望获得一个值。 用户空间的库函数ipc_recv将会调用sys_ipc_recv并且寻找相关被接收的值。同样地，ipc_send将会重复地调用sys_ipc_try_send直到成功。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sending-and-receiving-messages"},{"categories":["sys"],"content":"Transferring Pages当一个用户环境调用sys_ipc_recv使用了一个合法的dstva参数，那么这个环境将会愿意去接受一个页的映射。如果发送方发送了一个页，那么这个页将会被映射到接收方的dstva这个地址空间去。 如果接收方已经映射了页帧在dstva，那么先前的页映射将会被取消。 当一个用户环境调用sys_ipc_try_send传递小于UTOP的参数srcva，这意味着发送方想将这个页映射到接收方的内存空间，并且设置权限位perm。成功IPC后，发送方保持之前的页映射，但是接收方映射了与发送方相同的页帧到dstva，这使得双方能共享同一个页。如果发送方或者接收方没有指出哪个页需要被发送，那么就没有页被发送。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#transferring-pages"},{"categories":["sys"],"content":"练习15 先实现sys_ipc_recv和sys_ipc_try_send,checkperm需要被置0，因为不一定需要父子关系才能引用。 实现ipc_recv和ipc_send，这是对系统调用的一个封装。 用user/pingpong和user/primes测试IPC机制。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#练习15"},{"categories":["sys"],"content":"sys_ipc_recv()static int sys_ipc_recv(void *dstva) { // LAB 4: Your code here. //panic(\"sys_ipc_recv not implemented\"); if ((uint32_t)dstva \u003c UTOP \u0026\u0026 (uint32_t)dstva % PGSIZE) return -E_INVAL; //mapping //set status curenv-\u003eenv_ipc_recving = true; curenv-\u003eenv_ipc_dstva = dstva; curenv-\u003eenv_status = ENV_NOT_RUNNABLE; sched_yield(); return 0; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_ipc_recv"},{"categories":["sys"],"content":"sys_ipc_try_send()static int sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm) { // LAB 4: Your code here. //panic(\"sys_ipc_try_send not implemented\"); struct Env *dstenv; struct PageInfo *pp; pte_t *pte; //cprintf(\"%x, val: %d\\n\", srcva, value); if (envid2env(envid, \u0026dstenv, 0) \u003c 0) return -E_BAD_ENV; if (!dstenv-\u003eenv_ipc_recving) return -E_IPC_NOT_RECV; if (perm \u0026 ~PTE_SYSCALL) return -E_INVAL; // for page mapping checks // if ((uint32_t)srcva \u003c UTOP) { if ((uint32_t)srcva % PGSIZE) return -E_INVAL; if (!(pp = page_lookup(curenv-\u003eenv_pgdir, srcva, \u0026pte))) return -E_INVAL; if (perm \u0026 PTE_W \u0026\u0026 !(*pte \u0026 PTE_W)) return -E_INVAL; if (page_insert(dstenv-\u003eenv_pgdir, pp, dstenv-\u003eenv_ipc_dstva, perm) \u003c 0) return -E_NO_MEM; } // update target env fields dstenv-\u003eenv_ipc_recving = false; dstenv-\u003eenv_ipc_from = curenv-\u003eenv_id; dstenv-\u003eenv_ipc_value = value; dstenv-\u003eenv_ipc_perm = perm; dstenv-\u003eenv_status = ENV_RUNNABLE; dstenv-\u003eenv_tf.tf_regs.reg_eax = 0; return 0; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#sys_ipc_try_send"},{"categories":["sys"],"content":"ipc_recv()int32_t ipc_recv(envid_t *from_env_store, void *pg, int *perm_store) { // LAB 4: Your code here. //panic(\"ipc_recv not implemented\"); int r; void *va; if (pg != NULL) va = pg; if (pg == NULL) va = (void *)-1; //system call failed if (sys_ipc_recv(va) \u003c 0) { *from_env_store = 0; *perm_store = 0; } //store infomation for caller if (from_env_store) *from_env_store = thisenv-\u003eenv_ipc_from; if (perm_store) *perm_store = thisenv-\u003eenv_ipc_perm; return thisenv-\u003eenv_ipc_value; } ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#ipc_recv"},{"categories":["sys"],"content":"ipc_send()void ipc_send(envid_t to_env, uint32_t val, void *pg, int perm) { // LAB 4: Your code here. //panic(\"ipc_send not implemented\"); int r; void *va; if (!pg) va = (void *)-1; else va = pg; while (1) { r = sys_ipc_try_send(to_env, val, va, perm); if (r == 0) break; if (r \u003c 0 \u0026\u0026 r != -E_IPC_NOT_RECV) panic(\"error on send ipc_send, %e\", r); if (r == -E_IPC_NOT_RECV) sys_yield(); } } 梳理一个过程(pingpong程序)： sys_ipc_recv将当前env设置为不可运行状态后调用调度程序，发送方开始执行检查并且配置自己和接收方内存空间的页映射等相关信息，设置完后通过return返回到trap()函数，通过env_run()返回用户态，准备执行ipc_recv接收刚才接收方的消息，执行调度。接收方的用户环境已经设置为可运行状态，从而开始执行env_run，此时这个环境中eax的值还是之前系统调用号12，如果运行env_tf_pop会直接回到调用的地点引发错误。所以，发送方应该将接收方的eax置为0表示接收成功。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:1:4","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#ipc_send"},{"categories":["sys"],"content":"make grademake[1]: Leaving directory '/home/moonlight/lab' dumbfork: OK (1.4s) Part A score: 5/5 faultread: OK (0.9s) faultwrite: OK (1.0s) faultdie: OK (2.0s) faultregs: OK (2.0s) faultalloc: OK (1.0s) faultallocbad: OK (1.8s) faultnostack: OK (1.1s) faultbadhandler: OK (1.9s) faultevilhandler: OK (2.2s) forktree: OK (2.0s) Part B score: 50/50 spin: OK (1.9s) stresssched: OK (3.4s) sendpage: OK (1.8s) (Old jos.out.sendpage failure log removed) pingpong: OK (2.0s) (Old jos.out.pingpong failure log removed) primes: OK (13.9s) (Old jos.out.primes failure log removed) Part C score: 25/25 Score: 80/80 moonlight@ubuntu:~/lab$ Challenge 1:solute the ipc_send loop //todo here , reading IA32 ipc_send use ipc_find_env firstly to find corrsponding env whose status is runnable call sys_ipc_try_send for the status of target env is running ,I should send an IPC interrupt using lapic_ipi() function in the file lapic.c. makes it runnable call sys_ipc_try_send thread introduction : http://www.hpl.hp.com/techreports/Compaq-DEC/SRC-RR-35.pdf kernel design : https://github.com/fATwaer/fatwaer.github.io/tree/master/pdf/os/SRC-RR-35.pdf ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#make-grade"},{"categories":["sys"],"content":"总结上面两篇paper非常值得一看，JOS到目前为止都没用到thread这个概念，但是在接下来的学习中是非常重要的，另外一直没有看完的是IA32手册，这份手册提供了很多操作系统的细节，虽然没必要全部读完，但是我觉得至少把个位数的章节读完是很有必要的。 Lab4到这里已经结束了，从5.7到5.19大概花了两周的时间，不同部分的代码依赖很强，一点不小心就会引发非常严重的错误。不过在这个实验中，第一次听说了回归测试这个概念，应该与单元测试功能相同，是为大型程序阶段性检测的一种技巧。JOS替换了进程的叫法，称之为“用户环境”。在实验中可以体会到，一个用户环境的创建包括很多过程，页表，页映射，当前执行的CPU，错误处理机制，正常栈，异常栈等等信息都要提前准备好才把这个进程设置为可运行状态，所准备的一切都是为一个需要执行的任务做下铺垫。 ","date":"2018-05-07","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab4:Preemptive Multitasking","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/#总结"},{"categories":["sys"],"content":" 4月22日 - 5月2日 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#"},{"categories":["sys"],"content":"PART A这章的练习将会取实现一些基础的用户模式下的环境，也就是进程。在这章，创建一个用户环境，读取程序镜像并且运行。 这是关于这章节代码文件的介绍 inc/env.h Public definitions for user-mode environments trap.h Public definitions for trap handling syscall.h Public definitions for system calls from user environments to the kernel lib.h Public definitions for the user-mode support library kern/env.h Kernel-private definitions for user-mode environments env.c Kernel code implementing user-mode environments trap.h Kernel-private trap handling definitions trap.c Trap handling code trapentry.S Assembly-language trap handler entry-points syscall.h Kernel-private definitions for system call handling syscall.c System call implementation code lib/Makefrag Makefile fragment to build user-mode library, obj/lib/ libjos.a entry.S Assembly-language entry-point for user environments libmain.c User-mode library setup code called from entry.S syscall.c User-mode system call stub functions console.c User-mode implementations of putchar and getchar, providing console I/O exit.c User-mode implementation of exit panic.c User-mode implementation of panic user/ * Various test programs to check kernel lab 3 code ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#part-a"},{"categories":["sys"],"content":"内联汇编简单描述: __asm__(汇编语句模板: 输出部分: 输入部分: 破坏描述部分) 具体详情 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#内联汇编"},{"categories":["sys"],"content":"文件概述在文件inc/env.h中定义了Env结构体，用来存储一些关于用户环境(进程)的结构体。 struct Env { struct Trapframe env_tf; // Saved registers struct Env *env_link; // Next free Env envid_t env_id; // Unique environment identifier envid_t env_parent_id; // env_id of this env's parent enum EnvType env_type; // Indicates special system environments unsigned env_status; // Status of the environment uint32_t env_runs; // Number of times environment has run // Address space pde_t *env_pgdir; // Kernel virtual address of page dir }; 在这个结构体中，env_status用来指示当前进程的状态，有以下几种定义在一个枚举类型里面。 enum { ENV_FREE = 0, ENV_DYING, ENV_RUNNABLE, ENV_RUNNING, ENV_NOT_RUNNABLE }; 文件kern/env.c文件中，有三个文件域的定义。 struct Env *envs = NULL; // All environments struct Env *curenv = NULL; // The current env static struct Env *env_free_list; // Free environment list envs指向保存所有Env结构体的内存页，并且指向虚拟内存UTOP。 curenv是字面意思，指向当前执行的进程。 env_free_list是一个链表表头，类似之前的page_free_list。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#文件概述"},{"categories":["sys"],"content":"练习1 分配NENV个Env结构体，并且用envs指针指向它们 // Make 'envs' point to an array of size 'NENV' of 'struct Env'. envs = (struct Env *)boot_alloc(NENV * sizeof(struct Env)); memset(envs, 0, NENV * sizeof(struct Env)); // Map the 'envs' array read-only by the user at linear address UENVS // (ie. perm = PTE_U | PTE_P). boot_map_region(kern_pgdir, UENVS, PTSIZE, PADDR(envs), PTE_U | PTE_P); ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习1"},{"categories":["sys"],"content":"练习2 创建并且运行进程 完成以下函数: env_init() Initialize all of the Env structures in the envs array and add them to the env_free_list. Also calls env_init_percpu, which configures the segmentation hardware with separate segments for privilege level 0 ( kernel) and privilege level 3 (user). env_setup_vm() Allocate a page directory for a new environment and initialize the kernel portion of the new environment's address space. region_alloc() Allocates and maps physical memory for an environment load_icode() You will need to parse an ELF binary image, much like the boot loader already does, and load its contents into the user address space of a new environment. env_create() Allocate an environment with env_alloc and call load_icode to load an ELF binary into it. env_run() Start a given environment running in user mode. As you write these functions, you might find the new cprintf verb %e useful -- it prints a description corresponding to an error code. For example, r = -E_NO_MEM; panic(\"env_alloc: %e\", r); will panic with the message \"env_alloc: out of memory\". ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习2"},{"categories":["sys"],"content":"env_init()void env_init(void) { // Set up envs array // LAB 3: Your code here. int i; for (i = NENV - 1; i \u003e= 0; i--) { // reversal order envs[i].env_id = 0; envs[i].env_status = ENV_FREE; envs[i].env_link = env_free_list; env_free_list = \u0026envs[i]; } // Per-CPU part of the initialization env_init_percpu(); } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#env_init"},{"categories":["sys"],"content":"env_setup_vm()static int env_setup_vm(struct Env *e) { int i; struct PageInfo *p = NULL; // Allocate a page for the page directory if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM; // LAB 3: Your code here. e-\u003eenv_pgdir = (pte_t *)page2kva(p); p-\u003epp_ref++; /* copy structs to UTOP*/ memcpy(e-\u003eenv_pgdir, kern_pgdir, PGSIZE); // UVPT maps the env's own page table read-only. // Permissions: kernel R, user R e-\u003eenv_pgdir[PDX(UVPT)] = PADDR(e-\u003eenv_pgdir) | PTE_P | PTE_U; return 0; } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#env_setup_vm"},{"categories":["sys"],"content":"region_alloc()static void region_alloc(struct Env *e, void *va, size_t len) { // LAB 3: Your code here. // (But only if you need it for load_icode.) // // Hint: It is easier to use region_alloc if the caller can pass // 'va' and 'len' values that are not page-aligned. // You should round va down, and round (va + len) up. // (Watch out for corner-cases!) uintptr_t va_beg = ROUNDDOWN((uint32_t)va, PGSIZE); uintptr_t va_end = ROUNDUP((uint32_t)(va+len), PGSIZE); uintptr_t i; for (i = va_beg; i \u003c va_end; i += PGSIZE) { /* maps each page to pa */ struct PageInfo *p; if (!(p = page_alloc(ALLOC_ZERO))) panic(\"lack of free pages\"); if ((page_insert(e-\u003eenv_pgdir, p, (void *)i, PTE_P | PTE_U | PTE_W)) == -E_NO_MEM) panic(\"lack memmory\"); } } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#region_alloc"},{"categories":["sys"],"content":"load_icode()static void load_icode(struct Env *e, uint8_t *binary) { // LAB 3: Your code here. /* user mode */ lcr3(PADDR(e-\u003eenv_pgdir)); struct Elf *elf = (struct Elf *)binary; /* check file format */ if (elf-\u003ee_magic != ELF_MAGIC) panic(\"load_icode() : format error \"); if (elf-\u003ee_entry == 0) panic(\"load_icode() : ELF file loads failed\"); e-\u003eenv_tf.tf_eip = elf-\u003ee_entry; struct Proghdr *ph, *eph; ph = (struct Proghdr *)(binary + elf-\u003ee_phoff); eph = ph + elf-\u003ee_phnum; for (; ph \u003c eph; ph++) { if (ph-\u003ep_type == ELF_PROG_LOAD) { region_alloc(e, (void *)(ph-\u003ep_va), ph-\u003ep_memsz); memcpy((void *)ph-\u003ep_va, (void *)binary + ph-\u003ep_offset, (size_t)(ph-\u003ep_filesz)); } } lcr3(PADDR(kern_pgdir)); // Now map one page for the program's initial stack // at virtual address USTACKTOP - PGSIZE. // LAB 3: Your code here. region_alloc(e, (void *)USTACKTOP-PGSIZE, PGSIZE); } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#load_icode"},{"categories":["sys"],"content":"env_create()void env_create(uint8_t *binary, enum EnvType type) { // LAB 3: Your code here. struct Env * env; if (env_alloc(\u0026env, 0) \u003c 0) panic(\"env_alloc error !\"); load_icode(env, binary); env-\u003eenv_type = type; } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:5:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#env_create"},{"categories":["sys"],"content":"env_run()void env_run(struct Env *e) { if (curenv != NULL \u0026\u0026 curenv-\u003eenv_status == ENV_RUNNING) curenv-\u003eenv_status = ENV_RUNNABLE; curenv = e; curenv-\u003eenv_status = ENV_RUNNING; curenv-\u003eenv_runs++; lcr3(PADDR(curenv-\u003eenv_pgdir)); env_pop_tf(\u0026(curenv-\u003eenv_tf)); // Hint: This function loads the new environment's state from // e-\u003eenv_tf. Go back through the code you wrote above // and make sure you have set the relevant parts of // e-\u003eenv_tf to sensible values. // LAB 3: Your code here. //panic(\"env_run not yet implemented\"); } 代码完成后应该还是会无限重启，因为，在执行完env_pop_tf的时候会去调用用户自己写的代码，但是会要用到从用户态到内核态的跳转，这部分代码并没有完成。 start (kern/entry.S) i386_init (kern/init.c) cons_init mem_init env_init trap_init (still incomplete at this point) env_create env_run env_pop_tf 在qemu上运行这个内核，如果调用了成功执行到env_pop_tf的话，基本成功了。此时，内核会去执行一个hello的二进制文件，但是会用到系统调用和使用int中断指令。但是此时的JOS并没有完成用户空间到内核空间的跳转。CPU发现没有办法解决这个的办法，于是生成一个__二重错误异常__，然后继续发现还是没有办法去处理这个错误机制，于是引发__三重错误异常__，这时候，CPU就会要重置，使得整个系统重新启动。这就是现在看到的无限重启的行为。 用make-qemu和make gdb编译出内核，用break env_pop_tf在函数env_pop_tf处设置断点，单步执行，看能否能进入hello.asm中，地址在用户内存空间(0x08000000+)。然后在obj/user/hello.asm中找到sys_cputs中的int $0x30指令。如果成功执行到了这儿，说明之前的代码没有问题。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:6:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#env_run"},{"categories":["sys"],"content":"练习3阅读Chapter 9, Exceptions and Interrupts 中断是外部发给CPU的信号，而异常是CPU在自己处理命令时候出现的错误。 其中中断分为可屏蔽和不可屏蔽的。 异常也有三种(Faults/Traps/Aborts)，Faults异常是在执行这条指令之前就被指出的错误，但是如果在执行的过程中遇到了faults级的错误，CPU将会让机器保存状态，并且允许被修正重新执行。 第二种是Traps异常，是一种执行完后立即报告的异常，允许程序连续性执行，异常处理的返回地址就是trap指令后的那条。 第三种是Aborts异常，这种异常不报告异常发生的精确位置，也不运行程序继续往下执行。往往是发生了严重的错误，例如硬件错误和不合法的数值。 Table 9-1. Interrupt and Exception ID Assignments Identifier Description 0 Divide error 1 Debug exceptions 2 Nonmaskable interrupt 3 Breakpoint (one-byte INT 3 instruction) 4 Overflow (INTO instruction) 5 Bounds check (BOUND instruction) 6 Invalid opcode 7 Coprocessor not available 8 Double fault 9 (reserved) 10 Invalid TSS 11 Segment not present 12 Stack exception 13 General protection 14 Page fault 15 (reserved) 16 Coprecessor error 17-31 (reserved) 32-255 Available for external interrupts via INTR pin IF(interrput-enable flag)是控制屏蔽外中断的标志位。当IF=0，中断会被屏蔽，IF=1，中断才会被接收。 CLI (Clear Interrupt-Enable Flag) and STI (Set Interrupt-Enable Flag) explicitly alter IF (bit 9 in the flag register). IF标志位被以下三种情况隐性影响： PUSHF存储所有flag，包括IF。在栈中的IF，可以被修改。 任务切换时，POP和IRET读取flag寄存器，因此，这步操作能修改IF 中断通过interrupt gates(?)能自动重置IF，也就关闭外中断。 设置段地址的时候也会发生中断，影响程式的执行。通常设置栈区的段的时候通常使用以下这一对指令。 MOV SS, AX MOV ESP, StackTop 如果这时候发生中断或者异常，SS已经被设置成了AX，而ESP的值还没被传达到，栈指针，SS:ESP在处理中断和异常的时候是不正常的，所以80386CPU在处理这两条指令的时候会屏蔽NMI, INTR, debug exceptions, and single-step traps这些中断。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习3"},{"categories":["sys"],"content":"练习4 编辑trapentry.S和trap.c安装中断向量，宏TRAPHADNLER和TRAPHANDLER_NOEC可以帮助安装向量，中断向量被定义在inc/trap.h中。然后提供一共_alltraps去准备堆栈。在函数trap_init()中初始化idt中断向量数组，并且使用SETGATE去指向相关的函数。 为不同的中断生成入口，两个宏的差别在于是否有error code。，如果有的话，硬件会自动将错误信息压栈。如果没有的话，宏TRAPHANDLER_NOEC会压入一个0值。 TRAPHANDLER_NOEC(divid_entry, T_DIVIDE); TRAPHANDLER_NOEC(debug_entry, T_DEBUG); TRAPHANDLER_NOEC(nmi_entry, T_NMI); TRAPHANDLER_NOEC(brkpt_entry, T_BRKPT); TRAPHANDLER_NOEC(oflow_entry, T_OFLOW); TRAPHANDLER_NOEC(bound_entry, T_BOUND); TRAPHANDLER_NOEC(illop_entry, T_ILLOP); TRAPHANDLER_NOEC(device_entry, T_DEVICE); TRAPHANDLER(dblflt_entry, T_DBLFLT); TRAPHANDLER(tss_entry, T_TSS); TRAPHANDLER(segnp_entry, T_SEGNP); TRAPHANDLER(stack_entry, T_STACK); TRAPHANDLER(gpflt_entry, T_GPFLT); TRAPHANDLER(pgflt_entry, T_PGFLT); TRAPHANDLER_NOEC(fperr_entry, T_FPERR); TRAPHANDLER_NOEC(syscall_entry, T_SYSCALL); _alltraps将所有的寄存器状态保存，压栈。 _alltraps: pushl %ds pushl %es pushal mov $GD_KD, %ax mov %ax, %es mov %ax, %ds push %esp call trap 根据练习提示，将段寄存器es和ds设置为GDT的kernel数据段，然后将esp压栈，调用trap。 这里直接调用trap就行，调用函数的参数已经在堆栈中，跳转到函数开始的地方就是一个普通的函数调用。 回顾之前的Lab2，在env_run()之前，会执行trap_init()，目的就是为了安装中断向量表。 trap.c/trap_init()中，将idt数组已知中断全部设置好，并将处理这个中断或者异常的handler安装到GDT中的.text域中，并且设置好权限。 void trap_init(void) { extern struct Segdesc gdt[]; // LAB 3: Your code here. void divid_entry(); void debug_entry(); void nmi_entry(); void brkpt_entry(); void oflow_entry(); void bound_entry(); void illop_entry(); void device_entry(); void dblflt_entry(); void tss_entry(); void segnp_entry(); void stack_entry(); void gpflt_entry(); void pgflt_entry(); void fperr_entry(); void syscall_entry(); SETGATE(idt[T_DIVIDE], 1, GD_KT, divid_entry, 0); SETGATE(idt[T_DEBUG], 1, GD_KT, debug_entry, 3); SETGATE(idt[T_NMI], 1, GD_KT, nmi_entry, 0); SETGATE(idt[T_BRKPT], 1, GD_KT, brkpt_entry, 3); SETGATE(idt[T_OFLOW], 1, GD_KT, oflow_entry, 0); SETGATE(idt[T_BOUND], 1, GD_KT, bound_entry, 0); SETGATE(idt[T_ILLOP], 1, GD_KT, illop_entry, 0); SETGATE(idt[T_DEVICE], 1, GD_KT, device_entry, 0); SETGATE(idt[T_DBLFLT], 1, GD_KT, dblflt_entry, 0); SETGATE(idt[T_TSS], 1, GD_KT, tss_entry, 0); SETGATE(idt[T_SEGNP], 1, GD_KT, segnp_entry, 0); SETGATE(idt[T_STACK], 1, GD_KT, stack_entry, 0); SETGATE(idt[T_GPFLT], 1, GD_KT, gpflt_entry, 0); SETGATE(idt[T_PGFLT], 1, GD_KT, pgflt_entry, 0); SETGATE(idt[T_FPERR], 1, GD_KT, fperr_entry, 0); SETGATE(idt[T_SYSCALL], 1, GD_KT, syscall_entry, 3); // Per-CPU setup trap_init_percpu(); } Q1:What is the purpose of having an individual handler function for each exception/interrupt? (i.e., if all exceptions/interrupts were delivered to the same handler, what feature that exists in the current implementation could not be provided?) 不同的权限组应该要有不同的解决办法。 Q2:Did you have to do anything to make the user/softint program behave correctly? The grade script expects it to produce a general protection fault (trap 13), but softint’s code says int 14. Why should this produce interrupt vector 13? What happens if the kernel actually allows softint’s int 14 instruction to invoke the kernel’s page fault handler (which is interrupt vector 14)? user/softint用户程序中就只有一句: asm volatile (\"int $14\"); 用来产生page fault，但是这是用户程序产生的。一般产生页错误，查看page fault的处理办法page_fault_handler()中env_destroy(curenv);会将这个用户环境销毁。一般用户应该没有这样的权限。 所以对于权限不够的用户，应该产生General protection fault 。 This concludes part A of the lab. ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习4"},{"categories":["sys"],"content":"PART B这一部分解决__Page Faults, Breakpoints Exceptions, System Calls__ _alltraps会调用traps traps可以分为四个部分 关闭中断 asm volatile(\"cld\" ::: \"cc\"); assert(!(read_eflags() \u0026 FL_IF)); 如果是用户模式，复制一份用户栈。 if ((tf-\u003etf_cs \u0026 3) == 3) { assert(curenv); curenv-\u003eenv_tf = *tf; tf = \u0026curenv-\u003eenv_tf; } last_tf = tf; 处理中断 trap_dispatch(tf); 如果这个用户环境未被销毁，那么继续执行。 assert(curenv \u0026\u0026 curenv-\u003eenv_status == ENV_RUNNING); env_run(curenv); ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#part-b"},{"categories":["sys"],"content":"练习5 , 6 让14号中断调用page_fault_handler()函数 breakpoint异常，3号中断通常是用来给调试器使用，它允许程序代码临时性地代替程序指令。在JOS中使用monitor()来执行处理异常。 page_fault_handler函数中通过fault_va = rcr2()获取页出错的虚拟地址。 这两个练习都是在trap_dispatch中修改，代码如下。 // Handle page fault exceptions. if (tf-\u003etf_trapno == T_PGFLT) { page_fault_handler(tf); return ; } // after int 3 interrupt , this function // uses panic() to output debugger infomations. if (tf-\u003etf_trapno == T_BRKPT) { monitor(tf); return ; } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习5--6"},{"categories":["sys"],"content":"Challenge//想做做不出来…留个思路 monitor中执行函数 激活tf栈中的eflags中TF位，开启单步调试 然后使用IRET返回中断，弹栈。 optional Q1:The break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault? interrupt gate中DPL影响这两种情况，当调用的时候，eflags中的CPL的值大于DPL的时候会产生general protection fault，因为特权等级不够。 Q2:What do you think is the point of these mechanisms, particularly in light of what the user/softint test program does? 用户不能产生14中断，特权级不够。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#challenge"},{"categories":["sys"],"content":"练习7 完成系统调用 用户通过系统调用进入内核态，并且保存用户的状态信息，内核执行合适的处理代码，然后恢复到用户态，当然，也需要确定调用是从内核态到用户态还是内核自身调用系统函数。 JOS中系统调用的中断号是0x30，不会由计算机硬件产生，所以需要写好相应的调用代码。 应用程序将会把系统调用的编号和系统调用的参数保存在寄存器中。system call number将会保存在%eax中，接下来最多五个参数分别保存在 %edx, %ecx, %ebx, %edi, %esi中。system call函数已经写好在了文件lib/syscall.c中。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习7"},{"categories":["sys"],"content":"trap_init()在trap_init()中添加相应的handler: void syscall_entry(); ... ... SETGATE(idt[T_SYSCALL], 1, GD_KT, syscall_entry, 3); ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#trap_init"},{"categories":["sys"],"content":"trap_dispatch()然后在trap_dispatch()中为中断添加调用： // system call if (tf-\u003etf_trapno == T_SYSCALL) { tf-\u003etf_regs.reg_eax = syscall( tf-\u003etf_regs.reg_eax, tf-\u003etf_regs.reg_edx, tf-\u003etf_regs.reg_ecx, tf-\u003etf_regs.reg_ebx, tf-\u003etf_regs.reg_edi, tf-\u003etf_regs.reg_esi); return ; } ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#trap_dispatch"},{"categories":["sys"],"content":"syscall()利用lib/syscall.c中的syscall进行转移到真正处理通用系统调用的文件中，根据inc/syscall.h中的enum定义分发到相应的系统调用的处理函数去。 // Dispatches to the correct kernel function, passing the arguments. int32_t syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5) { // Call the function corresponding to the 'syscallno' parameter. // Return any appropriate return value. // LAB 3: Your code here. cprintf(\"call number:%d \\n\", syscallno); switch (syscallno) { case SYS_cputs: sys_cputs((char *)a1, a2); return 0; case SYS_cgetc: return sys_cgetc(); case SYS_getenvid: return sys_getenvid(); case SYS_env_destroy: return sys_env_destroy(a1); default: return -E_INVAL; } } 完成这里，利用make run-hello检测自己的系统调用是否成功。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#syscall"},{"categories":["sys"],"content":"练习8用户程序从这里开始执行，确认好相关信息后跳转到 libmain执行。 .text .globl _start _start: // See if we were started with arguments on the stack cmpl $USTACKTOP, %esp jne args_exist // If not, push dummy argc/argv arguments. // This happens when we are loaded by the kernel, // because the kernel does not know about passing arguments. pushl $0 pushl $0 args_exist: call libmain 1: jmp 1b 将libmain()改成 // LAB 3: Your code here. thisenv = envs + ENVX(sys_getenvid()); ENVX宏定义在env.h文件中。 然后接下来调用用户程序umain和exit()，umain就相当于平时执行的C程序中main函数，exit()执行系统调用函数sys_env_destroy()。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习8"},{"categories":["sys"],"content":"练习9/10修改kern/trap.c,当内核页错误的时候调用panic，检查tf_cs的低位。 阅读kern/pmap.c中user_mem_assert函数，并且实现user_mem_check函数。 修改kern/syscall.c，检查系统调用的参数。 修改kern/kdebug.c中的debuginfo_eip，调用user_mem_check检查usd,stabs,stabstr。 内存保护是操作系统的一个决定性的特性，确保程序的BUG不会影响到其他程序和操作系统自己。 操作系统通常依赖硬件去实现内存保护，当程序使用一个非法的内存地址或者对指定的虚拟地址没有访问权，处理器会中断程序指令并且产生一个fault级别异常，然后陷入内核态，去处理这个操作。如果这个错误可以修复，内核通过代码修复，然后让程序继续运行，否则，摧毁该程序。 一种常见的可以修复的错误就是栈增长，大多数系统初始化一个进程通常只会分配一个stack页，当程序使用这个分配好的栈的更下层的时候，内核将会自动分配更多的空间，当然会有一个分配的最大值。 大多数系统调用接口让用户程序传递一个指针给系统内核，这个指针指向一个用户内存空间的一个可读可写的缓冲区。系统内核通过解引用这个指针和用户程序进行交互，但是存在以下两个问题。 内核态出现页错误比在用户态出现页错误可能更加严重，如果内核在操作自己的数据结构的时候发生了页错误，这是一个内核BUG，解决错误的handler此时应该panic。但是当内核解引用用户程序传递过来的指针的时候，内核需要确认这个指针的是属于该用户程序的。 内核的权限通常高于用户程序，用户可能会传递一个内核可以读取，但是该程序不能读取的内存地址。内核需要非常仔细的检查这类指针，因为这样可能会造成隐私信息泄露和破坏内核完整性。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#练习910"},{"categories":["sys"],"content":"page_fault_handler()// LAB 3: Your code here.(1) if ((tf-\u003etf_cs \u0026 3) == 0) panic(\"kernel page fault\"); 在8086模式下，寄存器CS,DS,ES等被称作段偏移，但是在保护模式下，CS,DS,ES等寄存器被用作段选择子，在GDT中选定相应的段，根据全局描述符中的信息，程序只能在相应的内存段中运行，读取，写入，否则会发生中断或者异常。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#page_fault_handler"},{"categories":["sys"],"content":"user_mem_checkint user_mem_check(struct Env *env, const void *va, size_t len, int perm) { // LAB 3: Your code here. if ((uintptr_t)va \u003e= ULIM) { user_mem_check_addr = (uintptr_t) va; return -E_FAULT; } uintptr_t beg = ROUNDDOWN((uint32_t)va, PGSIZE); uintptr_t end = ROUNDUP((uintptr_t)va+len, PGSIZE); uintptr_t i; pte_t *phaddr_entry; for (i = beg; i != end; i += PGSIZE) { phaddr_entry = pgdir_walk(env-\u003eenv_pgdir, (void *)i, false); if ( phaddr_entry == NULL || !(*phaddr_entry \u0026 PTE_P) || (*phaddr_entry \u0026 perm ) != perm) { user_mem_check_addr = i \u003c (uintptr_t)va ? (uintptr_t)va : i; cprintf(\"%x\\n\", user_mem_check_addr); return -E_FAULT; } } return 0; } BUG ： 这里在调用pgdir_walk的时候把env-\u003eenv_pgdir写成了kern_pgdir，用户一般都不会有内核的地址空间的读写权限，导致make run相关程序的时候发生失败。 ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#user_mem_check"},{"categories":["sys"],"content":"sys_cputs()// Check that the user has permission to read memory [s, s+len). // Destroy the environment if not. // LAB 3: Your code here. user_mem_assert(curenv, s, len, PTE_U); ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#sys_cputs"},{"categories":["sys"],"content":"debuginfo_eip()// Make sure this memory is valid. // Return -1 if it is not. Hint: Call user_mem_check. // LAB 3: Your code here. if (user_mem_check(curenv, usd, sizeof(struct UserStabData), PTE_U) \u003c 0) return -1; stabs = usd-\u003estabs; stab_end = usd-\u003estab_end; stabstr = usd-\u003estabstr; stabstr_end = usd-\u003estabstr_end; // Make sure the STABS and string table memory is valid. // LAB 3: Your code here. if (user_mem_check(curenv, stabs, stab_end - stabs, PTE_U) \u003c 0) return -1; if (user_mem_check(curenv, stabstr, stabstr_end - stabstr, PTE_U) \u003c 0) return -1; Q: run user/breakpoint, you should be able to run backtrace from the kernel monitor and see the backtrace traverse into lib/libmain.c before the kernel panics with a page fault. What causes this page fault? You don’t need to fix it, but you should understand why it happens. // todo ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#debuginfo_eip"},{"categories":["sys"],"content":"make grademake[1]: Leaving directory '/home/moonlight/lab' divzero: OK (1.3s) softint: OK (1.0s) badsegment: OK (1.1s) Part A score: 30/30 faultread: OK (0.9s) faultreadkernel: OK (1.9s) faultwrite: OK (1.1s) faultwritekernel: OK (1.7s) breakpoint: OK (1.4s) testbss: OK (1.7s) hello: OK (2.2s) buggyhello: OK (2.0s) buggyhello2: OK (2.1s) evilhello: OK (1.7s) Part B score: 50/50 Score: 80/80 This completes the lab. ","date":"2018-04-22","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab3:User Environments","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/#make-grade"},{"categories":["language"],"content":"extern从该文件外部获取变量定义，在文件域默认有extern属性。存储属性为static，也就是在文件执行前就被放在静态数据区。 ","date":"2018-04-19","objectID":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/:1:0","series":null,"tags":["c/c++"],"title":"static,extern关键词和函数指针数组","uri":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/#extern"},{"categories":["language"],"content":"static只在该文件域可以使用，存储属性为static。 ","date":"2018-04-19","objectID":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/:2:0","series":null,"tags":["c/c++"],"title":"static,extern关键词和函数指针数组","uri":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/#static"},{"categories":["language"],"content":"实例extern.c #include \u003cstdio.h\u003e int k = 10; extern void print(void); int main() { printf(\"k: %d\\n\", k); print(); } extern2.c #include \u003cstdio.h\u003e void print(void) { extern int k; printf(\"extern int k: %d\\n\", k); } shell $ gcc -o ex extern.c extern2.c $ ./ex ","date":"2018-04-19","objectID":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/:3:0","series":null,"tags":["c/c++"],"title":"static,extern关键词和函数指针数组","uri":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/#实例"},{"categories":["language"],"content":"函数指针数组#include \u003cstdio.h\u003e static int print1(void) { printf(\"function: print1()\\n\"); } static int print2(void) { printf(\"function: print2()\\n\"); } static int (*arr[])(void) = { [0] print1, [1] print2, }; int (* foo)(void); int main(void) { foo = arr[0]; foo(); } __static int (*arr[])(void)__可以理解为arr[]数组中存有两个类型为__static int(void)__的函数指针 static关键词可以设计__抽象数据类型ADT(abstract data type)__黑盒。 可以设计一个这样的头文件作为接口： list.h /* ** ** headfile for ADT ** */ /* macro */ #define NAME_LEN 30 #define ADDR_LEN 100 #define PHONE_LEN 11 #define MAX_ADDRESSES 1000 /* interface declaration */ char const * lookup_address(char const *name); char const * lookup_phone(char const *name); list.c #include \u003cstdio.h\u003e#include \u003cstring.h\u003e#include \"list.h\" /* static data type*/ static char name[MAX_ADDRESSES][NAME_LEN]; static char address[MAX_ADDRESSES][ADDR_LEN]; static char phone[MAX_ADDRESSES][PHONE_LEN]; static int find_entry(const char *name2find) { int entry; for (entry = 0; entry \u003c MAX_ADDRESSES; entry += 1) if(strcmp(name2find, name[entry]) == 0) return entry; return -1; } const char * lookup_address(const char *name) { int entry; entry = find_entry(name); if(entry == -1) return NULL; else return address[entry]; } const char * lookup_phone(const char *name) { // ... // ... // implement // ... // ... } 这样调用接口就能获得数据，但是不能直接得到数据，有点像OOP编程的思想。当然，直接用数组作为数据存储的容器，这儿只是一个例子，改变自《pointers on c》。 ","date":"2018-04-19","objectID":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/:4:0","series":null,"tags":["c/c++"],"title":"static,extern关键词和函数指针数组","uri":"/static-extern%E5%85%B3%E9%94%AE%E8%AF%8D%E5%92%8C%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84/#函数指针数组"},{"categories":["env"],"content":"远程到本地 $ git fetch $ git merge origin/master ","date":"2018-04-17","objectID":"/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git 基础操作","uri":"/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/#远程到本地"},{"categories":["env"],"content":"本地到远程 关联 git remote add origin git@github.com:haoxr/-faceDetection.git 提交到本地 $ git add . $ git commit -m \"commit infomation\" push $ git push -u origin master \u003c- 第一次使用 $ git push origin master ","date":"2018-04-17","objectID":"/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git 基础操作","uri":"/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/#本地到远程"},{"categories":["sys"],"content":"Exercise 1: 内存初始化在 lab1 中开启了分段和分页，并且初始化了内核页目录（地址存储在CR3中），于是有了下面这样的地址转换机制。 地址转换 首先通过相应段寄存器获得地址基址，然后以虚拟地址作为偏移获得线性地址。线性地址在通过一定的机制，获得实际的物理地址。 线性地址转换过程: 段翻译机制输出一个线性地址（Linear address） Linear address(LA)，用于接下来的转换，在 CR0 寄存器 PG 位未设置的时候，线性地址会被直接作为物理地址。 // A linear address 'la' has a three-part structure as follows: // // +--------10------+-------10-------+---------12----------+ // | Page Directory | Page Table | Offset within Page | // | Index | Index | | // +----------------+----------------+---------------------+ // \\--- PDX(la) --/ \\--- PTX(la) --/ \\---- PGOFF(la) ----/ // \\---------- PGNUM(la) ----------/ // // The PDX, PTX, PGOFF, and PGNUM macros decompose linear addresses as shown. // To construct a linear address la from PDX(la), PTX(la), and PGOFF(la), // use PGADDR(PDX(la), PTX(la), PGOFF(la)). 首先取线性地址的高10位作为页目录索引(Page Directory Index)，共1024个，从 0 ~ 1023。再使用cr3寄存器中的高二十位定位内存中页目录的基址。 在页目录和页表中，每个单元都是4bytes。 最后在页目录中的寻址组成为： 每个索引只使用高20位进行寻址，因为页操作的最小粒度为4KB。只需要4个字节的前面20位进行寻址就行了，剩下的比特可以用作其他标志位。 根据前十位索引获得相应的页目录项后，用其前20位作为一个4KB对齐的地址作为页表（Page Table）的基址。然后从线性地址中取出中间的10位作为的索引，得到相应的页表项（Page Table Entry）。 继续从PTE中取出前20位得到4KB对齐的基址，然后从利用线性地址（LA）最后12位作为在这4K页内的偏移，组合得到32位的地址，即最终的物理地址。 下面是JOS需要完成的内存布局。 /* * Virtual memory map: Permissions * kernel/user * * 4 Gig --------\u003e +------------------------------+ * | | RW/-- * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * : . : * : . : * : . : * |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| RW/-- * | | RW/-- * | Remapped Physical Memory | RW/-- * | | RW/-- * KERNBASE, ----\u003e +------------------------------+ 0xf0000000 --+ * KSTACKTOP | CPU0's Kernel Stack | RW/-- KSTKSIZE | * | - - - - - - - - - - - - - - -| | * | Invalid Memory (*) | --/-- KSTKGAP | * +------------------------------+ | * | CPU1's Kernel Stack | RW/-- KSTKSIZE | * | - - - - - - - - - - - - - - -| PTSIZE * | Invalid Memory (*) | --/-- KSTKGAP | * +------------------------------+ | * : . : | * : . : | * MMIOLIM ------\u003e +------------------------------+ 0xefc00000 --+ * | Memory-mapped I/O | RW/-- PTSIZE * ULIM, MMIOBASE --\u003e +------------------------------+ 0xef800000 * | Cur. Page Table (User R-) | R-/R- PTSIZE * UVPT ----\u003e +------------------------------+ 0xef400000 * | RO PAGES | R-/R- PTSIZE * UPAGES ----\u003e +------------------------------+ 0xef000000 * | RO ENVS | R-/R- PTSIZE * UTOP,UENVS ------\u003e +------------------------------+ 0xeec00000 * UXSTACKTOP -/ | User Exception Stack | RW/RW PGSIZE * +------------------------------+ 0xeebff000 * | Empty Memory (*) | --/-- PGSIZE * USTACKTOP ---\u003e +------------------------------+ 0xeebfe000 * | Normal User Stack | RW/RW PGSIZE * +------------------------------+ 0xeebfd000 * | | * | | * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * . . * . . * . . * |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| * | Program Data \u0026 Heap | * UTEXT --------\u003e +------------------------------+ 0x00800000 * PFTEMP -------\u003e | Empty Memory (*) | PTSIZE * | | * UTEMP --------\u003e +------------------------------+ 0x00400000 --+ * | Empty Memory (*) | | * | - - - - - - - - - - - - - - -| | * | User STAB Data (optional) | PTSIZE * USTABDATA ----\u003e +------------------------------+ 0x00200000 | * | Empty Memory (*) | | * 0 ------------\u003e +------------------------------+ --+ * * (*) Note: The kernel ensures that \"Invalid Memory\" is *never* mapped. * \"Empty Memory\" is normally unmapped, but user programs may map pages * there if desired. JOS user programs map pages temporarily at UTEMP. */ 首先是执行 i386_detect_memory() 探测内存，分别调用了3次读取CMOS寄存器的函数： basemem = nvram_read(NVRAM_BASELO); extmem = nvram_read(NVRAM_EXTLO); ext16mem = nvram_read(NVRAM_EXT16LO) * 64; 追踪到 kclock.h 注释 #define MC_NVRAM_START 0xe /* start of NVRAM: offset 14 */ ... /* NVRAM bytes 7 \u0026 8: base memory size */ #define NVRAM_BASELO (MC_NVRAM_START + 7) /* low byte; RTC off. 0x15 */ #define NVRAM_BASEHI (MC_NVRAM_START + 8) /* high byte; RTC off. 0x16 */ /* NVRAM bytes 9 \u0026 10: extended memory size (between 1MB and 16MB) */ #define NVRAM_EXTLO (MC_NVRAM_START + 9) /* low byte; RTC off. 0x17 */ #define NVRAM_EXTHI (MC_NVRAM_START +","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#exercise-1-内存初始化"},{"categories":["sys"],"content":"练习2了解x86保护机制和段页翻译. 参考资料： Intel 80386 Reference Manual: chapters 5 and 6 Intel® 64 and IA-32 Architectures Software Developer’s Manual 保护机制的产生实际上是为了探测和找到程序中可能出现的bug。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#练习2"},{"categories":["sys"],"content":"练习3","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#练习3"},{"categories":["sys"],"content":"使用QEMU和GDB查看内存进入保护模式后可以通过 ctrl+a c 进入QEMU的监视器，查看内存情况。 (QEMU) xp phisical address 查看物理地址信息 (gdb) x/x virtual address 查看虚拟地址信息 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:3:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#使用qemu和gdb查看内存"},{"categories":["sys"],"content":"练习4JOS中定义了两种针对于不同地址的数据类型,uintptr_t代表虚拟地址,physaddr_t表示物理地址,宏定义都为uint32_t。解引用(dereference)都要通过段页机制实现，所以如果对物理地址进行解引用，会有非预期的结果。 Question Assuming that the following JOS kernel code is correct, what type should variable x have, uintptr_t or physaddr_t? mystery_t x; char* value = return_a_pointer(); *value = 10; x = (mystery_t) value; 根据上述对类型的描述，因为有解引用操作，x的类型应该为uintptr_t。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#练习4"},{"categories":["sys"],"content":"引用计数每一个 struct PageInfo 对应一个4KB物理页，对应一个页，如果计数到达了 0，说明这块内存将不再使用，一般来说，引用计数的值应该等于在 UTOP 以下的页表中出现的次数。因为高于 UTOP 的页表一般被内核所使用，不应该释放。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:4:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#引用计数"},{"categories":["sys"],"content":"Page Table Management因为此时内核已经开启了页机制，所以不可能绕过这个机制，所使用的地址必须映射在页目录中的地址。 PADDR(va) : virtual address - KERNELBASE， va 如果小于 KERNELBASE 则 panic。 KADDR(pa) : physical address + KERNELBASE，pa 如果超出实际内存大小 则 panic。 *page2kva(struct PageInfo ) : struct PageInfo pointer -\u003e virtual address pte_t * pgdir_walk(pde_t *pgdir, const void *va, int create) { size_t pgdir_index = PDX(va); size_t page_offset = PTX(va); pde_t dir_entry = pgdir[pgdir_index]; if (!(dir_entry \u0026 PTE_P)) { // get page table address which a pointer point to . if(create){ struct PageInfo *allocated_page = page_alloc(ALLOC_ZERO); if(allocated_page == NULL) return NULL; // increment reference count allocated_page-\u003epp_ref++; // the page physical address physaddr_t pg_phyaddr = page2pa(allocated_page) ; // fill page table entry pgdir[pgdir_index] = pg_phyaddr | PTE_P | PTE_W | PTE_U; } else { return NULL; } } // point to a page table pte_t *pt_base = KADDR(PTE_ADDR(pgdir[pgdir_index])); return \u0026(pt_base[page_offset]); } static void boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm) { pte_t *pte; // 'size' is a multiple of PGSIZE. size_t page_num = size / PGSIZE; uint32_t i; for(i = 0; i \u003c page_num; i++) { pte = pgdir_walk(pgdir, (void *)va, true); if (pte == NULL) return; *pte = pa | perm | PTE_P; pa += PGSIZE; va += PGSIZE; } } struct PageInfo * page_lookup(pde_t *pgdir, void *va, pte_t **pte_store) { struct PageInfo *ret = NULL; pte_t *pte = pgdir_walk(pgdir, va, false); if(pte == NULL) return NULL; if((*pte \u0026 PTE_P) == 0) return NULL; ret = pa2page(PTE_ADDR(*pte)); if(pte_store != NULL) { *pte_store = pte; } return ret; } void page_remove(pde_t *pgdir, void *va) { // get page table entry and PageInfo. pte_t *pte = NULL; struct PageInfo* upage = page_lookup(pgdir, va, \u0026pte); if(upage == NULL) return; // decrement reference count // freeing it if there are no more refs page_decref(upage); // flush page-translation cache about this page tlb_invalidate(pgdir, va); // clean pte *pte = 0 ; } int page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm) { // modify pde pte_t *entry = pgdir_walk(pgdir, va, true); if (entry == NULL) return -E_NO_MEM; // page colides pp-\u003epp_ref++; if (*entry \u0026 PTE_P) { // decrement and free // page invalidate in page_remove() page_remove(pgdir, va); } // modify pte *entry = page2pa(pp) | perm | PTE_P; return 0; } Intel TLB 无效技术有两种方法： 向CR3寄存器写入值时，所有处理器自动刷新相对于非全局TLB表项 在Pentium Pro及以后的处理器中，invlpg 指令能使映射指定线性地址的单个TLB表项无效 练习4到此完成。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:4:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#page-table-management"},{"categories":["sys"],"content":"练习5Kernal Address Space JOS把线性地址分为两部分，低地址的用户环境(User enviroment - Processes)和高地址的内核，用户部分在Lab3中加载使用。内存分给内核从KERNBASE开始到内存结束共大约256MB。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:5:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#练习5"},{"categories":["sys"],"content":"权限和错误隔离为了防止用户代码的bug覆盖写内核数据或者代码导致崩溃，使用权限bit位限制用户代码的权限，使其只能访问其内存空间。对于用户级代码来说大于ULIM的是不允许访问的，属于内核的空间。内存地址[UTOP,ULIM) 对于User和Kernal都是只读的，用于内核暴露一部分只读数据结构给用户。 完成 mem_init() 剩余的代码： // Map 'pages' read-only by the user at linear address UPAGES boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), PTE_U | PTE_P); // Use the physical memory that 'bootstack' refers to as the kernel boot_map_region(kern_pgdir, (KSTACKTOP-KSTKSIZE), KSTKSIZE, PADDR(bootstack), PTE_W | PTE_P); // Map all of physical memory at KERNBASE. boot_map_region(kern_pgdir, KERNBASE, 0xFFFFFFF, 0, PTE_W | PTE_P); 通过剩下几个测试 $ make qemu-nox ... 6828 decimal is 15254 octal! Physical memory: 131072K available, base = 640K, extended = 130432K check_page_free_list() succeeded! check_page_alloc() succeeded! check_page() succeeded! check_kern_pgdir() succeeded! check_page_free_list() succeeded! check_page_installed_pgdir() succeeded! 然后将新填写的页目录地址重新加载到CR3寄存器内，在开启剩余一些CR0寄存器位。 lcr3(PADDR(kern_pgdir)); cr0 = rcr0(); cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP; cr0 \u0026= ~(CR0_TS|CR0_EM); lcr0(cr0); |PE| ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:5:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#权限和错误隔离"},{"categories":["sys"],"content":"Question Q2:What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point? Q3:We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel’s memory? What specific mechanisms protect the kernel memory? 与页目录和页表中的 User/supervisor flag 和 Read/write flag 有关 “ When the processor is in user mode, it can write only to usermode pages that are read/write accessible. User-mode pages which are read/write or read-only are readable; supervisor-mode pages are neither readable nor writable from user mode. ” Intel® 64 and IA-32 Architectures Software Developer’s Manual 4.11.3 Page Type 可以看到 jos 只有 UPAGES 以上 PTSIZE 的内存设置了 PTE_U，除了这个部分对于用户级别可以读，其他的部分都是不可读或写的。 Q5:How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down? 2G Q6: Revisit the page table setup in kern/entry.S and kern/entrypgdir.c. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary? mov $relocated, %eax jmp *%eax jmp 完后就到了高地址，在临时的内核页目录中，同时将虚拟地址 [0 ~ 4MB) 和 [KERNELBASE ~ KERNELBASE+4MB) 映射了物理内存 [0 ~ 4MB)，所以即使 PE 置位后仍然能正常执行。在 lab2 中重新加载了新映射的 kern_pgdir，里面并没有映射 [0 ~ 4MB) 这一部分，继续在低地址执行但是页表里面并没有相应的项。 答案参考: https://github.com/Clann24/jos/tree/master/lab2 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:5:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#question"},{"categories":["sys"],"content":"Challenge 2 这个给JOS增加一个调试器，很有必要做一下，方便之后的学习。 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:6:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#challenge-2"},{"categories":["sys"],"content":"辅助函数 str2ptr()JOS中没有包含标准库，需要自己写一下字符串到整形的转换。 pde_t * str2ptr(char *str) { pde_t ptr; int temp, i; size_t length; length = strlen(str) ; ptr = 0; for (i = 2; str[i] != 0; i++) { if(str[i] \u003c= '9') temp = str[i] - '0'; else temp = str[i] - 'a' + 10; ptr += temp * ( 1 \u003c\u003c (length - i - 1) * 4 ); } return (pde_t *)ptr; } ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:6:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#辅助函数-str2ptr"},{"categories":["sys"],"content":"mon_mapinfo()int mon_mapinfo(int argc, char **argv, struct Trapframe *tf) { extern pde_t *kern_pgdir; pde_t *pg_pa, *pg_va, size, iter; extern pte_t * pgdir_walk(pde_t *,const void *, int); if (argc \u003c 3) { cprintf(\"too few argument \\n\"); return 0; } if (argv[1][0] == '0' \u0026\u0026 argv[1][1] == 'x') { /* show address */ /*initialize some variables*/ size = str2ptr(argv[2]) - str2ptr(argv[1]); pg_va = str2ptr(argv[1]); /* use pgdir_walk function to get page entry */ for (iter = (pde_t)pg_va; iter \u003c= (pde_t)str2ptr(argv[2]); iter += PGSIZE) { pg_pa = pgdir_walk(kern_pgdir, (void *)iter, false); if (pg_pa == (void *)0) cprintf(\"0x%x: None\\n\", iter); else cprintf(\"0x%x: %x\\n\", iter, *pg_pa \u0026 ~0xFFF); } } else if (strcmp(\"set\", argv[1]) == 0) { /* set flag to Page Entry */ pte_t flag; pg_va = str2ptr(argv[2]); pg_pa = pgdir_walk(kern_pgdir, (void *)pg_va, false); if (pg_pa == (void *)0) { cprintf(\"Error: Unallocated page\"); return 0; } else { flag = (pte_t) str2ptr(argv[3]); cprintf(\"set physical address %x: flag = %x -\u003e\", *pg_pa \u0026 ~0xFFF, *pg_pa); flag \u0026= 0xFFF; /* promise that the flag cann't affect the address */ *pg_pa \u0026= ~0xFFF; *pg_pa |= flag; cprintf(\" %x\\n\", *pg_pa \u0026 0xFFF); } } else { cprintf(\"Usage error: showmapings \"); cprintf(\"smp 0xff00ff00 0xff00ff00\\n\"); cprintf(\"smp set 0xff00ff00 0x1\\n\"); } return 0; } ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:6:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#mon_mapinfo"},{"categories":["sys"],"content":"showK\u003e smp 0xf0000000 0xf01000000 0xf0000000: 0 0xf0001000: 1000 0xf0002000: 2000 0xf0003000: 3000 0xf0004000: 4000 0xf0005000: 5000 0xf0006000: 6000 0xf0007000: 7000 0xf0008000: 8000 0xf0009000: 9000 ... 0xf00fe000: fe000 0xf00ff000: ff000 0xf0100000: 100000 正好说明虚拟地址__KERNBASE~0xFFFFFFFF__被映射到了__0x00000000~0x0FFFFFFF__ ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:6:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#show"},{"categories":["sys"],"content":"setK\u003e smp set 0xf0000000 0x1 set physical address 0: flag = 3 -\u003e 1 ","date":"2018-04-12","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/:6:4","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab2:Memory Management","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/#set"},{"categories":["env"],"content":"注： 博客已经从hexo迁移到了hugo，部分格式已经不能渲染出来。 ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:0:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#"},{"categories":["env"],"content":"categories和tagsthemes文件夹下面的_config.yml有一个memu选项，hiker是默认有归档选项的。但是分类和标签是空页面，本地访问会提示 GET ERROR 的404错误。在md文件有表示的情况下，像如下配置即可。 type: \"categories\" layout: \"categories\" comments: false type: \"tags\" layout: \"tags\" comments: false ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:1:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#categories和tags"},{"categories":["env"],"content":"hexo-auto-category插件在_post文件夹下面创建的文件夹，都会被当作一个category，并分别将各个文件夹下面的md文件自动加上相应的category标识。 安装 $ npm install hexo-auto-category --save $ hexo clean \u0026\u0026 hexo g \u0026\u0026 hexo s _config.yml配置 # Generate categories from directory-tree # Dependencies: https://github.com/xu-song/hexo-auto-category # depth: the depth of directory-tree you want to generate, should \u003e 0 auto_category: enable: true depth: github网址: https://github.com/xu-song/hexo-auto-category ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:2:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#hexo-auto-category插件"},{"categories":["env"],"content":"live-2d这是个非常有趣的插件，看板娘get！ 安装: $ npm install --save hexo-helper-live2d 根据原github,修改hexo文件夹下面的_config.yml。 然后要安装相应的模组： $ npm install {your model's package name} 模组下载地址:https://github.com/xiazeyu/live2d-widget-models ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:3:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#live-2d"},{"categories":["env"],"content":"hexo-helper-qrcode二维码 Install $ npm i -S hexo-helper-qrcode Usage \u003cimg src=\"\u003c%- qrcode(url) %\u003e\"\u003e \u003c!-- white margin, default 0 --\u003e \u003cimg src=\"\u003c%- qrcode(url, { margin: 2 }) %\u003e\"\u003e \u003c!-- size of one module in pixels, default 6 --\u003e \u003cimg src=\"\u003c%- qrcode(url, { size: 4 }) %\u003e\"\u003e ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:4:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#hexo-helper-qrcode"},{"categories":["env"],"content":"fontawesome在md文档中加入矢量图 \u003ci class=\"fa fa-twitter fa-2x\"\u003e\u003c/i\u003e hugo 不支持 fontwawesome : http://www.bootcss.com/p/font-awesome/design.html ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:5:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#fontawesome"},{"categories":["env"],"content":"hexo-githus$ npm install --save hexo-githus {% github name repo commit-sha-1 [auto_expand = true | false] [width = 50%] %} {% github fatwaer APUE-Practice-Code 6fb648e42bc1229199b80f1aba04280f9e5ad271 [width = 50%] %} ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:6:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#hexo-githus"},{"categories":["env"],"content":"hexo-sliding-spoilershell $ npm install hexo-sliding-spoiler --save __config.yml plugins: - hexo-sliding-spoiler markdown {% spoiler title %} content {% endspoiler %} {% spoiler title %} code test int main() { return 0; } test bold {% endspoiler %} ","date":"2018-04-05","objectID":"/hexo%E9%85%8D%E7%BD%AE/:7:0","series":null,"tags":["config"],"title":"hexo 配置","uri":"/hexo%E9%85%8D%E7%BD%AE/#hexo-sliding-spoiler"},{"categories":["sys"],"content":" 3月14日 - 3月28日 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:0:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#"},{"categories":["sys"],"content":"Exercise 1熟悉x86汇编和AT\u0026T汇编 16-bit intel 8088 1MB = 1048576bit 内存地址: 0x00000 ~ 0xFFFFF 640KB(0x00000 ~ 0xA0000) 用户可用 参考资料 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:1:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-1"},{"categories":["sys"],"content":"GDB启动过程首先打开一个终端到目的lab根文件夹 $ make qemu-nox-gdb 再打开一个新的终端窗口执行以下命令进行监听 $ make gdb 以及一些常用的gdb命令 b: 0xffff: 在0xffff出下断点 c: continue to breakpoint si: 单步前进 x/5: 0xFFFFF 从0xFFFFF开始的5个命令 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:1:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#gdb启动过程"},{"categories":["sys"],"content":"Exercise 2第一条指令: [f000:fff0] 0xffff0: ljmp $0xf000,$0xe05b 当处理器重置时，会进入实模式并将CS设置为0xf000，IP设置为0xfff0(CS:IP=0xffff0)。 这个地址与BIOS的结束位置0x100000差16bytes。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:2:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-2"},{"categories":["sys"],"content":"启动后追踪BIOS的部分代码[f000:e05b] 0xffff0: ljmp $0xf000,$0xe05b [f000:e05b] 0xfe05b: cmpl $0x0,%cs:0x6c48 ;把0与cs:6c48所指向内存的值比较 [f000:e062] 0xfe062: jne 0xfd2e1 ;与CS:0x6c48(f6c48)处的值与0比较，不是0跳转 [f000:e066] 0xfe066: xor %dx,%dx ;dx清0 [f000:e068] 0xfe068: mov %dx,%ss ;ss置0,AT\u0026T汇编mov指令反向 [f000:e06a] 0xfe06a: mov $0x7000,%esp ;esp设置为0x7000,实模式引导区位置 [f000:e070] 0xfe070: mov $0xf3691,%executed ;edx设置为0xf3691 [f000:e076] 0xfe076: jmp 0xfd165 ;跳转 0xfd165 [f000:d165] 0xfd165: mov %eax,%ecx [f000:d168] 0xfd168: cli ;屏蔽中断 [f000:d169] 0xfd169: cld ;DF设置为0，指在每次传送一次将esi和edi自动+1;std将DF设置为1,传送自减 [f000:d16a] 0xfd16a: mov $0x8f,%eax [f000:d170] 0xfd170: out %al,$0x70 ;将al中的值0x8f输出到外部设备0x70端口,NMI不可屏蔽中断使能位为1 [f000:d172] 0xfd172: in $0x71,%al ;将0x71端口的值输出到al,GDB查看寄存器信息看见eax值被清0 ;A20地址线使能,进入保护模式 [f000:d174] 0xfd174: in $0x92,%al [f000:d176] 0xfd176: or $0x2,%al [f000:d178] 0xfd178: out %al,$0x92 ;加载6个字节 [f000:d17a] 0xfd17a: lidtw %cs:0x6c38 ;加载中断向量表 -\u003eidt寄存器 [f000:d180] 0xfd180: lgdtw %cs:0x6bf4 ;加载全局描述符表-\u003egdt寄存器 ;cr0寄存器置为1，进入保护模式 [f000:d186] 0xfd186: mov %cr0,%eax [f000:d189] 0xfd189: or $0x1,%eax [f000:d18d] 0xfd18d: mov %eax,%cr0 ;重新加载全局描述符GDT 0xfd190: ljmpl $0x8,$0xfd198 0xfd198: mov $0x10,%ax 0xfd19b: add %al,(%bx,%si) 0xfd19d: mov %ax,%ds 0xfd19f: mov %ax,%es 0xfd1a1: mov %ax,%ss 0xfd1a3: mov %ax,%fs 重新加载的 x86汇编复习 外围设备端口 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:2:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#启动后追踪bios的部分代码"},{"categories":["sys"],"content":"软盘硬盘磁盘的最小传输单元(sector)： 512bytes 16位机，在CD-ROM启动之前，后被扩展。xv6使用传统硬盘,512bytes/sector boot sector 在开机时被读入物理地址为 0x7c00 ~ 0x7dff ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:2:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#软盘硬盘"},{"categories":["sys"],"content":"Exercise 3 在0x7c00设置断点,对比源代码boot/boot.S，GDB，反汇编文件obj/boot/boot.asm 跟随boot/main.c文件的bootmain()函数到readsect()函数，弄清楚readsect()中的指令直至返回到bootmain()，确认从磁盘中读取kernel的for循环。跟随到bootloader完成引导。 boot/boot.S: 源代码 obj/boot/boot.asm: 反汇编代码 boot/main.c: 加载kernel的C代码 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-3"},{"categories":["sys"],"content":"boot.S打开/lab/boot可以看到一段注释，CPU启动后，切换至保护模式。BIOS把磁盘第一个扇区读入内存0x7c00处，并且在实模式下执行，将CS:IP指向0:7c00。 代码基本有注释，有几个点得注意下: inb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.2 将外围设备0x64端口读1byte？到al中，0x64端口的第1位的 bit 1 = 1 input buffer full (input 60/64 has data for 8042)判断输入缓冲区是不是满的，再用test和jnz来循环等待。 movb $0xd1,%al # 0xd1 -\u003e port 0x64 outb %al,$0x64 下次下入0x60的数据将会写入804x控制器。 movb $0xdf,%al # 0xdf -\u003e port 0x60 outb %al,$0x60 0xdf写入到0x60中，让地址线A20使能，开启32位保护模式。 lgdt gdtdesc 加载全局描述表，具体见:http://www.cnblogs.com/fatsheep9146/p/5115086.html ljmp $PROT_MODE_CSEG, $protcseg 关于这个跳转有一个好的解释如下图。 是保护模式下的跳转方法。 movl $start, %esp esp的值设置为0x7c00,准备开始执行boot loader 。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#boots"},{"categories":["sys"],"content":"main.c在这个文件内补充了一个启动过程和DISK的排布: disk layout boot.S和main.c是启动器，存储在磁盘的第一个扇区。 第二个扇区存储内核镜像。 内核镜像必须是ELF文件格式。 BOOT UP STEPS CPU读取BIOS到内存中并且执行。 BIOS初始化设备，中断历程，并且读取第一个扇区并且跳转执行。 如果boot loader存储在第一个扇区，那么cpu由其接管。 boot.S开启保护模式，设置栈空间，调用bootmain()。 然后bootmain()接管cpu，读取内核并且跳转。 #define ELFHDR ((struct Elf *) 0x10000) // scratch space ELFHDR为一个固定值 0x10000 readseg((uint32_t) ELFHDR, SECTSIZE8, 0); 把磁盘中的ELF文件头(5128=4MB？待解决)读到内存0x10000 ph = (struct Proghdr *) ((uint8_t *) ELFHDR + ELFHDR-\u003ee_phoff); Proghdr结构体类型指针ph,指向Program Table表头 eph = ph + ELFHDR-\u003ee_phnum; 指向表尾 for (; ph \u003c eph; ph++) readseg(ph-\u003ep_pa, ph-\u003ep_memsz, ph-\u003ep_offset); 根据这从磁盘读出的4MB ELF文件头，再从磁盘中读取ELF文件的数据段，代码段…. ((void (*)(void)) (ELFHDR-\u003ee_entry))(); 暂时不清楚，跳到elf文件执行入口？ The ELF file contains headers that describe how these sections should be stored in memory . ELF文件: /ELF文件/ wiki-ELF: https://en.wikipedia.org/wiki/Executable_and_Linkable_Format ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#mainc"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc \u003creadseg\u003e 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存\u003e放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2\u003e个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d \u003creadseg+0x31\u003e while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset \u003e\u003e 8); outb(0x1F5, offset \u003e\u003e 16); outb(0x1F6, (offset \u003e\u003e 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 \u003creadseg+0x1b\u003e 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 \u003cbootmain+0x5c\u003e 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc \u003creadseg\u003e 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-\u003ee_entry))(); 最后一步，转到内核的开始点。 BIOS启动-\u003e保护模式-\u003e读取第一个扇区到内存-\u003e跳转至0x7c00地址执行bootstrap-\u003e加载磁盘中的系统内核elf文件到0x10000 -\u003e 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#gdb调试"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#readsect"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#outb"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#insl"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#if判断"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#for循环读取"},{"categories":["sys"],"content":"GDB调试 readsect()7d15: 55 push %ebp 7d16: 89 e5 mov %esp,%ebp 7d18: 56 push %esi 7d19: 53 push %ebx 保存寄存器信息 7d1a: 6a 00 push $0x0 7d1c: 68 00 10 00 00 push $0x1000 7d21: 68 00 00 01 00 push $0x10000 7d26: e8 b1 ff ff ff call 7cdc 偏移0x0,大小0x1000(512x8),装载的内存地址0x10000 7ce1: 8b 7d 10 mov 0x10(%ebp),%edi 7ce5: 8b 75 0c mov 0xc(%ebp),%esi 7ce8: 8b 5d 08 mov 0x8(%ebp),%ebx 因为此时的%ebp的值为0x7bdc，在这里面存放的是bootmain过程的%ebp值，0x04(%ebp)即0x7be0存放的是bootmain的返回地址，0x08(%ebp)存放的是第1个输入参数0x10000，0xc(%ebp)存放的是第2个参数0x1000，0x10(%ebp)中存放的是第3个参数0x00 //具体原因:(待) 执行完后ebx: 0x10000 esi: 0x1000 edi: 0x0 7cee: 01 de add %ebx,%esi 从内存的开始到第一个扇区的结束。 7cf0: 47 inc %edi edi+1 7cf7: 39 f3 cmp %esi,%ebx 7cf9: 73 12 jae 7d0d while的判断条件。 call readsect call waitdisk ret outb()返回后直接进入 outb()中 outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset 8); outb(0x1F5, offset 16); outb(0x1F6, (offset 24) | 0xE0); outb(0x1F7, 0x20); “通过这些指令可以看出，系统是先想0x1F2端口送入一个值1，代表取出一个扇区，然后向0x1F3~0x1F6中送入你要读取的扇区编号的32bit表示形式。最后向0x1F7端口输出0x20指令表示要读取这个扇区。” insl()7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx edi = 0x10000 ecx = 0x80 edx = 0x1f0 repnz insl (%dx),%es:(%edi) repnz为装饰符，重复执行后面的语句，直到cx寄存器为0。 dx存要访问的端口，edi存要存放的内存起始地址。每次传输4字节 执行前 执行2次 直到ecx减为0，继续接下来的执行。这个时候从0x10000~0x100200(512字节)已经加载完成。 GDB查看内存信息: x/12xb 0x10000 7d09: 58 pop %eax 7d0a: 5a pop %edx 7d0b: eb ea jmp 7cf7 把pa和end_pa拿出来，即while的条件比较。当pa = end_pa 跳出while。 设置断点到while结束 7d0d: 8d 65 f4 lea -0xc(%ebp),%esp 7d10: 5b pop %ebx 7d11: 5e pop %esi 7d12: 5f pop %edi 7d13: 5d pop %ebp 7d14: c3 ret 恢复栈寄存器，返回到bootmain() if判断7d2b: 83 c4 0c add $0xc,%esp 7d2e: 81 3d 00 00 01 00 7f cmpl $0x464c457f,0x10000 7d35: 45 4c 46 7d38: 75 37 jne 7d71 7d2b存疑 7d2e:文件在内存中起始地址内容与0x464c467f比较，ELF文件头标志，16进制数分别代表‘F’,‘L’,‘E’,0X7F。 7d38在文件内容不符合的条件下跳转。 for循环读取7d3a: a1 1c 00 01 00 mov 0x1001c,%eax 7d3f: 0f b7 35 2c 00 01 00 movzwl 0x1002c,%esi 分别对应ph和eph,ph为ELF文件的Program Table Headers起始偏移，eph存入的是Program Table Headers的个数。 7d46: 8d 98 00 00 01 00 lea 0x10000(%eax),%ebx 切换到Intel汇编是lea ebx,[eax+0x10000]，ebx = eax + 0x10000 。 7d4c: c1 e6 05 shl $0x5,%esi 7d4f: 01 de add %ebx,%esi 设定Program Table Headers结束地址？ 7d55: ff 73 04 pushl 0x4(%ebx) 7d58: ff 73 14 pushl 0x14(%ebx) 7d5b: 83 c3 20 add $0x20,%ebx 7d5e: ff 73 ec pushl -0x14(%ebx) 7d61: e8 76 ff ff ff call 7cdc 这四条指令应该可以理解为readseg(ebx+c,ebx+14,ebx+4)，类似于读取elf文件的第一个段，把磁盘的内容取到内存中去。操作系统内核到现在已经加载完成。 内核跳转7d6b: ff 15 18 00 01 00 call *0x10018 ((void (*)(void)) (ELFHDR-e_entry))(); 最后一步，转到内核的开始点。 BIOS启动-保护模式-读取第一个扇区到内存-跳转至0x7c00地址执行bootstrap-加载磁盘中的系统内核elf文件到0x10000 - 最后跳转到内核开始处。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:3","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#内核跳转"},{"categories":["sys"],"content":"问题 At what point does the processor start executing 32-bit code? What exactly causes the switch from 16- to 32-bit mode? movl %cr0, %eax orl $CR0_PE_ON, %eax movl %eax, %cr0 开启cr0寄存器最低位 What is the last instruction of the boot loader executed, and what is the first instruction of the kernel it just loaded? movl $start, %esp ; bootloader开始地址压栈 push %ebp ;准备readseg()的参数 Where is the first instruction of the kernel? 0x1000c How does the boot loader decide how many sectors it must read in order to fetch the entire kernel from disk? Where does it find this information? 在elf文件中，首先宏定义了一个结构体指针指向elf文件在内存中的加载处，然后利用elf文件提供的信息加载Program table Headers所指定的信息。ELFHDR-\u003ee_phnum这个偏移加上基础地址就得到了文件头的个数。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:3:4","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#问题"},{"categories":["sys"],"content":"Exercise 4","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:4:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-4"},{"categories":["sys"],"content":"pointer.cc[1] = 300; *(c + 2) = 301; 3[c] = 302; 第三个输出的地方，有一个没有接触过的数组访问方法 “3[c]”的结果和“c[3]”的结果一样，有点类似于at\u0026t汇编中的 mov 0x3(%ebx),eax ，也许是衍生出来的一种形式。 b = (int *) a + 1; c = (int *) ((char *) a + 1); b为一个为整形指针，b的值+1，int指针的值+4 而c为char形，c值+1，char形指针+1 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:4:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#pointerc"},{"categories":["sys"],"content":"ELF查看文件头 objdump -h obj/kern/kernel objdump -x obj/kern/kernel kernel Program Header: LOAD off 0x00001000 vaddr 0xf0100000 paddr 0x00100000 align 2**12 filesz 0x00007120 memsz 0x00007120 flags r-x LOAD off 0x00009000 vaddr 0xf0108000 paddr 0x00108000 align 2**12 filesz 0x0000a300 memsz 0x0000a944 flags rw- STACK off 0x00000000 vaddr 0x00000000 paddr 0x00000000 align 2**4 filesz 0x00000000 memsz 0x00000000 flags rwx vadd(virturl address),paddr(physical address),LOAD(ELF object need to be loaded) align的大小表示是我在用python的时候想起来的，2**n 表示的是 2^n次方。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:4:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#elf"},{"categories":["sys"],"content":"Exercise 5 LOAD address and LINKER address 关于link address 和load address,我在网上找到这样一个说法: load address，表示一个已确定对象的实际加载地址。如C中可执行程序的main函数的地址，在编译完成的时候其地址已经确认（当然在系统中这是一个逻辑地址） link address，表示一个未确定对象的应该加载的地址。如你使用C动态库中的printf函数的地址。在编译完成的时候不能确定其地址，因为它的实体是在动态链接库中，只能给它规定一个应该加载的地址，在程序加载的时候才能真正确认是否可以加载在这个地址上（可能出现动态库找不到的情况，这时候就加载错误了） VMA为link address,程序开始执行的地方；LMA为load address,将会被bootloader读取到的内存地址。 跟着这个链接，改变boot/Makefrag的文件内容，原文件内容 改-Ttext的参数，从0x7c00改为0x7e00 原boot.asm(make后产生的)变为 每个命令在这个asm文件内的地址都发生了变化。 跟踪bootstrap,设置断点在0x7c00,si执行几步。 lgdtw 0x7e64,本应该加载0x7c64的,但是内存区域内容没有内容 ljmp $0x8,$0x7e32,这是跳转到保护模式程序段的跳转命令，但是跳转失败 我改变了boot/Makefrag中-Ttext的参数，把boot loader的link地址从0x7c00改成了0x7e00。由make命令从boot.S生成到boot.asm的文件中，命令的地址都发生了变化，但是BIOS默认读取boot到地址0x7c00，但是代码的性质，例如lgdtw加载全局描述符命令，已经发生了改变。代码本应被读到0x7e00执行，实际是在0x7c00执行，到最后一步一步的出错。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:5:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-5"},{"categories":["sys"],"content":"Exercise 6objdump -f obj/kern/kernel 得到内核ELF文件中程序入口 0x0010000c 这个练习的问题是：在0x7c00这个位置和在bootloader进入kernel的时候为什么从0x10000开始，8 word长的内存中内容不同？ 因为bootloader已经readseg()这个函数的时候，将ELF从磁盘读到了0x10000这个地址了。 (还是没弄清如何确认读多少个扇区) ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:6:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-6"},{"categories":["sys"],"content":"Exercise 7 kern/kernel.ld 存放link address 和load address ld文件格式：https://www.math.utah.edu/docs/info/ld_3.html entry_pgdir 将虚拟地址0xf0000000~0xf0400000 映射到 0x00000000~0x00400000 文件 kern/entry.S 根据练习的引导，将断点设置在mov eax,cr0处，查看0x00100000和0xf0100000的内存空间。 运行前： 运行后： 地址0xf0100000被映射成功了，与0x00100000地址处内容相同。 注释执行这个程序，往后面看几条汇编： 0x100025: mov $0xf010002c,%eax 0x10002a: jmp *%eax 程序将会跳转到0xf010002c这个地址去，但是用gdb查看这个地址并没有指令： 程序就会往非预期的方向前进。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:7:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-7"},{"categories":["sys"],"content":"Exercise 8阅读三个c文件： kern/printf.c lib/printfmt.c kern/console.c 从文件名上猜测，printf文件应该是实现输出的主体，printfmt.c应该是一个写满方法的库，console.c应该和shell类似，输出内容和交互的主体。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-8"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i \u003c 12800; i++) delay(); outb(COM1 + COM_TX, c); } COM1 + COM_LSR = 0x03FD ，COM_LSR_TXRDY = 0x20 = 0010 0000 根据这个链接查询端口，(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY)这一个判断条件就是取串口寄存器的第五位，判断transmitter holding register是否为空。 COM1 + COM_TX = 0X03F8 用for循环最多12800次来等待串口寄存器为空，然后执行outb，将参数 c 写入到串口transmitter holding register保存数据。 lpt_putc()static void lpt_putc(int c) { int i; for (i = 0; !(inb(0x378+1) \u0026 0x80) \u0026\u0026 i \u003c 12800; i++) delay(); outb(0x378+0, c); outb(0x378+2, 0x08|0x04|0x01); outb(0x378+2, 0x08); } 0378-037A 被叫做并行打印端口（parallel printer port） 0x378 : 数据端口 | 0x37A : 控制端口 !(inb(0x378+1) \u0026 0x80) 用来判断端口是否闲置 outb(0x378+0, c); 写进数据端口？ 接下来，对输出进行初始化等，具体不明确。 bit 3 = 1 select printer bit 2 = 0 initialize printer bit 1 = 1 automatic line feed bit 0 = 1 strobe cga_putc()static void cga_putc(int c) { // if no attribute given, then use black on white if (!(c \u0026 ~0xFF)) c |= 0x0700; switch (c \u0026 0xff) { ... } } 这种形式和颜色表示有关，一部分比特位控制背景颜色，一部分控制前景颜色，还有一部分负责字符数据。 cga的相关注释 以及what-is-the-function-of-0x0700-in-cga-putc if (crt_pos \u003e= CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i \u003c CRT_SIZE; i++) crt_buf[i] = 0x0700 | ' '; crt_pos -= CRT_COLS; } 这段代码的作用当显示坐标超出了整个console的大小时进行的操作，先用memmove函数crt_buf + CRT_COLS复制crt_buf处，复制长度为CRT_SIZE - CRT_COLS，也就是把页面往上推了一行。然后在for循环中，将最后一行清空。 vprintfmtvprintfmt(void (putch)(int, void), void *putdat, const char fmt, va_list ap) void (putch)(int, void): void (int, void ) 类型函数指针 putdat: 输出字符地址的指针 fmt : 指向格式化字符串 ap： 额外的参数 printf(fmt, ap); ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#consolec"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i = CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#cons_putc"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i = CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#serial_putc"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i = CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#lpt_putc"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i = CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#cga_putc"},{"categories":["sys"],"content":"console.ccons_putc()先从cons_putc()函数开始，代码注释为输出字符到console界面，跟随这个走应该能了解到字符的输出过程。 static void cons_putc(int c) { serial_putc(c); lpt_putc(c); cga_putc(c); } 跟随子程序： serial_putc()static void serial_putc(int c) { int i; for (i = 0; !(inb(COM1 + COM_LSR) \u0026 COM_LSR_TXRDY) \u0026\u0026 i = CRT_SIZE) { int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:1","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#vprintfmt"},{"categories":["sys"],"content":"print.c#include \u003cinc/types.h\u003e#include \u003cinc/stdio.h\u003e#include \u003cinc/stdarg.h\u003e static void putch(int ch, int *cnt) { cputchar(ch); *cnt++; } int vcprintf(const char *fmt, va_list ap) { int cnt = 0; vprintfmt((void*)putch, \u0026cnt, fmt, ap); return cnt; } int cprintf(const char *fmt, ...) { va_list ap; int cnt; va_start(ap, fmt); cnt = vcprintf(fmt, ap); va_end(ap); return cnt; } cprintf(“string”, arg1, arg2)这个函数的调用方法和printf相似，应该就是最终调用函数。 关于ap这个变量，由下面这个程序： #include \u003cstdarg.h\u003e#include \u003cstdio.h\u003e int sum(int, ...); int main() { printf(\"sum :%d\\n\", sum(4, 15, 56, 10, 22) ); return 0; } int sum(int num_args, ...) { int val = 0; va_list ap; int i; printf(\"%d\\n\", num_args); va_start(ap, num_args); for(i = 0; i \u003c num_args; i++) { val += va_arg(ap, int); } va_end(ap); return val; } 补充十进制输出符号 “%o” 的代码片段 根据之前10进制的改就好了: num = getuint(\u0026ap, lflag); base = 8; goto number 题目: Explain the interface between printf.c and console.c. Specifically, what function does console.c export? How is this function used by printf.c? printer.c中的函数是三个主要函数，cprintf()基本上算是c语言中printf()的复刻版，调用顺序：cprintf() -\u003e vcprintf() -\u003e putch() ,调用putch的时候就会发现会要用到console.c中接触底层的函数 serial_putc(c)判断串口为空，lpt_putc(c)判断并行读写？cga_putc(c)负责最后的输出。 Explain the following from console.c: 已分析。 For the following questions you might wish to consult the notes for Lecture 2. These notes cover GCC’s calling convention on the x86. Trace the execution of the following code step-by-step: int x = 1, y = 3, z = 4; cprintf(“x %d, y %x, z %d\\n”, x, y, z); In the call to cprintf(), to what does fmt point? To what does ap point? List (in order of execution) each call to cons_putc, va_arg, and vcprintf. For cons_putc, list its argument as well. For va_arg, list what ap points to before and after the call. For vcprintf list the values of its two arguments. 1.fmt-\u003e “x %d, y %x, z %d\\n” , ap 应该是 x,y,z的集合 2.va_arg这个调用,是每次从ap这个list中取一个值，比如原来参数列表中有x, y, z三个参数, va_arg(ap, int)调用一次，就会取出一个参数x，原列表a中只剩y, z了 参考链接：http://www.cnblogs.com/fatsheep9146/p/5070145.html Run the following code. unsigned int i = 0x00646c72; cprintf(“H%x Wo%s”, 57616, \u0026i); What is the output? The output depends on that fact that the x86 is little-endian. If the x86 were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value? while (1) { while ((ch = *(unsigned char *) fmt++) != '%') { if (ch == '\\0') return; putch(ch, putdat); } 1.首先这一个循环输出所有普通字符，直到fmt指到 %(开始switch) 和 \\0(结束输出) 符号， 2.先是’x'16进制格式 case 'x': num = getuint(\u0026ap, lflag); base = 16; getuint函数: static unsigned long long getuint(va_list *ap, int lflag) { if (lflag \u003e= 2) return va_arg(*ap, unsigned long long); else if (lflag) return va_arg(*ap, unsigned long); else return va_arg(*ap, unsigned int); } 返回一个根据ap列表中的参数,类型由flag控制。flag的值由’l’来自增,例如: “ld” ,“lld” 再调用 printnum(putch, putdat, num, base, width, padc); 这是个递归函数，根据base进制等参数输出数字。 3.再是'%s’格式,输出参数i所在地址的字符串。 57616 = 0xe110 ,所以会输出He110 x86是little-endian, i = 0x00646c72 , 实际在内存中存储是 72 6c 64 00 ,即 ‘r’, ‘l’, ’d', ‘\\0’ 最后的输出结果应该为: “He110 Worlds” In the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen? cprintf(“x=%d y=%d”, 3); 这个问题和va_arg调用有关 #include \u003cstdarg.h\u003e#include \u003cstdio.h\u003e int out_range(int, ...); int main() { out_range(2,11,2); return 0; } int out_range(int num, ...) { int val = 0; int i; va_list ap; va_start(ap, num); for(i = 0; i \u003c 3; ++i) { val = va_arg(ap, int); printf(\"%d\\n\",val); } va_end(ap); } ### result 11 2 1577856 情况和数组越界类似。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:8:2","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#printc"},{"categories":["sys"],"content":"Exercise 9内核什么时候初始化堆栈，堆栈在内存的什么地方，内核如何为堆栈保留空间，哪一个指针指向堆栈的结束处？ 在内核的入口设置断点，跟随几条指令： mov $0x0,%ebp mov $0xf0110000,%esp call 0xf0100094 \u003ci386_init\u003e esp指向栈顶指针,entry.S最后定义了bootstrap的大小KSTKSIZE = 8 * PGSIZE = 8 * 4096 = 32KB 所以堆栈位于内存的0x0010800 ~ 0x0011000,堆栈向下增长,esp指向栈顶 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:9:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-9"},{"categories":["sys"],"content":"Exercise 10-12每个函数调用时，父函数先将参数压栈，使用call命令的时候，将eip压栈。然后进入子函数的时候，将原来的ebp压栈，把esp赋值给ebp，此时两寄存器都指向同一个地址。 接下来，子函数为程序分配内存空间，栈向下增长，即将esp减去一个值。 内存结构就是： +-----+ | ... | +-----+ | arg3| +-----+ | arg2| +-----+ | arg1| +-----+ | eip | +-----+ | ebp | +-----+\u003c-(ebp) |unkn | +-----+\u003c-(esp) int mon_backtrace(int argc, char **argv, struct Trapframe *tf) { // Your code here. uint32_t *ebp = (uint32_t*)read_ebp(); struct Eipdebuginfo info; cprintf(\"Stack backtrace:\\n\"); for(; ebp != 0; ebp = (uint32_t*) *ebp) { cprintf(\" ebp %x eip %x args %08x %08x %08x %08x %08x\\n\", ebp, *(ebp+1), *(ebp+2), *(ebp+3), *(ebp+4), *(ebp+5), *(ebp+6)); if(debuginfo_eip(*(ebp+1),\u0026info) == 0) cprintf(\" %s:%d: %.*s+%d\\n\", info.eip_file, info.eip_line, info.eip_fn_namelen, info.eip_fn_name, *(ebp+1) - info.eip_fn_addr); } return 0; } 接下来要补全debuginfo_eip()中二分查找行的操作，根据前面的代码和提示，补全代码。 stabs文档:http://www.sourceware.org/gdb/onlinedocs/stabs.html#Stab-Sections stab_binsearch(stabs, \u0026lline, \u0026rline, N_SLINE, addr); if(lline \u003c= rline) { info-\u003eeip_line = stabs[lline].n_desc; } else { return -1; } 最后一步是输出调试信息，debuginfo_eip()是通过结构体Eipdebuginfo的成员值来返回的。 这个结构体的定义在kern/kdebug.h中，根据结构体定义信息用cprintf输出就行了。练习最后提示了printf(\"%.*s\",stringlength ,string)对练习中函数名输出有帮助。 $ make grade ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:10:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#exercise-10-12"},{"categories":["sys"],"content":"总结 开机时候，ip指向一个高地址，执行跳转命令到BIOS的程序段，通过BIOS将磁盘的Boot加载到内存地址0x7c00处。 Boot程序加载全局描述符，将外围设备使能。进入保护模式，将扇区已ELF文件形式存在的系统内核加载到物理地址0x10000处，再通过ELF文件的程序入口，跳转到内核。 内核开始时候，打开分页操作，分配堆栈，并将物理地址从0x10000映射到虚拟地址0xf010000处。 最后就是理解系统调用时，堆栈的变化，还有修改一些类似printf函数的功能。 ","date":"2018-03-14","objectID":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/:11:0","series":null,"tags":["OS"],"title":"6.828-操作系统工程-Lab1:Booting a PC","uri":"/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab1-booting-a-pc/#总结"},{"categories":["汇编语言"],"content":"前言王爽老师的《汇编语言》中练习习题8中，有要求在DOS实模式下操作汇编代码。 之前一直用的是windows 2003的CMD中自带的debug调试，所以趁这次机会，把DOS环境搭建一下。 ","date":"2017-11-17","objectID":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/:0:1","series":null,"tags":["Assembly"],"title":"DOS实模式的搭建","uri":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/#前言"},{"categories":["汇编语言"],"content":"安装安装方法和普通ISO文件安装方法差不多，首先选择ISO文件、对应的操作系统，然后用vmware的默认硬件甚至一步一步确定就行。 接下来，启动虚拟机，会弹出一个选择页面，等待一段时间后会自动跳转到安装界面。 然后会提示重新启动，跟着提示来，会提示一个错误： 这应该是DOS支持的磁盘格式为FAT32，而现在的windows支持的硬盘格式是NTFS，两者格式不兼容导致的。 我们关闭虚拟机重新启动下，在下面这个界面按F2进入BIOS设置首先启动项： ","date":"2017-11-17","objectID":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/:0:2","series":null,"tags":["Assembly"],"title":"DOS实模式的搭建","uri":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/#安装"},{"categories":["汇编语言"],"content":"修改启动项跟着以下步骤操作： img [class names] 1. → 移动选项卡至 ‘boot’ 2. ↓ 移动选项至 ‘CD-ROM Drive’ 3. 按住 ‘shift’ 和 ‘+’ 将选中的CD-ROM Drive向上移动 4. 按F10保存退出 此时该虚拟机会重新启动，然后重新进入安装界面。 根据提示，一步一步按确定，基本都是肯定选项。 [注意]直到提示关于 ‘Adds-On’ 额外的软件安装，在这里我们选择 ‘Cancel’ 取消，不进行额外的操作。 如图可见，安装成功，重新启动。 重新启动后发现，还是进入的安装界面，这是因为之前在BIOS内设置过优先启动项的缘故。 和之前的操作一样，在vmware动画界面按F2进入BIOS，用组合键 shift 和 - 将CD-ROM Drive恢复到原来的位置(默认是第三个)。 好了，到现在完成了DOS的安装了，但是还有个问题，就是VMware并没有给DOS提供vmtools，所以物理机和虚拟机之间传输文件并不方便。 ","date":"2017-11-17","objectID":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/:0:3","series":null,"tags":["Assembly"],"title":"DOS实模式的搭建","uri":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/#修改启动项"},{"categories":["汇编语言"],"content":"文件传输首先，我们先关闭DOS虚拟机，然后在左侧硬件配置处点击硬盘。 根据红色箭头提示，点击映射。 然后把**“以只读文件模式打开文件”**前面的勾去掉，然后关闭警告，打开我的电脑，可以发现本地多出一个磁盘 打开后可以看到DOS的实际文件，也就是说，我们可以直接对DOS的文件进行操作。 我们可以把自己的要编译的汇编代码放进去。(图中\"lab8.asm\") 再断开连接，否则DOS将无法启动。 最后，我们再验证一下。 如图，纯DOS系统里已经有了自己放进去的文件。 DOS 7.10.iso 云盘链接 : http://pan.baidu.com/s/1slPZQot 密码: x0ht ","date":"2017-11-17","objectID":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/:0:4","series":null,"tags":["Assembly"],"title":"DOS实模式的搭建","uri":"/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/#文件传输"},{"categories":null,"content":"There have serveral methods: /***overload function****/ void print(int* pi) { if (pi) cout \u003c\u003c *pi \u003c\u003c endl; } void print(const char* p) { if (p) while (*p) cout \u003c\u003c *p++; cout \u003c\u003c endl; } void print(const int* beg, const int* end) { while (beg != end) cout \u003c\u003c *beg++ \u003c\u003c endl; } void print(const int ia[], size_t size) { for (size_t i = 0; i != size; ++i) { cout \u003c\u003c ia[i] \u003c\u003c endl; } } void print(const int(\u0026arr)[2]) { for (auto i : arr) cout \u003c\u003c i \u003c\u003c endl; } int main() { int i = 0, j[2] = {0, 1}; char ch[5] = \"Getup!\"; print(ch); print(begin(j), end(j)); print(\u0026i); print(j, end(j) - begin(j)); print(const_cast\u003cconst int(\u0026)[2]\u003e(j)); } ","date":"2017-06-02","objectID":"/c-/:0:0","series":null,"tags":["c/c++"],"title":"C++ iterater","uri":"/c-/#"}]