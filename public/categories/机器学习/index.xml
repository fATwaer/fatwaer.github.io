<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>机器学习 - 分类 - pokpok的研究日志</title>
        <link>/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
        <description>机器学习 - 分类 - pokpok的研究日志</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 03 Mar 2022 07:59:50 &#43;0800</lastBuildDate><atom:link href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>机器学习整理（异常检测和高斯分布）</title>
    <link>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</link>
    <pubDate>Thu, 03 Mar 2022 07:59:50 &#43;0800</pubDate><author>
        <name>北极乌布</name>
    </author><guid>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</guid>
    <description><![CDATA[异常检测异常检测是一种无监督学习算法，选定一些特征作为输入，输出为概率 $p(x)$ ，当 $p(x_{test}) &lt; \epsilon$ 时，概率 $p$ 小于异常的阈值 $\epsilon$ ， 那么判断样本为异常样本。使用场]]></description>
</item><item>
    <title>机器学习整理（神经网络）</title>
    <link>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
    <pubDate>Thu, 24 Feb 2022 07:59:50 &#43;0800</pubDate><author>
        <name>北极乌布</name>
    </author><guid>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
    <description><![CDATA[神经元神经网络由多个神经元组成，其中神经元由几个部分组成：输入、输入权重、输出和激活函数组成，类似于生物神经元的树突、轴突的组成。 神经元的输]]></description>
</item><item>
    <title>机器学习整理（逻辑回归）</title>
    <link>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
    <pubDate>Tue, 22 Feb 2022 07:59:50 &#43;0800</pubDate><author>
        <name>北极乌布</name>
    </author><guid>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</guid>
    <description><![CDATA[二分类问题问题定义：给定一些特征，给其分类之一。 假设函数 $h(x)$ 定义： $$ h(x) = g(\theta^Tx) $$ $$ g(z) = \dfrac{1}{1 +e^{-z}} $$ 决策边界： 当 $h(x) &gt;= 0.5$ 的时候，y 更有可能预测为 1。 当 $h(x) &lt; 0.5$]]></description>
</item><item>
    <title>机器学习整理（线性回归）</title>
    <link>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
    <pubDate>Mon, 21 Feb 2022 07:59:50 &#43;0800</pubDate><author>
        <name>北极乌布</name>
    </author><guid>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B4%E7%90%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
    <description><![CDATA[单元线性回归1、定义假设函数 $h(x) = \theta_1x + \theta_0$ 2、尝试用样本拟合假设函数，所有样本点到假设函数的距离，其中$m$为样本数量: $$sum = \dfrac{1}{2m} \sum_{1}^{m} (h(x_i) - y_i)^2$$ 3、当 sum 的]]></description>
</item></channel>
</rss>
