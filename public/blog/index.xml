<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 on Pwaer&#39;s Blog</title>
    <link>https://pwaer.ink/blog/</link>
    <description>Recent content in 首页 on Pwaer&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2014 00:00:00 +0000</lastBuildDate><atom:link href="https://pwaer.ink/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ElasticSearch：增删改查和常用查询语法</title>
      <link>https://pwaer.ink/blog/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2/</link>
      <pubDate>Fri, 16 Jul 2021 22:37:19 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2/</guid>
      <description>包括 Elasticsearch 的CRUD和基础检索方式</description>
    </item>
    
    <item>
      <title>实效性软件构建的途径-下</title>
      <link>https://pwaer.ink/blog/notes/programatic2/</link>
      <pubDate>Wed, 15 Apr 2020 19:32:10 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/notes/programatic2/</guid>
      <description>前言 如果一次性总结，文章太过于冗长，上部分更加是一种在编程中会碰到的技术细节，而这一部分是一些编程中需要记住的良好习惯。
1. 养成估算的习惯 1000字节数据通过路由器需要多少时间？类似这样的问题需要有个大致的答案，通过学习估算，能将估算发展到对事物的数量级有直觉的程度，就可以确定方案的可能性。
无论什么时候有人需要你进行估算，你都可以给出答案。 如果没有经验，估算通常可以去问问已经做过该事情的人。 追踪自己的估算能力，如果估算错了，找出什么事情与自己的预期不同。
2. 调试的过程 这里不讲技术上怎么调试，而是另外一种途径进行调试：向别人一行一行解释代码的作用，并且详细描述假定的情况，可能在解释的过程中就可以知道哪里处理问题。
花很长时间找到bug后，想想可以做点什么使找到这个bug更加容易，例如内建更加好的测试。
3. 重构 不要害怕重构，老旧的代码如果不适用，所有代码都可以被替换。重构往往在非正交设计，违反DRY原则、过时的知识、性能缺陷存在时发生。
那么如何合理地进行重构？
 不要在重构同时新增功能 开始重构前要有良好的测试，确保重构后能通过 采用小改动的模式，利用局部改动慢慢扩大到更大规模的改动，避免长时间的调试  4. 测试的一些建议 根据合约(契约式编程)进行单元测试，先测试子模块，再测试模块自身子模块，再测试模块自身。 单元测试应该在模块目录，使测试代码容易找到，既可以说明怎么使用模块的功能，又可以用于构建回归测试，验证未来对代码的改动是否正确。
另外测试都应该具有以下功能：
 setup和cleanup的标准途径 可选择地选择可用测试方法 分析输出结果的手段 标准化故障报告的形式  5. 曳光弹与原型开发 曳光弹原本是指在机枪子弹中间接出现的用于显示子弹射击目标的子弹，比起精确计算风向、射速、角度再射击，曳光弹的方式更加实际。曳光弹的原理就是指，尝试制作一个项目，慢慢地靠近客户需求的一种构建方式，可以有效的展现工作进度，并且这种构建方式的每一段代码都需要有完整的错误检查，结构，文档，以及自查。
而原型开发这种方式通常是一种实验性的探索，为取得某种功能，不必关注太多细节情况，通常没有太多文档和注释。
6. 做变化的催化剂 这一点对自己的要求比较高，在团队合作中，写出很好的代码，让团队的其他人大吃一惊，渐渐影响他们，从而提高项目质量。
7. 不要过度修饰和求精程序 这和过早优化的概念同理，但概念更加偏向于用户，今日了不起的软件往往被明天更加完美的软件更加可取，让用户先使用，用他们的反馈引领软件走向最终解决方案。但是并不是说就可以用不整洁的代码，或者制作糟糕的代码。
8. 管理知识资产 对于金融资产的管理：
 定期投资，形成习惯 多元化是长期成功的关键 在保守的投资和高风险，高回报的投资之间平衡资产 设法低买高卖获取最大回报 周期性的评估和平衡财产  而程序员管理自己的知识资产可以类比：
 定投，周期性的学习 多元化，广度学习，底线是需要知道目前所使用技术的各种特性，优劣 管理风险，不要把所学的技术都放在一个篮子里 低买高卖：新兴技术可能就是被低估的股票，提前学习可能可以更好的找到工作 重新评估：热门技术可能很快就冷门了，甚至过一段时间有需要重新温习忘记的数据库技术等，需要对自己的知识体系重新评估。  所以可以给自己设立一些周期性的目标，防止自己的脱节：
 定期投资可以是每年至少学习一种新的语言，每月阅读一本技术书籍，阅读非技术书籍。 偶尔学习一些公开课 参与一些组织，打听公司以外的人都在做什么 试验不同的环境，技术或者非技术都是如此，逃离舒适区 持续投入！  9. 交流 交流很重要，即使是“自闭”人群，该说话的时候还是得好好说话。</description>
    </item>
    
    <item>
      <title>实效性软件构建的途径-上</title>
      <link>https://pwaer.ink/blog/notes/programatic1/</link>
      <pubDate>Sun, 12 Apr 2020 19:32:10 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/notes/programatic1/</guid>
      <description>前言 无意中看到了这本书，译名是程序员修炼之道，想尝试在这本书中找到一些跟软件构建相关问题的答案。这本书虽然是上个世纪出版的，要注意时代的局限性和过期的经验，进行自我验证，但一遍看下来，对我来说，干货还是有很多的。
1. 需求挖掘 这一点我认为是最重要的一点，于是放在最前面。
找出用户为何要做特定事情的原因，而不是目前要做这件事情的方式，开发最终是需要解决商业问题。 比如，“只有员工和上级和人事部门才能查看员工的档案”和“只有指定人员能查看员工档案”，后者更加容易编写出适用于元数据编程的程序，也更加的灵活。
这个用户不仅仅指实际使用的人，也可以是交给你这个工作的人。
2. 做好退路和保险 书中是用代码所存储的机器因为崩溃而引发的问题，虽然在git的时代，这种问题不容易发生了，但是这种想法得印在脑子里，如果真发生类似的问题，损失将是非常大的。
这一点和可撤销性想类似，要考虑架构部署的改动和灵活性，假设某次会议决定使用MySQL进行存储数据，但是在快完成时，需要换成其他DB进行存储，如果要改动很大，那么就是错误建立在了假定的决策上面。假定项目以后只会用到MySQL，很多代码都被写死了。
再比如开发Unix软件，是否考虑所有平台的可以执行问题，例如epoll可以在linux上使用，那么如果在只有Kqueue的FreeBSD上面会怎么样，所以需要保证代码在一些决策上可以变通。
3. 不要破窗户 这也就是常说的破窗效应，一扇破窗户，只要一段时间不修理，就会逐渐带来废弃感，逐渐变为破败的废弃物。软件中的破窗户就是指，低劣的设计，错误的决策，糟糕的代码。应该发现一个就修一个，如果没时间就加入注释，并且可以深究窗户什么时候破的，原因是什么，如何修理。
并且要注意变化，随着软件补丁的添加，会慢慢偏离其规范，周期性地审视环境的变化，以免量变引发的雪崩。
4. 重复的工作(Don&amp;rsquo;t Repeat Yourself) 这种重复不单单指代码的复制粘贴，还有可能是一些不容易发现的错误。
强加的重复  例如客户端和服务端使用不同的语言，那么两端都会有类似的数据结构，可以用schema的元数据自动生成相关的类定义。 文档：注释会随代码更新而过时，注释应该用于更加高级的说明，我的理解是注释应该写下这段代码应该干什么，而不是干了什么 语言：例如C/C++应该在头文件的函数声明前说明接口问题，实现文件中记载实现细节 文档和代码：如果边写代码边写文档，就会造成代码和文档的重复问题，比如代码改动了，文档也会随即发生变。如果最开始就根据用户的需求写成文档来生成测试，所有的代码只需要在提交时通过所有的测试即可。  无意的重复 通常是设计问题引起的，注意数据之间的关联性，书中的例子是一个数据集合中同时出现了两个点和一段距离，如果点发生了变化，那么需要同时更改距离，比较好的做法是通过点来计算距离，而不是通过赋值。
耐性的重复 这就是在项目中放着好好的代码不用，自己重写写个轮子来浪费时间。
开发者之间的重复 分工不明确导致工作职责重复，这个往往需要清晰的设计和强有力的技术项目领导进行责任划分。
5. 解耦 接口设计时，应该考虑到传入的类型，比如某个函数需要B类型中的时间成员变量，下面这种耦合度更低。
void foo(B &amp;amp;b) { theTime = b.t; } void foo(time &amp;amp;t) { theTime = t; } 较小响应集 根据统计结果，较大响应集更加容易出错，响应集的定义是：类的各个方法直接调用的函数的数目。
Demeter法则 wiki：https://en.wikipedia.org/wiki/Law_of_Demeter
 每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元； 每个单元只能和它的朋友交谈：不能和陌生单元交谈； 只和自己直接的朋友交谈。  在OOP中，这个法则的规定为某个对象的任何方法都应该只调用属于一下情形中的方法：
 它自身的方法 传入该方法的任何参数的方法 该类所属的成员对象所含有的方法 所持有的任何对象的方法  class Demeter { private: A *a; int func(); public: // .</description>
    </item>
    
    <item>
      <title>如何进行调试以及性能剖析</title>
      <link>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/</link>
      <pubDate>Fri, 20 Mar 2020 16:01:24 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/</guid>
      <description>“The most effective debugging tool is still careful thought, coupled with judiciously placed print statements” — Brian Kernighan, Unix for Beginners.
 最朴素的debug方法还是使用print，并且在合适的地方插入print语句，过多的日志信息反而会引起混乱，使debug效率降低。
日志分级 根据事情的验证程度，可以将事件的严重情况分为：
 INFO WARNING ERROR CRITICAL  每当输出日志的时候，在响应事件前面加上前缀，相关的语言应该都有现成的库，根据需求进行选取即可。
对于一个事件运行的程序，比如daemon进程，日志输出在响应文件夹，利用grep就能很好的查询不同严重程度的事件的发生情况。
日志的位置通常在/var/log目录下，例如nginx的日志文件就在/var/log/nginx目录下，系统服务systemd的地址文件就在/var/log/journal目录下。
日志除了写入文件外，还能通过相关配置写入到套接字/远程服务器上，对日志进行集中处理或存储。
其他： - 交互式日志查看工具: lnav
debug 工具 除了GNU项目中的gdb和python自带的pdb，还有一些能在debug过程中自动显示相关变量以及寄存器值的debug工具：
 pwndb lldb  backtrace 利用strace可以查询一些系统调用的次数，例如
store : ~/go &amp;gt;&amp;gt; ls bin pkg src store : ~/go &amp;gt;&amp;gt; sudo strace -e lstat ls -l &amp;gt; /dev/null lstat(&amp;#34;pkg&amp;#34;, {st_mode=S_IFDIR|0755, st_size=4096, .</description>
    </item>
    
    <item>
      <title>B-tree和LSM-tree</title>
      <link>https://pwaer.ink/blog/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/b-tree-and-lsm-tree/</link>
      <pubDate>Wed, 18 Mar 2020 22:29:40 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/b-tree-and-lsm-tree/</guid>
      <description>最初的数据库 LSM-tree得从最简单的数据库的shell实现说起，如：
#! /bin/bash  db_set() { echo &amp;#34;$1,$2&amp;#34; &amp;gt;&amp;gt; database } db_get() { grep &amp;#34;^$1,&amp;#34; database | sed -e &amp;#34;s/^$1,//&amp;#34; | tail -n 1 } db_set将两个参数简单追加database文件，而db_get利用匹配出来的结果去掉key和逗号得到value，再利用tail获取到最set到database中去。
读取优化 很明显，由于是追加写也是最简单的写操作，这种set方式通常足够高效，但是对于get，事件复杂度就需要上升到O(n)，所以最常见的想法是对数据追加索引，比如利用哈希表在内存中设置一个key，而key对应的value设置为该key/value在文件中的偏移。
   key byte offset     abc 0   b 64   &amp;hellip; &amp;hellip;   aacb 3613    就有类似于这样一个哈希表存储在内存中，这也就是Bitcask的核心做法，只需要一次磁盘寻址就可以加载到这个value，适合每个键的值频繁更新的场景。
存储优化 因为都会往同一个文件追加文件，所以设置键的写入，会造成磁盘空间用尽。解决办法是将日志分解成一定大小的段，文件到达一定大小就关闭，后续的写入写到新的段文件中，读请求仍旧使用旧段文件，当后台线程将后台文件合并/压缩后，读请求就能切换到新的合并段上，旧段文件安全删除。
其他  文件格式：替换类似于CSV的字符格式为二进制格式。 删除记录：追加删除标记，当合并时检测到这个标记丢弃响应的key 崩溃恢复：这个主要针对存储在内存中的哈希表，当机器宕机后，哈希表将会丢失，重启恢复需要重新读取所有的段文件才能恢复，Bitcask的做法时将相应段的哈希表快照存储磁盘中。 记录写入：写入操作的过程中如果发送了崩溃，那么最新的值将是不完整的，可以在一条记录前追加校验，如果损毁就需要丢弃。 并发控制：写入需要按先后顺序写入，所以写线程通常只有一个，而读取是可以多个同时进行的。  SSTables SSTables全名为排序字符串表(Sort String Tables)，写入的记录会被排序。对key进行排序会有如下的有点：</description>
    </item>
    
    <item>
      <title>Golang原生RPC与gPRC</title>
      <link>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/rpc-and-grpc/</link>
      <pubDate>Wed, 26 Feb 2020 22:19:35 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/rpc-and-grpc/</guid>
      <description>前言 因为前段时间把6.824的lab3做完了，但是lab内部是用channel mock了一个简单的网络来测试网络丢包，网络分区等问题，也就是说跑在单机上面，其rpc也是通过channel和反射实现。目前比较有名的RPC框架就是gRPC，golang也自带了rpc库，这篇文章主要讲述这两者的简单使用，以及谈论一些关于rpc的观点。
RPC历史 RPC也称远程过程调用，自从上世纪70年代就存在的思想，RPC模型是尝试使远程服务看起来像在统一进程空间的函数一样。但是，一种基于HTTP原则的设计理念REST可以扮演RPC的角色，利用url表示资源，利用HTTP的其他功能提供身份验证等，并且RPC虽然看上去非常简洁，实际上是存在缺陷的，比如rpc的时间根据网络情况可能大不相同，网络不可信时，超时重传会使RPC函数被调用多次，这就又需要这个函数能保证幂等性等。
虽然有以上问题，RPC没有消失肯定有其独特存在的原因，首先是使用二进制编码的RPC协议能实现比REST上基于JSON的数据流协议获得更好的性能(但是JSON数据流可以提供良好的调试功能，这是二进制编码不可比拟的)。所以REST一般用于公共API，而RPC框架侧重于同一组织内多项服务之间的请求，也通常发生在同一个数据中心。
RPC的目标是让客户端和服务端易于交互(编程意义上)，隐藏底层的网络协议。
原生RPC 这里直接尝试写一个简单的KV服务，提供Put，Get的接口。
客户端代码 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;log&amp;#34; &amp;#34;net/rpc&amp;#34; ) // // Common RPC request/reply definitions //  const ( OK = &amp;#34;OK&amp;#34; ErrNoKey = &amp;#34;ErrNoKey&amp;#34; ) type Err string type PutArgs struct { Key string Value string } type PutReply struct { Err Err } type GetArgs struct { Key string } type GetReply struct { Err Err Value string } // // Client //  func connect() *rpc.</description>
    </item>
    
    <item>
      <title>Shell Tools and Scripting</title>
      <link>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/shell-tools-and-scripting/</link>
      <pubDate>Thu, 13 Feb 2020 20:55:13 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/shell-tools-and-scripting/</guid>
      <description>前言 这篇笔记主要是说明一些bash scripts中要注意的问题，比如变量的赋值，函数，Shebang，特殊变量，通配符等；以及介绍一些提高在shell环境下提高工作效率的工具，例如查看使用方法的时候，可以快速翻阅 TLDR 获取命令的用法，而不用使用 man 手册慢慢地找相关的参数等。
基本变量 赋值变量通过 foo=bar 来完成，并且带空格的 foo = bar 不会成功，因为相当于直接连续调用 foo 、 = 、 bar 三个命令，另外双引号 &amp;quot; 会展开变量而单引号不会 &#39; 。
foo=bar echo &amp;#34;$foo&amp;#34; # prints bar echo &amp;#39;$foo&amp;#39; # prints $foo 函数 mcd.sh
mcd () { mkdir -p &amp;#34;$1&amp;#34; cd &amp;#34;$1&amp;#34; } Here $1 is the first argument to the script/function
 $0 - Name of the script $1 to $9 - Arguments to the script.</description>
    </item>
    
    <item>
      <title>6.824 Lab3 Fault-tolerant Key/Value Service</title>
      <link>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/kv-server/</link>
      <pubDate>Wed, 12 Feb 2020 10:42:40 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/kv-server/</guid>
      <description>强一致性Key/Value服务 其实在写完Raft后，K/V的接口已经比较明显了，只需要将操作写入Raft entry的Command内，然后等待Raft的同步，再应用到状态机（例如map[string]string）即可，但是实际上在跑3A测试的时候还是出现了很多问题。
并发(Concurrency) 虽然保证同一个客户端同时只会发送一个Put或者Get请求，但是在面对多个客户端时，如何处理这些请求，并且将这些请求写入到Raft的log entry中。老生常谈的问题，但是在这里处理比较简单，在Raft开始协调一个新的共识(Agreement)的时候,也就是start()，已经使用了mutex来附加新的entry到log中。
网络不可靠(Unreliable) 这里是在3A碰到的第一个要认真考虑的点，如果一个RPC请求（比如append “1”-&amp;gt;&amp;ldquo;2&amp;rdquo;）经过了慢速网络而触发了重传，导致这个RPC被调用了两次，所以在Hint中有提醒，让client的每一个请求都有一个独一无二的ID来保证每个操作只能被执行一次。而如何使得每个操作只会被执行一次，并保证幂等性，还需要考虑到接下来的几个情况。
服务器主机崩溃(Crash) 服务器主机崩溃的情景里要考虑的不是网络问题，而是当发生了主机崩溃，往往代表着新的一轮选举和新的leader诞生。所以当真正发生leader切换的时候，客户端需要做的事情是将当前的RPC重新发往新的leader。另外一点是持久化问题，这个会在快照机制中遇到一些需要思考的点。
网络分区(Partition) 由于是实现一个强一致性的KV服务，在并发条件下，每一个Get/Put/Append操作都会被按顺序执行一次，而每次调用都需要监控之前的操作序列所做的操作所带来的影响，就好像在调用前，前面的所有的调用已经完成，通常称其为线性化。
最先碰到网络分区和检查一致性是TestOnePartition3A，这个测试中做了如下几件事情：
 创建一个5个server的kv服务器集群 客户端请求: Put:1 -&amp;gt; 13 建立网络分区，3台主机处于大多数(majority)，另外两台主机(保证有一台是leader)处于少数(minority)。 往majority中提交Put:1-&amp;gt;14 检查majority 往minority中提交操作Put:1 -&amp;gt; 15和Get:1 检测6中两个操作是否会成功 往majority提交Put:1-&amp;gt;16并检查 合并两个分区，检查最后Key 1的值。  最后的值应该为15，在这里碰到的一致性检查是关于第六步Get操作，从Raft可以知道在minority中提交的操作是不会被commit的，更不会被应用到状态机，此时minority中的key 1的值是13，相比于majority中的14，是一个过期的值，所以6步中的Get RPC在分区合并前不应该返回。
当分区合并后，minority的leader会被majority中的新leader的心跳设置为follower，所以旧leader的kv服务应该检测到自己不再是leader而返回现存的RPC：Put:1 -&amp;gt; 15和Get:1，使客户端重定向到新的leader。
而Get什么时候返回？这个在Hint中也提到了，最方便的做法就是将Get也塞入raft的log entry内，在这种情境下，处于minority分区的Get操作就会被读取到过期的数据。
标识操作(UniqueID) 如何为每一个操作定独一无二ID？我的做法是每个操作维护三个变量以及新加一个RPC用于客户端注册：
 seriesN：每个客户端初始化为-1，每执行一次Get/Put/Append调用前自增1。 Client ID：初始化为-1，用于辨识客户端，由kv服务端来分配，客户端进行维护。 Server ID：代表分配Client ID的服务端，用于解决同一个操作因为leader切换而造成ID冲突。  每当启用一个新的客户端并且提交操作时，先自增seriesN，如果Client ID为-1，就会向服务端注册自己，即请求一个可用的Client ID，并设置Server ID。每当一个操作在raft中达成共识时，应用到状态机后，应该记录Cid和Sid的最大值，用于防止重复的操作被提交到状态机。
当出现小于当前seriesN的操作出现时，需要返回一个duplicate的错误告知客户端。
考虑下面这种情景：
s1 | x = 0 | x += 1 同步到其他server s2 | x = 0 | x += 1 s3 | x = 0 | x += 1 s4 | x = 0 | x += 1 s5 | x = 0 | nil   leader s1 提交了一个 x += 1 的操作后，并同步到了s2, s3, s4，然后发生分区。 s2 当选新一轮的leader，并同步完成 s1 恢复到该分区中，被s2的心跳转变为follower client对s1的rpc被返回，重定向到s2，重复的op被提交。  这里也可以通过比较相同clinetID的seriesN来决定是否应用到状态机，但是如果第一步中，x += 1 并没有提交到s1以外的服务器，s2服务器当选leader后先为另一个client分配了相同的client ID，在分区合并前提交过几次操作，那么 x += 1的操作将会被驳回，所以这里需要server ID处理命名空间的冲突。</description>
    </item>
    
    <item>
      <title>Protection Mechanism on 80386</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/protection/</link>
      <pubDate>Mon, 11 Nov 2019 12:34:17 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/protection/</guid>
      <description>80386 下的保护模式划为5个部分：
 类型检查 界限检查 可寻址域的限制 过程调用的限制 指令集的限制  事实上按照段页机制又需要分为段机制下的保护和页机制下的保护。
段级别的保护 段描述符中存储了保护参数，当段描述符到段寄存器中和访问相应的段时，CPU 会自动启用保护机制进行检测。
 段描述符格式
 上图中一共有三种段，除了常被应用程序使用的数据段和可执行段外，还有一种用作门（gate）的描述符。
当段寄存器加载一个段的时候，不仅仅只是加载了段的基地址，还会加载其他的保护机制所需要用到的信息。在段寄存器的不可见部分存储了段基地址，界限，特权等级，所以在保护机制在检查合法性时没有额外的时钟周期损耗。
段机制的类型检查 描述符中的 TYPE 域用来区分不同描述符的格式和描述符的作用。
  在数据段的 writable bit 代表正在执行的指令可否写入到该段。
  代码段中的 readable bit 代表正在执行的指令能否读取该段中的数据，例如操作数为常量的情况。
一个可读可执行的段可以被两种形式加载：
 通过 CS 寄存器，例如 ljmp cs:addr 加载到通用段寄存器中    类型检查会在两种情况下进行：
  当描述符被加载到到段寄存器时，相应的段寄存器只能加载对应的描述符种类，例如：
 CS 寄存器只能加载可执行的段 不可读但是可执行的段不能被加载到数据段寄存器中 只有科协的数据段能被加载到SS寄存器    当指令显式或者隐式地引用段寄存器，相应的段只能被预先定义好的方式来使用，例如：
 不能尝试往可执行的段中写入 不能往w位未置位的数据段中写入 不能读取r位未置位的可执行段（数据段默认可读）    段机制的界限检查 故名思意，界限（limit）域在描述符中被处理器阻止程序寻址到超出段界限外的地方，与段界限相关的还有 G (granularity) bit，对于数据段，还有 E-bit (expansion-direction bit) 和 the B-bit (big bit)。</description>
    </item>
    
    <item>
      <title>Hugo is comming !</title>
      <link>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hugo%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Wed, 18 Sep 2019 14:11:14 +0800</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hugo%E9%85%8D%E7%BD%AE/</guid>
      <description>将博客从 hexo 迁到了 hugo，主要原因是文章越来越多，hexo build速度就显得力不从心了，hexo 很多主题都不再维护，甚至很少有新的主题发布出来，而 hugo 相反，随着golang热度的上涨，社区也很活跃，其主题的更新在官网可以看出来相对频繁。我目前使用的主题是由zzossig 提供的Zzo主题。
 Hugo 总览 看到比较合适的主题，有需要自己定制的话，可以简单过一遍Hugo的一个官方教程(大概3-4小时)：
 https://www.youtube.com/watch?v=qtIqKaDlqXo&amp;amp;list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3
 Hugo 的安装和环境配置 Hugo 提供了较为详细的官方教程，安装过程非常详细，如果是在windows上安装，可以下载二进制文件到任意目录下，并且将改目录添加到PATH环境变量即可。
Hugo 的基本使用 将hugo的环境搭建完成后博客根目录进行初始化：
hugo version mkdir Sites cd Sites hugo new site sitename 然后需要去主题页找一个合适的主题，并且下载到Sites/sitename/themes目录，或者在Sites/sitename目录下执行：
git init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 然后将配置文件中的主题设置为下载到themes目录中的主题文件夹名字：
echo &amp;#39;theme = &amp;#34;ananke&amp;#34;&amp;#39; &amp;gt;&amp;gt; config.toml 像hexo一样，hugo提供了本地预览的功能，在 Sites/sitename目录下运行，然后就可以访问localhost:1313来访问博客了：
$ hugo server Building sites … | EN | KO -------------------+-----+------ Pages | 54 | 10 Paginator pages | 3 | 0 Non-page files | 0 | 0 Static files | 209 | 209 Processed images | 0 | 0 Aliases | 11 | 1 Sitemaps | 2 | 1 Cleaned | 0 | 0 Built in 5641 ms Environment: &amp;#34;development&amp;#34; Serving pages from memory Running in Fast Render Mode.</description>
    </item>
    
    <item>
      <title>6.824 Notes：MapReduce、GFS、Raft</title>
      <link>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/6.824-notesmapreducegfsraft/</link>
      <pubDate>Tue, 15 Jan 2019 15:49:46 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/6.824-notesmapreducegfsraft/</guid>
      <description>最近这段时间有一些空闲时间，可以开始做下6.824，目前是Spring 2018，最新的2019也快出了，提前刷下notes和paper。
分布式系统是关于多个计算机系统共同合作并且进行存储大量的网站数据，执行mapreduce，端对端共享的一种系统，大量的关键基础设施都是分布式的。
分布式系统的优点是能够组织物理上分离的实体，通过isolation取得系统安全，通过replication获取容错机制，通过并行CPUs/mem/disk/net来比例提升系统速度。
当然也有些缺点，这些过程中必须需要处理大量的并发部件，必须应对部分组件失效，以及很难获取一些潜在的性能。
MapReduce(2004) input is divided into M files [diagram: maps generate rows of K-V pairs, reduces consume columns] Input1 -&amp;gt; Map -&amp;gt; a,1 b,1 c,1 Input2 -&amp;gt; Map -&amp;gt; b,1 Input3 -&amp;gt; Map -&amp;gt; a,1 c,1 | | | | | -&amp;gt; Reduce -&amp;gt; c,2 | -----&amp;gt; Reduce -&amp;gt; b,2 ---------&amp;gt; Reduce -&amp;gt; a,2  对于输入的文件，首先将其分为 M 个文件，对于每一个文件调用一个 Map()作为一次作业，每一个Map()调用产生一组 &amp;lt;k2, v2&amp;gt;键值对(图中的一行)作为中间数据。
MapReduce聚集键为 k2 的所有中间值，将其传输给Reduce()调用，并且以 &amp;lt;k2, v3&amp;gt; 的集合作为最终输出存入到Reduce的输出文件中。也就形成了最后的形式API形式：</description>
    </item>
    
    <item>
      <title>Data-Intensive System</title>
      <link>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/data-intensive-system/</link>
      <pubDate>Fri, 11 Jan 2019 11:57:29 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/data-intensive-system/</guid>
      <description>数据组件   消息队列
Redis: https://github.com/antirez/redis
Apache Kafka
  主数据库
//todo
  全文索引
Elasticsearch: https://github.com/elastic/elasticsearch
Apache Solr
  内存缓存
Memcached: https://github.com/memcached/memcached
  </description>
    </item>
    
    <item>
      <title>Effective Go</title>
      <link>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/effective-go/</link>
      <pubDate>Thu, 10 Jan 2019 12:48:14 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/effective-go/</guid>
      <description>goroutine部分 goroutine的一些tricks，比如
func Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // 注意括号 - 必须调用该函数。 }  直接在go关键字后面接一个lambada表达式作为例程。
goroutine通常和channal一起使用，Unix的管道是基于生产-消费者模型，而channal则使用CSP(Communicating Sequential Process)进行构建。信道没有数据的时候会进行阻塞，利用这种条件可以实现一些信号量机制。
var sem = make(chan int, MaxOutstanding) func handle(r *Request) { sem &amp;lt;- 1 // 等待活动队列清空。 process(r) // 可能需要很长时间。 &amp;lt;-sem // 完成；使下一个请求可以运行。 } func Serve(queue chan *Request) { for { req := &amp;lt;-queue go handle(req) // 无需等待 handle 结束。 } }  例如这样一段代码可以实现最大接受请求数量为MaxOutstanding,当新的请求到达时，req := &amp;lt;-queue从阻塞中恢复并且执行goroutine处理请求，再往sem里面写入内容时，会因为队列满了而阻塞，当然这样也有局限性，当有大量请求到达的时候，会不停地新生成新的goroutine，占用系统资源。
func Serve(queue chan *Request) { for req := range queue { req := req // 为该Go程创建 req 的新实例。 sem &amp;lt;- 1 go func() { process(req) &amp;lt;-sem }() } }  解决方案是在循环的routine中尝试往信道中写入内容，这样可以正确实现队列的大小限制。考虑去掉req := req这一行，req变量在每个循环中都被赋予不同的值，但是实际上底层使用的同样的内存，相应的goroutine后的函数闭包可以引用该作用域的变量并且保持和修改，所以每个新生成的goroutine都会使用同一个变量，造成比较严重的错误。</description>
    </item>
    
    <item>
      <title>Core Java for DataBase</title>
      <link>https://pwaer.ink/blog/jvm%E7%9B%B8%E5%85%B3/core-java-for-database/</link>
      <pubDate>Sun, 18 Nov 2018 16:36:16 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/jvm%E7%9B%B8%E5%85%B3/core-java-for-database/</guid>
      <description>前言 最近想深入下数据库原理，在知乎和Google发现有几门开源的好课值得去学习。我选择的是6.830，首先是之前有刷过6.828，相对来说比较熟悉，不过实现是选择的是java，这也就是我为什么写博客的理由。另外也被人推荐的CMU15445,这门课程稍微浏览了下主页，是使用C++来实现的，并且课件PPT和视频都非常良心。
这是头一次认真接触JAVA，我使用的是《JAVA核心技术　卷１》,是一本相对来说比较方便C/C++程序员入坑的书，这篇博客也会根据这本书的目录作为大纲进行梳理。
基本结构 基本类型大多数语言其实差不了太多，不做太多废话，但是字符串的操作更加接近与python那一类的语言，自动拼接、垃圾回收之类的。
字符串 字符串判断为空：
if (str.length() == 0) or if (str.equals(&amp;quot;&amp;quot;))  虽然可以进行字符串拼接，但是效率比较低，可以使用StringBuilder类:
StringBuilder builder = new StringBuilder(); builder.append(ch); builder.append(str); builder.toString();  作用域 JAVA的作用域和C/C++不同，内部块中的同名变量名不会覆盖外部块的变量名，甚至无法通过编译。所以在内部块中需要取不同的变量名，但在class中，可以使用this指针来指定变量。
数组 JAVA的数组都是分配在堆上，这又是和C/C++不同的一点：
JAVA中的:
int[] a = new int[100];  等同于C/C++中的:
int* a = new int[100];  不同于:
int a[100];  并且数组的完整拷贝通过方法Arrays.copyOf():
newArr = Arrays.copyOf(oldArr, oldArr.lenght());  也可以通过这个方法来扩展数组：
Arr = Arrays.copyOf(Arr, 2 * Arr.lenght());  对象与类 OO应该是JAVA的重点，OOP三个特性：
 封装：用一个类将实现和使用分开，只保留接口与外部进行联系。 继承：子类自动继承其父类的属性和方法，并且可以添加新的方法和属性。 多态：虽然多个子类都有同一个方法，但是子类的子类实例化之后都可以获得完全不同的结果。  通过下面的方法实例化一个类：</description>
    </item>
    
    <item>
      <title>算法与数据结构总结</title>
      <link>https://pwaer.ink/blog/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/</link>
      <pubDate>Sun, 09 Sep 2018 18:41:48 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%80%BB%E7%BB%93/</guid>
      <description>CLRS快撸完一半了，所以趁开学前做下小总结，CLRS研究问题的方式和平时的感觉有那么些不太一样，但是接触久了就会慢慢习惯，主要注重算法的运行时间和算法可行性。初阶学习目标是掌握几种重要的排序算法和课堂中没有学到的数据结构。
首先还要推荐一下usfca的这个算法可视化的网站：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html
排序算法 排序算法在系统学习之前，只会冒泡排序，非常简单但是时间复杂度为O(n^2)的算法，是一种没有怎么优化过的想法。
插入排序 插入排序(insert sort)是学习CLRS最先接触的算法，可以理解为将序列中的元素插入到一个已经排序好的队列中去。提供一个序列的起始位置(be)和长度(len)，循环从起始位置的下一个元素开始迭代，作为需要插入的数值(key)，将所有大于关键字元素后移一位，最后在放入对应的位置。期望运行时间(n^2)。
for (int i = be + 1; i &amp;lt; len; i++) { int key = a[i]; int j = i - 1; while (j &amp;gt;= 0 &amp;amp;&amp;amp; a[j] &amp;gt; key) { a[j+1] = a[j]; j--; } a[j+1] = key; } 归并排序 归并排序(merge sort)是接触分治法接触到的算法，这种方法是将需要解决的问题细分为细小的问题，然后递归求解这些子问题，直接求解，最后将这些子问题的解合并成原问题的解。应用到排序算法中的话就是将待排序的元素分成n/2两个子序列，然后递归解决子序列的顺序问题，最后合并两个已排序的子序列，形成排序好的队列。期望运行时间(nlgn)。
首先是归并过程的辅助函数:
void SortAlgorithm::mergeArray(int p, int q, int r) { int n1 = q - p + 1; int n2 = r - q; int L[n1], R[n2]; int i1, i2; for (int i = 0; i &amp;lt; n1; i++) L[i] = a[p+i]; for (int i = 0; i &amp;lt; n2; i++) R[i] = a[q+i+1]; i1 = 0; i2 = 0; for (int k = p; k &amp;lt;= r; k++) { if ((L[i1] &amp;lt;= R[i2] &amp;amp;&amp;amp; i1 &amp;lt; n1 )|| i2 == n2) { a[k] = L[i1]; i1++; } else { a[k] = R[i2]; i2++; } } } 前面两个for循环是赋值递归过程已经排好的两个子数组left和right，然后根据i1和i2所指向的数组元素大小放入到原来的数组中去，完成两个子数组的归并。</description>
    </item>
    
    <item>
      <title>6-828-操作系统工程-Lab6-Network Driver(Final)</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/</link>
      <pubDate>Mon, 28 May 2018 09:26:33 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab6-network-driver/</guid>
      <description>这章节是完成一个网络驱动程序，现在系统中已经存在了文件系统里，所以可以添加一个网络栈，是基于82540EM芯片(E1000)。这章节内容比我想象中难，虽然之前概览了一下，但是实际做起来的时候涉及到的概念和知识超出我现在所掌握的。
准备 git
$ git add . $ git commit -am &amp;#34;lab 5 done&amp;#34; $ make handin $ git pull $ git checkout -b lab6 origin/lab6 $ git merge lab5 Auto-merging lib/fd.c Auto-merging kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c Auto-merging inc/lib.h Auto-merging fs/serv.c Merge made by the &amp;#39;recursive&amp;#39; strategy. boot/main.c | 1 - fs/bc.c | 22 +- fs/fs.c | 73 +- .... user/faultio.c | 2 +- user/forktree.c | 1 + user/sh.c | 9 +- user/testfile.</description>
    </item>
    
    <item>
      <title>6-828-操作系统工程-Lab5-File system, Spawn and Shell</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/</link>
      <pubDate>Sun, 20 May 2018 18:37:16 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab5-file-system-spawn-and-shell/</guid>
      <description>这个实验主要是实现spawn库函数用来读取并运行可执行文件，然后扩充操作系统的内核和库 ，使得足以在控制台上运行shell。实现这些特性需要一个文件系统，而接下来就会介绍一个简单的可读写的文件系统。
准备 git
$ find . -name &amp;#34;*.swp&amp;#34; | xargs rm $ git add . $ git commit -m &amp;#34;lab4 done&amp;#34; $ git pull $ git merge lab4 Auto-merging kern/trap.c CONFLICT (content): Merge conflict in kern/trap.c Auto-merging kern/syscall.c Auto-merging kern/init.c CONFLICT (content): Merge conflict in kern/init.c Auto-merging kern/env.c CONFLICT (content): Merge conflict in kern/env.c Auto-merging inc/lib.h Automatic merge failed; fix conflicts and then commit the result. 解决conflict，并且确认pingpong, primes, 和forktree这三个用户程序可以正常运行。</description>
    </item>
    
    <item>
      <title>6.828-操作系统工程-Lab4:Preemptive Multitasking</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/</link>
      <pubDate>Mon, 07 May 2018 19:28:03 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab4-preemptive-multitasking/</guid>
      <description>在这个实验中，将会在多个用户环境同时运行时实现抢占式多任务。
 part A:为JOS添加多处理器的支持，实现round-robin scheduling和增加基础的用户环境管理的系统调用，例如创建和销毁用户环境，分配和映射内存中的内容。 part B: 实现fork()函数，允许用户环境去添加一份自己环境的拷贝。 part C: 添加进程间的通信IPC(inter-process communication)，允许不同的用户环境各自通信和同步；添加硬件时钟中断和抢占任务。
 准备开始 git
#git rest --hard FETCH_HEAD git add -u git commit -m &amp;quot;&amp;quot; git pull git checkout -b lab4 origin/lab4 git merge lab3  confilcts in file config/lab.mk
源文件描述 kern/cpu.h Kernel-private definitions for multiprocessor support kern/mpconfig.c Code to read the multiprocessor configuration kern/lapic.c Kernel code driving the local APIC unit in each processor kern/mpentry.S Assembly-language entry code for non-boot CPUs kern/spinlock.</description>
    </item>
    
    <item>
      <title>6.828-操作系统工程-Lab3:User Environments</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/</link>
      <pubDate>Sun, 22 Apr 2018 23:01:09 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab3-user-environments/</guid>
      <description>4月22日 - 5月2日
 PART A 这章的练习将会取实现一些基础的用户模式下的环境，也就是进程。在这章，创建一个用户环境，读取程序镜像并且运行。 这是关于这章节代码文件的介绍
inc/env.h Public definitions for user-mode environments trap.h Public definitions for trap handling syscall.h Public definitions for system calls from user environments to the kernel lib.h Public definitions for the user-mode support library kern/env.h Kernel-private definitions for user-mode environments env.c Kernel code implementing user-mode environments trap.h Kernel-private trap handling definitions trap.c Trap handling code trapentry.S Assembly-language trap handler entry-points syscall.h Kernel-private definitions for system call handling syscall.</description>
    </item>
    
    <item>
      <title>Git 基础操作</title>
      <link>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Tue, 17 Apr 2018 23:27:42 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/git-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</guid>
      <description>远程到本地  $ git fetch $ git merge origin/master  本地到远程  关联
git remote add origin git@github.com:haoxr/-faceDetection.git  提交到本地
$ git add . $ git commit -m &amp;quot;commit infomation&amp;quot;  push
$ git push -u origin master &amp;lt;- 第一次使用 $ git push origin master </description>
    </item>
    
    <item>
      <title>6.828-操作系统工程-Lab2:Memory Management</title>
      <link>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/</link>
      <pubDate>Thu, 12 Apr 2018 19:18:13 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6-828-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B-lab2-memory-management/</guid>
      <description>Exercise 1: 内存初始化 在 lab1 中开启了分段和分页，并且初始化了内核页目录（地址存储在CR3中），于是有了下面这样的地址转换机制。
 地址转换
 首先通过相应段寄存器获得地址基址，然后以虚拟地址作为偏移获得线性地址。线性地址在通过一定的机制，获得实际的物理地址。
线性地址转换过程:
段翻译机制输出一个线性地址（Linear address） Linear address(LA)，用于接下来的转换，在 CR0 寄存器 PG 位未设置的时候，线性地址会被直接作为物理地址。
// A linear address &amp;#39;la&amp;#39; has a three-part structure as follows: // // +--------10------+-------10-------+---------12----------+ // | Page Directory | Page Table | Offset within Page | // | Index | Index | | // +----------------+----------------+---------------------+ // \--- PDX(la) --/ \--- PTX(la) --/ \---- PGOFF(la) ----/ // \---------- PGNUM(la) ----------/ // // The PDX, PTX, PGOFF, and PGNUM macros decompose linear addresses as shown.</description>
    </item>
    
    <item>
      <title>hexo 配置</title>
      <link>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hexo%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Thu, 05 Apr 2018 15:17:47 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/hexo%E9%85%8D%E7%BD%AE/</guid>
      <description>&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;： 博客已经从hexo迁移到了hugo，部分格式已经不能渲染出来。&lt;/p&gt;
&lt;h2 id=&#34;categories和tags&#34;&gt;categories和tags&lt;/h2&gt;
&lt;p&gt;themes文件夹下面的_config.yml有一个memu选项，hiker是默认有归档选项的。但是分类和标签是空页面，本地访问会提示 GET ERROR 的404错误。在md文件有表示的情况下，像如下配置即可。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;type: &lt;span style=&#34;font-style:italic&#34;&gt;&amp;#34;categories&amp;#34;&lt;/span&gt;
layout: &lt;span style=&#34;font-style:italic&#34;&gt;&amp;#34;categories&amp;#34;&lt;/span&gt;
comments: false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;type: &lt;span style=&#34;font-style:italic&#34;&gt;&amp;#34;tags&amp;#34;&lt;/span&gt;
layout: &lt;span style=&#34;font-style:italic&#34;&gt;&amp;#34;tags&amp;#34;&lt;/span&gt;
comments: false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab11</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab11/</link>
      <pubDate>Wed, 22 Nov 2017 22:39:56 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab11/</guid>
      <description>&lt;p&gt;为了循环方便，我们设置&lt;strong&gt;SI&lt;/strong&gt;为**-1**&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab10</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab10/</link>
      <pubDate>Tue, 21 Nov 2017 22:41:02 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab10/</guid>
      <description>&lt;p&gt;实验10 一共3个小实验，分别完成三个函数。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab8</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab8/</link>
      <pubDate>Fri, 17 Nov 2017 12:15:41 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab8/</guid>
      <description>assume cs:codesg codesg segment mov ax,4c00h int 21h start: mov ax,0 s: nop nop mov di,offset s mov si,offset s2 mov ax,cs:[si] mov cs:[di],ax s0: jmp short s s1: mov ax,0 int 21h mov ax,0 s2: jmp short s1 nop codesg ends end start 其中
jmp short s 命令占用两个字节</description>
    </item>
    
    <item>
      <title>DOS实模式的搭建</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 17 Nov 2017 00:17:04 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/dos%E5%AE%9E%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%90%AD%E5%BB%BA/</guid>
      <description>前言 王爽老师的《汇编语言》中练习习题8中，有要求在DOS实模式下操作汇编代码。 之前一直用的是windows 2003的CMD中自带的debug调试，所以趁这次机会，把DOS环境搭建一下。
安装 安装方法和普通ISO文件安装方法差不多，首先选择ISO文件、对应的操作系统，然后用vmware的默认硬件甚至一步一步确定就行。
接下来，启动虚拟机，会弹出一个选择页面，等待一段时间后会自动跳转到安装界面。
然后会提示重新启动，跟着提示来，会提示一个错误：
这应该是DOS支持的磁盘格式为FAT32，而现在的windows支持的硬盘格式是NTFS，两者格式不兼容导致的。 我们关闭虚拟机重新启动下，在下面这个界面按F2进入BIOS设置首先启动项：
修改启动项 跟着以下步骤操作： img [class names] 1. → 移动选项卡至 &amp;lsquo;boot&amp;rsquo; 2. ↓ 移动选项至 &amp;lsquo;CD-ROM Drive&amp;rsquo; 3. 按住 &amp;lsquo;shift&amp;rsquo; 和 &amp;lsquo;+&amp;rsquo; 将选中的CD-ROM Drive向上移动 4. 按F10保存退出
此时该虚拟机会重新启动，然后重新进入安装界面。 根据提示，一步一步按确定，基本都是肯定选项。 [注意]直到提示关于 &amp;lsquo;Adds-On&amp;rsquo; 额外的软件安装，在这里我们选择 &amp;lsquo;Cancel&amp;rsquo; 取消，不进行额外的操作。
如图可见，安装成功，重新启动。 重新启动后发现，还是进入的安装界面，这是因为之前在BIOS内设置过优先启动项的缘故。 和之前的操作一样，在vmware动画界面按F2进入BIOS，用组合键 shift 和 - 将CD-ROM Drive恢复到原来的位置(默认是第三个)。
好了，到现在完成了DOS的安装了，但是还有个问题，就是VMware并没有给DOS提供vmtools，所以物理机和虚拟机之间传输文件并不方便。
文件传输 首先，我们先关闭DOS虚拟机，然后在左侧硬件配置处点击硬盘。
根据红色箭头提示，点击映射。
然后把**&amp;ldquo;以只读文件模式打开文件&amp;rdquo;**前面的勾去掉，然后关闭警告，打开我的电脑，可以发现本地多出一个磁盘
打开后可以看到DOS的实际文件，也就是说，我们可以直接对DOS的文件进行操作。 我们可以把自己的要编译的汇编代码放进去。(图中&amp;quot;lab8.asm&amp;quot;)
再断开连接，否则DOS将无法启动。 最后，我们再验证一下。
如图，纯DOS系统里已经有了自己放进去的文件。
 DOS 7.10.iso 云盘链接 : http://pan.baidu.com/s/1slPZQot 密码: x0ht
 </description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab6</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab6/</link>
      <pubDate>Mon, 13 Nov 2017 23:11:53 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab6/</guid>
      <description>datasg segment db &amp;#39;1. display &amp;#39; db &amp;#39;2. brows &amp;#39; db &amp;#39;3. replace &amp;#39; db &amp;#39;4. modify &amp;#39; datasg ends 将数据段前四个字母改为大写字母 &amp;amp;nbsp代码如下:
assume cs:codesg,ss:stacksg,ds:datasg stacksg segment dw 0,0,0,0,0,0,0,0 stacksg ends datasg segment db &amp;#39;1. display &amp;#39; db &amp;#39;2. brows &amp;#39; db &amp;#39;3. replace &amp;#39; db &amp;#39;4. modify &amp;#39; datasg ends codesg segment start: mov ax,stacksg mov ss,ax mov sp,16 mov ax,datasg mov ds,ax mov cx,4h mov bx,0 s1:	push cx mov cx,4 mov si,0 s2:	mov al,[bx+3+si] and al,11011111b mov [bx+3+si],al inc si loop s2 add bx,16 pop cx loop s1 mov ax,4c00h int 21h codesg ends end start	</description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab5</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab5/</link>
      <pubDate>Mon, 13 Nov 2017 22:49:40 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab5/</guid>
      <description>根据程序编译连接并用Debug加载、跟踪，然后回答问题。
(1) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h,0789h,0abch,0defh,0fedh,0cbah,0987h data ends stack segment dw 0,0,0,0,0,0,0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop	ds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B4B
(2) assume cs:code,ds:data,ss:stack data segment dw 0123h,0456h data ends stack segment dw 0,0 stack ends code segment start: mov ax,stack mov ss,ax mov sp,10h mov ax,data mov ds,ax push ds:[0] push ds:[2] pop ds:[2] pop	ds:[0] mov ax,4c00h int 21h code ends end start CS=0B4A;SS=0B49;DS=0B48</description>
    </item>
    
    <item>
      <title>《汇编语言》 Lab1</title>
      <link>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab1/</link>
      <pubDate>Mon, 13 Nov 2017 22:05:05 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/assemblylab1/</guid>
      <description>assume cs:codesg codesg segment mov ax,2000 mov ss,ax mov sp,0 add sp,10 pop ax pop bx push ax push bx pop ax pop bx move ax,4c00 int 21 codesg ends end </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pwaer.ink/blog/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pwaer.ink/blog/%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6/elasticsearch/</guid>
      <description>elasticsearch 文档创建和删除 创建和更新文档 官方提供的接口:
PUT /&amp;lt;target&amp;gt;/_doc/&amp;lt;_id&amp;gt; POST /&amp;lt;target&amp;gt;/_doc/ PUT /&amp;lt;target&amp;gt;/_create/&amp;lt;_id&amp;gt; POST /&amp;lt;target&amp;gt;/_create/&amp;lt;_id&amp;gt; 下面的例子利用PUT方法创建一个 id 为1的文档：
PUT /index-001/_doc/1 { &amp;#34;title&amp;#34;: &amp;#34;Elasticsearch: The Definitive Guide&amp;#34;, &amp;#34;authors&amp;#34;: [ &amp;#34;clinton gormley&amp;#34;, &amp;#34;zachary tong&amp;#34; ], &amp;#34;summary&amp;#34;: &amp;#34;A distibuted real-time search and analytics engine&amp;#34;, &amp;#34;publish_date&amp;#34;: &amp;#34;2015-02-07&amp;#34;, &amp;#34;num_reviews&amp;#34;: 20, &amp;#34;publisher&amp;#34;: &amp;#34;oreilly&amp;#34; } 响应结构为：
{ &amp;#34;_index&amp;#34; : &amp;#34;index-001&amp;#34;, &amp;#34;_type&amp;#34; : &amp;#34;_doc&amp;#34;, &amp;#34;_id&amp;#34; : &amp;#34;1&amp;#34;, &amp;#34;_version&amp;#34; : 1, &amp;#34;result&amp;#34; : &amp;#34;created&amp;#34;, &amp;#34;_shards&amp;#34; : { &amp;#34;total&amp;#34; : 2, &amp;#34;successful&amp;#34; : 1, &amp;#34;failed&amp;#34; : 0 }, &amp;#34;_seq_no&amp;#34; : 18, &amp;#34;_primary_term&amp;#34; : 1 } 其中，version字段为1，并且result的值为created。</description>
    </item>
    
  </channel>
</rss>
